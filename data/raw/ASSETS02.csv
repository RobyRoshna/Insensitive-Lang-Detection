Title,DOI,Abstract,BibTeX
From assistive technology to a web accessibility service,10.1145/638249.638253,"This paper considers different ways to enhance access to the World Wide Web for persons with sensory, cognitive, or motor limitations. Paradoxically, while complex Web architectures may seem to have inhibited accessibility, they have broadened the range of points where we can try to improve it. This paper identifies these points and evaluates the advantages and disadvantages of each. In particular, it describes a project to develop a strategy to enhance access that can be distributed across multiple control points and implemented as an aggregation of Web services.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Web services, World Wide Web, accessibility, adaptive interfaces', 'numpages': '5', 'pages': '4–8', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'This paper considers different ways to enhance access to the World Wide Web for persons with sensory, cognitive, or motor limitations. Paradoxically, while complex Web architectures may seem to have inhibited accessibility, they have broadened the range of points where we can try to improve it. This paper identifies these points and evaluates the advantages and disadvantages of each. In particular, it describes a project to develop a strategy to enhance access that can be distributed across multiple control points and implemented as an aggregation of Web services.', 'doi': '10.1145/638249.638253', 'url': 'https://doi.org/10.1145/638249.638253', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'From assistive technology to a web accessibility service', 'author': 'Fairweather, Peter G. and Hanson, Vicki L. and Detweiler, Sam R. and Schwerdtfeger, Richard S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638253'}"
Improving the accessibility of aurally rendered HTML tables,10.1145/638249.638254,"Current techniques employed to aurally render HTML tables often result in output that is very difficult for sight-impaired users to understand. This paper proposes TTPML, an XML-compliant markup language, which facilitates the generation of prose descriptions of tabular information. The markup language enables content creators to specify contextual reinforcement of, and linear navigation through, tabular information. The markup language may be applied to pre-existing Web content and is reusable across multiple tables. TTPML may be interpreted by origin servers, proxy servers, or browsers. We believe that our approach benefits sight-impaired users by improving accessibility to tabular information.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Web accessibility, XML, aural interfaces, tables', 'numpages': '8', 'pages': '9–16', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'Current techniques employed to aurally render HTML tables often result in output that is very difficult for sight-impaired users to understand. This paper proposes TTPML, an XML-compliant markup language, which facilitates the generation of prose descriptions of tabular information. The markup language enables content creators to specify contextual reinforcement of, and linear navigation through, tabular information. The markup language may be applied to pre-existing Web content and is reusable across multiple tables. TTPML may be interpreted by origin servers, proxy servers, or browsers. We believe that our approach benefits sight-impaired users by improving accessibility to tabular information.', 'doi': '10.1145/638249.638254', 'url': 'https://doi.org/10.1145/638249.638254', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Improving the accessibility of aurally rendered HTML tables', 'author': 'Filepp, Robert and Challenger, James and Rosu, Daniela', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638254'}"
Web accessibility for low bandwidth input,10.1145/638249.638255,"One of the first, most common, and most useful applications that today's computer users access is the World Wide Web (web). One population of users for whom the web is especially important is those with motor disabilities, because it may enable them to do things that they might not otherwise be able to do: shopping; getting an education; running a business. This is particularly important for low bandwidth users: users with such limited motor and speech that they can only produce one or two signals when communicating with a computer. We present requirements for low bandwidth web accessibility, and two tools that address these requirements. The first is a modified web browser, the second a proxy that modifies HTML. Both work without requiring web page authors to modify their pages.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'WWW, low bandwidth input, motor impairment, web proxy', 'numpages': '8', 'pages': '17–24', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""One of the first, most common, and most useful applications that today's computer users access is the World Wide Web (web). One population of users for whom the web is especially important is those with motor disabilities, because it may enable them to do things that they might not otherwise be able to do: shopping; getting an education; running a business. This is particularly important for low bandwidth users: users with such limited motor and speech that they can only produce one or two signals when communicating with a computer. We present requirements for low bandwidth web accessibility, and two tools that address these requirements. The first is a modified web browser, the second a proxy that modifies HTML. Both work without requiring web page authors to modify their pages."", 'doi': '10.1145/638249.638255', 'url': 'https://doi.org/10.1145/638249.638255', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Web accessibility for low bandwidth input', 'author': 'Mankoff, Jennifer and Dey, Anind and Batra, Udit and Moore, Melody', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638255'}"
"Navigation of HTML tables, frames, and XML fragments",10.1145/638249.638256,"In this paper, we provide a progress report on the development of technology to support the non-visual navigation of complex HTML and XML structures.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Web Accessibility, visually impaired users', 'numpages': '8', 'pages': '25–32', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'In this paper, we provide a progress report on the development of technology to support the non-visual navigation of complex HTML and XML structures.', 'doi': '10.1145/638249.638256', 'url': 'https://doi.org/10.1145/638249.638256', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Navigation of HTML tables, frames, and XML fragments', 'author': 'Pontelli, E. and Gillan, D. and Xiong, W. and Saad, E. and Gupta, G. and Karshmer, A. I.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638256'}"
Sketching images eyes-free: a grid-based dynamic drawing tool for the blind,10.1145/638249.638258,"In this paper we describe one method of transforming a mouse-based graphical user interface into a navigable, grid-based auditory interface. We also report the results of an experiment that tested the effectiveness of a drawing tool for the blind called IC2D that uses this interaction style. The experiment included eight visually impaired participants and eight blindfolded sighted participants. The results show that auditory interpretation of graphics is an effective interface technique for visually impaired users. Further, the experiment demonstrates that visually impaired users can develop meaningful drawings when given adequate technological support.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'IC2D, auditory user interfaces, drawing, graphical semantic enhancement, graphics, grid, visually impaired', 'numpages': '8', 'pages': '33–40', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'In this paper we describe one method of transforming a mouse-based graphical user interface into a navigable, grid-based auditory interface. We also report the results of an experiment that tested the effectiveness of a drawing tool for the blind called IC2D that uses this interaction style. The experiment included eight visually impaired participants and eight blindfolded sighted participants. The results show that auditory interpretation of graphics is an effective interface technique for visually impaired users. Further, the experiment demonstrates that visually impaired users can develop meaningful drawings when given adequate technological support.', 'doi': '10.1145/638249.638258', 'url': 'https://doi.org/10.1145/638249.638258', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Sketching images eyes-free: a grid-based dynamic drawing tool for the blind', 'author': 'Kamel, Hesham M. and Landay, James A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638258'}"
Design and implementation of virtual environments training of the visually impaire,10.1145/638249.638259,"This paper presents the virtual reality applications developed for the feasibility study tests of the EU funded IST project ENORASI. ENORASI aims at developing a highly interactive and extensible haptic VR training system that allows visually impaired people, especially those blind from birth, to study and interact with various virtual objects. A number of custom applications have been developed based on the interface provided by the CyberGrasp haptic device. Eight test categories were identified and corresponding tests were developed for each category. Twenty-six blind persons conducted the tests and the evaluation results have shown the degree of acceptance of the technology and the feasibility of the proposed approach.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'haptics, training, virtual environments, visually impaired', 'numpages': '8', 'pages': '41–48', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'This paper presents the virtual reality applications developed for the feasibility study tests of the EU funded IST project ENORASI. ENORASI aims at developing a highly interactive and extensible haptic VR training system that allows visually impaired people, especially those blind from birth, to study and interact with various virtual objects. A number of custom applications have been developed based on the interface provided by the CyberGrasp haptic device. Eight test categories were identified and corresponding tests were developed for each category. Twenty-six blind persons conducted the tests and the evaluation results have shown the degree of acceptance of the technology and the feasibility of the proposed approach.', 'doi': '10.1145/638249.638259', 'url': 'https://doi.org/10.1145/638249.638259', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Design and implementation of virtual environments training of the visually impaire', 'author': 'Tzovaras, D. and Nikolakis, G. and Fergadis, G. and Malasiotis, S. and Stavrakis, M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638259'}"
Multimodal feedback: establishing a performance baseline for improved access by individuals with visual impairments,10.1145/638249.638260,"Multimodal interfaces have the potential to enhance a user's overall performance, especially when one perceptual channel, such as vision, is compromised. This research investigated how unimodal, bimodal, and trimodal feedback affected the performance of fully sighted users. Limited research exists that investigates how fully sighted users react to multimodal feedback forms, and to-date even less research is available that has investigated how users with visual impairments respond to multiple forms of feedback. A complex direct manipulation task, consisting of a series search and selection drag-and-drop subtasks, was evaluated in this study. The multiple forms of feedback investigated were auditory, haptic and visual. Each form of feedback was tested alone and in combination. User performance was assessed through measures of workload time. Workload was measured objectively and subjectively, through the physiological measure of pupil diameter and a portion of the NASA Task Load Index (TLX) workload survey, respectively. Time was captured by a measure of how long it took to complete a particular element of the task. The results demonstrate that multimodal feedback improves the performance of fully sighted users and offers great potential to users with visual impairments. As a result, this study serves as a baseline to drive the research and development of effective feedback combinations to enhance performance for individuals with visual impairments.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'auditory, feedback, haptic, human-computer interaction, multimodal, visual, visual impairment', 'numpages': '8', 'pages': '49–56', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""Multimodal interfaces have the potential to enhance a user's overall performance, especially when one perceptual channel, such as vision, is compromised. This research investigated how unimodal, bimodal, and trimodal feedback affected the performance of fully sighted users. Limited research exists that investigates how fully sighted users react to multimodal feedback forms, and to-date even less research is available that has investigated how users with visual impairments respond to multiple forms of feedback. A complex direct manipulation task, consisting of a series search and selection drag-and-drop subtasks, was evaluated in this study. The multiple forms of feedback investigated were auditory, haptic and visual. Each form of feedback was tested alone and in combination. User performance was assessed through measures of workload time. Workload was measured objectively and subjectively, through the physiological measure of pupil diameter and a portion of the NASA Task Load Index (TLX) workload survey, respectively. Time was captured by a measure of how long it took to complete a particular element of the task. The results demonstrate that multimodal feedback improves the performance of fully sighted users and offers great potential to users with visual impairments. As a result, this study serves as a baseline to drive the research and development of effective feedback combinations to enhance performance for individuals with visual impairments."", 'doi': '10.1145/638249.638260', 'url': 'https://doi.org/10.1145/638249.638260', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Multimodal feedback: establishing a performance baseline for improved access by individuals with visual impairments', 'author': 'Vitense, Holly S. and Jacko, Julie A. and Emery, V. Kathlene', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638260'}"
Multimodal virtual reality versus printed medium in visualization for blind people,10.1145/638249.638261,"In this paper, we describe a study comparing the strengths of a multimodal Virtual Reality (VR) interface against traditional tactile diagrams in conveying information to visually impaired and blind people. The multimodal VR interface consists of a force feedback device (SensAble PHANTOM), synthesized speech and non-speech audio. Potential advantages of the VR technology are well known however its real usability in comparison with the conventional paper-based medium is seldom investigated. We have addressed this issue in our evaluation. The experimental results show benefits from using the multimodal approach in terms of more accurate information about the graphs obtained by users.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'assistive technology, haptics, human computer interaction, multimodal interface, virtual reality', 'numpages': '8', 'pages': '57–64', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'In this paper, we describe a study comparing the strengths of a multimodal Virtual Reality (VR) interface against traditional tactile diagrams in conveying information to visually impaired and blind people. The multimodal VR interface consists of a force feedback device (SensAble PHANTOM), synthesized speech and non-speech audio. Potential advantages of the VR technology are well known however its real usability in comparison with the conventional paper-based medium is seldom investigated. We have addressed this issue in our evaluation. The experimental results show benefits from using the multimodal approach in terms of more accurate information about the graphs obtained by users.', 'doi': '10.1145/638249.638261', 'url': 'https://doi.org/10.1145/638249.638261', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Multimodal virtual reality versus printed medium in visualization for blind people', 'author': 'Yu, Wai and Brewster, Stephen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638261'}"
Auditory and tactile interfaces for representing the visual effects on the web,10.1145/638249.638263,"In this paper, we describe auditory and tactile interfaces to represent visual effects nonvisually for blind users, allowing intuitive recognition of visual content that appears on the Web. This research examines how visual effects could be recognized by blind subjects using the senses of hearing and touch, aiming at integrating the results into a practical system in the future. As an initial step, two experiments were performed, one for sonification and tactilization of a page overview based on color-based fragmented groupings without speech, and one for sonification and tactilization of emphasized text based on analyzing rich text information with speech. The subjects could recognize visual representations presented by auditory and tactile interfaces throughout the experiment, and were conscious of the importance of the visual structures. We believe this shows our approach may be practical and available in the future.We will summarize our results and discuss what kind of information is suitable for each sense, as well as the next planned experiment and other future work.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'auditory interface, blind, nonvisual, sonification, tactile interface, tactilization', 'numpages': '8', 'pages': '65–72', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'In this paper, we describe auditory and tactile interfaces to represent visual effects nonvisually for blind users, allowing intuitive recognition of visual content that appears on the Web. This research examines how visual effects could be recognized by blind subjects using the senses of hearing and touch, aiming at integrating the results into a practical system in the future. As an initial step, two experiments were performed, one for sonification and tactilization of a page overview based on color-based fragmented groupings without speech, and one for sonification and tactilization of emphasized text based on analyzing rich text information with speech. The subjects could recognize visual representations presented by auditory and tactile interfaces throughout the experiment, and were conscious of the importance of the visual structures. We believe this shows our approach may be practical and available in the future.We will summarize our results and discuss what kind of information is suitable for each sense, as well as the next planned experiment and other future work.', 'doi': '10.1145/638249.638263', 'url': 'https://doi.org/10.1145/638249.638263', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Auditory and tactile interfaces for representing the visual effects on the web', 'author': 'Asakawa, Chieko and Takagi, Hironobu and Ino, Shuichi and Ifukube, Tohru', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638263'}"
"Planning, reasoning, and agents for non-visual navigation of tables and frames",10.1145/638249.638264,"In this paper we demonstrate how the DSL for Table navigation [16] can be reinterpreted in the context of an action theory [8]. We also show how this generalization provides the ability to carry out more complex tasks such as (i) allowing the user to describe the objective of his/her navigation as a goal and let automatic mechanisms (i.e., a planner) develop (part of) the navigation process; and (ii) allowing the semantic description to predefine not only complete navigation strategies (as in [16]) but also partial skeletons, making the remaining part of the navigation dependent on run-time factors, e.g., user's goals, specific aspects of the table's content, User's run-time decisions.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'agents, domain specific language, semantics navigation', 'numpages': '8', 'pages': '73–80', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""In this paper we demonstrate how the DSL for Table navigation [16] can be reinterpreted in the context of an action theory [8]. We also show how this generalization provides the ability to carry out more complex tasks such as (i) allowing the user to describe the objective of his/her navigation as a goal and let automatic mechanisms (i.e., a planner) develop (part of) the navigation process; and (ii) allowing the semantic description to predefine not only complete navigation strategies (as in [16]) but also partial skeletons, making the remaining part of the navigation dependent on run-time factors, e.g., user's goals, specific aspects of the table's content, User's run-time decisions."", 'doi': '10.1145/638249.638264', 'url': 'https://doi.org/10.1145/638249.638264', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Planning, reasoning, and agents for non-visual navigation of tables and frames', 'author': 'Pontelli, Enrico and Son, Tran Cao', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638264'}"
Site-wide annotation: reconstructing existing pages to be accessible,10.1145/638249.638265,"The Web has become a new information resource for the blind. However, Web accessibility is becoming worse, since page authors tend to care only for the visual appearance. We have developed an Accessibility Transcoding System to solve this problem. This system has the ability to transcode complete pages on annotated sites into totally accessible pages without changing the original pages. However, site-wide annotation authoring is an extremely tedious and time-consuming task. This prevented us from applying our transcoding system to a wide variety of sites. In order to overcome this difficulty, we developed a new algorithm, ""Dynamic Annotation Matching"". By utilizing this algorithm, our transcoding system can automatically determine appropriate annotations based on each page's layout. We also developed a site-wide annotation-authoring tool, ""Site Pattern Analyzer."" We evaluated the feasibility of creating site-wide annotations by using the algorithm and the tool, and report on our success here.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Web Accessibility, annotation, layout-based annotation matching, transcoding', 'numpages': '8', 'pages': '81–88', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'The Web has become a new information resource for the blind. However, Web accessibility is becoming worse, since page authors tend to care only for the visual appearance. We have developed an Accessibility Transcoding System to solve this problem. This system has the ability to transcode complete pages on annotated sites into totally accessible pages without changing the original pages. However, site-wide annotation authoring is an extremely tedious and time-consuming task. This prevented us from applying our transcoding system to a wide variety of sites. In order to overcome this difficulty, we developed a new algorithm, ""Dynamic Annotation Matching"". By utilizing this algorithm, our transcoding system can automatically determine appropriate annotations based on each page\'s layout. We also developed a site-wide annotation-authoring tool, ""Site Pattern Analyzer."" We evaluated the feasibility of creating site-wide annotations by using the algorithm and the tool, and report on our success here.', 'doi': '10.1145/638249.638265', 'url': 'https://doi.org/10.1145/638249.638265', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Site-wide annotation: reconstructing existing pages to be accessible', 'author': 'Takagi, Hironobu and Asakawa, Chieko and Fukuda, Kentarou and Maeda, Junji', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638265'}"
Using handhelds to help people with motor impairments,10.1145/638249.638266,"People with Muscular Dystrophy (MD) and certain other muscular and nervous system disorders lose their gross motor control while retaining fine motor control. The result is that they lose the ability to move their wrists and arms, and therefore their ability to operate a mouse and keyboard. However, they can often still use their fingers to control a pencil or stylus, and thus can use a handheld computer such as a Palm. We have developed software that allows the handheld to substitute for the mouse and keyboard of a PC, and tested it with four people (ages 10, 12, 27 and 53) with MD. The 12-year old had lost the ability to use a mouse and keyboard, but with our software, he was able to use the Palm to access email, the web and computer games. The 27-year-old reported that he found the Palm so much better that he was using it full-time instead of a keyboard and mouse. The other two subjects said that our software was much less tiring than using the conventional input devices, and enabled them to use computers for longer periods. We report the results of these case studies, and the adaptations made to our software for people with disabilities.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Muscular Dystrophy, Palm pilot, Pebbles, Personal Digital Assistants (PDAs), assistive technologies, disabilities, hand-held computers, handicapped', 'numpages': '8', 'pages': '89–96', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'People with Muscular Dystrophy (MD) and certain other muscular and nervous system disorders lose their gross motor control while retaining fine motor control. The result is that they lose the ability to move their wrists and arms, and therefore their ability to operate a mouse and keyboard. However, they can often still use their fingers to control a pencil or stylus, and thus can use a handheld computer such as a Palm. We have developed software that allows the handheld to substitute for the mouse and keyboard of a PC, and tested it with four people (ages 10, 12, 27 and 53) with MD. The 12-year old had lost the ability to use a mouse and keyboard, but with our software, he was able to use the Palm to access email, the web and computer games. The 27-year-old reported that he found the Palm so much better that he was using it full-time instead of a keyboard and mouse. The other two subjects said that our software was much less tiring than using the conventional input devices, and enabled them to use computers for longer periods. We report the results of these case studies, and the adaptations made to our software for people with disabilities.', 'doi': '10.1145/638249.638266', 'url': 'https://doi.org/10.1145/638249.638266', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Using handhelds to help people with motor impairments', 'author': 'Myers, Brad A. and Wobbrock, Jacob O. and Yang, Sunny and Yeung, Brian and Nichols, Jeffrey and Miller, Robert', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638266'}"
Ongoing investigation of the ways in which some of the problems encountered by some dyslexics can be alleviated using computer techniques,10.1145/638249.638268,"This paper describes the ongoing development of a highly configurable word processing environment developed using a pragmatic, obstacle-by-obstacle approach to alleviating some of the visual problems encountered by dyslexic computer users. The paper describes the current version of the software and the development methodology as well as the results of a pilot study which indicated that visual environment individually configured using the SeeWord software improved reading accuracy as well as subjectively rated reading comfort.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'configuration, dyslexia, user-centred design, word processing', 'numpages': '7', 'pages': '97–103', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'This paper describes the ongoing development of a highly configurable word processing environment developed using a pragmatic, obstacle-by-obstacle approach to alleviating some of the visual problems encountered by dyslexic computer users. The paper describes the current version of the software and the development methodology as well as the results of a pilot study which indicated that visual environment individually configured using the SeeWord software improved reading accuracy as well as subjectively rated reading comfort.', 'doi': '10.1145/638249.638268', 'url': 'https://doi.org/10.1145/638249.638268', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Ongoing investigation of the ways in which some of the problems encountered by some dyslexics can be alleviated using computer techniques', 'author': 'Dickinson, Anna and Gregor, Peter and Newell, Alan F.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638268'}"
Virtual environments for social skills training: the importance of scaffolding in practice,10.1145/638249.638269,"Virtual Environments (VE's) offer the potential for users to explore social situations and 'try out' different behaviour responses for a variety of simulates social interactions. One of the challenges for the VE developer is how to construct the VE to allow freedom of exploration and flexibility in interactive behaviour, without the risk of users deliberately or inadvertently missing important learning goals. Scaffolding embedded within the VE software can aid the user's learning in different contexts, such as individual, tutored or group learning situations. This paper describes two single-user VE scenarios that have been developed within the AS interactive project and presents observation results from initial trials conducted at a user school.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Virtual Environments, autism, scaffolding of learning, social skills training', 'numpages': '7', 'pages': '104–110', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""Virtual Environments (VE's) offer the potential for users to explore social situations and 'try out' different behaviour responses for a variety of simulates social interactions. One of the challenges for the VE developer is how to construct the VE to allow freedom of exploration and flexibility in interactive behaviour, without the risk of users deliberately or inadvertently missing important learning goals. Scaffolding embedded within the VE software can aid the user's learning in different contexts, such as individual, tutored or group learning situations. This paper describes two single-user VE scenarios that have been developed within the AS interactive project and presents observation results from initial trials conducted at a user school."", 'doi': '10.1145/638249.638269', 'url': 'https://doi.org/10.1145/638249.638269', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Virtual environments for social skills training: the importance of scaffolding in practice', 'author': 'Kerr, Steven J. and Neale, Helen R. and Cobb, Sue V. G.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638269'}"
Modeling educational software for people with disabilities: theory and practice,10.1145/638249.638270,"Interactive multimedia learning systems are not suitable for people with disabilities. They tend to propose interfaces which are not accessible for learners with vision or auditory disabilities. Modeling techniques are necessary to map real world experiences to virtual worlds by using 3D auditory representations of objects for blind people and visual representations for deaf people. In this paper we describe common aspects and differences in the process of modeling the real world for applications involving tests and evaluations of cognitive tasks with people with reduced visual or auditory cues. To validate our concepts, we examine two existing systems using them as examples: AudioDoom and Whisper. AudioDoom allows blind children to explore and interact with virtual worlds created with spatial sound. Whisper implements a workplace to help people with impaired auditory abilities to recognize speech errors. The new common model considers not only the representation of the real world as proposed by the system but also the modeling of the learner's knowledge about the virtual world. This can be used by the tutoring system to enable the learner to receive relevant feedback. Finally, we analyze the most important characteristics in developing systems by comparing and evaluating them and proposing some recommendations and guidelines.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'modeling methodologies, sensory disabilities, tutoring systems, user adapted interfaces', 'numpages': '8', 'pages': '111–118', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""Interactive multimedia learning systems are not suitable for people with disabilities. They tend to propose interfaces which are not accessible for learners with vision or auditory disabilities. Modeling techniques are necessary to map real world experiences to virtual worlds by using 3D auditory representations of objects for blind people and visual representations for deaf people. In this paper we describe common aspects and differences in the process of modeling the real world for applications involving tests and evaluations of cognitive tasks with people with reduced visual or auditory cues. To validate our concepts, we examine two existing systems using them as examples: AudioDoom and Whisper. AudioDoom allows blind children to explore and interact with virtual worlds created with spatial sound. Whisper implements a workplace to help people with impaired auditory abilities to recognize speech errors. The new common model considers not only the representation of the real world as proposed by the system but also the modeling of the learner's knowledge about the virtual world. This can be used by the tutoring system to enable the learner to receive relevant feedback. Finally, we analyze the most important characteristics in developing systems by comparing and evaluating them and proposing some recommendations and guidelines."", 'doi': '10.1145/638249.638270', 'url': 'https://doi.org/10.1145/638249.638270', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Modeling educational software for people with disabilities: theory and practice', 'author': ""Baloian, Nelson and Luther, Wolfram and S\\'{a}nchez, Jaime"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638270'}"
Zooming interfaces! enhancing the performance of eye controlled pointing devices,10.1145/638249.638272,"This paper quantifies the benefits and usability problems associated with eye-based pointing direct interaction on a standard graphical user interface. It shows where and how, with the addition of a second supporting modality, the typically poor performance and subjective assessment of eye-based pointing devices can be improved to match the performance of other assistive technology devices. It shows that target size is the overriding factor affecting device performance and that when target sizes are artificially increased by 'zooming in' on the interface under the control of a supporting modality then eye-based pointing becomes a viable and usable interaction methodology for people with high-level motor disabilities.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'assistive technology, eye-tracking, graphical user interfaces, pointing devices, zoom screen', 'numpages': '8', 'pages': '119–126', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""This paper quantifies the benefits and usability problems associated with eye-based pointing direct interaction on a standard graphical user interface. It shows where and how, with the addition of a second supporting modality, the typically poor performance and subjective assessment of eye-based pointing devices can be improved to match the performance of other assistive technology devices. It shows that target size is the overriding factor affecting device performance and that when target sizes are artificially increased by 'zooming in' on the interface under the control of a supporting modality then eye-based pointing becomes a viable and usable interaction methodology for people with high-level motor disabilities."", 'doi': '10.1145/638249.638272', 'url': 'https://doi.org/10.1145/638249.638272', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Zooming interfaces! enhancing the performance of eye controlled pointing devices', 'author': 'Bates, Richard and Istance, Howell', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638272'}"
"HaWCoS: the ""hands-free"" wheelchair control system",10.1145/638249.638273,"A system allowing to control an electrically powered wheelchair without using the hands is introduced. HaWCoS -- the ""Hands-free"" Wheelchair Control System -- relies upon muscle contractions as input signals. The working principle is as follows. The constant stream of EMG signals associated with any arbitrary muscle of the wheelchair driver is monitored and reduced to a stream of contraction events. The reduced stream affects an internal program state which is translated into appropriate commands understood by the wheelchair electronics. The feasibility of the proposed approach is illustrated by a prototypical implementation for a state-of-the-art wheelchair. Operating a HaWCoS-wheelchair requires extremely little effort, which makes the system suitable even for people suffering from very severe physical disabilities.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'EMG signal, electrical wheelchair, muscle control', 'numpages': '8', 'pages': '127–134', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'A system allowing to control an electrically powered wheelchair without using the hands is introduced. HaWCoS -- the ""Hands-free"" Wheelchair Control System -- relies upon muscle contractions as input signals. The working principle is as follows. The constant stream of EMG signals associated with any arbitrary muscle of the wheelchair driver is monitored and reduced to a stream of contraction events. The reduced stream affects an internal program state which is translated into appropriate commands understood by the wheelchair electronics. The feasibility of the proposed approach is illustrated by a prototypical implementation for a state-of-the-art wheelchair. Operating a HaWCoS-wheelchair requires extremely little effort, which makes the system suitable even for people suffering from very severe physical disabilities.', 'doi': '10.1145/638249.638273', 'url': 'https://doi.org/10.1145/638249.638273', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'HaWCoS: the ""hands-free"" wheelchair control system', 'author': 'Felzer, Torsten and Freisleben, Bernd', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638273'}"
Cursor measures for motion-impaired computer users,10.1145/638249.638274,"""Point and click"" interactions remain one of the key features of graphical user interfaces (GUIs). People with motion-impairments, however, can often have difficulty with accurate control of standard pointing devices. This paper discusses work that aims to reveal the nature of these difficulties through analyses that consider the cursor's path of movement. A range of potential cursor measures was applied, and a number of them were found to be significant in capturing the differences between able-bodied users and motion-impaired users, as well as the differences between a haptic force feedback condition and a control condition. cursor measures found in the literature, however, do not make up a comprehensive list, but provide a starting point for analysing cursor movements more completely. Six new cursor characteristics for motion-impaired users are introduced to capture aspects of cursor movement different from those already proposed.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'cursor studies, force feedback, motion-impaired users', 'numpages': '8', 'pages': '135–142', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': '""Point and click"" interactions remain one of the key features of graphical user interfaces (GUIs). People with motion-impairments, however, can often have difficulty with accurate control of standard pointing devices. This paper discusses work that aims to reveal the nature of these difficulties through analyses that consider the cursor\'s path of movement. A range of potential cursor measures was applied, and a number of them were found to be significant in capturing the differences between able-bodied users and motion-impaired users, as well as the differences between a haptic force feedback condition and a control condition. cursor measures found in the literature, however, do not make up a comprehensive list, but provide a starting point for analysing cursor movements more completely. Six new cursor characteristics for motion-impaired users are introduced to capture aspects of cursor movement different from those already proposed.', 'doi': '10.1145/638249.638274', 'url': 'https://doi.org/10.1145/638249.638274', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Cursor measures for motion-impaired computer users', 'author': 'Keates, Simeon and Hwang, Faustina and Langdon, Patrick and Clarkson, P. John and Robinson, Peter', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638274'}"
An invisible keyguard,10.1145/638249.638275,"Overlap errors, in which two keys are pressed down at once, are a common typing error for people with motor disabilities. Keyguards are a commonly suggested means to may reduce overlap errors. However, they are also unpopular with many users. We present an alternative to the keyguard, a software filter which targets overlap errors. Basic, keystroke timing-based, and language-based techniques for identifying and correcting overlap errors are described. Their performance is compared using a corpus of typing data recorded by keyboard users with motor disabilities. The best filter performance was obtained by keystroke timing characteristics to identify and filter out extra characters. Accuracy of error identification was dependent on the typing style of the user. The filter accurately corrected 80\% of the overlap errors presented. Combining the identification and correction techniques gave a 50--75\% reduction in errors for the three study participants with the highest error rates.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'OverlapKeys, accessibility, keyboard, keyguard, motor disabilities, typing errors', 'numpages': '7', 'pages': '143–149', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'Overlap errors, in which two keys are pressed down at once, are a common typing error for people with motor disabilities. Keyguards are a commonly suggested means to may reduce overlap errors. However, they are also unpopular with many users. We present an alternative to the keyguard, a software filter which targets overlap errors. Basic, keystroke timing-based, and language-based techniques for identifying and correcting overlap errors are described. Their performance is compared using a corpus of typing data recorded by keyboard users with motor disabilities. The best filter performance was obtained by keystroke timing characteristics to identify and filter out extra characters. Accuracy of error identification was dependent on the typing style of the user. The filter accurately corrected 80\\% of the overlap errors presented. Combining the identification and correction techniques gave a 50--75\\% reduction in errors for the three study participants with the highest error rates.', 'doi': '10.1145/638249.638275', 'url': 'https://doi.org/10.1145/638249.638275', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'An invisible keyguard', 'author': 'Trewin, Shari', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638275'}"
Designing for dynamic diversity: interfaces for older people,10.1145/638249.638277,"In this paper, we describe why designers need to look beyond the twin aims of designing for the 'typical' user and designing ""prostheses"". Making accessible interfaces for older people is a unique but many-faceted challenge. Effective applications and interface design needs to address the dynamic diversity of the human species. We introduce a new design paradigm, Design for Dynamic Diversity, and suggest a methodology to assist its achievement, User Sensitive Inclusive Design.To support our argument for a new form of design we report experimentation, which indicates that older people have significantly different and dynamically changing needs. We also put forward initial solutions for Designing for Dynamic Diversity, where memory, vision and confidence provide the parameters for discussion, and illustrate the importance of User Sensitive Inclusive Design in establishing a framework for the operation of Design for Dynamic Diversity.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Design for Dynamic Diversity, HCI, User Sensitive Inclusive Design, aging, design for all, older people, universal accessibility, usability engineering', 'numpages': '6', 'pages': '151–156', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'In this paper, we describe why designers need to look beyond the twin aims of designing for the \'typical\' user and designing ""prostheses"". Making accessible interfaces for older people is a unique but many-faceted challenge. Effective applications and interface design needs to address the dynamic diversity of the human species. We introduce a new design paradigm, Design for Dynamic Diversity, and suggest a methodology to assist its achievement, User Sensitive Inclusive Design.To support our argument for a new form of design we report experimentation, which indicates that older people have significantly different and dynamically changing needs. We also put forward initial solutions for Designing for Dynamic Diversity, where memory, vision and confidence provide the parameters for discussion, and illustrate the importance of User Sensitive Inclusive Design in establishing a framework for the operation of Design for Dynamic Diversity.', 'doi': '10.1145/638249.638277', 'url': 'https://doi.org/10.1145/638249.638277', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Designing for dynamic diversity: interfaces for older people', 'author': 'Gregor, Peter and Newell, Alan F. and Zajicek, Mary', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638277'}"
A novel multi-stage approach to the detection of visuo-spatial neglect based on the analysis of figure-copying tasks,10.1145/638249.638278,"This paper examines a computer-based technique for the detection of visuo-spatial neglect from the responses of a simple geometric shape copying task. Defining pass/fail criteria based on the presence of drawn components, responses can be accurately and objectively assessed. More importantly, we show that by analysing novel dynamic performance features detailing timing and constructional aspects of each response, significant performance deficits can be noted in drawings made by clinically diagnosed neglect subjects that would have been classified as 'normal' using conventional static analysis, thus improving the sensitivity of the assessment.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'automated diagnosis, drawing analysis, visuo-spatial neglect', 'numpages': '5', 'pages': '157–161', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""This paper examines a computer-based technique for the detection of visuo-spatial neglect from the responses of a simple geometric shape copying task. Defining pass/fail criteria based on the presence of drawn components, responses can be accurately and objectively assessed. More importantly, we show that by analysing novel dynamic performance features detailing timing and constructional aspects of each response, significant performance deficits can be noted in drawings made by clinically diagnosed neglect subjects that would have been classified as 'normal' using conventional static analysis, thus improving the sensitivity of the assessment."", 'doi': '10.1145/638249.638278', 'url': 'https://doi.org/10.1145/638249.638278', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'A novel multi-stage approach to the detection of visuo-spatial neglect based on the analysis of figure-copying tasks', 'author': 'Guest, R. M. and Fairhurst, M. C.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638278'}"
Assistive social interaction for non-speaking people living in the community,10.1145/638249.638279,"The move from institution to community care has resulted in more disabled and elderly people receiving care at home. For some, their disability or frailty prevents them from being involved in social activities outside the home, resulting in unacceptable social isolation. This problem is compounded if the person has a speech or language impairment. In general, social interaction is important for people, and they often use stories, pictures and other media to present important events to others, In this paper, we will describe a communication service designed to provide non-speaking people with a means to interact socially when living independently, based on the sharing of stories using pictures and other media.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Internet, assitive communication, community care, social isolation, videoconferencing', 'numpages': '8', 'pages': '162–169', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'The move from institution to community care has resulted in more disabled and elderly people receiving care at home. For some, their disability or frailty prevents them from being involved in social activities outside the home, resulting in unacceptable social isolation. This problem is compounded if the person has a speech or language impairment. In general, social interaction is important for people, and they often use stories, pictures and other media to present important events to others, In this paper, we will describe a communication service designed to provide non-speaking people with a means to interact socially when living independently, based on the sharing of stories using pictures and other media.', 'doi': '10.1145/638249.638279', 'url': 'https://doi.org/10.1145/638249.638279', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Assistive social interaction for non-speaking people living in the community', 'author': 'Hine, Nick and Arnott, John L.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638279'}"
Older adults' evaluations of speech output,10.1145/638249.638280,"Speech output is frequently used to provide access to interactive systems for visually impaired users, many of whom are older adults. This paper considers the use of speech output within the context of an Intelligent Home System designed to allow older adults to remain living independently for longer. The importance of user evaluations of the system 'voice' in this context is discussed and an experiment is reported that investigated the effect of voice gender and type (natural or synthetic) on older users' evaluations. A within-subjects factorial design was used with sixteen participants over the age of 65. The results show that male voices were preferred to female voices overall and natural voices were preferred to synthetic voices. The implications of these results for the choice of system voice characteristics for speech output are discussed.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'assistive technology, human-computer interaction, intelligent home systems., older adults, speech output, visual impairment', 'numpages': '8', 'pages': '170–177', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""Speech output is frequently used to provide access to interactive systems for visually impaired users, many of whom are older adults. This paper considers the use of speech output within the context of an Intelligent Home System designed to allow older adults to remain living independently for longer. The importance of user evaluations of the system 'voice' in this context is discussed and an experiment is reported that investigated the effect of voice gender and type (natural or synthetic) on older users' evaluations. A within-subjects factorial design was used with sixteen participants over the age of 65. The results show that male voices were preferred to female voices overall and natural voices were preferred to synthetic voices. The implications of these results for the choice of system voice characteristics for speech output are discussed."", 'doi': '10.1145/638249.638280', 'url': 'https://doi.org/10.1145/638249.638280', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': ""Older adults' evaluations of speech output"", 'author': 'Lines, Lorna and Hone, Kate S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638280'}"
Speech-based cursor control,10.1145/638249.638282,"Speech recognition can be a powerful tool for individuals with physical disabilities that hinder their ability to use traditional input devices. State-of-the-art speech recognition systems typically provide mechanisms for both data entry and cursor control, but the researchers continue to investigate methods of improving these interactions. Numerous researchers are investigating methods to improve the underlying technologies that make speech recognition possible and others focus on understanding the difficulties users experience using dictation-oriented applications, but few researchers have investigated the issues involved in speech-based cursor control. In this article, we describe a study that investigates the efficacy of two variations of a standard speech-based cursor control mechanism. One employs the standard mouse cursor while the second provides a predictive cursor designed to help users compensate for the delays often associated with speech recognition. As expected, larger targets and shorter distances resulted in shorter target selection times while larger targets also resulted in fewer errors. Although there were no differences between the standard and predictive cursors, a relationship between the delays associated with spoken input, the speed at which the cursor moves, and the minimum size for targets that can be reliably selected emerged that can guide the application of similar speech-based cursor control mechanisms as well as future research.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'cursor, mouse cursor, navigation, predictive, speech recognition', 'numpages': '8', 'pages': '178–185', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'Speech recognition can be a powerful tool for individuals with physical disabilities that hinder their ability to use traditional input devices. State-of-the-art speech recognition systems typically provide mechanisms for both data entry and cursor control, but the researchers continue to investigate methods of improving these interactions. Numerous researchers are investigating methods to improve the underlying technologies that make speech recognition possible and others focus on understanding the difficulties users experience using dictation-oriented applications, but few researchers have investigated the issues involved in speech-based cursor control. In this article, we describe a study that investigates the efficacy of two variations of a standard speech-based cursor control mechanism. One employs the standard mouse cursor while the second provides a predictive cursor designed to help users compensate for the delays often associated with speech recognition. As expected, larger targets and shorter distances resulted in shorter target selection times while larger targets also resulted in fewer errors. Although there were no differences between the standard and predictive cursors, a relationship between the delays associated with spoken input, the speed at which the cursor moves, and the minimum size for targets that can be reliably selected emerged that can guide the application of similar speech-based cursor control mechanisms as well as future research.', 'doi': '10.1145/638249.638282', 'url': 'https://doi.org/10.1145/638249.638282', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Speech-based cursor control', 'author': 'Karimullah, Azfar S. and Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638282'}"
A predictive Blissymbolic to English translation system,10.1145/638249.638283,This paper reports on the use of predictive techniques to translate Blissymbol sentences into grammatically correct English. Evaluations of this approach show that it is possible to translate short sentences by analysing the likelihood of word tri-gram occurrences in English source texts. The translation system is designed to be a component of a Blissymbol word processor which allows users to convert Blissymbol sentences into grammatically correct English.,"{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'AAC, Blissymbolics, natural language translation', 'numpages': '6', 'pages': '186–191', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'This paper reports on the use of predictive techniques to translate Blissymbol sentences into grammatically correct English. Evaluations of this approach show that it is possible to translate short sentences by analysing the likelihood of word tri-gram occurrences in English source texts. The translation system is designed to be a component of a Blissymbol word processor which allows users to convert Blissymbol sentences into grammatically correct English.', 'doi': '10.1145/638249.638283', 'url': 'https://doi.org/10.1145/638249.638283', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'A predictive Blissymbolic to English translation system', 'author': 'Waller, Annalu and Jack, Kris', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638283'}"
Speech recognition in university classrooms: liberated learning project,10.1145/638249.638284,"The LIBERATED LEARNING PROJECT (LLP) is an applied research project studying two core questions:1) Can speech recognition (SR) technology successfully digitize lectures to display spoken words as text in university classrooms?2) Can speech recognition technology be used successfully as an alternative to traditional classroom notetaking for persons with disabilities?This paper addresses these intriguing questions and explores the underlying complex relationship between speech recognition technology, university educational environments, and disability issues.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'accessibility, higher education, speech recognition', 'numpages': '5', 'pages': '192–196', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'The LIBERATED LEARNING PROJECT (LLP) is an applied research project studying two core questions:1) Can speech recognition (SR) technology successfully digitize lectures to display spoken words as text in university classrooms?2) Can speech recognition technology be used successfully as an alternative to traditional classroom notetaking for persons with disabilities?This paper addresses these intriguing questions and explores the underlying complex relationship between speech recognition technology, university educational environments, and disability issues.', 'doi': '10.1145/638249.638284', 'url': 'https://doi.org/10.1145/638249.638284', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Speech recognition in university classrooms: liberated learning project', 'author': 'Bain, Keith and Basson, Sara H. and Wald, Mike', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638284'}"
Voice over Workplace (VoWP): voice navigation in a complex business GUI,10.1145/638249.638285,"Voice interfaces can be used to meet some accessibility requirements for physically disabled users, but only if they address inherent usability problems, namely, the trade-off between user efficiency and ambiguity handling. This paper explores usability issues related to voice interfaces for complex GUIs. We present two user studies on a series of interface designs to support voice navigation within a complex business GUI, and discuss the findings as they relate to efficiency and ambiguity handling. We conclude by discussing future directions for this work, including the addition of data input capabilities, which will be necessary to provide a truly accessible solution.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'GUI, accessibility, physical disabilities, user studies, voice interface', 'numpages': '8', 'pages': '197–204', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'Voice interfaces can be used to meet some accessibility requirements for physically disabled users, but only if they address inherent usability problems, namely, the trade-off between user efficiency and ambiguity handling. This paper explores usability issues related to voice interfaces for complex GUIs. We present two user studies on a series of interface designs to support voice navigation within a complex business GUI, and discuss the findings as they relate to efficiency and ambiguity handling. We conclude by discussing future directions for this work, including the addition of data input capabilities, which will be necessary to provide a truly accessible solution.', 'doi': '10.1145/638249.638285', 'url': 'https://doi.org/10.1145/638249.638285', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Voice over Workplace (VoWP): voice navigation in a complex business GUI', 'author': 'James, Frankie and Roelands, Jeff', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638285'}"
"Tessa, a system to aid communication with deaf people",10.1145/638249.638287,"TESSA is an experimental system that aims to aid transactions between a deaf person and a clerk in a Post Office by translating the clerk's speech to sign language. A speech recogniser recognises speech from the clerk and the system then synthesizes the appropriate sequence of signs in British Sign language (BSL) using a specially-developed avatar. By using a phrase lookup approach to language translation, which is appropriate for the highly constrained discourse in a Post Office, we were able to build a working system that we could evaluate. We summarise the results of this evaluation (undertaken by deaf users and Post office clerks), and discuss how the findings from the evaluation are being used in the development of an improved system.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Aids for the Deaf, avatars, interactive systems, speech recognition, translation systems', 'numpages': '8', 'pages': '205–212', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""TESSA is an experimental system that aims to aid transactions between a deaf person and a clerk in a Post Office by translating the clerk's speech to sign language. A speech recogniser recognises speech from the clerk and the system then synthesizes the appropriate sequence of signs in British Sign language (BSL) using a specially-developed avatar. By using a phrase lookup approach to language translation, which is appropriate for the highly constrained discourse in a Post Office, we were able to build a working system that we could evaluate. We summarise the results of this evaluation (undertaken by deaf users and Post office clerks), and discuss how the findings from the evaluation are being used in the development of an improved system."", 'doi': '10.1145/638249.638287', 'url': 'https://doi.org/10.1145/638249.638287', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Tessa, a system to aid communication with deaf people', 'author': 'Cox, Stephen and Lincoln, Michael and Tryggvason, Judy and Nakisa, Melanie and Wells, Mark and Tutt, Marcus and Abbott, Sanja', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638287'}"
"Capturing phrases for ICU-Talk, a communication aid for intubated intensive care patients.",10.1145/638249.638288,"The need for intubated patients, within the intensive care setting, to communicate more effectively led to the development of ICU-Talk, an augmentative and alternative communication aid. The communication aid contains a database containing both core and patient-specific vocabulary. Many users of communication aids can provide direct input into the vocabulary, but intensive care patients are not in this position. This paper discusses the methods chosen to gather the vocabulary for an intensive care setting.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'AAC, ICU, communication, vocabulary', 'numpages': '5', 'pages': '213–217', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'The need for intubated patients, within the intensive care setting, to communicate more effectively led to the development of ICU-Talk, an augmentative and alternative communication aid. The communication aid contains a database containing both core and patient-specific vocabulary. Many users of communication aids can provide direct input into the vocabulary, but intensive care patients are not in this position. This paper discusses the methods chosen to gather the vocabulary for an intensive care setting.', 'doi': '10.1145/638249.638288', 'url': 'https://doi.org/10.1145/638249.638288', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'Capturing phrases for ICU-Talk, a communication aid for intubated intensive care patients.', 'author': 'Ashraf, S. and Judson, A. and Ricketts, I. W. and Waller, A. and Alm, N. and Gordon, B. and MacAulay, F. and Brodie, J. K. and Etchels, M. and Warden, A. and Shearer, A. J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638288'}"
A new generation of communication aids under the ULYSSES component-based framework,10.1145/638249.638289,"In this paper, we introduce a new generation of computer-based communication aids, designed and developed using state of the art software engineering models and architectures. The communicators we present are based on a component-based framework called ULYSSES that aims to simplify the integration of multi-vendor components into low cost products and maximizes modularity and reusability. Following the ULYSSES approach, one can build up powerful and reliable applications, adaptable to various user needs and requirements. For developers of AAC components, ULYSSES provides an engineering-for-reuse environment with guidelines and tools to build software modules, which can operate effectively and interact with each other transparently, without even being aware of each other's existence. Furthermore, ULYSSES grants a process of engineering-with-reuse for AAC system integrators for the selection and assembly of components on demand to build user-specific robust communicators out of pre-fabricated software parts. Thus, adding or removing characteristics and features as needed, is becoming an easy task for system AAC systems integrators. Three complete Interpersonal Communication Aids are presented as cases of ULYSSES application in this specific domain.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'Augmentative and Alternative Communication (AAC), communication aids, communicators, component based development, framework architecture', 'numpages': '8', 'pages': '218–225', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': ""In this paper, we introduce a new generation of computer-based communication aids, designed and developed using state of the art software engineering models and architectures. The communicators we present are based on a component-based framework called ULYSSES that aims to simplify the integration of multi-vendor components into low cost products and maximizes modularity and reusability. Following the ULYSSES approach, one can build up powerful and reliable applications, adaptable to various user needs and requirements. For developers of AAC components, ULYSSES provides an engineering-for-reuse environment with guidelines and tools to build software modules, which can operate effectively and interact with each other transparently, without even being aware of each other's existence. Furthermore, ULYSSES grants a process of engineering-with-reuse for AAC system integrators for the selection and assembly of components on demand to build user-specific robust communicators out of pre-fabricated software parts. Thus, adding or removing characteristics and features as needed, is becoming an easy task for system AAC systems integrators. Three complete Interpersonal Communication Aids are presented as cases of ULYSSES application in this specific domain."", 'doi': '10.1145/638249.638289', 'url': 'https://doi.org/10.1145/638249.638289', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'A new generation of communication aids under the ULYSSES component-based framework', 'author': 'Kouroupetroglou, Georgios and Pino, Alexandros', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638289'}"
"ICU-Talk, a communication aid for intubated intensive care patients",10.1145/638249.638290,"A Multi-disciplinary project staffed by personnel from nursing, computer science and speech and language therapy developed a computer based communication aid called ICU-Talk. This device has been designed specifically for intubated patients in hospital intensive care units. The ICU-Talk device was trialled with real patients. This paper reports the challenges faced when developing a device for this patient group and environment. A description of the methods used to produce ICU-Talk and results from the trials will be presented.","{'series': ""Assets '02"", 'location': 'Edinburgh, Scotland', 'keywords': 'AAC, HCI, ICU, communication, usability', 'numpages': '5', 'pages': '226–230', 'booktitle': 'Proceedings of the Fifth International ACM Conference on Assistive Technologies', 'abstract': 'A Multi-disciplinary project staffed by personnel from nursing, computer science and speech and language therapy developed a computer based communication aid called ICU-Talk. This device has been designed specifically for intubated patients in hospital intensive care units. The ICU-Talk device was trialled with real patients. This paper reports the challenges faced when developing a device for this patient group and environment. A description of the methods used to produce ICU-Talk and results from the trials will be presented.', 'doi': '10.1145/638249.638290', 'url': 'https://doi.org/10.1145/638249.638290', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581134649', 'year': '2002', 'title': 'ICU-Talk, a communication aid for intubated intensive care patients', 'author': 'MacAulay, F. and Judson, A. and Etchels, M. and Ashraf, S. and Ricketts, I. W. and Waller, A. and Brodie, J. K. and Alm, N. and Warden, A. and Shearer, A. J. and Gordon, B.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/638249.638290'}"