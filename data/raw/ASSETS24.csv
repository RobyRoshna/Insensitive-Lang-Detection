Title,DOI,Abstract,BibTeX
A Journey in Accessibility: Digital-World to Real-World,10.1145/3663548.3698037,"Progress in accessibility technology has dramatically improved the quality of life for people with disabilities. The SIGACCESS community has played a crucial role in this progress since its establishment in the late 1990s. This community connect researchers and share, with the world, innovative ideas based on the latest science and technology. My journey with SIGACCESS began in 1998, inspired by the technical challenges encountered during the development of the world's first practical voice web browser, the “IBM Home Page Reader”. This work later received the SIGACCESS ASSETS Paper Impact Award in 2013. After more than a decade of research in digital accessibility, I shifted my focus to a daunting, unsolved challenge: enabling independent movement in urban environments for people with visual impairments—the challenge of real-world accessibility. In this address, I will give a brief overview of my research in digital accessibility, look at my work on an autonomous navigation robot, the “AI suitcase”, and note the importance of social acceptance to successfully implement such new technology. I will then address the tremendous potential we SIGACCESS members possess, to practically apply the latest science and technology research, thereby steadily improving the quality of life for all people.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Braille, Indoor Navigation, Navigation Robot, Visual Impairments, Web Accessibility', 'numpages': '1', 'articleno': '1', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Progress in accessibility technology has dramatically improved the quality of life for people with disabilities. The SIGACCESS community has played a crucial role in this progress since its establishment in the late 1990s. This community connect researchers and share, with the world, innovative ideas based on the latest science and technology. My journey with SIGACCESS began in 1998, inspired by the technical challenges encountered during the development of the world's first practical voice web browser, the “IBM Home Page Reader”. This work later received the SIGACCESS ASSETS Paper Impact Award in 2013. After more than a decade of research in digital accessibility, I shifted my focus to a daunting, unsolved challenge: enabling independent movement in urban environments for people with visual impairments—the challenge of real-world accessibility. In this address, I will give a brief overview of my research in digital accessibility, look at my work on an autonomous navigation robot, the “AI suitcase”, and note the importance of social acceptance to successfully implement such new technology. I will then address the tremendous potential we SIGACCESS members possess, to practically apply the latest science and technology research, thereby steadily improving the quality of life for all people."", 'doi': '10.1145/3663548.3698037', 'url': 'https://doi.org/10.1145/3663548.3698037', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'A Journey in Accessibility: Digital-World to Real-World', 'author': 'Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3698037'}"
"""We Musicians Know How to Divide and Conquer"": Exploring Multimodal Interactions To Improve Music Reading and Memorization for Blind and Low Vision Learners",10.1145/3663548.3675604,"Despite the potential of multimodal assistive technologies (MATs) to convey visual information, such as music notation, to blind or low-vision (BLV) individuals, we do not fully understand how MATs can be used to improve music reading and memorization. Through ideation and co-design workshops, we explored how modalities, such as sound and vibration, can improve music reading and memorization through hands-free timely interactions and reminders. Our design workshops presented a unique opportunity for BLV musicians and learners to collaborate and actively engage in the research and design process informed by their individual perspectives and lived experiences. We classified the complex challenges of reading and memorizing music into intrinsic (related to the cognitive aspects of music understanding) and extraneous (pertaining to external factors such as interaction and access) complexities and found that specific modalities are well suited to tackle particular problems. We conclude by outlining design implications and future research directions aimed at developing MATs that holistically improve music learning for BLV people.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Blind and Low Vision Music Learning, Cognitive Load Theory, Multimodal Assistive Technologies, Music Reading and Memorization, Vibrotactile Feedback', 'numpages': '14', 'articleno': '2', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite the potential of multimodal assistive technologies (MATs) to convey visual information, such as music notation, to blind or low-vision (BLV) individuals, we do not fully understand how MATs can be used to improve music reading and memorization. Through ideation and co-design workshops, we explored how modalities, such as sound and vibration, can improve music reading and memorization through hands-free timely interactions and reminders. Our design workshops presented a unique opportunity for BLV musicians and learners to collaborate and actively engage in the research and design process informed by their individual perspectives and lived experiences. We classified the complex challenges of reading and memorizing music into intrinsic (related to the cognitive aspects of music understanding) and extraneous (pertaining to external factors such as interaction and access) complexities and found that specific modalities are well suited to tackle particular problems. We conclude by outlining design implications and future research directions aimed at developing MATs that holistically improve music learning for BLV people.', 'doi': '10.1145/3663548.3675604', 'url': 'https://doi.org/10.1145/3663548.3675604', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""We Musicians Know How to Divide and Conquer"": Exploring Multimodal Interactions To Improve Music Reading and Memorization for Blind and Low Vision Learners', 'author': 'Lu, Leon and Crispin, Chase and Girouard, Audrey', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675604'}"
Engaging with Children's Artwork in Mixed Visual-Ability Families,10.1145/3663548.3675613,"We present two studies exploring how blind or low-vision (BLV) family members engage with their sighted children’s artwork, strategies to support understanding and interpretation, and the potential role of technology, such as AI, therein. Our first study involved 14 BLV individuals, and the second included five groups of BLV individuals with their children. Through semi-structured interviews with AI descriptions of children’s artwork and multi-sensory design probes, we found that BLV family members value artwork engagement as a bonding opportunity, preferring the child’s storytelling and interpretation over other nonvisual representations. Additionally, despite some inaccuracies, BLV family members felt that AI-generated descriptions could facilitate dialogue with their children and aid self-guided art discovery. We close with specific design considerations for supporting artwork engagement in mixed visual-ability families, including enabling artwork access through various methods, supporting children’s corrections of AI output, and distinctions in context vs. content and interpretation vs. description of children’s artwork.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AI, Accessibility, blind or low-vision, children’s artwork, mixed-ability families', 'numpages': '19', 'articleno': '3', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present two studies exploring how blind or low-vision (BLV) family members engage with their sighted children’s artwork, strategies to support understanding and interpretation, and the potential role of technology, such as AI, therein. Our first study involved 14 BLV individuals, and the second included five groups of BLV individuals with their children. Through semi-structured interviews with AI descriptions of children’s artwork and multi-sensory design probes, we found that BLV family members value artwork engagement as a bonding opportunity, preferring the child’s storytelling and interpretation over other nonvisual representations. Additionally, despite some inaccuracies, BLV family members felt that AI-generated descriptions could facilitate dialogue with their children and aid self-guided art discovery. We close with specific design considerations for supporting artwork engagement in mixed visual-ability families, including enabling artwork access through various methods, supporting children’s corrections of AI output, and distinctions in context vs. content and interpretation vs. description of children’s artwork.', 'doi': '10.1145/3663548.3675613', 'url': 'https://doi.org/10.1145/3663548.3675613', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""Engaging with Children's Artwork in Mixed Visual-Ability Families"", 'author': 'Chheda-Kothary, Arnavi and Wobbrock, Jacob O. and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675613'}"
Beadwork Bridge: Understanding and Exploring the Opportunities of Beadwork in Enriching School Education for Blind and Low Vision (BLV) People,10.1145/3663548.3675623,"Tactile perception is a crucial channel for education in individuals with blindness and low vision (BLV), and beadwork is a low-cost and widely adopted tool in their educational practices. In this paper, we aim to explore what the field of Human-Computer Interaction (HCI) can learn from beadwork practices in relation to educational somatic experiences and tangible interaction. To understand how beadwork practices are enacted, we conducted in-class observations, semi-structured interviews, and focus groups with BLV students and teachers. Our results suggest that beadwork is an effective tool to foster personal development (e.g., mathematical and creativity skills) and social engagement (e.g., career development). Based on our findings, we offer insights into how beadwork can serve as a cost-effective material for HCI, particularly in the context of embodied cognition and soma design. Finally, we propose how state-of-the-art technology could be integrated to optimize the overall process.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Blind and low vision, beadwork, embodiment cognition, school education, soma design, tactile materials', 'numpages': '14', 'articleno': '4', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tactile perception is a crucial channel for education in individuals with blindness and low vision (BLV), and beadwork is a low-cost and widely adopted tool in their educational practices. In this paper, we aim to explore what the field of Human-Computer Interaction (HCI) can learn from beadwork practices in relation to educational somatic experiences and tangible interaction. To understand how beadwork practices are enacted, we conducted in-class observations, semi-structured interviews, and focus groups with BLV students and teachers. Our results suggest that beadwork is an effective tool to foster personal development (e.g., mathematical and creativity skills) and social engagement (e.g., career development). Based on our findings, we offer insights into how beadwork can serve as a cost-effective material for HCI, particularly in the context of embodied cognition and soma design. Finally, we propose how state-of-the-art technology could be integrated to optimize the overall process.', 'doi': '10.1145/3663548.3675623', 'url': 'https://doi.org/10.1145/3663548.3675623', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Beadwork Bridge: Understanding and Exploring the Opportunities of Beadwork in Enriching School Education for Blind and Low Vision (BLV) People', 'author': 'Zhang, Shumeng and Lin, Weiyue and Li, Zisu and Jiang, Ruiqi and Liang, Chen and Fan, Mingming and Masu, Raul', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675623'}"
Painting with Cameras and Drawing with Text: AI Use in Accessible Creativity,10.1145/3663548.3675644,"Generative AI (GAI) is proliferating, and among its many applications are to support creative work (e.g., generating text, images, music) and to enhance accessibility (e.g., captions of images and audio). As GAI evolves, creatives must consider how (or how not) to incorporate these tools into their practices. In this paper, we present interviews at the intersection of these applications. We learned from 10 creatives with disabilities who intentionally use and do not use GAI in and around their creative work. Their mediums ranged from audio engineering to leatherwork, and they collectively experienced a variety of disabilities, from sensory to motor to invisible disabilities. We share cross-cutting themes of their access hacks, how creative practice and access work become entangled, and their perspectives on how GAI should and should not fit into their workflows. In turn, we offer qualities of accessible creativity with responsible AI that can inform future research.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, creativity, disability, generative AI, responsible AI', 'numpages': '19', 'articleno': '5', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Generative AI (GAI) is proliferating, and among its many applications are to support creative work (e.g., generating text, images, music) and to enhance accessibility (e.g., captions of images and audio). As GAI evolves, creatives must consider how (or how not) to incorporate these tools into their practices. In this paper, we present interviews at the intersection of these applications. We learned from 10 creatives with disabilities who intentionally use and do not use GAI in and around their creative work. Their mediums ranged from audio engineering to leatherwork, and they collectively experienced a variety of disabilities, from sensory to motor to invisible disabilities. We share cross-cutting themes of their access hacks, how creative practice and access work become entangled, and their perspectives on how GAI should and should not fit into their workflows. In turn, we offer qualities of accessible creativity with responsible AI that can inform future research.', 'doi': '10.1145/3663548.3675644', 'url': 'https://doi.org/10.1145/3663548.3675644', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Painting with Cameras and Drawing with Text: AI Use in Accessible Creativity', 'author': 'Bennett, Cynthia L and Shelby, Renee and Rostamzadeh, Negar and Kane, Shaun K', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675644'}"
Towards Accessible Musical Performances in Virtual Reality: Designing a Conceptual Framework for Omnidirectional Audio Descriptions,10.1145/3663548.3675618,"Our research focuses on making musical performance experience in virtual reality (VR) settings non-visually accessible for Blind and Low Vision (BLV) individuals by designing a conceptual framework for omnidirectional audio descriptions (AD). We address BLV users’ prevalent challenges in accessing effective AD during VR musical performances. Employing a two-phased interview methodology, we initially collected qualitative data about BLV AD users’ experiences, followed by gathering insights from BLV professionals who specialize in AD. This approach ensures that the developed solutions are both user-centric and practically feasible. The study devises strategies for three design concepts of omnidirectional AD (Spatial AD, View-dependent AD, and Explorative AD) tailored to different types of musical performances, which vary in their visual and auditory components. Each design concept offers unique benefits; collectively, they enhance accessibility and enjoyment for BLV audiences by addressing specific user needs. Key insights highlight the crucial role of flexibility and user control in AD implementation. Based on these insights, we propose a comprehensive conceptual framework to enhance musical experiences for BLV users within VR environments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Audio Description, Blind and Low Vision Users, Musical Performances, Virtual Reality', 'numpages': '17', 'articleno': '6', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Our research focuses on making musical performance experience in virtual reality (VR) settings non-visually accessible for Blind and Low Vision (BLV) individuals by designing a conceptual framework for omnidirectional audio descriptions (AD). We address BLV users’ prevalent challenges in accessing effective AD during VR musical performances. Employing a two-phased interview methodology, we initially collected qualitative data about BLV AD users’ experiences, followed by gathering insights from BLV professionals who specialize in AD. This approach ensures that the developed solutions are both user-centric and practically feasible. The study devises strategies for three design concepts of omnidirectional AD (Spatial AD, View-dependent AD, and Explorative AD) tailored to different types of musical performances, which vary in their visual and auditory components. Each design concept offers unique benefits; collectively, they enhance accessibility and enjoyment for BLV audiences by addressing specific user needs. Key insights highlight the crucial role of flexibility and user control in AD implementation. Based on these insights, we propose a comprehensive conceptual framework to enhance musical experiences for BLV users within VR environments.', 'doi': '10.1145/3663548.3675618', 'url': 'https://doi.org/10.1145/3663548.3675618', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards Accessible Musical Performances in Virtual Reality: Designing a Conceptual Framework for Omnidirectional Audio Descriptions', 'author': 'Dang, Khang and Burke, Grace and Korreshi, Hamdi and Lee, Sooyeon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675618'}"
I tried everything. Nothing works: Challenges and Creative Processes from Digital Artists with Upper Limb Motor Impairments,10.1145/3663548.3675654,"Digital artists with motor impairments in their upper limbs face considerable barriers to accessibility when using drawing tools. Our work aims to investigate the complex relationship between digital artists’ creative processes and their accessibility challenges. We conducted 15 interviews with artists who use input devices to make digital art, analyzing their accessibility challenges for producing digital artwork. We reviewed how effective the solutions are in diminishing the impact on their creative processes and identifying design opportunities for the research community. Using thematic analysis, we look at the challenges participants reported in their artistic production, including managing pain, discomfort, and injuries alongside workarounds. Secondly, the artists reported the complexities of managing internal and external perceptions. Lastly, the ways creative processes are impacted by the accessibility challenges and solutions related to their upper limb motor impairments. We discuss research directions which can better address the impact of accessibility challenges on creative processes, the balance of creative agency over tools, and design insights for more accessible artistic technologies.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Digital Artists, Disability Art, Graphic Input Devices, People with Disabilities, Upper Limb Motor Impairment', 'numpages': '17', 'articleno': '7', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Digital artists with motor impairments in their upper limbs face considerable barriers to accessibility when using drawing tools. Our work aims to investigate the complex relationship between digital artists’ creative processes and their accessibility challenges. We conducted 15 interviews with artists who use input devices to make digital art, analyzing their accessibility challenges for producing digital artwork. We reviewed how effective the solutions are in diminishing the impact on their creative processes and identifying design opportunities for the research community. Using thematic analysis, we look at the challenges participants reported in their artistic production, including managing pain, discomfort, and injuries alongside workarounds. Secondly, the artists reported the complexities of managing internal and external perceptions. Lastly, the ways creative processes are impacted by the accessibility challenges and solutions related to their upper limb motor impairments. We discuss research directions which can better address the impact of accessibility challenges on creative processes, the balance of creative agency over tools, and design insights for more accessible artistic technologies.', 'doi': '10.1145/3663548.3675654', 'url': 'https://doi.org/10.1145/3663548.3675654', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'I tried everything. Nothing works: Challenges and Creative Processes from Digital Artists with Upper Limb Motor Impairments', 'author': 'Cossovich, Rodolfo and Wu, Shanel and Girouard, Audrey', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675654'}"
WheelPoser: Sparse-IMU Based Body Pose Estimation for Wheelchair Users,10.1145/3663548.3675638,"Despite researchers having extensively studied various ways to track body pose on-the-go, most prior work does not take into account wheelchair users, leading to poor tracking performance. Wheelchair users could greatly benefit from this pose information to prevent injuries, monitor their health, identify environmental accessibility barriers, and interact with gaming and VR experiences. In this work, we present WheelPoser, a real-time pose estimation system specifically designed for wheelchair users. Our system uses only four strategically placed IMUs on the user’s body and wheelchair, making it far more practical than prior systems using cameras and dense IMU arrays. WheelPoser is able to track a wheelchair user’s pose with a mean joint angle error of 14.30° and a mean joint position error of 6.74&nbsp;cm, more than three times better than similar systems using sparse IMUs. To train our system, we collect a novel WheelPoser-IMU dataset, consisting of 167 minutes of paired IMU sensor and motion capture data of people in wheelchairs, including wheelchair-specific motions such as propulsion and pressure relief. Finally, we explore the potential application space enabled by our system and discuss future opportunities. Open-source code, models, and dataset can be found here: https://github.com/axle-lab/WheelPoser.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Inertial Measurement Units, Motion Capture, Pose Estimation, Real-time, Wheelchair Users', 'numpages': '17', 'articleno': '8', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite researchers having extensively studied various ways to track body pose on-the-go, most prior work does not take into account wheelchair users, leading to poor tracking performance. Wheelchair users could greatly benefit from this pose information to prevent injuries, monitor their health, identify environmental accessibility barriers, and interact with gaming and VR experiences. In this work, we present WheelPoser, a real-time pose estimation system specifically designed for wheelchair users. Our system uses only four strategically placed IMUs on the user’s body and wheelchair, making it far more practical than prior systems using cameras and dense IMU arrays. WheelPoser is able to track a wheelchair user’s pose with a mean joint angle error of 14.30° and a mean joint position error of 6.74&nbsp;cm, more than three times better than similar systems using sparse IMUs. To train our system, we collect a novel WheelPoser-IMU dataset, consisting of 167 minutes of paired IMU sensor and motion capture data of people in wheelchairs, including wheelchair-specific motions such as propulsion and pressure relief. Finally, we explore the potential application space enabled by our system and discuss future opportunities. Open-source code, models, and dataset can be found here: https://github.com/axle-lab/WheelPoser.', 'doi': '10.1145/3663548.3675638', 'url': 'https://doi.org/10.1145/3663548.3675638', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'WheelPoser: Sparse-IMU Based Body Pose Estimation for Wheelchair Users', 'author': 'Li, Yunzhi and Mollyn, Vimal and Yuan, Kuang and Carrington, Patrick', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675638'}"
"SeaHare: An omidirectional electric wheelchair integrating independent, remote and shared control modalities",10.1145/3663548.3675657,"Depending on one’s needs electric wheelchairs can feature different interfaces and driving paradigms with control handed to the user, a remote pilot, or shared. However, these systems have generally been implemented on separate wheelchairs, making comparison difficult. We present the design of an omnidirectional electric wheelchair that can be controlled using two sensing seats detecting changes in the centre of gravity. One of the sensing seats is used by the person on the wheelchair, whereas the other is used as a remote control by a second person. We explore the use of the wheelchair using different control paradigms (independent, remote, and shared) from both the wheelchair and the remote control seat with 5 dyads and 1 triad of participants, including wheelchair users and non. Results highlight key advantages and disadvantages of the SeaHare in different paradigms, with participants’ perceptions affected by their skills and lived experiences, and reflections on how different control modes might suit different scenarios.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Center of gravity, Collaboration, Control modes, Disability, Remote Control, Shared control, Wheelchair', 'numpages': '16', 'articleno': '9', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Depending on one’s needs electric wheelchairs can feature different interfaces and driving paradigms with control handed to the user, a remote pilot, or shared. However, these systems have generally been implemented on separate wheelchairs, making comparison difficult. We present the design of an omnidirectional electric wheelchair that can be controlled using two sensing seats detecting changes in the centre of gravity. One of the sensing seats is used by the person on the wheelchair, whereas the other is used as a remote control by a second person. We explore the use of the wheelchair using different control paradigms (independent, remote, and shared) from both the wheelchair and the remote control seat with 5 dyads and 1 triad of participants, including wheelchair users and non. Results highlight key advantages and disadvantages of the SeaHare in different paradigms, with participants’ perceptions affected by their skills and lived experiences, and reflections on how different control modes might suit different scenarios.', 'doi': '10.1145/3663548.3675657', 'url': 'https://doi.org/10.1145/3663548.3675657', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'SeaHare: An omidirectional electric wheelchair integrating independent, remote and shared control modalities', 'author': 'Barbareschi, Giulia and Ryoichi, Ando and Kawaguchi, Midori and Takeda, Minato and Minamizawa, Kouta', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675657'}"
Co-Designing Programmable Fidgeting Experience with Swarm Robots for Adults with ADHD,10.1145/3663548.3675614,"Individuals with ADHD grapple with elevated stress levels, emotional regulation challenges, and difficulty sustaining focus. Fidgeting, a behavior traditionally frowned upon, has been shown to help people with ADHD in concentration, emotional and mental state management, and energy regulation. However, traditional fidgeting devices have limited fixed affordances providing cookie-cutter style fidgeting experience to all despite individual differences. Recognizing the uniqueness of individual fidgeting tendencies, we use small tabletop robots to provide a customizable fidgeting interaction experience and conduct co-design sessions with 16 adults diagnosed with ADHD to explore how they envision their fidgeting interactions being changed with these programmable robots. We examine core elements defining a successful fidgeting interaction with robots, assess the significance of customizability in these interactions and any common trends among participants, and investigate additional advantages that interactions with robots may offer. This research reveals nuanced preferences of adults with ADHD concerning robot-assisted fidgeting.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Adults with ADHD, Co-design, Programmable Fidgeting, Swarm Robots', 'numpages': '14', 'articleno': '10', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Individuals with ADHD grapple with elevated stress levels, emotional regulation challenges, and difficulty sustaining focus. Fidgeting, a behavior traditionally frowned upon, has been shown to help people with ADHD in concentration, emotional and mental state management, and energy regulation. However, traditional fidgeting devices have limited fixed affordances providing cookie-cutter style fidgeting experience to all despite individual differences. Recognizing the uniqueness of individual fidgeting tendencies, we use small tabletop robots to provide a customizable fidgeting interaction experience and conduct co-design sessions with 16 adults diagnosed with ADHD to explore how they envision their fidgeting interactions being changed with these programmable robots. We examine core elements defining a successful fidgeting interaction with robots, assess the significance of customizability in these interactions and any common trends among participants, and investigate additional advantages that interactions with robots may offer. This research reveals nuanced preferences of adults with ADHD concerning robot-assisted fidgeting.', 'doi': '10.1145/3663548.3675614', 'url': 'https://doi.org/10.1145/3663548.3675614', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Co-Designing Programmable Fidgeting Experience with Swarm Robots for Adults with ADHD', 'author': 'Pulatova, Samira and Kim, Lawrence H', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675614'}"
Co-designing Robot Dogs with and for Neurodivergent Individuals: Opportunities and Challenges,10.1145/3663548.3675603,"Social robots have been demonstrated to support neurodivergent individuals in health and educational settings, but the roles and benefits of social robots in the everyday lives of neurodivergent people are underexplored. We investigated daily-life use cases of robot dogs for neurodivergent individuals through three co-design workshops over five weeks. The workshops included interactions between neurodivergent participants and robot dogs, followed by feedback sessions. Participants showed high acceptance levels towards robot dogs and envisioned use cases that fulfilled practical, emotional, and social needs. Some participants associated robotic failures with rejection, leading us to further explore the impacts and communication of failures. Results showed how robot dogs can provide opportunities for users to be in a caregiving role and engage in interpersonal interactions. We conclude by discussing how to leverage the potential benefits of social robots by designing for social opportunities and ways to design failures to mitigate potential harms for users.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'neurodivergent, participatory design, social robotics', 'numpages': '15', 'articleno': '11', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social robots have been demonstrated to support neurodivergent individuals in health and educational settings, but the roles and benefits of social robots in the everyday lives of neurodivergent people are underexplored. We investigated daily-life use cases of robot dogs for neurodivergent individuals through three co-design workshops over five weeks. The workshops included interactions between neurodivergent participants and robot dogs, followed by feedback sessions. Participants showed high acceptance levels towards robot dogs and envisioned use cases that fulfilled practical, emotional, and social needs. Some participants associated robotic failures with rejection, leading us to further explore the impacts and communication of failures. Results showed how robot dogs can provide opportunities for users to be in a caregiving role and engage in interpersonal interactions. We conclude by discussing how to leverage the potential benefits of social robots by designing for social opportunities and ways to design failures to mitigate potential harms for users.', 'doi': '10.1145/3663548.3675603', 'url': 'https://doi.org/10.1145/3663548.3675603', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Co-designing Robot Dogs with and for Neurodivergent Individuals: Opportunities and Challenges', 'author': 'Kong, Ha-Kyung and Xie, Derek and Chandra, Ankith and Lowy, Rachel and Maignan, Arielle F and Ha, Sehoon and Park, Chung Hyuk and Kim, Jennifer G', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675603'}"
"Dude, Where's My Luggage? An Autoethnographic Account of Airport Navigation by a Traveler with Residual Vision",10.1145/3663548.3675624,"The ability to navigate independently through indoor spaces, like airports, is critical for people with visual impairments (PWVI). Yet, prior assistive technology (AT) research tends to decenter the needs of people with residual vision, who constitute the vast majority of PWVI. We conducted an autoethnography of a PWVI with residual vision across eight round-trips through six airports. We found that the physical and digital infrastructure of airports imbue assumptions of total sightedness, while assistive services assume total blindness, with little consideration for travelers with residual vision. We document how accessibility at points of interest is equally important to the navigability between them, suggesting that traditional turn-by-turn approaches may be insufficient for independent air travel by PWVI. Moreover, we argue that current airport and navigation AT design undermines the agency of travelers with residual vision; we call for development of a new class of navigation technologies that center the usable vision of PWVI.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Airport navigation, autoethnography, navigation systems for the visually impaired, public transit', 'numpages': '13', 'articleno': '12', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The ability to navigate independently through indoor spaces, like airports, is critical for people with visual impairments (PWVI). Yet, prior assistive technology (AT) research tends to decenter the needs of people with residual vision, who constitute the vast majority of PWVI. We conducted an autoethnography of a PWVI with residual vision across eight round-trips through six airports. We found that the physical and digital infrastructure of airports imbue assumptions of total sightedness, while assistive services assume total blindness, with little consideration for travelers with residual vision. We document how accessibility at points of interest is equally important to the navigability between them, suggesting that traditional turn-by-turn approaches may be insufficient for independent air travel by PWVI. Moreover, we argue that current airport and navigation AT design undermines the agency of travelers with residual vision; we call for development of a new class of navigation technologies that center the usable vision of PWVI.', 'doi': '10.1145/3663548.3675624', 'url': 'https://doi.org/10.1145/3663548.3675624', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""Dude, Where's My Luggage? An Autoethnographic Account of Airport Navigation by a Traveler with Residual Vision"", 'author': 'Cassidy, Cameron Tyler and Branham, Stacy Marie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675624'}"
Exploring Videoconferencing for Older Adults with Cognitive Concerns Using a Dramaturgical Lens,10.1145/3663548.3675647,"While videoconferencing is a promising technology, it may present unique challenges and barriers for older adults with cognitive concerns. This paper presents a deconstructed view of videoconferencing technology use using a sociological dramaturgical framework developed by Erving Goffman. Our study recruited 17 older adults with varying cognitive concerns, employing technology discussion groups, interviews, and observations to gather data. Through a reflexive thematic analysis, we explore videoconferencing use among older adults with cognitive concerns, focusing on three major areas: the ""performances and roles"" where users adapt to new roles through videoconferencing; the ""backstage,"" which involves the physical and logistical setup; and the ""frontstage,"" where people communicate through audio and visual channels to present a desired impression. Our discussion generates insights into how deconstructing these elements can inform more meaningful and accessible HCI design.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '13', 'articleno': '13', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'While videoconferencing is a promising technology, it may present unique challenges and barriers for older adults with cognitive concerns. This paper presents a deconstructed view of videoconferencing technology use using a sociological dramaturgical framework developed by Erving Goffman. Our study recruited 17 older adults with varying cognitive concerns, employing technology discussion groups, interviews, and observations to gather data. Through a reflexive thematic analysis, we explore videoconferencing use among older adults with cognitive concerns, focusing on three major areas: the ""performances and roles"" where users adapt to new roles through videoconferencing; the ""backstage,"" which involves the physical and logistical setup; and the ""frontstage,"" where people communicate through audio and visual channels to present a desired impression. Our discussion generates insights into how deconstructing these elements can inform more meaningful and accessible HCI design.', 'doi': '10.1145/3663548.3675647', 'url': 'https://doi.org/10.1145/3663548.3675647', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring Videoconferencing for Older Adults with Cognitive Concerns Using a Dramaturgical Lens', 'author': 'Hu, Ruipu and Gao, Ge and Lazar, Amanda', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675647'}"
Towards Construction-Oriented Play for Vision-Diverse People,10.1145/3663548.3675607,"Playful forms of construction, both analog and digital, enable players of all ages to build whatever they imagine. Engaging in construction-oriented play grants diverse people a wide range of benefits, such as enhanced collaborative problem solving, gains in spatial reasoning, and increases in demonstrated creativity. However, the inaccessibility of construction-oriented play, especially in the digital medium, precludes blind and low-vision players from these important benefits. In this work, we sought to understand how construction-oriented play affects blind players’ lives and the access challenges they face. Through semi-structured interviews with 17 participants aged 10 to 48, we found that construction-oriented play provides BLV individuals with socialization, cultural inclusion, and therapeutic benefits, fostering creativity and expression; however, vision-diverse players often rely on tactile references, sighted assistance, and/or customized game modifications to overcome accessibility challenges. We contribute a qualitative empirical understanding of how blind and low-vision people are interacting with digital and tangible construction media and discuss future directions for more accessible construction-oriented play.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind users, Crafting, Gaming', 'numpages': '12', 'articleno': '14', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Playful forms of construction, both analog and digital, enable players of all ages to build whatever they imagine. Engaging in construction-oriented play grants diverse people a wide range of benefits, such as enhanced collaborative problem solving, gains in spatial reasoning, and increases in demonstrated creativity. However, the inaccessibility of construction-oriented play, especially in the digital medium, precludes blind and low-vision players from these important benefits. In this work, we sought to understand how construction-oriented play affects blind players’ lives and the access challenges they face. Through semi-structured interviews with 17 participants aged 10 to 48, we found that construction-oriented play provides BLV individuals with socialization, cultural inclusion, and therapeutic benefits, fostering creativity and expression; however, vision-diverse players often rely on tactile references, sighted assistance, and/or customized game modifications to overcome accessibility challenges. We contribute a qualitative empirical understanding of how blind and low-vision people are interacting with digital and tangible construction media and discuss future directions for more accessible construction-oriented play.', 'doi': '10.1145/3663548.3675607', 'url': 'https://doi.org/10.1145/3663548.3675607', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards Construction-Oriented Play for Vision-Diverse People', 'author': 'Rodriguez, Adrian and Devasia, Nisha and Pei, Michelle and Kientz, Julie A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675607'}"
Low Vision Boxing: Participatory Design of Adaptive Kickboxing Experiences with Low Vision Person,10.1145/3663548.3675619,"Visually impaired individuals often face challenges related to physical inactivity, stemming from limited accessibility to sports activities. While assistive technologies and adaptive sports have made progress, high-intensity contact sports remain largely inaccessible. This paper presents an approach to improve the accessibility of kickboxing for visually impaired individuals. We prioritize simple, immediate solutions that maximize the use of residual vision, diverging from conventional assistive technologies that rely on auditory or tactile feedback. Employing a participatory design methodology, we involved visually impaired individuals throughout the development process of specialized kickboxing equipment. This approach enabled us to address user-specific needs and challenges directly. Our research contributes to expanding sports participation opportunities for the visually impaired and fostering a more inclusive sports environment. We detail the development process of our adaptive kickboxing equipment and discuss its effectiveness in enhancing the sports experience for visually impaired individuals.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Adaptive sports, Inclusive design, Kickboxing, Low vision, Participatory design, Visual impairment', 'numpages': '18', 'articleno': '15', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Visually impaired individuals often face challenges related to physical inactivity, stemming from limited accessibility to sports activities. While assistive technologies and adaptive sports have made progress, high-intensity contact sports remain largely inaccessible. This paper presents an approach to improve the accessibility of kickboxing for visually impaired individuals. We prioritize simple, immediate solutions that maximize the use of residual vision, diverging from conventional assistive technologies that rely on auditory or tactile feedback. Employing a participatory design methodology, we involved visually impaired individuals throughout the development process of specialized kickboxing equipment. This approach enabled us to address user-specific needs and challenges directly. Our research contributes to expanding sports participation opportunities for the visually impaired and fostering a more inclusive sports environment. We detail the development process of our adaptive kickboxing equipment and discuss its effectiveness in enhancing the sports experience for visually impaired individuals.', 'doi': '10.1145/3663548.3675619', 'url': 'https://doi.org/10.1145/3663548.3675619', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Low Vision Boxing: Participatory Design of Adaptive Kickboxing Experiences with Low Vision Person', 'author': 'Tsutsui, Ayaka and Yamamoto, Kenta and Zhao, Yinan and Suzuki, Ippei and Tanaka, Kengo and Ochiai, Yoichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675619'}"
Exploring The Affordances of Game-Aware Streaming to Support Blind and Low Vision Viewers: A Design Probe Study,10.1145/3663548.3675665,"This paper explores new ways to support blind and low vision (BLV) game stream participants. Prior work on game-aware streaming systems has focused on the potential for viewer interaction and personalization for sighted viewers, but how such systems impact interaction and personalization for BLV viewers remains largely unexplored. Most streaming experiences have significant visual information but no non-visual or sensemaking alternatives, which can exclude BLV viewers from understanding and interacting with the streaming experience. Building on the pre-existing system MARS, we developed a design probe that makes game data available to stream viewers in personalizable visual and non-visual formats. We use this probe to investigate the needs of BLV game stream viewers through qualitative interviews and live prototype testing sessions on Twitch. In addition to the technical contributions of our probe, our work addresses how game-aware streaming technologies can align with the needs and motivations of BLV viewers, and paves the way for novel designs in future iterations of game-aware streaming technologies.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind and Low Vision, Games Accessibility, Live Streaming, Twitch', 'numpages': '13', 'articleno': '16', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper explores new ways to support blind and low vision (BLV) game stream participants. Prior work on game-aware streaming systems has focused on the potential for viewer interaction and personalization for sighted viewers, but how such systems impact interaction and personalization for BLV viewers remains largely unexplored. Most streaming experiences have significant visual information but no non-visual or sensemaking alternatives, which can exclude BLV viewers from understanding and interacting with the streaming experience. Building on the pre-existing system MARS, we developed a design probe that makes game data available to stream viewers in personalizable visual and non-visual formats. We use this probe to investigate the needs of BLV game stream viewers through qualitative interviews and live prototype testing sessions on Twitch. In addition to the technical contributions of our probe, our work addresses how game-aware streaming technologies can align with the needs and motivations of BLV viewers, and paves the way for novel designs in future iterations of game-aware streaming technologies.', 'doi': '10.1145/3663548.3675665', 'url': 'https://doi.org/10.1145/3663548.3675665', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring The Affordances of Game-Aware Streaming to Support Blind and Low Vision Viewers: A Design Probe Study', 'author': 'Hammad, Noor and Elavsky, Frank and Moharana, Sanika and Chen, Jessie and Lee, Seyoung and Carrington, Patrick and Moritz, Dominik and Hammer, Jessica and Harpstead, Erik', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675665'}"
Inclusion as a Process: Co-Designing an Inclusive Robotic Game with Neurodiverse Classrooms,10.1145/3663548.3675664,"Neurodivergent children spend most of their time in neurodiverse schools alongside their neurotypical peers and often face social exclusion. Inclusive play activities are a strong vehicle of inclusion. Unfortunately, games designed for the specific needs of neurodiverse groups are scarce. Given the potential of robots to support play, we led a co-design process to build an inclusive robotic game for neurodiverse classrooms. We conducted five co-design workshops, engaging 80 children from neurodiverse classrooms in designing an inclusive game. Employing the resulting design insights, we iteratively prototyped and playtested a tabletop robotic game leveraging off-the-shelf robots. Reflecting upon our findings, we discuss how the longitudinal co-design process (rather than the resulting game) was key in allowing children the space to learn how to accommodate accessibility needs and create inclusive play experiences. We posit the use of co-design to enhance children’s interpersonal relationships, fosters feelings of ownership, and encourages appropriation practices as a strategy to sustain inclusive experiences that extend beyond project timelines or artefact designs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Children, Classrooms, Co-design, Games, Inclusion, Neurodivergent, Neurodiverse', 'numpages': '15', 'articleno': '17', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Neurodivergent children spend most of their time in neurodiverse schools alongside their neurotypical peers and often face social exclusion. Inclusive play activities are a strong vehicle of inclusion. Unfortunately, games designed for the specific needs of neurodiverse groups are scarce. Given the potential of robots to support play, we led a co-design process to build an inclusive robotic game for neurodiverse classrooms. We conducted five co-design workshops, engaging 80 children from neurodiverse classrooms in designing an inclusive game. Employing the resulting design insights, we iteratively prototyped and playtested a tabletop robotic game leveraging off-the-shelf robots. Reflecting upon our findings, we discuss how the longitudinal co-design process (rather than the resulting game) was key in allowing children the space to learn how to accommodate accessibility needs and create inclusive play experiences. We posit the use of co-design to enhance children’s interpersonal relationships, fosters feelings of ownership, and encourages appropriation practices as a strategy to sustain inclusive experiences that extend beyond project timelines or artefact designs.', 'doi': '10.1145/3663548.3675664', 'url': 'https://doi.org/10.1145/3663548.3675664', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Inclusion as a Process: Co-Designing an Inclusive Robotic Game with Neurodiverse Classrooms', 'author': 'Piedade, Patricia and Neto, Isabel and Pires, Ana Cristina and Prada, Rui and Nicolau, Hugo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675664'}"
Brain Body Jockey project: Transcending Bodily Limitations in Live Performance via Human Augmentation,10.1145/3663548.3675621,"Musicians with significant mobility limitations, face unique challenges in being able to use their bodies to interact with fans during live performances. In this paper we present the results of a collaboration between a professional DJ with advanced Amyotrophic Lateral Sclerosis and a group of technologists and researchers culminating in two public live performances leveraging human augmentation technologies to enhance the artist’s stage presence. Our system combines Brain Machine Interface, and accelerometer based trigger, to select pre-programmed moves performed by robotic arms during a live event, as well as for facilitating direct physical interaction during a “Meet the DJ” event. Our evaluation includes ethnographic observations and interviews with the artist and members of the audience. Results show that the system allowed artist and audience to feel a sense of unity, expanded the imagination of creative possibilities, and challenged conventional perceptions of disability in the arts and beyond.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ALS, BMI, DJ, Interaction, Robot Arm', 'numpages': '14', 'articleno': '18', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Musicians with significant mobility limitations, face unique challenges in being able to use their bodies to interact with fans during live performances. In this paper we present the results of a collaboration between a professional DJ with advanced Amyotrophic Lateral Sclerosis and a group of technologists and researchers culminating in two public live performances leveraging human augmentation technologies to enhance the artist’s stage presence. Our system combines Brain Machine Interface, and accelerometer based trigger, to select pre-programmed moves performed by robotic arms during a live event, as well as for facilitating direct physical interaction during a “Meet the DJ” event. Our evaluation includes ethnographic observations and interviews with the artist and members of the audience. Results show that the system allowed artist and audience to feel a sense of unity, expanded the imagination of creative possibilities, and challenged conventional perceptions of disability in the arts and beyond.', 'doi': '10.1145/3663548.3675621', 'url': 'https://doi.org/10.1145/3663548.3675621', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Brain Body Jockey project: Transcending Bodily Limitations in Live Performance via Human Augmentation', 'author': 'Barbareschi, Giulia and Zhou, Songchen and Ryoichi, Ando and Kawaguchi, Midori and Armstrong, Mark and Ogino, Mikito and Aoiki, Shunsuke and Ohta, Eisaku and Taguchi, Harunobu and Kamiyama, Youichi and Muto, Masatane and Yoshifuji, Kentaro and Minamizawa, Kouta', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675621'}"
From research participant to co-researcher: Chloe's story on co-designing inclusive technologies with people with intellectual disability,10.1145/3663548.3688541,"This experience report offers the perspective of the first author, Chloe, a woman with intellectual disability, on participation in technology co-design and her views of how technology, particularly social robots, can be designed for everyone’s benefit. The core of the report are quotes from Chloe in response to questions of the research team, with some context in terms of literature and background for her experiences. A short discussion contributed by the academic researcher authors reflects on relationship building throughout series of co-design research projects and highlights future directions for inclusive co-design research, the nuances between co-design research participants and co-researchers.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Inclusion, Intellectual Disabilities, Museums, Social Robots, User Experience', 'numpages': '6', 'articleno': '19', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This experience report offers the perspective of the first author, Chloe, a woman with intellectual disability, on participation in technology co-design and her views of how technology, particularly social robots, can be designed for everyone’s benefit. The core of the report are quotes from Chloe in response to questions of the research team, with some context in terms of literature and background for her experiences. A short discussion contributed by the academic researcher authors reflects on relationship building throughout series of co-design research projects and highlights future directions for inclusive co-design research, the nuances between co-design research participants and co-researchers.', 'doi': '10.1145/3663548.3688541', 'url': 'https://doi.org/10.1145/3663548.3688541', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""From research participant to co-researcher: Chloe's story on co-designing inclusive technologies with people with intellectual disability"", 'author': 'Haidenhofer, Choe and Sitbon, Laurianne and Beaumont, Chris P and Hoogstrate, Maria and Korte, Jessica L', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688541'}"
Accessible Nonverbal Cues to Support Conversations in VR for Blind and Low Vision People,10.1145/3663548.3675663,"Social VR has increased in popularity due to its affordances for rich, embodied, and nonverbal communication. However, nonverbal communication remains inaccessible for blind and low vision people in social VR. We designed accessible cues with audio and haptics to represent three nonverbal behaviors: eye contact, head shaking, and head nodding. We evaluated these cues in real-time conversation tasks where 16 blind and low vision participants conversed with two other users in VR. We found that the cues were effective in supporting conversations in VR. Participants had statistically significantly higher scores for accuracy and confidence in detecting attention during conversations with the cues than without. We also found that participants had a range of preferences and uses for the cues, such as learning social norms. We present design implications for handling additional cues in the future, such as the challenges of incorporating AI. Through this work, we take a step towards making interpersonal embodied interactions in VR fully accessible for blind and low vision people.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'VR, accessibility, blind, low vision', 'numpages': '13', 'articleno': '20', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social VR has increased in popularity due to its affordances for rich, embodied, and nonverbal communication. However, nonverbal communication remains inaccessible for blind and low vision people in social VR. We designed accessible cues with audio and haptics to represent three nonverbal behaviors: eye contact, head shaking, and head nodding. We evaluated these cues in real-time conversation tasks where 16 blind and low vision participants conversed with two other users in VR. We found that the cues were effective in supporting conversations in VR. Participants had statistically significantly higher scores for accuracy and confidence in detecting attention during conversations with the cues than without. We also found that participants had a range of preferences and uses for the cues, such as learning social norms. We present design implications for handling additional cues in the future, such as the challenges of incorporating AI. Through this work, we take a step towards making interpersonal embodied interactions in VR fully accessible for blind and low vision people.', 'doi': '10.1145/3663548.3675663', 'url': 'https://doi.org/10.1145/3663548.3675663', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Accessible Nonverbal Cues to Support Conversations in VR for Blind and Low Vision People', 'author': 'Jung, Crescentia and Collins, Jazmin and Gonzalez Penuela, Ricardo E. and Segal, Jonathan Isaac and Won, Andrea Stevenson and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675663'}"
From Information Seeking to Empowerment: Using Large Language Model Chatbot in Supporting Wheelchair Life in Low Resource Settings,10.1145/3663548.3675609,"To tackle the lack of wheelchair service information and training in low and middle-income countries (LMICs), we deployed Wheelpedia, a WhatsApp chatbot powered by a large language model (LLM) as a design probe for 2 months to concretely explore how it can support wheelchair users and professionals in Nigeria and Kenya. Through 18 semi-structured interviews and analysis of 471 messages, we focused on not only Wheelpedia's acceptability and usability but also how users orient themselves with the probe, integrate its information, and manage trust with it. The findings revealed participants' overwhelming enthusiasm towards the chatbot's potential in education, fostering empowerment, and reducing social stigma. We discuss challenges like users' difficulty in formulating questions, unfamiliarity with the concept of chatbots, and requests for image output. This paper contributes valuable insights into the design implications and research opportunities for deploying LLM chatbots in low-resourced settings with complex accessibility needs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '18', 'articleno': '21', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""To tackle the lack of wheelchair service information and training in low and middle-income countries (LMICs), we deployed Wheelpedia, a WhatsApp chatbot powered by a large language model (LLM) as a design probe for 2 months to concretely explore how it can support wheelchair users and professionals in Nigeria and Kenya. Through 18 semi-structured interviews and analysis of 471 messages, we focused on not only Wheelpedia's acceptability and usability but also how users orient themselves with the probe, integrate its information, and manage trust with it. The findings revealed participants' overwhelming enthusiasm towards the chatbot's potential in education, fostering empowerment, and reducing social stigma. We discuss challenges like users' difficulty in formulating questions, unfamiliarity with the concept of chatbots, and requests for image output. This paper contributes valuable insights into the design implications and research opportunities for deploying LLM chatbots in low-resourced settings with complex accessibility needs."", 'doi': '10.1145/3663548.3675609', 'url': 'https://doi.org/10.1145/3663548.3675609', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'From Information Seeking to Empowerment: Using Large Language Model Chatbot in Supporting Wheelchair Life in Low Resource Settings', 'author': 'Mo, Wen and Singh, Aneesha and Holloway, Catherine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675609'}"
EmoBridge: Bridging the Communication Gap between Students with Disabilities and Peer Note-Takers Utilizing Emojis and Real-Time Sharing,10.1145/3663548.3675629,"Students with disabilities (SWDs) often struggle with note-taking during lectures. Therefore, many higher education institutions have implemented peer note-taking programs (PNTPs), where peer note-takers (PNTs) assist SWDs in taking lecture notes. To better understand the experiences of SWDs and PNTs, we conducted semi-structured interviews with eight SWDs and eight PNTs. We found that the interaction between SWDs and PNTs was predominantly unidirectional, highlighting specific needs and challenges. In response, we developed EmoBridge, a collaborative note-taking platform that facilitates real-time collaboration and communication between PNT-SWD pairs using emojis. We evaluated EmoBridge through an in-the-wild study with seven PNT-SWD pairs. The results showed improved class participation for SWDs and a reduced sense of sole responsibility for PNTs. Based on these insights, we discuss design implications for collaborative note-taking systems aimed at enhancing PNTPs and fostering more effective and inclusive educational experiences for SWDs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Students with disabilities, collaborative note-taking, emoji, higher education, notetaking support, peer note-taking program, peer notetaker, student accessibility, university disability support', 'numpages': '18', 'articleno': '22', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Students with disabilities (SWDs) often struggle with note-taking during lectures. Therefore, many higher education institutions have implemented peer note-taking programs (PNTPs), where peer note-takers (PNTs) assist SWDs in taking lecture notes. To better understand the experiences of SWDs and PNTs, we conducted semi-structured interviews with eight SWDs and eight PNTs. We found that the interaction between SWDs and PNTs was predominantly unidirectional, highlighting specific needs and challenges. In response, we developed EmoBridge, a collaborative note-taking platform that facilitates real-time collaboration and communication between PNT-SWD pairs using emojis. We evaluated EmoBridge through an in-the-wild study with seven PNT-SWD pairs. The results showed improved class participation for SWDs and a reduced sense of sole responsibility for PNTs. Based on these insights, we discuss design implications for collaborative note-taking systems aimed at enhancing PNTPs and fostering more effective and inclusive educational experiences for SWDs.', 'doi': '10.1145/3663548.3675629', 'url': 'https://doi.org/10.1145/3663548.3675629', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'EmoBridge: Bridging the Communication Gap between Students with Disabilities and Peer Note-Takers Utilizing Emojis and Real-Time Sharing', 'author': 'Song, HyungWoo and Shin, Minjeong and Chu, Hyehyun and Hong, Jiin and Lee, Jaechan and Eun, Jinsu and Lim, Hajin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675629'}"
Envisioning Collective Communication Access: A Theoretically-Grounded Review of Captioning Literature from 2013-2023,10.1145/3663548.3675649,"A significant body of human-computer interaction accessibility research explores ways technology can improve communication access. Yet, this research infrequently engages other fields with complementary expertise – namely disability studies, Deaf studies, disability justice, and communication studies. To facilitate interdisciplinary communication access research, we synthesize thinking from these four fields into a framework of collective communication access. We then analyze human-centered accessibility-focused captioning research published between 2013 and 2023, investigating how collective communication access principles are or are not employed. We find that, while the majority of captioning research does not demonstrate a collective communication access approach, it reaches a baseline of targeting change toward inaccessible technical infrastructures and engaging d/Deaf and hard of hearing people as captioning experts. The small body of work that aligns with our framework, however, demonstrates that designing to change discriminatory social conditions and engaging conversation partners in access is a promising direction for future work.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Captioning, Collective Access, Communication Studies, Deaf Studies, Disability Justice, Disability Studies', 'numpages': '18', 'articleno': '23', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A significant body of human-computer interaction accessibility research explores ways technology can improve communication access. Yet, this research infrequently engages other fields with complementary expertise – namely disability studies, Deaf studies, disability justice, and communication studies. To facilitate interdisciplinary communication access research, we synthesize thinking from these four fields into a framework of collective communication access. We then analyze human-centered accessibility-focused captioning research published between 2013 and 2023, investigating how collective communication access principles are or are not employed. We find that, while the majority of captioning research does not demonstrate a collective communication access approach, it reaches a baseline of targeting change toward inaccessible technical infrastructures and engaging d/Deaf and hard of hearing people as captioning experts. The small body of work that aligns with our framework, however, demonstrates that designing to change discriminatory social conditions and engaging conversation partners in access is a promising direction for future work.', 'doi': '10.1145/3663548.3675649', 'url': 'https://doi.org/10.1145/3663548.3675649', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Envisioning Collective Communication Access: A Theoretically-Grounded Review of Captioning Literature from 2013-2023', 'author': 'McDonnell, Emma J and Findlater, Leah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675649'}"
TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users,10.1145/3663548.3675633,"Autistic individuals often experience difficulties in conveying and interpreting emotional tone and non-literal nuances. Many also mask1 their communication style to avoid being misconstrued by others, spending considerable time and mental effort in the process. To address these challenges in text-based communication, we present TwIPS2, a prototype texting application powered by a large language model (LLM), which can assist users with: a) deciphering tone and meaning of incoming messages, b) ensuring the emotional tone of their message is in line with their intent, and c) coming up with alternate phrasing for messages that could be misconstrued and received negatively by others. We leverage an AI-based simulation and a conversational script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our findings show TwIPS enables a convenient way for participants to seek clarifications, provides a better alternative to tone indicators, and facilitates constructive reflection on writing technique and style. We also examine how autistic users utilize language for self-expression and interpretation in instant messaging, and gather feedback for enhancing our prototype. We conclude with a discussion around balancing user-autonomy with AI-mediation, establishing appropriate trust levels in AI systems, and autistic users’ customization needs in the context of AI-assisted communication.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '18', 'articleno': '24', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Autistic individuals often experience difficulties in conveying and interpreting emotional tone and non-literal nuances. Many also mask1 their communication style to avoid being misconstrued by others, spending considerable time and mental effort in the process. To address these challenges in text-based communication, we present TwIPS2, a prototype texting application powered by a large language model (LLM), which can assist users with: a) deciphering tone and meaning of incoming messages, b) ensuring the emotional tone of their message is in line with their intent, and c) coming up with alternate phrasing for messages that could be misconstrued and received negatively by others. We leverage an AI-based simulation and a conversational script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our findings show TwIPS enables a convenient way for participants to seek clarifications, provides a better alternative to tone indicators, and facilitates constructive reflection on writing technique and style. We also examine how autistic users utilize language for self-expression and interpretation in instant messaging, and gather feedback for enhancing our prototype. We conclude with a discussion around balancing user-autonomy with AI-mediation, establishing appropriate trust levels in AI systems, and autistic users’ customization needs in the context of AI-assisted communication.', 'doi': '10.1145/3663548.3675633', 'url': 'https://doi.org/10.1145/3663548.3675633', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users', 'author': 'Haroon, Rukhshan and Dogar, Fahad', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675633'}"
"Adapting UX Research for People Living with Alzheimer's, Dementia, and MCI: Improving the UX Research Process for Participants",10.1145/3663548.3688542,"As the number of people living with Alzheimer's and other dementia rises, more technology targeted for this group of users is being developed. However, despite advances in remote user research and the benefits of technology to support the independence of people living with dementia, a small amount of information about UX Research with this audience is available. Though there are barriers to conducting user research with people living with dementia, creating technology that appropriately fits their needs is only possible by including them in the research. Conducting research with people living with dementia requires flexibility to ensure that participants’ needs are prioritized and the most actionable feedback is collected. This paper highlights some of the adaptations I make to traditional UX research practices when planning for, leading, and analyzing research with people living with Alzheimer's, other dementia, and Mild Cognitive Impairment (MCI).&nbsp;","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': ""Accessibility, Adapting UX research, Alzheimer's, Dementia, Mild Cognitive Impairment, User research"", 'numpages': '6', 'articleno': '25', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""As the number of people living with Alzheimer's and other dementia rises, more technology targeted for this group of users is being developed. However, despite advances in remote user research and the benefits of technology to support the independence of people living with dementia, a small amount of information about UX Research with this audience is available. Though there are barriers to conducting user research with people living with dementia, creating technology that appropriately fits their needs is only possible by including them in the research. Conducting research with people living with dementia requires flexibility to ensure that participants’ needs are prioritized and the most actionable feedback is collected. This paper highlights some of the adaptations I make to traditional UX research practices when planning for, leading, and analyzing research with people living with Alzheimer's, other dementia, and Mild Cognitive Impairment (MCI).&nbsp;"", 'doi': '10.1145/3663548.3688542', 'url': 'https://doi.org/10.1145/3663548.3688542', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""Adapting UX Research for People Living with Alzheimer's, Dementia, and MCI: Improving the UX Research Process for Participants"", 'author': 'Kleban, Krista D.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688542'}"
A Recipe for Success? Exploring Strategies for Improving Non-Visual Access to Cooking Instructions,10.1145/3663548.3675662,"Cooking is an essential activity that enhances quality of life by enabling individuals to prepare their own meals. However, cooking often requires multitasking between cooking tasks and following instructions, which can be challenging to cooks with vision impairments if recipes or other instructions are inaccessible. To explore the practices and challenges of recipe access while cooking, we conducted semi-structured interviews with 20 people with vision impairments who have cooking experience and four cooking instructors at a vision rehabilitation center. We also asked participants to edit and give feedback on existing recipes. We revealed unique practices and challenges to accessing recipe information at different cooking stages, such as the heavy burden of hand-washing to interact with recipe readers. We also presented the preferred information representation and structure of recipes. We then highlighted design features of technological supports that could facilitate the development of more accessible kitchen technologies for recipe access. Our work contributes nuanced insights and design guidelines to enhance recipe accessibility for people with vision impairments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Assistive Technology, Blind, Cooking, Recipes', 'numpages': '15', 'articleno': '26', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Cooking is an essential activity that enhances quality of life by enabling individuals to prepare their own meals. However, cooking often requires multitasking between cooking tasks and following instructions, which can be challenging to cooks with vision impairments if recipes or other instructions are inaccessible. To explore the practices and challenges of recipe access while cooking, we conducted semi-structured interviews with 20 people with vision impairments who have cooking experience and four cooking instructors at a vision rehabilitation center. We also asked participants to edit and give feedback on existing recipes. We revealed unique practices and challenges to accessing recipe information at different cooking stages, such as the heavy burden of hand-washing to interact with recipe readers. We also presented the preferred information representation and structure of recipes. We then highlighted design features of technological supports that could facilitate the development of more accessible kitchen technologies for recipe access. Our work contributes nuanced insights and design guidelines to enhance recipe accessibility for people with vision impairments.', 'doi': '10.1145/3663548.3675662', 'url': 'https://doi.org/10.1145/3663548.3675662', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'A Recipe for Success? Exploring Strategies for Improving Non-Visual Access to Cooking Instructions', 'author': 'Li, Franklin Mingzhe and Wang, Ashley and Carrington, Patrick and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675662'}"
"""It's an independent living skill, but covered with fun!"": Prompting At-Home Skill Development for Children with Vision Impairment",10.1145/3663548.3675626,"This study examined how to design tools that build independence with Blind or Visually Impaired (BVI) children and their families. Beyond core academics, BVI children require instruction on independent living skills, with their curriculum necessitating parent-school cooperation to support continued education at home. However, most technology for BVI children focus on academics, spatial orientation, and physical mobility. In this work, we aim to design a tool for independence that aligns with existing familial structures and activities. Through interviews and diary studies with five families, we explored development practices parents used with their BVI children, parent-teacher relationships, and how a prompting and reflection tool supported family goals. This study highlights home routines and independence skills that benefit from customized prompting, how activity prompts can encourage parents to scale back their assistance and propel independence, and how reflection builds optimism and empowers parents in the learning process.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'activity prompting, blind, collaboration, expanded core curriculum, independence, learning, parents, skill development, teachers, visual impairment', 'numpages': '14', 'articleno': '27', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study examined how to design tools that build independence with Blind or Visually Impaired (BVI) children and their families. Beyond core academics, BVI children require instruction on independent living skills, with their curriculum necessitating parent-school cooperation to support continued education at home. However, most technology for BVI children focus on academics, spatial orientation, and physical mobility. In this work, we aim to design a tool for independence that aligns with existing familial structures and activities. Through interviews and diary studies with five families, we explored development practices parents used with their BVI children, parent-teacher relationships, and how a prompting and reflection tool supported family goals. This study highlights home routines and independence skills that benefit from customized prompting, how activity prompts can encourage parents to scale back their assistance and propel independence, and how reflection builds optimism and empowers parents in the learning process.', 'doi': '10.1145/3663548.3675626', 'url': 'https://doi.org/10.1145/3663548.3675626', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""It\'s an independent living skill, but covered with fun!"": Prompting At-Home Skill Development for Children with Vision Impairment', 'author': 'Gadiraju, Vinitha and Jayne, Lucia and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675626'}"
Towards Designing Digital Learning Tools for Students with Cortical/Cerebral Visual Impairments: Leveraging Insights from Teachers of the Visually Impaired,10.1145/3663548.3675636,"Cortical/cerebral visual impairment (CVI) is a neurological vision impairment that affects the visual processing centers of the brain. Digital learning tools are becoming increasingly popular in schools, but limited research has examined how tools can help students with CVI, who have distinct academic needs. To better understand how tools should be designed to help students with CVI, we interviewed 20 U.S.-based Teachers of the Visually Impaired (TVIs) who worked with students with CVI. We found that our participants analyzed highly specific information about students’ visual, learning, social, and environmental needs to create accommodations for academic materials, most of which they created on their own. Participants shared design critiques of existing digital learning tools and felt that well-designed tools could save them time and improve learning opportunities for their students. We provide design considerations for tools that can be effectively used by students with CVI.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '18', 'articleno': '28', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Cortical/cerebral visual impairment (CVI) is a neurological vision impairment that affects the visual processing centers of the brain. Digital learning tools are becoming increasingly popular in schools, but limited research has examined how tools can help students with CVI, who have distinct academic needs. To better understand how tools should be designed to help students with CVI, we interviewed 20 U.S.-based Teachers of the Visually Impaired (TVIs) who worked with students with CVI. We found that our participants analyzed highly specific information about students’ visual, learning, social, and environmental needs to create accommodations for academic materials, most of which they created on their own. Participants shared design critiques of existing digital learning tools and felt that well-designed tools could save them time and improve learning opportunities for their students. We provide design considerations for tools that can be effectively used by students with CVI.', 'doi': '10.1145/3663548.3675636', 'url': 'https://doi.org/10.1145/3663548.3675636', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards Designing Digital Learning Tools for Students with Cortical/Cerebral Visual Impairments: Leveraging Insights from Teachers of the Visually Impaired', 'author': 'Smolansky, Adele and Yang, Miranda and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675636'}"
Scaffolding Digital Literacy Through Digital Skills Training for Disabled People in the Global South,10.1145/3663548.3675666,"Digital inclusion is essential for attaining the United Nations’ Sustainable Development Goals and for ensuring no one is left behind. In low-and-middle countries (LMICs), people lack the digital skills to access good-quality employment opportunities. It has been shown in other contexts that scaffolding the learning of digital skills can enhance people’s attainment of digital skills; specifically, these interventions target increasing the zones of actual development and independent action. However, to date, fewer studies have looked specifically at the role of digital skills training via smartphones for blind and partially sighted and deaf and hard-of-hearing people in LMICs. We conducted classroom-based training and peer learning through WhatsApp groups for 138 people in India and Kenya. Our findings emphasize the role of inclusive scaffolding and instructional and community-based peer learning. As such, we present a new digital scaffolding framework for inclusive instructional and peer learning, extending Vygotsky’s Scaffolding Theory.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'LMIC, digital skills, hearing impairment, scaffolding, visual impairment', 'numpages': '14', 'articleno': '29', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Digital inclusion is essential for attaining the United Nations’ Sustainable Development Goals and for ensuring no one is left behind. In low-and-middle countries (LMICs), people lack the digital skills to access good-quality employment opportunities. It has been shown in other contexts that scaffolding the learning of digital skills can enhance people’s attainment of digital skills; specifically, these interventions target increasing the zones of actual development and independent action. However, to date, fewer studies have looked specifically at the role of digital skills training via smartphones for blind and partially sighted and deaf and hard-of-hearing people in LMICs. We conducted classroom-based training and peer learning through WhatsApp groups for 138 people in India and Kenya. Our findings emphasize the role of inclusive scaffolding and instructional and community-based peer learning. As such, we present a new digital scaffolding framework for inclusive instructional and peer learning, extending Vygotsky’s Scaffolding Theory.', 'doi': '10.1145/3663548.3675666', 'url': 'https://doi.org/10.1145/3663548.3675666', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Scaffolding Digital Literacy Through Digital Skills Training for Disabled People in the Global South', 'author': 'Gunupudi, Laxmi and Bandukda, Maryam and Barbareschi, Giulia and Bhatnagar, Tigmanshu and Singh, Aanchal and Mishra, Satish and Prakash, Amit and Holloway, Catherine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675666'}"
Not a “Typical Expat”: An Autoethnographic Account on Accessible Relocation,10.1145/3663548.3688546,"In this experience report, we report on the first author’s recent personal experience of relocation from Turkey to Germany as a postdoctoral researcher with a mobility disability. Here, we outline the details of the relocation process in three phases. In each phase, we share reflections on the relocation experience specifically outlining accessibility challenges. We focus on customizing existing and new access needs, dealing with language barriers as a blocker for interpersonal accessibility, but also discuss digital access, and visibility of access information in relation to connecting with local disabled communities. We refine our insights into lessons learnt from this process, outlining implications for policy makers, researchers and designers, academic community, as well as for the disabled community. Through this autoethnographic experience report, we aim to open a space to critically rethink accessibility on the move and the role of technology, specifically in the context of relocation.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, autoethnography, disabled expat, relocation', 'numpages': '6', 'articleno': '30', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this experience report, we report on the first author’s recent personal experience of relocation from Turkey to Germany as a postdoctoral researcher with a mobility disability. Here, we outline the details of the relocation process in three phases. In each phase, we share reflections on the relocation experience specifically outlining accessibility challenges. We focus on customizing existing and new access needs, dealing with language barriers as a blocker for interpersonal accessibility, but also discuss digital access, and visibility of access information in relation to connecting with local disabled communities. We refine our insights into lessons learnt from this process, outlining implications for policy makers, researchers and designers, academic community, as well as for the disabled community. Through this autoethnographic experience report, we aim to open a space to critically rethink accessibility on the move and the role of technology, specifically in the context of relocation.', 'doi': '10.1145/3663548.3688546', 'url': 'https://doi.org/10.1145/3663548.3688546', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Not a “Typical Expat”: An Autoethnographic Account on Accessible Relocation', 'author': 'Yildiz, Zeynep and Karmann, Caroline and Gerling, Kathrin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688546'}"
SoundHapticVR: Head-Based Spatial Haptic Feedback for Accessible Sounds in Virtual Reality for Deaf and Hard of Hearing Users,10.1145/3663548.3675639,"Virtual Reality (VR) systems use immersive spatial audio to convey critical information, but these audio cues are often inaccessible to Deaf or Hard-of-Hearing (DHH) individuals. To address this, we developed SoundHapticVR, a head-based haptic system that converts audio signals into haptic feedback using multi-channel acoustic haptic actuators. We evaluated SoundHapticVR through three studies: determining the maximum tactile frequency threshold on different head regions for DHH users, identifying the ideal number and arrangement of transducers for sound localization, and assessing participants’ ability to differentiate sound sources with haptic patterns. Findings indicate that tactile perception thresholds vary across head regions, necessitating consistent frequency equalization. Adding a front transducer significantly improved sound localization, and participants could correlate distinct haptic patterns with specific objects. Overall, this system has the potential to make VR applications more accessible to DHH users.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Audio Accessibility, Deaf and Hard of Hearing, Haptics, Sound Localization, Virtual Reality', 'numpages': '17', 'articleno': '31', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Virtual Reality (VR) systems use immersive spatial audio to convey critical information, but these audio cues are often inaccessible to Deaf or Hard-of-Hearing (DHH) individuals. To address this, we developed SoundHapticVR, a head-based haptic system that converts audio signals into haptic feedback using multi-channel acoustic haptic actuators. We evaluated SoundHapticVR through three studies: determining the maximum tactile frequency threshold on different head regions for DHH users, identifying the ideal number and arrangement of transducers for sound localization, and assessing participants’ ability to differentiate sound sources with haptic patterns. Findings indicate that tactile perception thresholds vary across head regions, necessitating consistent frequency equalization. Adding a front transducer significantly improved sound localization, and participants could correlate distinct haptic patterns with specific objects. Overall, this system has the potential to make VR applications more accessible to DHH users.', 'doi': '10.1145/3663548.3675639', 'url': 'https://doi.org/10.1145/3663548.3675639', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'SoundHapticVR: Head-Based Spatial Haptic Feedback for Accessible Sounds in Virtual Reality for Deaf and Hard of Hearing Users', 'author': 'Chelladurai, Pratheep Kumar and Li, Ziming and Weber, Maximilian and Oh, Tae and Peiris, Roshan L', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675639'}"
Accessibility through Awareness of Noise Sensitivity Management and Regulation Practices,10.1145/3663548.3675630,"Noise sensitivity results in a range of experiences, from small annoyances to extreme pain in response to sound. While anyone can experience it, many neurodivergent people report this sensory processing challenge. Novel technologies can help people with noise sensitivity (PWNS) manage their sensitivities. We conducted an interview study with 21 PWNS and 9 caregivers over three months to understand their management and regulation practices and opportunities for technology-mediated support. We found that awareness is a salient factor that influences both management and regulation practices. Based on their awareness, people primarily use avoidance and sound masking approaches or engage in personal coping strategies such as journaling, setting boundaries, and alerting others to regulate. We build on prior research on interdependence, mutual care, and collaborative work to situate the concept of joint awareness to foster collaborative management and regulation for noise sensitivity. Then, we discuss the role of awareness in noise sensitivity management and regulation and provide design principles for the creation of future technology to support noise sensitivity awareness, management, and regulation.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Assistive Technology, Awareness, Collaborative Management, Interdependence, Noise Sensitivity, Self-Regulation', 'numpages': '12', 'articleno': '32', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Noise sensitivity results in a range of experiences, from small annoyances to extreme pain in response to sound. While anyone can experience it, many neurodivergent people report this sensory processing challenge. Novel technologies can help people with noise sensitivity (PWNS) manage their sensitivities. We conducted an interview study with 21 PWNS and 9 caregivers over three months to understand their management and regulation practices and opportunities for technology-mediated support. We found that awareness is a salient factor that influences both management and regulation practices. Based on their awareness, people primarily use avoidance and sound masking approaches or engage in personal coping strategies such as journaling, setting boundaries, and alerting others to regulate. We build on prior research on interdependence, mutual care, and collaborative work to situate the concept of joint awareness to foster collaborative management and regulation for noise sensitivity. Then, we discuss the role of awareness in noise sensitivity management and regulation and provide design principles for the creation of future technology to support noise sensitivity awareness, management, and regulation.', 'doi': '10.1145/3663548.3675630', 'url': 'https://doi.org/10.1145/3663548.3675630', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Accessibility through Awareness of Noise Sensitivity Management and Regulation Practices', 'author': 'Dotch, Emani and Mavrovounioti, Avery and Du, Weijie and Ankrah, Elizabeth and Johnson, Jazette and Min, Aehong and Hayes, Gillian R', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675630'}"
MaskSound: Exploring Sound Masking Approaches to Support People with Autism in Managing Noise Sensitivity,10.1145/3663548.3675656,"Noise sensitivity is a frequently reported characteristic in many autistic individuals. While strategies like sound isolation (e.g., noise-canceling headphones) and avoidance behaviors (e.g., leaving a crowded room) can help, they can reduce situational awareness and limit social engagement. In this paper, we examine an alternate approach to managing noise sensitivity: introducing ambient background sounds to reduce the perception of disruptive noises, i.e., sound masking. Through two studies (with ten and nine autistic individuals respectively), we investigated the autistic individuals’ preferred sound masks (e.g., white noise, brown noise, calming water sounds) for different contexts (e.g., traffic, speech) and elicited reactions for a future interactive tool to deliver effective sound masks. Our findings have implications not just for the accessibility community, but also for designers and researchers working on sound augmentation technology.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '12', 'articleno': '33', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Noise sensitivity is a frequently reported characteristic in many autistic individuals. While strategies like sound isolation (e.g., noise-canceling headphones) and avoidance behaviors (e.g., leaving a crowded room) can help, they can reduce situational awareness and limit social engagement. In this paper, we examine an alternate approach to managing noise sensitivity: introducing ambient background sounds to reduce the perception of disruptive noises, i.e., sound masking. Through two studies (with ten and nine autistic individuals respectively), we investigated the autistic individuals’ preferred sound masks (e.g., white noise, brown noise, calming water sounds) for different contexts (e.g., traffic, speech) and elicited reactions for a future interactive tool to deliver effective sound masks. Our findings have implications not just for the accessibility community, but also for designers and researchers working on sound augmentation technology.', 'doi': '10.1145/3663548.3675656', 'url': 'https://doi.org/10.1145/3663548.3675656', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'MaskSound: Exploring Sound Masking Approaches to Support People with Autism in Managing Noise Sensitivity', 'author': 'Park, Anna Y and Jin, Andy and Huang, Jeremy Zhengqi and Carr, Jesse and Jain, Dhruv', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675656'}"
SoundModVR: Sound Modifications in Virtual Reality to Support People who are Deaf and Hard of Hearing,10.1145/3663548.3675653,"Previous VR sound accessibility work substituted sounds with visual or haptic output to increase VR accessibility for deaf and hard of hearing (DHH) people. However, deafness occurs on a spectrum, and many DHH people (e.g., those with partial hearing) can also benefit greatly from having more control over the audio instead of substituting it with another modality. In this paper, we explore the possibilities of modifying sounds in VR to support DHH people. To understand the best modification features for this goal, we designed and implemented 18 VR sound modification tools spanning four categories, including prioritizing sounds, modifying sound parameters, providing spatial assistance, and adding additional sounds. We evaluated our tools in five diverse VR scenarios with 10 DHH people, finding that our tool can improve DHH users’ VR experience, but could be further improved by providing more customization options and decreasing distraction. We then compiled a Unity toolkit from select tools and conducted a preliminary evaluation with six Unity VR developers. Findings show that our toolkit is easy to use and debug but could be enhanced through modularization and better documentation. We close by discussing further implications of sound modification in VR.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '15', 'articleno': '34', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Previous VR sound accessibility work substituted sounds with visual or haptic output to increase VR accessibility for deaf and hard of hearing (DHH) people. However, deafness occurs on a spectrum, and many DHH people (e.g., those with partial hearing) can also benefit greatly from having more control over the audio instead of substituting it with another modality. In this paper, we explore the possibilities of modifying sounds in VR to support DHH people. To understand the best modification features for this goal, we designed and implemented 18 VR sound modification tools spanning four categories, including prioritizing sounds, modifying sound parameters, providing spatial assistance, and adding additional sounds. We evaluated our tools in five diverse VR scenarios with 10 DHH people, finding that our tool can improve DHH users’ VR experience, but could be further improved by providing more customization options and decreasing distraction. We then compiled a Unity toolkit from select tools and conducted a preliminary evaluation with six Unity VR developers. Findings show that our toolkit is easy to use and debug but could be enhanced through modularization and better documentation. We close by discussing further implications of sound modification in VR.', 'doi': '10.1145/3663548.3675653', 'url': 'https://doi.org/10.1145/3663548.3675653', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'SoundModVR: Sound Modifications in Virtual Reality to Support People who are Deaf and Hard of Hearing', 'author': 'Cao, Xinyun and Jain, Dhruv', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675653'}"
"""Seven Stitches Later"": A Technologically Interdependent Travel Experience From The Perspective Of A Visually Impaired Individual",10.1145/3663548.3688544,"Travel is an integral aspect of our lives, and this rings true for blind and visually impaired individuals alike. This activity can be enhanced with technology to facilitate a safer and more efficient experience, however with the abundance of options available it becomes difficult to establish a decision on which tools to use. In this autoethnography, I propose a technologically interdependent travel framework comprised of five pillars, orientation, communication, evaluation, navigation, and transportation. Based on over ten years of technology-supported travel experiences I have encountered first-hand as a visually impaired traveler, this experience report serves as a demonstration of what tools I have chosen and why, as well as how I utilize them throughout a naturalistic travel experience while associating each tool to a pillar from the proposed framework. I conclude this report with a recognition of existing limitations and opportunities for future research based on my observations and experiences.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Interdependent, Mobility, Navigation, Orientation, Technology, Transportation, Travel', 'numpages': '6', 'articleno': '35', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Travel is an integral aspect of our lives, and this rings true for blind and visually impaired individuals alike. This activity can be enhanced with technology to facilitate a safer and more efficient experience, however with the abundance of options available it becomes difficult to establish a decision on which tools to use. In this autoethnography, I propose a technologically interdependent travel framework comprised of five pillars, orientation, communication, evaluation, navigation, and transportation. Based on over ten years of technology-supported travel experiences I have encountered first-hand as a visually impaired traveler, this experience report serves as a demonstration of what tools I have chosen and why, as well as how I utilize them throughout a naturalistic travel experience while associating each tool to a pillar from the proposed framework. I conclude this report with a recognition of existing limitations and opportunities for future research based on my observations and experiences.', 'doi': '10.1145/3663548.3688544', 'url': 'https://doi.org/10.1145/3663548.3688544', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""Seven Stitches Later"": A Technologically Interdependent Travel Experience From The Perspective Of A Visually Impaired Individual', 'author': 'Zeidieh, Aziz N', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688544'}"
Uncovering the New Accessibility Crisis in Scholarly PDFs: Publishing Model and Platform Changes Contribute to Declining Scholarly Document Accessibility in the Last Decade,10.1145/3663548.3675634,"Most scholarly works are distributed online in PDF format, which can present significant accessibility challenges for blind and low-vision readers. To characterize the scope of this issue, we perform a large-scale analysis of 20K open- and closed-access scholarly PDFs published between 2014–2023 sampled across broad fields of study. We assess the accessibility compliance of these documents based on six criteria: Default Language, Appropriate Nesting, Tagged PDF, Table Headers, Tab Order, and Alt-Text; selected based on prior work and the SIGACCESS Guide for Accessible PDFs [34]. To ensure robustness, we corroborate our findings through automated accessibility checking, manual evaluation of alt text, comparative assessments with an alternate accessibility checker, and manual assessments with screen readers. Our findings reveal that less than 3.2\% of tested PDFs satisfy all criteria, while a large majority (74.9\%) fail to meet any criteria at all. Worse yet, we observe a concerning drop in PDF accessibility since 2019, largely among open access papers, suggesting that efforts to improve document accessibility have not taken hold and are on a backslide. While investigating factors contributing to this drop, we identify key associations between fields of study, creation platforms used, models of publishing, and PDF accessibility compliance, suggesting that publisher and author choices significantly influence document accessibility. This paper highlights a new crisis in scholarly document accessibility and the need for a multi-faceted approach to address the problem, involving the development of better tools, enhanced author education, and systemic changes in academic publishing practices.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '16', 'articleno': '36', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most scholarly works are distributed online in PDF format, which can present significant accessibility challenges for blind and low-vision readers. To characterize the scope of this issue, we perform a large-scale analysis of 20K open- and closed-access scholarly PDFs published between 2014–2023 sampled across broad fields of study. We assess the accessibility compliance of these documents based on six criteria: Default Language, Appropriate Nesting, Tagged PDF, Table Headers, Tab Order, and Alt-Text; selected based on prior work and the SIGACCESS Guide for Accessible PDFs [34]. To ensure robustness, we corroborate our findings through automated accessibility checking, manual evaluation of alt text, comparative assessments with an alternate accessibility checker, and manual assessments with screen readers. Our findings reveal that less than 3.2\\% of tested PDFs satisfy all criteria, while a large majority (74.9\\%) fail to meet any criteria at all. Worse yet, we observe a concerning drop in PDF accessibility since 2019, largely among open access papers, suggesting that efforts to improve document accessibility have not taken hold and are on a backslide. While investigating factors contributing to this drop, we identify key associations between fields of study, creation platforms used, models of publishing, and PDF accessibility compliance, suggesting that publisher and author choices significantly influence document accessibility. This paper highlights a new crisis in scholarly document accessibility and the need for a multi-faceted approach to address the problem, involving the development of better tools, enhanced author education, and systemic changes in academic publishing practices.', 'doi': '10.1145/3663548.3675634', 'url': 'https://doi.org/10.1145/3663548.3675634', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Uncovering the New Accessibility Crisis in Scholarly PDFs: Publishing Model and Platform Changes Contribute to Declining Scholarly Document Accessibility in the Last Decade', 'author': 'Kumar, Anukriti and Wang, Lucy Lu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675634'}"
SMART-TBI: Design and Evaluation of the Social Media Accessibility and Rehabilitation Toolkit for Users with Traumatic Brain Injury,10.1145/3663548.3675641,"Traumatic brain injury (TBI) can cause a range of cognitive and communication challenges that negatively affect social participation in both face-to-face interactions and computer-mediated communication. In particular, individuals with TBI report barriers that limit access to participation on social media platforms. To improve access to and use of social media for users with TBI, we introduce the Social Media Accessibility and Rehabilitation Toolkit (SMART-TBI). The toolkit includes five aids (Writing Aid, Interpretation Aid, Filter Mode, Focus Mode, and Facebook Customization) designed to address the cognitive and communicative needs of individuals with TBI. We asked eight users with moderate-severe TBI and five TBI rehabilitation experts to evaluate each aid. Our findings revealed potential benefits of aids and areas for improvement, including the need for psychological safety, privacy control, and balancing business and accessibility needs; and overall mixed reactions among the participants to AI-based aids.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Facebook, Social Media, Traumatic Brain Injury (TBI)', 'numpages': '19', 'articleno': '37', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Traumatic brain injury (TBI) can cause a range of cognitive and communication challenges that negatively affect social participation in both face-to-face interactions and computer-mediated communication. In particular, individuals with TBI report barriers that limit access to participation on social media platforms. To improve access to and use of social media for users with TBI, we introduce the Social Media Accessibility and Rehabilitation Toolkit (SMART-TBI). The toolkit includes five aids (Writing Aid, Interpretation Aid, Filter Mode, Focus Mode, and Facebook Customization) designed to address the cognitive and communicative needs of individuals with TBI. We asked eight users with moderate-severe TBI and five TBI rehabilitation experts to evaluate each aid. Our findings revealed potential benefits of aids and areas for improvement, including the need for psychological safety, privacy control, and balancing business and accessibility needs; and overall mixed reactions among the participants to AI-based aids.', 'doi': '10.1145/3663548.3675641', 'url': 'https://doi.org/10.1145/3663548.3675641', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'SMART-TBI: Design and Evaluation of the Social Media Accessibility and Rehabilitation Toolkit for Users with Traumatic Brain Injury', 'author': 'Hu, Yaxin and Lim, Hajin and Kakonge, Lisa and Mitchell, Jade T. and Johnson, Hailey L. and Turkstra, Lyn S. and Duff, Melissa C. and Toma, Catalina L. and Mutlu, Bilge', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675641'}"
The Promise and Pitfalls of Web Accessibility Overlays for Blind and Low Vision Users,10.1145/3663548.3675650,"Web accessibility is essential for ensuring that all individuals, regardless of their physical or cognitive abilities, can access and effectively use the internet. This principle is fundamental as digital platforms increasingly become primary channels for education, communication, commerce, and entertainment. Our study critically evaluates the effectiveness of accessibility overlays, which are third-party tools that claim to enhance website usability for people with disabilities. Specifically, we focused on the experiences of blind and low-vision users, who are disproportionately impacted by poor web accessibility. Through a combination of online surveys and interviews, we engaged with participants who employ a variety of assistive technologies to navigate the web. The empirical evidence gathered paints a troubling picture: despite their intended purpose, accessibility overlays often fail to deliver on their promises and, in many cases, increase existing challenges. Participants frequently reported that these overlays conflicted with their assistive technologies, leading to reduced functionality and increased frustration. This points to a significant misalignment between the design of these tools and the real-world needs of users. The study highlights the pressing need to move away from superficial technological fixes and towards deeper, more meaningful engagement with the needs of disabled users. This involves embracing user-centered design practices that integrate accessibility considerations from the ground up, ensuring that digital environments are truly inclusive. By prioritizing comprehensive, well-integrated solutions over patches like overlays, we can foster a more accessible and equitable digital landscape.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility overlays, web accessibility', 'numpages': '12', 'articleno': '38', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Web accessibility is essential for ensuring that all individuals, regardless of their physical or cognitive abilities, can access and effectively use the internet. This principle is fundamental as digital platforms increasingly become primary channels for education, communication, commerce, and entertainment. Our study critically evaluates the effectiveness of accessibility overlays, which are third-party tools that claim to enhance website usability for people with disabilities. Specifically, we focused on the experiences of blind and low-vision users, who are disproportionately impacted by poor web accessibility. Through a combination of online surveys and interviews, we engaged with participants who employ a variety of assistive technologies to navigate the web. The empirical evidence gathered paints a troubling picture: despite their intended purpose, accessibility overlays often fail to deliver on their promises and, in many cases, increase existing challenges. Participants frequently reported that these overlays conflicted with their assistive technologies, leading to reduced functionality and increased frustration. This points to a significant misalignment between the design of these tools and the real-world needs of users. The study highlights the pressing need to move away from superficial technological fixes and towards deeper, more meaningful engagement with the needs of disabled users. This involves embracing user-centered design practices that integrate accessibility considerations from the ground up, ensuring that digital environments are truly inclusive. By prioritizing comprehensive, well-integrated solutions over patches like overlays, we can foster a more accessible and equitable digital landscape.', 'doi': '10.1145/3663548.3675650', 'url': 'https://doi.org/10.1145/3663548.3675650', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'The Promise and Pitfalls of Web Accessibility Overlays for Blind and Low Vision Users', 'author': 'Makati, Tlamelo and Tigwell, Garreth W. and Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675650'}"
Audio Description Customization,10.1145/3663548.3675617,"Blind and low-vision (BLV) people use audio descriptions (ADs) to access videos. However, current ADs are unalterable by end users, thus are incapable of supporting BLV individuals’ potentially diverse needs and preferences. This research investigates if customizing AD could improve how BLV individuals consume videos. We conducted an interview study (Study 1) with fifteen BLV participants, which revealed desires for customizing properties like length, emphasis, speed, voice, format, tone, and language. At the same time, concerns like interruptions and increased interaction load due to customization emerged. To examine AD customization’s effectiveness and tradeoffs, we designed CustomAD, a prototype that enables BLV users to customize AD content and presentation. An evaluation study (Study 2) with twelve BLV participants showed using CustomAD significantly enhanced BLV people’s video understanding, immersion, and information navigation efficiency. Our work illustrates the importance of AD customization and offers a design that enhances video accessibility for BLV individuals.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Audio Description, Blind and Low-vision Individual, Customization, Video Accessibility', 'numpages': '19', 'articleno': '39', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind and low-vision (BLV) people use audio descriptions (ADs) to access videos. However, current ADs are unalterable by end users, thus are incapable of supporting BLV individuals’ potentially diverse needs and preferences. This research investigates if customizing AD could improve how BLV individuals consume videos. We conducted an interview study (Study 1) with fifteen BLV participants, which revealed desires for customizing properties like length, emphasis, speed, voice, format, tone, and language. At the same time, concerns like interruptions and increased interaction load due to customization emerged. To examine AD customization’s effectiveness and tradeoffs, we designed CustomAD, a prototype that enables BLV users to customize AD content and presentation. An evaluation study (Study 2) with twelve BLV participants showed using CustomAD significantly enhanced BLV people’s video understanding, immersion, and information navigation efficiency. Our work illustrates the importance of AD customization and offers a design that enhances video accessibility for BLV individuals.', 'doi': '10.1145/3663548.3675617', 'url': 'https://doi.org/10.1145/3663548.3675617', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Audio Description Customization', 'author': 'Natalie, Rosiana and Chang, Ruei-Che and Sheshadri, Smitha and Guo, Anhong and Hara, Kotaro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675617'}"
Design and Evaluation of an Automatic Text Simplification Prototype with Deaf and Hard-of-hearing Readers,10.1145/3663548.3675645,"Research has observed benefits from providing lexical and syntactic approaches to Automatic Text Simplification (ATS) to Deaf and Hard-of-hearing (DHH) readers. However, little research has explored DHH readers’ design preferences and interactions with these approaches. This work first explores the design space of ATS systems with DHH readers, identifying potential design configurations for evaluation. Open-ended discussion of participants’ design preferences reveal values informing those preferences, including maintaining reading fluency and efficiency, and control over the tool. Using popular design choices from our formative study, we evaluated a prototype that provides various simplification types to explore DHH readers’ interactions with the system. We observed potential conflicts between participants’ values and design preferences, such as the prototype’s impact on participants’ reading speed and participants’ perceived need to reread simplifications suggested by the tool. However, participants found the tool useful, showing a nuanced preference towards world-level lexical simplifications using pop-ups. Our findings highlight the importance of the tool’s design on users’ reading experiences, and provide implications for the design and evaluation of ATS prototypes with target readers.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Automatic Text Simplification, Deaf and Hard-of-hearing Adults, Design Space, Reading', 'numpages': '18', 'articleno': '40', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Research has observed benefits from providing lexical and syntactic approaches to Automatic Text Simplification (ATS) to Deaf and Hard-of-hearing (DHH) readers. However, little research has explored DHH readers’ design preferences and interactions with these approaches. This work first explores the design space of ATS systems with DHH readers, identifying potential design configurations for evaluation. Open-ended discussion of participants’ design preferences reveal values informing those preferences, including maintaining reading fluency and efficiency, and control over the tool. Using popular design choices from our formative study, we evaluated a prototype that provides various simplification types to explore DHH readers’ interactions with the system. We observed potential conflicts between participants’ values and design preferences, such as the prototype’s impact on participants’ reading speed and participants’ perceived need to reread simplifications suggested by the tool. However, participants found the tool useful, showing a nuanced preference towards world-level lexical simplifications using pop-ups. Our findings highlight the importance of the tool’s design on users’ reading experiences, and provide implications for the design and evaluation of ATS prototypes with target readers.', 'doi': '10.1145/3663548.3675645', 'url': 'https://doi.org/10.1145/3663548.3675645', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Design and Evaluation of an Automatic Text Simplification Prototype with Deaf and Hard-of-hearing Readers', 'author': 'Alonzo, Oliver and Lee, Sooyeon and Amin, Akhter Al and Maddela, Mounica and Xu, Wei and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675645'}"
"""Slipping through the cracks"": A Duoethnography of Web Accessibility",10.1145/3663548.3688543,"The web is inaccessible. According to a 2024 review of 1 million websites, 95.9\% of home pages online had one or more accessibility failures—and many had over fifty automatically-detected issues [2]. Despite years of work analyzing accessibility failures and paths towards improvement, comparatively little work at ASSETS focuses on the labor of doing web accessibility. Drawing from a duoethnography of working on accessibility, this position paper explores the practical work of accessibility in academic and professional environments and makes concrete recommendations for web accessibility practitioners. We argue that accessibility is not primarily an issue of awareness or an overreliance on compliance: we show that accessibility is much better understood as a complex resource management problem that requires multifaceted and ongoing effort to maintain.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility Management, Autoethnography, Professional Practice of Web Accessibility, Qualitative Methods in Web Accessibility, Web Accessibility', 'numpages': '6', 'articleno': '41', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The web is inaccessible. According to a 2024 review of 1 million websites, 95.9\\% of home pages online had one or more accessibility failures—and many had over fifty automatically-detected issues [2]. Despite years of work analyzing accessibility failures and paths towards improvement, comparatively little work at ASSETS focuses on the labor of doing web accessibility. Drawing from a duoethnography of working on accessibility, this position paper explores the practical work of accessibility in academic and professional environments and makes concrete recommendations for web accessibility practitioners. We argue that accessibility is not primarily an issue of awareness or an overreliance on compliance: we show that accessibility is much better understood as a complex resource management problem that requires multifaceted and ongoing effort to maintain.', 'doi': '10.1145/3663548.3688543', 'url': 'https://doi.org/10.1145/3663548.3688543', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""Slipping through the cracks"": A Duoethnography of Web Accessibility', 'author': 'Abramovich, Shira and Patitsas, Elizabeth', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688543'}"
Looking Past Screens: Exploring Mixed Reality and Discreet AAC Devices,10.1145/3663548.3675655,"Augmentative and alternative communication (AAC) technologies are typically fixed-form factor mobile devices, which can be physically obtrusive and visually identifiable – perpetuating public stigmas and limiting non-verbal communication. These qualities are undesirable for many AAC-using communities including stroke survivors, who can have complex communication needs onset by aphasia and hemiplegic body paralysis. Furthermore, underrepresented communities such as people with aphasia are often unconsidered in the design of emerging technologies. We contest these trends by asking what these emerging and future technologies might mean for communication support. To do this, we envision and prototype mixed reality and discreet assistive technologies that support communication with people living with aphasia. We report results from the co-design process, including participants’ perspectives on nascent mixed reality, diegetic technologies, and outcomes from low-fidelity AAC prototyping. These activities culminated in three high-fidelity prototypes with different characteristics and form-factors: Pico-project AAC, Prompt AAC and Holo AAC, which embody projection, worn audio devices, and headset driven mixed reality. From subsequent focus groups, we present findings from an evaluation of all prototypes, reflecting on the possibilities of present and future mixed-reality technologies to augment communication.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AAC, Accessibility, Alternative and Augmentative Communication, Discreet and Wearable Devices, Mixed Reality, Pico Projection', 'numpages': '22', 'articleno': '42', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Augmentative and alternative communication (AAC) technologies are typically fixed-form factor mobile devices, which can be physically obtrusive and visually identifiable – perpetuating public stigmas and limiting non-verbal communication. These qualities are undesirable for many AAC-using communities including stroke survivors, who can have complex communication needs onset by aphasia and hemiplegic body paralysis. Furthermore, underrepresented communities such as people with aphasia are often unconsidered in the design of emerging technologies. We contest these trends by asking what these emerging and future technologies might mean for communication support. To do this, we envision and prototype mixed reality and discreet assistive technologies that support communication with people living with aphasia. We report results from the co-design process, including participants’ perspectives on nascent mixed reality, diegetic technologies, and outcomes from low-fidelity AAC prototyping. These activities culminated in three high-fidelity prototypes with different characteristics and form-factors: Pico-project AAC, Prompt AAC and Holo AAC, which embody projection, worn audio devices, and headset driven mixed reality. From subsequent focus groups, we present findings from an evaluation of all prototypes, reflecting on the possibilities of present and future mixed-reality technologies to augment communication.', 'doi': '10.1145/3663548.3675655', 'url': 'https://doi.org/10.1145/3663548.3675655', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Looking Past Screens: Exploring Mixed Reality and Discreet AAC Devices', 'author': 'Curtis, Humphrey and Jenkins, Adam D G and Ibrahim, Seray B and Neate, Timothy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675655'}"
Designing Accessible Adaptations for an Electronic Toolkit with Blind and Low Vision Users,10.1145/3663548.3675652,"There is a growing availability of computational and electronic toolkits designed for learning and enrichment activities, however, these toolkits are often inaccessible for blind and low vision (BLV) users. We co-designed with BLV participants, several types of adaption and augmentations that can increase the accessibility of a previously developed electronic toolkit. We explored NFC-enabled 3D-printed circuit templates, braided connectors, and other tactile adaptions developed from co-design sessions with BLV users. We evaluated the resulting toolkit with nine blind and low-vision participants and found that they experimentally and tactually learned to compose circuits of increasing complexity. A key design aspect was incorporating redundant methods that enabled participants to exercise their personal modality preferences when identifying components and making connections. Through our work, we highlight how digital fabrication can be applied to adapt modular electronic toolkits to increase the availability of existing electronics learning platforms for the BLV population.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind, Co-design, Electronics Toolkit, Low Vision', 'numpages': '15', 'articleno': '43', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'There is a growing availability of computational and electronic toolkits designed for learning and enrichment activities, however, these toolkits are often inaccessible for blind and low vision (BLV) users. We co-designed with BLV participants, several types of adaption and augmentations that can increase the accessibility of a previously developed electronic toolkit. We explored NFC-enabled 3D-printed circuit templates, braided connectors, and other tactile adaptions developed from co-design sessions with BLV users. We evaluated the resulting toolkit with nine blind and low-vision participants and found that they experimentally and tactually learned to compose circuits of increasing complexity. A key design aspect was incorporating redundant methods that enabled participants to exercise their personal modality preferences when identifying components and making connections. Through our work, we highlight how digital fabrication can be applied to adapt modular electronic toolkits to increase the availability of existing electronics learning platforms for the BLV population.', 'doi': '10.1145/3663548.3675652', 'url': 'https://doi.org/10.1145/3663548.3675652', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Designing Accessible Adaptations for an Electronic Toolkit with Blind and Low Vision Users', 'author': 'Johnstone, Jacqueline and Nadeeshani, Madhuka and Chen, Hanmin and Vemula, Mohith and Tandori, Erica J and Stephens, Kate and Senaratne, Hashini and Ellis, Kirsten and Ananthanarayan, Swamy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675652'}"
Vision-Based Assistive Technologies for People with Cerebral Visual Impairment: A Review and Focus Study,10.1145/3663548.3675637,"Over the past decade, considerable research has investigated Vision-Based Assistive Technologies (VBAT) to support people with vision impairments to understand and interact with their immediate environment using machine learning, computer vision, image enhancement, and/or augmented/virtual reality. However, this has almost totally overlooked a growing demographic: people with Cerebral Visual Impairment (CVI). Unlike ocular vision impairments, CVI arises from damage to the brain’s visual processing centres. Through a scoping review, this paper reveals a significant research gap in addressing the needs of this demographic. Three focus studies involving 7 participants with CVI explored the challenges, current strategies, and opportunities for VBAT. We also discussed the assistive technology needs of people with CVI compared with ocular low vision. Our findings highlight the opportunity for the Human-Computer Interaction and Assistive Technologies research community to explore and address this underrepresented domain, thereby enhancing the quality of life for people with CVI.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'assistive devices, augmented reality, cerebral visual impairment, computer vision, focus group discussion, machine learning, virtual reality', 'numpages': '20', 'articleno': '44', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Over the past decade, considerable research has investigated Vision-Based Assistive Technologies (VBAT) to support people with vision impairments to understand and interact with their immediate environment using machine learning, computer vision, image enhancement, and/or augmented/virtual reality. However, this has almost totally overlooked a growing demographic: people with Cerebral Visual Impairment (CVI). Unlike ocular vision impairments, CVI arises from damage to the brain’s visual processing centres. Through a scoping review, this paper reveals a significant research gap in addressing the needs of this demographic. Three focus studies involving 7 participants with CVI explored the challenges, current strategies, and opportunities for VBAT. We also discussed the assistive technology needs of people with CVI compared with ocular low vision. Our findings highlight the opportunity for the Human-Computer Interaction and Assistive Technologies research community to explore and address this underrepresented domain, thereby enhancing the quality of life for people with CVI.', 'doi': '10.1145/3663548.3675637', 'url': 'https://doi.org/10.1145/3663548.3675637', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Vision-Based Assistive Technologies for People with Cerebral Visual Impairment: A Review and Focus Study', 'author': 'Gamage, Bhanuka and Holloway, Leona and McDowell, Nicola and Do, Thanh-Toan and Price, Nicholas and Lowery, Arthur and Marriott, Kim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675637'}"
Intersecting Liminality: Acquiring a Smartphone as a Blind or Low Vision Older Adult,10.1145/3663548.3675622,"Older adults are increasingly acquiring smartphones. But acquiring smartphones can be difficult, and little is known about the particular challenges of older adults who are additionally blind or losing their vision. We shed light on the social and technical aspects of acquiring smartphones with vision loss, based on deep qualitative interviews with 22 blind or low vision (BLV) older adults aged 60 and over. Through our grounded theory analysis, we found that BLV older adults experience liminality as they acquire smartphones and transition through re-acquiring smartphones as they become blind, and they can transition through liminality by participating in mutual aid within the blind community. We contribute the notion of “Intersecting Liminality,” which explains the marginalizing experience of simultaneously transitioning through vision loss, aging, and technology acquisition. We contend that Intersecting Liminality can serve as a framework that centers the dynamic nature of disability to help our community generate a more nuanced understanding of technology acquisition and more effective assistive interventions.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, blind, life transition, liminality, low vision, mutual aid, smartphones, social support, technology adoption', 'numpages': '14', 'articleno': '45', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Older adults are increasingly acquiring smartphones. But acquiring smartphones can be difficult, and little is known about the particular challenges of older adults who are additionally blind or losing their vision. We shed light on the social and technical aspects of acquiring smartphones with vision loss, based on deep qualitative interviews with 22 blind or low vision (BLV) older adults aged 60 and over. Through our grounded theory analysis, we found that BLV older adults experience liminality as they acquire smartphones and transition through re-acquiring smartphones as they become blind, and they can transition through liminality by participating in mutual aid within the blind community. We contribute the notion of “Intersecting Liminality,” which explains the marginalizing experience of simultaneously transitioning through vision loss, aging, and technology acquisition. We contend that Intersecting Liminality can serve as a framework that centers the dynamic nature of disability to help our community generate a more nuanced understanding of technology acquisition and more effective assistive interventions.', 'doi': '10.1145/3663548.3675622', 'url': 'https://doi.org/10.1145/3663548.3675622', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Intersecting Liminality: Acquiring a Smartphone as a Blind or Low Vision Older Adult', 'author': 'Figueira, Isabela and Cha, Yoonha and Branham, Stacy M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675622'}"
"""I Wish You Could Make the Camera Stand Still"": Envisioning Media Accessibility Interventions with People with Aphasia",10.1145/3663548.3675598,"Audiovisual media is integral to modern living, yet is not always accessible to all. Modern accessibility interventions, such as subtitles, support many, however, communities with complex communication needs are largely unconsidered. In this work, we envision future accessibility interventions from the ground up with one such community – people with aphasia. Over two workshops and a probe activity, we problematise the space of audiovisual consumption by people with aphasia, and co-envision directions for development in accessible audiovisual media. From low-fi diegetic prototypes to mid-fidelity solutions, we explore new visions of accessibility interventions for complex communication needs – notably enabling high levels of content manipulation and personalisation. Our findings raise open questions and set directions for the research community in developing accessibility interventions for audiovisual media to support users with diverse needs in accessing audiovisual content.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, aphasia, audiovisual, complex communication needs, envisioning, media, probes, prototype', 'numpages': '17', 'articleno': '46', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Audiovisual media is integral to modern living, yet is not always accessible to all. Modern accessibility interventions, such as subtitles, support many, however, communities with complex communication needs are largely unconsidered. In this work, we envision future accessibility interventions from the ground up with one such community – people with aphasia. Over two workshops and a probe activity, we problematise the space of audiovisual consumption by people with aphasia, and co-envision directions for development in accessible audiovisual media. From low-fi diegetic prototypes to mid-fidelity solutions, we explore new visions of accessibility interventions for complex communication needs – notably enabling high levels of content manipulation and personalisation. Our findings raise open questions and set directions for the research community in developing accessibility interventions for audiovisual media to support users with diverse needs in accessing audiovisual content.', 'doi': '10.1145/3663548.3675598', 'url': 'https://doi.org/10.1145/3663548.3675598', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""I Wish You Could Make the Camera Stand Still"": Envisioning Media Accessibility Interventions with People with Aphasia', 'author': 'Nevsky, Alexandre and Bircanin, Filip and Cruice, Madeline N and Wilson, Stephanie and Simperl, Elena and Neate, Timothy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675598'}"
Information Wayfinding of Screen Reader Users: Five Personas to Expand Conceptualizations of User Experiences,10.1145/3663548.3688539,"Screen readers are important assistive technologies for blind people, but they are complex and can be challenging to use effectively. Over the course of several studies with screen reader users, the authors have found wide variations and sometimes surprising differences in people's skills, preferences, navigation, and troubleshooting approaches when using screen readers. These differences may not always be considered in research and development. To help address this shortcoming, we have developed five user personas describing a range of screen reader experiences.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, assistive technology, braille', 'numpages': '7', 'articleno': '47', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Screen readers are important assistive technologies for blind people, but they are complex and can be challenging to use effectively. Over the course of several studies with screen reader users, the authors have found wide variations and sometimes surprising differences in people's skills, preferences, navigation, and troubleshooting approaches when using screen readers. These differences may not always be considered in research and development. To help address this shortcoming, we have developed five user personas describing a range of screen reader experiences."", 'doi': '10.1145/3663548.3688539', 'url': 'https://doi.org/10.1145/3663548.3688539', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Information Wayfinding of Screen Reader Users: Five Personas to Expand Conceptualizations of User Experiences', 'author': 'Jordan, J. Bern and Van Hyning, Victoria and Jones, Mason A. and Bradley Montgomery, Rachael and Bottner, Elizabeth and Tansil, Evan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688539'}"
Help and The Social Construction of Access: A Case-Study from India,10.1145/3663548.3675606,"A goal of accessible technology (AT) design is often to increase independence, i.e., to enable people with disabilities to accomplish tasks on their own without help. Recent work challenges this view by recognizing the role of ‘help’ in addressing the access needs of people with disabilities. However, empirical evidence examining help is limited to the Global North; we address this gap using a case study of how people with visual impairments (PVI) navigate indoor environments in India. Using interviews with PVI and their companions and a video-diary study, we find that help is a key practice that PVI use to navigate indoor environments. We uncover how help is a situated phenomenon shaped by socio-material and cultural factors unique to the Indian context. We discuss the value of help in the context of broader HCI and Accessibility literature on mixed-ability and collaborative interactions. We also discuss implications our findings on help have for AT design.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blindness, Global South, India, Indoor Navigation, Social Accessibility, Visual Impairment', 'numpages': '12', 'articleno': '48', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A goal of accessible technology (AT) design is often to increase independence, i.e., to enable people with disabilities to accomplish tasks on their own without help. Recent work challenges this view by recognizing the role of ‘help’ in addressing the access needs of people with disabilities. However, empirical evidence examining help is limited to the Global North; we address this gap using a case study of how people with visual impairments (PVI) navigate indoor environments in India. Using interviews with PVI and their companions and a video-diary study, we find that help is a key practice that PVI use to navigate indoor environments. We uncover how help is a situated phenomenon shaped by socio-material and cultural factors unique to the Indian context. We discuss the value of help in the context of broader HCI and Accessibility literature on mixed-ability and collaborative interactions. We also discuss implications our findings on help have for AT design.', 'doi': '10.1145/3663548.3675606', 'url': 'https://doi.org/10.1145/3663548.3675606', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Help and The Social Construction of Access: A Case-Study from India', 'author': 'Kameswaran, Vaishnav and Robinson, Jerry and Sambasivan, Nithya and Aggarwal, Gaurav and Morris, Meredith Ringel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675606'}"
"Characterizing ""Motor Ability"" for Ability-Based Design",10.1145/3663548.3675646,"Ability-based design (Wobbrock et al. 2011, 2018) offers conceptual guidance for its use in designing accessible systems, but the construct of “ability” itself—a crucial notion for ability-based design—is surprisingly elusive and absent from extant accounts. Different disciplines offer disparate notions regarding definitions and measures of “ability,” but ability-based design has yet to avail itself of these notions in its operationalization. To address this gap, this work reviews literature that quantifies motor abilities, provides guidance to distill metrics for human-computer interaction, and conceptualizes how motor ability should be quantified for ability-based design. We offer a three-dimensional framework composed of the user, context, and task, and we locate various metrics for ability to be used when implementing ability-based designs. We support this new conceptualization with example personas that occupy this three-dimensional space. This work can inform those using ability-based design to create systems that are responsive to users’ abilities.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ability, ability-based design, accessibility, human motor control', 'numpages': '15', 'articleno': '49', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Ability-based design (Wobbrock et al. 2011, 2018) offers conceptual guidance for its use in designing accessible systems, but the construct of “ability” itself—a crucial notion for ability-based design—is surprisingly elusive and absent from extant accounts. Different disciplines offer disparate notions regarding definitions and measures of “ability,” but ability-based design has yet to avail itself of these notions in its operationalization. To address this gap, this work reviews literature that quantifies motor abilities, provides guidance to distill metrics for human-computer interaction, and conceptualizes how motor ability should be quantified for ability-based design. We offer a three-dimensional framework composed of the user, context, and task, and we locate various metrics for ability to be used when implementing ability-based designs. We support this new conceptualization with example personas that occupy this three-dimensional space. This work can inform those using ability-based design to create systems that are responsive to users’ abilities.', 'doi': '10.1145/3663548.3675646', 'url': 'https://doi.org/10.1145/3663548.3675646', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Characterizing ""Motor Ability"" for Ability-Based Design', 'author': 'Mitchell, Claire L. and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675646'}"
DREEM: Moving from Empathy to Enculturation in Disability Related Human-Centered Design,10.1145/3663548.3675642,"Empathy-building, the first stage in human-centered design, often involves methods that inadvertently reinforce negative stereotypes and biases toward disabled communities. In this work, we introduce a new method: Disability-Related Empathy from Existing Media (DREEM). This method focuses on enculturation rather than traditional ideas of empathy. DREEM leverages media created by disabled individuals to facilitate a deeper, culturally informed understanding. Cultural content is rich with authentic perspectives and tacit design knowledge from people with disabilities. Our four-step process includes (1) discovering relevant media, (2) close reading, (3) reflective journaling, and (4) aggregation of insights. In this article, we present our process of creating DREEM using research through design in multiple research and education contexts. Our findings show that DREEM can be applied in both design classrooms and research contexts to foster a more nuanced understanding of disability for newcomers to the space.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'design methods, disability, empathy, human centered design, qualitative methods', 'numpages': '17', 'articleno': '50', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Empathy-building, the first stage in human-centered design, often involves methods that inadvertently reinforce negative stereotypes and biases toward disabled communities. In this work, we introduce a new method: Disability-Related Empathy from Existing Media (DREEM). This method focuses on enculturation rather than traditional ideas of empathy. DREEM leverages media created by disabled individuals to facilitate a deeper, culturally informed understanding. Cultural content is rich with authentic perspectives and tacit design knowledge from people with disabilities. Our four-step process includes (1) discovering relevant media, (2) close reading, (3) reflective journaling, and (4) aggregation of insights. In this article, we present our process of creating DREEM using research through design in multiple research and education contexts. Our findings show that DREEM can be applied in both design classrooms and research contexts to foster a more nuanced understanding of disability for newcomers to the space.', 'doi': '10.1145/3663548.3675642', 'url': 'https://doi.org/10.1145/3663548.3675642', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'DREEM: Moving from Empathy to Enculturation in Disability Related Human-Centered Design', 'author': 'Baltaxe-Admony, Leya Breanna and Duval, Jared and Ringland, Kathryn E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675642'}"
"""I Am Human, Just Like You"": What Intersectional, Neurodivergent Lived Experiences Bring to Accessibility Research",10.1145/3663548.3675651,"The increasing prevalence of neurodivergence has led society to give greater recognition to the importance of neurodiversity. Yet societal perceptions of neurodivergence continue to be predominantly negative. Drawing on Critical Disability Studies, accessibility researchers have demonstrated how neuronormative assumptions dominate HCI. Despite their guidance, neurodivergent and disabled individuals are still marginalized in technology research. In particular, intersectional identities remain largely absent from HCI neurodivergence research. In this paper, I share my perspective as an outsider of the academic research community: I use critical autoethnography to analyze my experiences of coming to understand, accept, and value my neurodivergence within systems of power, privilege, and oppression. Using Data Feminism as an accessible and practical guide to intersectionality, I derive three tenets for reconceptualizing neurodivergence to be more inclusive of intersectional experiences: (1) neurodivergence is a functional difference, not a deficit; (2) neurodivergent disability is a moment of friction, not a static label; and (3) neurodivergence accessibility is a collaborative practice, not a one-sided solution. Then, I discuss the tenets in the context of existing HCI research, applying the same intersectional lens. Finally, I offer three suggestions for how accessibility research can apply these tenets in future work, to bridge the gap between accessibility theory and practice in HCI neurodivergence research.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ADHD, Autism, critical theory, disabilities studies, intersectional HCI, intersectionality, neurodivergence, neurodiversity', 'numpages': '20', 'articleno': '51', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The increasing prevalence of neurodivergence has led society to give greater recognition to the importance of neurodiversity. Yet societal perceptions of neurodivergence continue to be predominantly negative. Drawing on Critical Disability Studies, accessibility researchers have demonstrated how neuronormative assumptions dominate HCI. Despite their guidance, neurodivergent and disabled individuals are still marginalized in technology research. In particular, intersectional identities remain largely absent from HCI neurodivergence research. In this paper, I share my perspective as an outsider of the academic research community: I use critical autoethnography to analyze my experiences of coming to understand, accept, and value my neurodivergence within systems of power, privilege, and oppression. Using Data Feminism as an accessible and practical guide to intersectionality, I derive three tenets for reconceptualizing neurodivergence to be more inclusive of intersectional experiences: (1) neurodivergence is a functional difference, not a deficit; (2) neurodivergent disability is a moment of friction, not a static label; and (3) neurodivergence accessibility is a collaborative practice, not a one-sided solution. Then, I discuss the tenets in the context of existing HCI research, applying the same intersectional lens. Finally, I offer three suggestions for how accessibility research can apply these tenets in future work, to bridge the gap between accessibility theory and practice in HCI neurodivergence research.', 'doi': '10.1145/3663548.3675651', 'url': 'https://doi.org/10.1145/3663548.3675651', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""I Am Human, Just Like You"": What Intersectional, Neurodivergent Lived Experiences Bring to Accessibility Research', 'author': 'Le, Lindy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675651'}"
An Ecosystem of Support: A U.S. State Government-Supported DIY-AT Program for Residents with Disabilities,10.1145/3663548.3675667,"While Do-It-Yourself (DIY) approaches to producing customized assistive technology (AT) have been shown to support end-user agency and further technology democratization, research has shown that the utilization of digital fabrication tools requires a high level of technical expertise as well as financial investment. Facilitation of collaborations between end users and makers is a possible solution to these issues, however, previous efforts have uncovered issues around shared language, lack of consistent communication, and liability concerns. A promising direction for addressing these issues is to conceive of new types of multi-organizational collaborations that draw on complementary strengths. We explored these possibilities through an Action Research study in which we collaborated with the Maryland department of disability to launch a state level DIY-AT program. Through developing and supporting this program, we studied motivations for participation, relationships to creating and customizing AT, how individuals participated in and grew the program, and how the program allowed for individuals to reflect on their disabilities and AT use. Our findings generated an ecosystem model describing the interdependent relationships between and roles held by each stakeholder in the state DIY-AT program as well as a description of how this ecosystem encouraged expanding and transcending the understandings and definitions of AT and disability. We offer lessons learned for the design of future government-supported DIY-AT programs and reflections on the role of HCI researchers within these ecosystems.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': '3D printing, assistive technology, digital fabrication, ecosystems, higher education, makerspaces', 'numpages': '16', 'articleno': '52', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'While Do-It-Yourself (DIY) approaches to producing customized assistive technology (AT) have been shown to support end-user agency and further technology democratization, research has shown that the utilization of digital fabrication tools requires a high level of technical expertise as well as financial investment. Facilitation of collaborations between end users and makers is a possible solution to these issues, however, previous efforts have uncovered issues around shared language, lack of consistent communication, and liability concerns. A promising direction for addressing these issues is to conceive of new types of multi-organizational collaborations that draw on complementary strengths. We explored these possibilities through an Action Research study in which we collaborated with the Maryland department of disability to launch a state level DIY-AT program. Through developing and supporting this program, we studied motivations for participation, relationships to creating and customizing AT, how individuals participated in and grew the program, and how the program allowed for individuals to reflect on their disabilities and AT use. Our findings generated an ecosystem model describing the interdependent relationships between and roles held by each stakeholder in the state DIY-AT program as well as a description of how this ecosystem encouraged expanding and transcending the understandings and definitions of AT and disability. We offer lessons learned for the design of future government-supported DIY-AT programs and reflections on the role of HCI researchers within these ecosystems.', 'doi': '10.1145/3663548.3675667', 'url': 'https://doi.org/10.1145/3663548.3675667', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'An Ecosystem of Support: A U.S. State Government-Supported DIY-AT Program for Residents with Disabilities', 'author': 'Higgins, Erin and Sakowicz, Marie E and Hamidi, Foad', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675667'}"
Ethical Concerns when Working with Mixed-Ability Groups of Children,10.1145/3663548.3675648,"Accessibility research has gained traction, yet ethical gaps persist in the inclusion of individuals with disabilities, especially children. Inclusive research practices are essential to ensure that research and design solutions cater to the needs of all individuals, regardless of their abilities. Working with children with disabilities in Human-Computer Interaction and Human-Robot Interaction presents a unique set of ethical dilemmas. These young participants often require additional care, support, and accommodations, which can fall off researchers’ resources or expertise. The lack of clear guidance on navigating these challenges further aggravates the problem. To provide a basis on which to address this issue, we adopt a critical reflective approach, evaluating our impact by analyzing two case studies involving children with disabilities in HCI/HRI research. Flowing from these, we call for a shift in our approach to ethics in participatory research contexts to one that is processual, situational, and community-led.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Children, Ethics, Mixed-Ability', 'numpages': '9', 'articleno': '53', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Accessibility research has gained traction, yet ethical gaps persist in the inclusion of individuals with disabilities, especially children. Inclusive research practices are essential to ensure that research and design solutions cater to the needs of all individuals, regardless of their abilities. Working with children with disabilities in Human-Computer Interaction and Human-Robot Interaction presents a unique set of ethical dilemmas. These young participants often require additional care, support, and accommodations, which can fall off researchers’ resources or expertise. The lack of clear guidance on navigating these challenges further aggravates the problem. To provide a basis on which to address this issue, we adopt a critical reflective approach, evaluating our impact by analyzing two case studies involving children with disabilities in HCI/HRI research. Flowing from these, we call for a shift in our approach to ethics in participatory research contexts to one that is processual, situational, and community-led.', 'doi': '10.1145/3663548.3675648', 'url': 'https://doi.org/10.1145/3663548.3675648', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Ethical Concerns when Working with Mixed-Ability Groups of Children', 'author': 'Henriques, Ana O and Piedade, Patricia and Rocha, Filipa and Neto, Isabel and Nicolau, Hugo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675648'}"
Is it Part of Me? Exploring Experiences of Inclusive Avatar Use For Visible and Invisible Disabilities in Social VR,10.1145/3663548.3675601,"Social Virtual Reality (VR) platforms have surged in popularity in recent years, including among people with disabilities (PWD). Previous research has documented accessibility challenges, harassment, and negative experiences for PWD using disability signifiers in VR, primarily focusing on those with visible disabilities who encounter negative experiences. Yet, little is known about the experiences of people with invisible disabilities in social VR environments, and whether positive experiences are also common. To address these gaps, we designed inclusive avatars (avatars with disability signifiers) and investigated the lived experiences of 26 individuals with both visible and invisible disabilities immersing themselves in social interactions in VRChat for a week. We utilized a mixed methods experience sampling design and multilevel regression to explore the relationships between social interactions of PWD in VR and various psychological outcomes. Our results indicate that PWD, both visible and invisible, experienced positive and negative social interactions in VR. These interactions, in turn, significantly influenced users’ overall experience with inclusive avatars, affecting aspects such as emotional responses, engagement levels, satisfaction with the avatar’s design, and perceptions of inclusion in VR. Qualitative interviews of 18 participants allowed for a more nuanced exploration of the experiences of PWD by giving voice to users who are rarely studied in depth. Findings provided unique insights into both the positive and negative experiences of PWD, as well as identified key design factors influencing user experience in social VR.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, diary study, inclusive avatars, lived experiences, social VR', 'numpages': '15', 'articleno': '54', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social Virtual Reality (VR) platforms have surged in popularity in recent years, including among people with disabilities (PWD). Previous research has documented accessibility challenges, harassment, and negative experiences for PWD using disability signifiers in VR, primarily focusing on those with visible disabilities who encounter negative experiences. Yet, little is known about the experiences of people with invisible disabilities in social VR environments, and whether positive experiences are also common. To address these gaps, we designed inclusive avatars (avatars with disability signifiers) and investigated the lived experiences of 26 individuals with both visible and invisible disabilities immersing themselves in social interactions in VRChat for a week. We utilized a mixed methods experience sampling design and multilevel regression to explore the relationships between social interactions of PWD in VR and various psychological outcomes. Our results indicate that PWD, both visible and invisible, experienced positive and negative social interactions in VR. These interactions, in turn, significantly influenced users’ overall experience with inclusive avatars, affecting aspects such as emotional responses, engagement levels, satisfaction with the avatar’s design, and perceptions of inclusion in VR. Qualitative interviews of 18 participants allowed for a more nuanced exploration of the experiences of PWD by giving voice to users who are rarely studied in depth. Findings provided unique insights into both the positive and negative experiences of PWD, as well as identified key design factors influencing user experience in social VR.', 'doi': '10.1145/3663548.3675601', 'url': 'https://doi.org/10.1145/3663548.3675601', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Is it Part of Me? Exploring Experiences of Inclusive Avatar Use For Visible and Invisible Disabilities in Social VR', 'author': 'Angerbauer, Katrin and Van Wagoner, Phoenix and Halach, Tim and Vogelsang, Jonas and Hube, Natalie and Smith, Andria and Keplinger, Ksenia and Sedlmair, Michael', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675601'}"
ChartA11y: Designing Accessible Touch Experiences of Visualizations with Blind Smartphone Users,10.1145/3663548.3675611,"We introduce ChartA11y, an app developed to enable accessible 2-D visualizations on smartphones for blind users through a participatory and iterative design process involving 13 sessions with two blind partners. We also present a design journey for making accessible touch experiences that go beyond simple auditory feedback, incorporating multimodal interactions and multisensory data representations. Together, ChartA11y aimed at providing direct chart accessing and comprehensive chart understanding by applying a two-mode setting: a semantic navigation framework mode and a direct touch mapping mode. By re-designing traditional touch-to-audio interactions, ChartA11y also extends to accessible scatter plots, addressing the under-explored challenges posed by their non-linear data distribution. Our main contributions encompass the detailed participatory design process and the resulting system, ChartA11y, offering a novel approach for blind users to access visualizations on their smartphones.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Assistive Technology, Blind Users, Data Visualization, Multimodal Interaction, Participitory Design, Smartphone, Sonification, Touchscreen Experience', 'numpages': '15', 'articleno': '55', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We introduce ChartA11y, an app developed to enable accessible 2-D visualizations on smartphones for blind users through a participatory and iterative design process involving 13 sessions with two blind partners. We also present a design journey for making accessible touch experiences that go beyond simple auditory feedback, incorporating multimodal interactions and multisensory data representations. Together, ChartA11y aimed at providing direct chart accessing and comprehensive chart understanding by applying a two-mode setting: a semantic navigation framework mode and a direct touch mapping mode. By re-designing traditional touch-to-audio interactions, ChartA11y also extends to accessible scatter plots, addressing the under-explored challenges posed by their non-linear data distribution. Our main contributions encompass the detailed participatory design process and the resulting system, ChartA11y, offering a novel approach for blind users to access visualizations on their smartphones.', 'doi': '10.1145/3663548.3675611', 'url': 'https://doi.org/10.1145/3663548.3675611', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'ChartA11y: Designing Accessible Touch Experiences of Visualizations with Blind Smartphone Users', 'author': 'Zhang, Zhuohao and Thompson, John R and Shah, Aditi and Agrawal, Manish and Sarikaya, Alper and Wobbrock, Jacob O. and Cutrell, Edward and Lee, Bongshin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675611'}"
Understanding and Reducing the Challenges Faced by Creators of Accessible Online Data Visualizations,10.1145/3663548.3675625,"We sought to understand and reduce the challenges creators face with making their data visualizations accessible. Specifically, we administered a formative survey of 57 creators to comprehend their challenges, perceived importance, knowledge, and prioritization of data visualization accessibility. Participants identified five interventions to minimize their challenges: Workshops, Emulators, Evaluators, Feedback Collectors, and Multi-Modal Automated Tools. Additionally, we report specifications and recommendations from 12 visualization creators for effective versions of each intervention, gathered via semi-structured interviews. Utilizing our findings, such as a “mini-survey” format that is effective for collecting accessibility-related feedback from screen-reader users, we implemented and integrated these interventions into VoxLens (Sharif et al., 2022). We assessed our enhancements through a task-based user study with 10 visualization creators, finding 44\%, 17\%, and 12\% improvements in their understanding of screen-reader users’ challenges with data visualizations, knowledge of visualization accessibility, and perceived usefulness of the enhanced VoxLens, respectively.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, blind, challenges, data visualizations, screen-reader users, visualization creators', 'numpages': '20', 'articleno': '56', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We sought to understand and reduce the challenges creators face with making their data visualizations accessible. Specifically, we administered a formative survey of 57 creators to comprehend their challenges, perceived importance, knowledge, and prioritization of data visualization accessibility. Participants identified five interventions to minimize their challenges: Workshops, Emulators, Evaluators, Feedback Collectors, and Multi-Modal Automated Tools. Additionally, we report specifications and recommendations from 12 visualization creators for effective versions of each intervention, gathered via semi-structured interviews. Utilizing our findings, such as a “mini-survey” format that is effective for collecting accessibility-related feedback from screen-reader users, we implemented and integrated these interventions into VoxLens (Sharif et al., 2022). We assessed our enhancements through a task-based user study with 10 visualization creators, finding 44\\%, 17\\%, and 12\\% improvements in their understanding of screen-reader users’ challenges with data visualizations, knowledge of visualization accessibility, and perceived usefulness of the enhanced VoxLens, respectively.', 'doi': '10.1145/3663548.3675625', 'url': 'https://doi.org/10.1145/3663548.3675625', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Understanding and Reducing the Challenges Faced by Creators of Accessible Online Data Visualizations', 'author': 'Sharif, Ather and Kim, Joo Gyeong and Xu, Jessie Zijia and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675625'}"
MAIDR Meets AI: Exploring Multimodal LLM-Based Data Visualization Interpretation by and with Blind and Low-Vision Users,10.1145/3663548.3675660,"This paper investigates how blind and low-vision (BLV) users interact with multimodal large language models (LLMs) to interpret data visualizations. Building upon our previous work on the multimodal access and interactive data representation (MAIDR) framework, our mixed-visual-ability team co-designed maidrAI, an LLM extension providing multiple AI responses to users’ visual queries. To explore generative AI-based data representation, we conducted user studies with 8 BLV participants, tasking them with interpreting box plots using our system. We examined how participants personalize LLMs through prompt engineering, their preferences for data visualization descriptions, and strategies for verifying LLM responses. Our findings highlight three dimensions affecting BLV users’ decision-making process: modal preference, LLM customization, and multimodal data representation. This research contributes to designing more accessible data visualization tools for BLV users and advances the understanding of inclusive generative AI applications.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind, Data Visualization, Generative AI, Large Language Models, Low Vision, Multimodality, Screen Readers', 'numpages': '31', 'articleno': '57', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper investigates how blind and low-vision (BLV) users interact with multimodal large language models (LLMs) to interpret data visualizations. Building upon our previous work on the multimodal access and interactive data representation (MAIDR) framework, our mixed-visual-ability team co-designed maidrAI, an LLM extension providing multiple AI responses to users’ visual queries. To explore generative AI-based data representation, we conducted user studies with 8 BLV participants, tasking them with interpreting box plots using our system. We examined how participants personalize LLMs through prompt engineering, their preferences for data visualization descriptions, and strategies for verifying LLM responses. Our findings highlight three dimensions affecting BLV users’ decision-making process: modal preference, LLM customization, and multimodal data representation. This research contributes to designing more accessible data visualization tools for BLV users and advances the understanding of inclusive generative AI applications.', 'doi': '10.1145/3663548.3675660', 'url': 'https://doi.org/10.1145/3663548.3675660', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'MAIDR Meets AI: Exploring Multimodal LLM-Based Data Visualization Interpretation by and with Blind and Low-Vision Users', 'author': 'Seo, JooYoung and Kamath, Sanchita S. and Zeidieh, Aziz and Venkatesh, Saairam and McCurry, Sean', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675660'}"
"Our Stories, Our Data: Co-designing Visualizations with People with Intellectual and Developmental Disabilities",10.1145/3663548.3675615,"Individuals with Intellectual and Developmental Disabilities (IDD) have unique needs and challenges when working with data. While visualization aims to make data more accessible to a broad audience, our understanding of how to design cognitively accessible visualizations remains limited. In this study, we engaged 20 participants with IDD as co-designers to explore how they approach and visualize data. Our preliminary investigation paired four participants as data pen-pals in a six-week online asynchronous participatory design workshop. In response to the observed conceptual, technological, and emotional struggles with data, we subsequently organized a two-day in-person co-design workshop with 16 participants to further understand relevant visualization authoring and sensemaking strategies. Reflecting on how participants engaged with and represented data, we propose two strategies for cognitively accessible data visualizations: transforming numbers into narratives and blending data design with everyday aesthetics. Our findings emphasize the importance of involving individuals with IDD in the design process, demonstrating their capacity for data analysis and expression, and underscoring the need for a narrative and tangible approach to accessible data visualization.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Co-design, Cognitive Accessibility, Data Visualization, Storytelling', 'numpages': '17', 'articleno': '58', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Individuals with Intellectual and Developmental Disabilities (IDD) have unique needs and challenges when working with data. While visualization aims to make data more accessible to a broad audience, our understanding of how to design cognitively accessible visualizations remains limited. In this study, we engaged 20 participants with IDD as co-designers to explore how they approach and visualize data. Our preliminary investigation paired four participants as data pen-pals in a six-week online asynchronous participatory design workshop. In response to the observed conceptual, technological, and emotional struggles with data, we subsequently organized a two-day in-person co-design workshop with 16 participants to further understand relevant visualization authoring and sensemaking strategies. Reflecting on how participants engaged with and represented data, we propose two strategies for cognitively accessible data visualizations: transforming numbers into narratives and blending data design with everyday aesthetics. Our findings emphasize the importance of involving individuals with IDD in the design process, demonstrating their capacity for data analysis and expression, and underscoring the need for a narrative and tangible approach to accessible data visualization.', 'doi': '10.1145/3663548.3675615', 'url': 'https://doi.org/10.1145/3663548.3675615', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Our Stories, Our Data: Co-designing Visualizations with People with Intellectual and Developmental Disabilities', 'author': 'Wu, Keke and Quadri, Ghulam Jilani and Wang, Arran Zeyu and Osei-Tutu, David Kwame and Petersen, Emma and Koushik, Varsha and Szafir, Danielle Albers', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675615'}"
Understanding Low Vision Graphical Perception of Bar Charts,10.1145/3663548.3675616,"Bar charts are widely used for their simplicity in data representation, prompting numerous studies to explore and model how users interact with and perceive bar chart information. However, these studies have predominantly focused on sighted users, with a few also targeting blind screen-reader users, whereas the graphical perception of low-vision screen magnifier users is still an uncharted research territory. We fill this knowledge gap in this paper by designing four experiments for a laboratory study with 25 low-vision participants to examine their graphical perception while interacting with bar charts. For our investigation, we built a custom screen magnifier-based logger that captured micro-interaction details such as zooming and panning. Our findings indicate that low-vision users invest significant time counteracting blurring and contrast effects when analyzing charts. We also observed that low-vision users struggle more in interpreting bars within a single-column stack compared to other stacked bar configurations, and moreover, for a few participants, the perception accuracy is lower when comparing separated bars than when comparing adjacent bars.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Graph perception, Graph usability, Low vision, Screen magnifier', 'numpages': '10', 'articleno': '59', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Bar charts are widely used for their simplicity in data representation, prompting numerous studies to explore and model how users interact with and perceive bar chart information. However, these studies have predominantly focused on sighted users, with a few also targeting blind screen-reader users, whereas the graphical perception of low-vision screen magnifier users is still an uncharted research territory. We fill this knowledge gap in this paper by designing four experiments for a laboratory study with 25 low-vision participants to examine their graphical perception while interacting with bar charts. For our investigation, we built a custom screen magnifier-based logger that captured micro-interaction details such as zooming and panning. Our findings indicate that low-vision users invest significant time counteracting blurring and contrast effects when analyzing charts. We also observed that low-vision users struggle more in interpreting bars within a single-column stack compared to other stacked bar configurations, and moreover, for a few participants, the perception accuracy is lower when comparing separated bars than when comparing adjacent bars.', 'doi': '10.1145/3663548.3675616', 'url': 'https://doi.org/10.1145/3663548.3675616', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Understanding Low Vision Graphical Perception of Bar Charts', 'author': 'Prakash, Yash and Kolgar Nayak, Akshay and Jayarathna, Sampath and Lee, Hae-Na and Ashok, Vikas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675616'}"
AccessShare: Co-designing Data Access and Sharing with Blind People,10.1145/3663548.3675612,"Blind people are often called to contribute image data to datasets for AI innovation with the hope for future accessibility and inclusion. Yet, the visual inspection of the contributed images is inaccessible. To this day, we lack mechanisms for data inspection and control that are accessible to the blind community. To address this gap, we engage 10 blind participants in a scenario where they wear smartglasses and collect image data using an AI-infused application in their homes. We also engineer a design probe, a novel data access interface called AccessShare, and conduct a co-design study to discuss participants’ needs, preferences, and ideas on consent, data inspection, and control. Our findings reveal the impact of interactive informed consent and the complementary role of data inspection systems such as AccessShare in facilitating communication between data stewards and blind data contributors. We discuss how key insights can guide future informed consent and data control to promote inclusive and responsible data practices in AI.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '16', 'articleno': '60', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind people are often called to contribute image data to datasets for AI innovation with the hope for future accessibility and inclusion. Yet, the visual inspection of the contributed images is inaccessible. To this day, we lack mechanisms for data inspection and control that are accessible to the blind community. To address this gap, we engage 10 blind participants in a scenario where they wear smartglasses and collect image data using an AI-infused application in their homes. We also engineer a design probe, a novel data access interface called AccessShare, and conduct a co-design study to discuss participants’ needs, preferences, and ideas on consent, data inspection, and control. Our findings reveal the impact of interactive informed consent and the complementary role of data inspection systems such as AccessShare in facilitating communication between data stewards and blind data contributors. We discuss how key insights can guide future informed consent and data control to promote inclusive and responsible data practices in AI.', 'doi': '10.1145/3663548.3675612', 'url': 'https://doi.org/10.1145/3663548.3675612', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'AccessShare: Co-designing Data Access and Sharing with Blind People', 'author': 'Kamikubo, Rie and Zamiri Zeraati, Farnaz and Lee, Kyungjun and Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675612'}"
Misfitting With AI: How Blind People Verify and Contest AI Errors,10.1145/3663548.3675659,"Blind people use artificial intelligence-enabled visual assistance technologies (AI VAT) to gain visual access in their everyday lives, but these technologies are embedded with errors that may be difficult to verify non-visually. Previous studies have primarily explored sighted users’ understanding of AI output and created vision-dependent explainable AI (XAI) features. We extend this body of literature by conducting an in-depth qualitative study with 26 blind people to understand their verification experiences and preferences. We begin by describing errors blind people encounter, highlighting how AI VAT fails to support complex document layouts, diverse languages, and cultural artifacts. We then illuminate how blind people make sense of AI through experimenting with AI VAT, employing non-visual skills, strategically including sighted people, and cross-referencing with other devices. Participants provided detailed opportunities for designing accessible XAI, such as affordances to support contestation. Informed by disability studies framework of misfitting and fitting, we unpacked harmful assumptions with AI VAT, underscoring the importance of celebrating disabled ways of knowing. Lastly, we offer practical takeaways for Responsible AI practice to push the field of accessible XAI forward.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Artificial Intelligence, Be My Eyes, Blind people, Explainability, Seeing AI, Verification, Visual Assistance Technology', 'numpages': '17', 'articleno': '61', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind people use artificial intelligence-enabled visual assistance technologies (AI VAT) to gain visual access in their everyday lives, but these technologies are embedded with errors that may be difficult to verify non-visually. Previous studies have primarily explored sighted users’ understanding of AI output and created vision-dependent explainable AI (XAI) features. We extend this body of literature by conducting an in-depth qualitative study with 26 blind people to understand their verification experiences and preferences. We begin by describing errors blind people encounter, highlighting how AI VAT fails to support complex document layouts, diverse languages, and cultural artifacts. We then illuminate how blind people make sense of AI through experimenting with AI VAT, employing non-visual skills, strategically including sighted people, and cross-referencing with other devices. Participants provided detailed opportunities for designing accessible XAI, such as affordances to support contestation. Informed by disability studies framework of misfitting and fitting, we unpacked harmful assumptions with AI VAT, underscoring the importance of celebrating disabled ways of knowing. Lastly, we offer practical takeaways for Responsible AI practice to push the field of accessible XAI forward.', 'doi': '10.1145/3663548.3675659', 'url': 'https://doi.org/10.1145/3663548.3675659', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Misfitting With AI: How Blind People Verify and Contest AI Errors', 'author': 'Alharbi, Rahaf and Lor, Pa and Herskovitz, Jaylin and Schoenebeck, Sarita and Brewer, Robin N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675659'}"
Context-Aware Image Descriptions for Web Accessibility,10.1145/3663548.3675658,"Blind and low vision (BLV) internet users access images on the web via text descriptions. New vision-to-language models such as GPT-V, Gemini, and LLaVa can now provide detailed image descriptions on-demand. While prior research and guidelines state that BLV audiences’ information preferences depend on the context of the image, existing tools for accessing vision-to-language models provide only context-free image descriptions by generating descriptions for the image alone without considering the surrounding webpage context. To explore how to integrate image context into image descriptions, we designed a Chrome Extension that automatically extracts webpage context to inform GPT-4V-generated image descriptions. We gained feedback from 12 BLV participants in a user study comparing typical context-free image descriptions to context-aware image descriptions. We then further evaluated our context-informed image descriptions with a technical evaluation. Our user evaluation demonstrates that BLV participants frequently prefer context-aware descriptions to context-free descriptions. BLV participants also rate context-aware descriptions significantly higher in quality, imaginability, relevance, and plausibility. All participants shared that they wanted to use context-aware descriptions in the future and highlighted the potential for use in online shopping, social media, news, and personal interest blogs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Context Awareness, Image Descriptions, Text;', 'numpages': '17', 'articleno': '62', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind and low vision (BLV) internet users access images on the web via text descriptions. New vision-to-language models such as GPT-V, Gemini, and LLaVa can now provide detailed image descriptions on-demand. While prior research and guidelines state that BLV audiences’ information preferences depend on the context of the image, existing tools for accessing vision-to-language models provide only context-free image descriptions by generating descriptions for the image alone without considering the surrounding webpage context. To explore how to integrate image context into image descriptions, we designed a Chrome Extension that automatically extracts webpage context to inform GPT-4V-generated image descriptions. We gained feedback from 12 BLV participants in a user study comparing typical context-free image descriptions to context-aware image descriptions. We then further evaluated our context-informed image descriptions with a technical evaluation. Our user evaluation demonstrates that BLV participants frequently prefer context-aware descriptions to context-free descriptions. BLV participants also rate context-aware descriptions significantly higher in quality, imaginability, relevance, and plausibility. All participants shared that they wanted to use context-aware descriptions in the future and highlighted the potential for use in online shopping, social media, news, and personal interest blogs.', 'doi': '10.1145/3663548.3675658', 'url': 'https://doi.org/10.1145/3663548.3675658', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Context-Aware Image Descriptions for Web Accessibility', 'author': 'Gubbi Mohanbabu, Ananya and Pavel, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675658'}"
Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges,10.1145/3663548.3675635,"Object recognition technologies hold the potential to support blind and low-vision people in navigating the world around them. However, the gap between benchmark performances and practical usability remains a significant challenge. This paper presents a study aimed at understanding blind users’ interaction with object recognition systems for identifying and avoiding errors. Leveraging a pre-existing object recognition system, URCam, fine-tuned for our experiment, we conducted a user study involving 12 blind and low-vision participants. Through in-depth interviews and hands-on error identification tasks, we gained insights into users’ experiences, challenges, and strategies for identifying errors in camera-based assistive technologies and object recognition systems. During interviews, many participants preferred independent error review, while expressing apprehension toward misrecognitions. In the error identification task, participants varied viewpoints, backgrounds, and object sizes in their images to avoid and overcome errors. Even after repeating the task, participants identified only half of the errors, and the proportion of errors identified did not significantly differ from their first attempts. Based on these insights, we offer implications for designing accessible interfaces tailored to the needs of blind and low-vision users in identifying object recognition errors.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'blind, camera-based assistive technology, object recognition errors, visual impairment', 'numpages': '15', 'articleno': '63', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Object recognition technologies hold the potential to support blind and low-vision people in navigating the world around them. However, the gap between benchmark performances and practical usability remains a significant challenge. This paper presents a study aimed at understanding blind users’ interaction with object recognition systems for identifying and avoiding errors. Leveraging a pre-existing object recognition system, URCam, fine-tuned for our experiment, we conducted a user study involving 12 blind and low-vision participants. Through in-depth interviews and hands-on error identification tasks, we gained insights into users’ experiences, challenges, and strategies for identifying errors in camera-based assistive technologies and object recognition systems. During interviews, many participants preferred independent error review, while expressing apprehension toward misrecognitions. In the error identification task, participants varied viewpoints, backgrounds, and object sizes in their images to avoid and overcome errors. Even after repeating the task, participants identified only half of the errors, and the proportion of errors identified did not significantly differ from their first attempts. Based on these insights, we offer implications for designing accessible interfaces tailored to the needs of blind and low-vision users in identifying object recognition errors.', 'doi': '10.1145/3663548.3675635', 'url': 'https://doi.org/10.1145/3663548.3675635', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges', 'author': 'Hong, Jonggi and Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675635'}"
"""I look at it as the king of knowledge"": How Blind People Use and Understand Generative AI Tools",10.1145/3663548.3675631,"The proliferation of Generative Artificial Intelligence (GenAI) tools has brought a critical shift in how people approach information retrieval and content creation in diverse contexts. Yet, we have limited understanding of how blind people use and make sense of GenAI systems. To bridge this gap, we report findings from interviews with 19 blind individuals who incorporate mainstream GenAI tools like ChatGPT and Be My AI in their everyday practices. Our findings reveal how blind users navigate accessibility issues, inaccuracies, hallucinations, and idiosyncracies associated with GenAI and develop interesting (but often flawed) mental models of how these tools work. We discuss key considerations for rethinking access and information verification in GenAI tools, unpacking erroneous mental models among blind users, and reconciling harms and benefits of GenAI from an accessibility perspective.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, ChatGPT, Generative AI, blind, visual impairment', 'numpages': '14', 'articleno': '64', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The proliferation of Generative Artificial Intelligence (GenAI) tools has brought a critical shift in how people approach information retrieval and content creation in diverse contexts. Yet, we have limited understanding of how blind people use and make sense of GenAI systems. To bridge this gap, we report findings from interviews with 19 blind individuals who incorporate mainstream GenAI tools like ChatGPT and Be My AI in their everyday practices. Our findings reveal how blind users navigate accessibility issues, inaccuracies, hallucinations, and idiosyncracies associated with GenAI and develop interesting (but often flawed) mental models of how these tools work. We discuss key considerations for rethinking access and information verification in GenAI tools, unpacking erroneous mental models among blind users, and reconciling harms and benefits of GenAI from an accessibility perspective.', 'doi': '10.1145/3663548.3675631', 'url': 'https://doi.org/10.1145/3663548.3675631', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""I look at it as the king of knowledge"": How Blind People Use and Understand Generative AI Tools', 'author': 'Adnin, Rudaiba and Das, Maitraye', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675631'}"
EditScribe: Non-Visual Image Editing with Natural Language Verification Loops,10.1145/3663548.3675599,"Image editing is an iterative process that requires precise visual evaluation and manipulation for the output to match the editing intent. However, current image editing tools do not provide accessible interaction nor sufficient feedback for blind and low vision individuals to achieve this level of control. To address this, we developed EditScribe, a prototype system that makes object-level image editing actions accessible using natural language verification loops powered by large multimodal models. Using EditScribe, the user first comprehends the image content through initial general and object descriptions, then specifies edit actions using open-ended natural language prompts. EditScribe performs the image edit, and provides four types of verification feedback for the user to verify the performed edit, including a summary of visual changes, AI judgement, and updated general and object descriptions. The user can ask follow-up questions to clarify and probe into the edits or verification feedback, before performing another edit. In a study with ten blind or low-vision users, we found that EditScribe supported participants to perform and verify image edit actions non-visually. We observed different prompting strategies from participants, and their perceptions on the various types of verification feedback. Finally, we discuss the implications of leveraging natural language verification loops to make visual authoring non-visually accessible.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, assistive technology, blind, creativity support tools, generative AI, image editing, low vision, visual authoring', 'numpages': '19', 'articleno': '65', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Image editing is an iterative process that requires precise visual evaluation and manipulation for the output to match the editing intent. However, current image editing tools do not provide accessible interaction nor sufficient feedback for blind and low vision individuals to achieve this level of control. To address this, we developed EditScribe, a prototype system that makes object-level image editing actions accessible using natural language verification loops powered by large multimodal models. Using EditScribe, the user first comprehends the image content through initial general and object descriptions, then specifies edit actions using open-ended natural language prompts. EditScribe performs the image edit, and provides four types of verification feedback for the user to verify the performed edit, including a summary of visual changes, AI judgement, and updated general and object descriptions. The user can ask follow-up questions to clarify and probe into the edits or verification feedback, before performing another edit. In a study with ten blind or low-vision users, we found that EditScribe supported participants to perform and verify image edit actions non-visually. We observed different prompting strategies from participants, and their perceptions on the various types of verification feedback. Finally, we discuss the implications of leveraging natural language verification loops to make visual authoring non-visually accessible.', 'doi': '10.1145/3663548.3675599', 'url': 'https://doi.org/10.1145/3663548.3675599', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'EditScribe: Non-Visual Image Editing with Natural Language Verification Loops', 'author': 'Chang, Ruei-Che and Liu, Yuxuan and Zhang, Lotus and Guo, Anhong', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675599'}"
Breaking the News Barrier: Towards Understanding News Consumption Practices among BVI Individuals in India,10.1145/3663548.3675608,"Amidst the shift towards digital news media, the news consumption behavior of the blind and visually impaired (BVI) has undergone significant changes. Despite extensive prior work in HCI and Accessibility literature around digital media accessibility for the BVI community – digital news consumption practices among BVI individuals remain inadequately explored. This study focuses on digital news consumption practices among BVI individuals in India. We conducted semi-structured interviews and contextual inquiry with 17 participants, revealing diverse motivations rooted in social mobility and belongingness. Participants disclosed navigational barriers, such as dynamic advertisements, and consequently relied on volunteer-driven ad-free newspapers as a stopgap. While news source preferences were shaped by interface accessibility, factors like neutrality and coverage played a crucial role too. Our findings highlight the need for a nuanced understanding of BVI users’ experiences and inform implications and recommendations for designing accessible digital news platforms.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind and Visually Impaired, Information Access, News Consumption, Screen Readers', 'numpages': '11', 'articleno': '66', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Amidst the shift towards digital news media, the news consumption behavior of the blind and visually impaired (BVI) has undergone significant changes. Despite extensive prior work in HCI and Accessibility literature around digital media accessibility for the BVI community – digital news consumption practices among BVI individuals remain inadequately explored. This study focuses on digital news consumption practices among BVI individuals in India. We conducted semi-structured interviews and contextual inquiry with 17 participants, revealing diverse motivations rooted in social mobility and belongingness. Participants disclosed navigational barriers, such as dynamic advertisements, and consequently relied on volunteer-driven ad-free newspapers as a stopgap. While news source preferences were shaped by interface accessibility, factors like neutrality and coverage played a crucial role too. Our findings highlight the need for a nuanced understanding of BVI users’ experiences and inform implications and recommendations for designing accessible digital news platforms.', 'doi': '10.1145/3663548.3675608', 'url': 'https://doi.org/10.1145/3663548.3675608', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Breaking the News Barrier: Towards Understanding News Consumption Practices among BVI Individuals in India', 'author': 'Mowar, Peya and Gupta, Meghna and Jain, Mohit', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675608'}"
“Not Only Annoying but Dangerous”: devising an ecology of protections for photosensitive social media users,10.1145/3663548.3675610,"Photosensitivity among social media and internet users is an underappreciated risk factor for real physiological harm which can be actively or passively caused by designer and developer choices. Flashing graphics caused by GIFs, video, or even interface animations can trigger nausea, dizziness, migraines, and even seizures. Although there are some guidelines for protections for photosensitive users in W3C's WCAG, these guidelines are often not met by developers, and are insufficient for robust user protection. In this multi-pronged exploratory research project, we work with photosensitive users, design students, and graphics experts to imagine a complete ecosystem of protections which layer vulnerable users at the community, platform, system, and hardware levels. In this paper, we argue for the urgency of reforms in device and internet infrastructure, development practices, design norms, and community behaviors. We then propose an ecosystem of protections which more holistically shield photosensitive users from ambient, accidental, and malicious exposure to flashing graphics.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '14', 'articleno': '67', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Photosensitivity among social media and internet users is an underappreciated risk factor for real physiological harm which can be actively or passively caused by designer and developer choices. Flashing graphics caused by GIFs, video, or even interface animations can trigger nausea, dizziness, migraines, and even seizures. Although there are some guidelines for protections for photosensitive users in W3C's WCAG, these guidelines are often not met by developers, and are insufficient for robust user protection. In this multi-pronged exploratory research project, we work with photosensitive users, design students, and graphics experts to imagine a complete ecosystem of protections which layer vulnerable users at the community, platform, system, and hardware levels. In this paper, we argue for the urgency of reforms in device and internet infrastructure, development practices, design norms, and community behaviors. We then propose an ecosystem of protections which more holistically shield photosensitive users from ambient, accidental, and malicious exposure to flashing graphics."", 'doi': '10.1145/3663548.3675610', 'url': 'https://doi.org/10.1145/3663548.3675610', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '“Not Only Annoying but Dangerous”: devising an ecology of protections for photosensitive social media users', 'author': 'Williams, Rua Mae and Park, Chorong and Dodhy, Laila Sameer and Pal, Monaami and Dnyanmote, Atharva Anand and Lam, Luchcha Angel and Joo, Sean', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675610'}"
Design considerations for photosensitivity warnings in visual media,10.1145/3663548.3675643,"When digital content is tested for photosensitive safety and is found to contain seizure-inducing strobes or flashing lights, warnings about photosensitive risk are usually shown to the user prior to viewing the content. These photosensitivity warnings are an important accessibility feature for people with photosensitive epilepsy, allowing them to avoid interacting with content that may trigger seizures. However, little is known about how these warnings should be structured to maximize effectiveness in helping with people PSE navigate visual media safely. The design space for photosensitivity warnings is vast and includes questions such as what details to include about strobing light sequences or the content itself, where to place warnings within an interface, and what methods to use to extract information about the strobing light sequences (e.g., crowdsourced or automated methods). In this work, we contribute a thematic analysis of crowdsourced warnings drawn from the DoesTheDogDie online forum and an interview study with five people who have been diagnosed with photosensitive epilepsy about design considerations for photosensitivity warnings on digital platforms. To guide our interviews, we assembled examples of both crowdsourced and automated warnings about seizure-inducing content in films. Automated warnings were presented in the form of a high fidelity sketch demonstrating what an automated system for photosensitivity warnings might look like when deployed by a film streaming platform. We contribute design suggestions for the structure, content, and data sourcing of photosensitivity warnings for visual media based on the findings of our interviews. The results of this work will enable more effective and informative photosensitivity warnings across all forms of digital visual media.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, photosensitive epilepsy, video, warnings', 'numpages': '12', 'articleno': '68', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'When digital content is tested for photosensitive safety and is found to contain seizure-inducing strobes or flashing lights, warnings about photosensitive risk are usually shown to the user prior to viewing the content. These photosensitivity warnings are an important accessibility feature for people with photosensitive epilepsy, allowing them to avoid interacting with content that may trigger seizures. However, little is known about how these warnings should be structured to maximize effectiveness in helping with people PSE navigate visual media safely. The design space for photosensitivity warnings is vast and includes questions such as what details to include about strobing light sequences or the content itself, where to place warnings within an interface, and what methods to use to extract information about the strobing light sequences (e.g., crowdsourced or automated methods). In this work, we contribute a thematic analysis of crowdsourced warnings drawn from the DoesTheDogDie online forum and an interview study with five people who have been diagnosed with photosensitive epilepsy about design considerations for photosensitivity warnings on digital platforms. To guide our interviews, we assembled examples of both crowdsourced and automated warnings about seizure-inducing content in films. Automated warnings were presented in the form of a high fidelity sketch demonstrating what an automated system for photosensitivity warnings might look like when deployed by a film streaming platform. We contribute design suggestions for the structure, content, and data sourcing of photosensitivity warnings for visual media based on the findings of our interviews. The results of this work will enable more effective and informative photosensitivity warnings across all forms of digital visual media.', 'doi': '10.1145/3663548.3675643', 'url': 'https://doi.org/10.1145/3663548.3675643', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Design considerations for photosensitivity warnings in visual media', 'author': 'South, Laura and Yildirim, Caglar and Pavel, Amy and Borkin, Michelle A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675643'}"
Exploring how People with Spinal Cord Injuries Seek Support on Social Media,10.1145/3663548.3675628,"Individuals who have sustained a Spinal Cord Injury (SCI) undergo abrupt changes in their functional abilities, impacting all aspects of their lives and imposing a life-long reliance on assistive tools and support from others. This paper aims to understand individuals’ support-seeking behavior in social media as they adjust to their “new normal”—life with reduced mobility and sensation. To understand their online support-seeking behavior, we conducted content analysis on 960 post-threads from SCI-specific subreddit groups. We found that individuals seek informational and emotional support regardless of injury level and time elapsed since injury. Additionally, individuals seek and receive online informational support concerning assistive logistics, motor-functionality, newly acquired self-care, and daily living activities. Similarly, individuals seek emotional support for motivation, and creating new self-identity. Finally, we discuss how social media support dynamics might facilitate reconstructing self-identity, adopting assistive technology, and improving relationships to help adjust to the “new normal.”","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Online social space, Social support, Spinal Cord Injury', 'numpages': '17', 'articleno': '69', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Individuals who have sustained a Spinal Cord Injury (SCI) undergo abrupt changes in their functional abilities, impacting all aspects of their lives and imposing a life-long reliance on assistive tools and support from others. This paper aims to understand individuals’ support-seeking behavior in social media as they adjust to their “new normal”—life with reduced mobility and sensation. To understand their online support-seeking behavior, we conducted content analysis on 960 post-threads from SCI-specific subreddit groups. We found that individuals seek informational and emotional support regardless of injury level and time elapsed since injury. Additionally, individuals seek and receive online informational support concerning assistive logistics, motor-functionality, newly acquired self-care, and daily living activities. Similarly, individuals seek emotional support for motivation, and creating new self-identity. Finally, we discuss how social media support dynamics might facilitate reconstructing self-identity, adopting assistive technology, and improving relationships to help adjust to the “new normal.”', 'doi': '10.1145/3663548.3675628', 'url': 'https://doi.org/10.1145/3663548.3675628', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring how People with Spinal Cord Injuries Seek Support on Social Media', 'author': 'Motahar, Tamanna and Nurollahian, Sara and Kim, YeonJae and Kogan, Marina and Wiese, Jason', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675628'}"
AltCanvas: A Tile-Based Editor for Visual Content Creation with Generative AI for Blind or Visually Impaired People,10.1145/3663548.3675600,"People with visual impairments often struggle to create content that relies heavily on visual elements, particularly when conveying spatial and structural information. Existing accessible drawing tools, which construct images line by line, are suitable for simple tasks like math but not for more expressive artwork. On the other hand, emerging generative AI-based text-to-image tools can produce expressive illustrations from descriptions in natural language, but they lack precise control over image composition and properties. To address this gap, our work integrates generative AI with a constructive approach that provides users with enhanced control and editing capabilities. Our system, AltCanvas, features a tile-based interface enabling users to construct visual scenes incrementally, with each tile representing an object within the scene. Users can add, edit, move, and arrange objects while receiving speech and audio feedback. Once completed, the scene can be rendered as a color illustration or as a vector for tactile graphic generation. Involving 14 blind or low-vision users in design and evaluation, we found that participants effectively used the AltCanvas’s workflow to create illustrations.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '22', 'articleno': '70', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with visual impairments often struggle to create content that relies heavily on visual elements, particularly when conveying spatial and structural information. Existing accessible drawing tools, which construct images line by line, are suitable for simple tasks like math but not for more expressive artwork. On the other hand, emerging generative AI-based text-to-image tools can produce expressive illustrations from descriptions in natural language, but they lack precise control over image composition and properties. To address this gap, our work integrates generative AI with a constructive approach that provides users with enhanced control and editing capabilities. Our system, AltCanvas, features a tile-based interface enabling users to construct visual scenes incrementally, with each tile representing an object within the scene. Users can add, edit, move, and arrange objects while receiving speech and audio feedback. Once completed, the scene can be rendered as a color illustration or as a vector for tactile graphic generation. Involving 14 blind or low-vision users in design and evaluation, we found that participants effectively used the AltCanvas’s workflow to create illustrations.', 'doi': '10.1145/3663548.3675600', 'url': 'https://doi.org/10.1145/3663548.3675600', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'AltCanvas: A Tile-Based Editor for Visual Content Creation with Generative AI for Blind or Visually Impaired People', 'author': ""Lee, Seonghee and Kohga, Maho and Landau, Steve and O'Modhrain, Sile and Subramonyam, Hari"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675600'}"
"""It's like Goldilocks:"" Bespoke Slides for Fluctuating Audience Access Needs",10.1145/3663548.3675640,"Slide deck accessibility is often studied for people who are blind or visually impaired, but rarely for other people with access needs. We first conducted focus groups with 17 people with slide deck access needs and found that their access needs differed greatly and often conflicted. Moreover, some people’s access needs changed throughout the day (e.g., needing lower contrast colors at night). Therefore, we conducted a design probe with 14 of the existing participants to understand the experience of using a plug-in that lets audience members at a presentation modify a local copy of the slides to meet their accessibility needs. We then interviewed four slide deck authors and presenters to offer a preview of the perspectives that other stakeholders of this tool might have. Finally, we created a functional prototype as a Google Slides plug-in with a subset of the features requested by the participants.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '15', 'articleno': '71', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Slide deck accessibility is often studied for people who are blind or visually impaired, but rarely for other people with access needs. We first conducted focus groups with 17 people with slide deck access needs and found that their access needs differed greatly and often conflicted. Moreover, some people’s access needs changed throughout the day (e.g., needing lower contrast colors at night). Therefore, we conducted a design probe with 14 of the existing participants to understand the experience of using a plug-in that lets audience members at a presentation modify a local copy of the slides to meet their accessibility needs. We then interviewed four slide deck authors and presenters to offer a preview of the perspectives that other stakeholders of this tool might have. Finally, we created a functional prototype as a Google Slides plug-in with a subset of the features requested by the participants.', 'doi': '10.1145/3663548.3675640', 'url': 'https://doi.org/10.1145/3663548.3675640', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""It\'s like Goldilocks:"" Bespoke Slides for Fluctuating Audience Access Needs', 'author': 'Mack, Kelly Avery and Glazko, Kate S and Islam, Jamil and Hofmann, Megan and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675640'}"
“I Try to Represent Myself as I Am”: Self-Presentation Preferences of People with Invisible Disabilities through Embodied Social VR Avatars,10.1145/3663548.3675620,"With the increasing adoption of social virtual reality (VR), it is critical to design inclusive avatars. While researchers have investigated how and why blind and d/Deaf people wish to disclose their disabilities in VR, little is known about the preferences of many others with invisible disabilities (e.g., ADHD, dyslexia, chronic conditions). We filled this gap by interviewing 15 participants, each with one to three invisible disabilities, who represented 22 different invisible disabilities in total. We found that invisibly disabled people approached avatar-based disclosure through contextualized considerations informed by their prior experiences. For example, some wished to use VR’s embodied affordances, such as facial expressions and body language, to dynamically represent their energy level or willingness to engage with others, while others preferred not to disclose their disability identity in any context. We define a binary framework for embodied invisible disability expression (public and private) and discuss three disclosure patterns (Activists, Non-Disclosers, and Situational Disclosers) to inform the design of future inclusive VR experiences.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, avatars, customization, disability disclosure, invisible disabilities, social virtual reality, virtual reality', 'numpages': '15', 'articleno': '72', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'With the increasing adoption of social virtual reality (VR), it is critical to design inclusive avatars. While researchers have investigated how and why blind and d/Deaf people wish to disclose their disabilities in VR, little is known about the preferences of many others with invisible disabilities (e.g., ADHD, dyslexia, chronic conditions). We filled this gap by interviewing 15 participants, each with one to three invisible disabilities, who represented 22 different invisible disabilities in total. We found that invisibly disabled people approached avatar-based disclosure through contextualized considerations informed by their prior experiences. For example, some wished to use VR’s embodied affordances, such as facial expressions and body language, to dynamically represent their energy level or willingness to engage with others, while others preferred not to disclose their disability identity in any context. We define a binary framework for embodied invisible disability expression (public and private) and discuss three disclosure patterns (Activists, Non-Disclosers, and Situational Disclosers) to inform the design of future inclusive VR experiences.', 'doi': '10.1145/3663548.3675620', 'url': 'https://doi.org/10.1145/3663548.3675620', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '“I Try to Represent Myself as I Am”: Self-Presentation Preferences of People with Invisible Disabilities through Embodied Social VR Avatars', 'author': 'Gualano, Ria J. and Jiang, Lucy and Zhang, Kexin and Shende, Tanisha and Won, Andrea Stevenson and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675620'}"
Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models,10.1145/3663548.3675605,"Blind individuals, who by necessity depend on screen readers to interact with computers, face considerable challenges in navigating the diverse and complex graphical user interfaces of different computer applications. The heterogeneity of various application interfaces often requires blind users to remember different keyboard combinations and navigation methods to use each application effectively. To alleviate this significant interaction burden imposed by heterogeneous application interfaces, we present&nbsp;Savant, a novel assistive technology powered by large language models (LLMs) that allows blind screen reader users to interact uniformly with any application interface through natural language. Novelly, Savant can automate a series of tedious screen reader actions on the control elements of the application when prompted by a natural language command from the user. These commands can be flexible in the sense that the user is not strictly required to specify the exact names of the control elements in the command. A user study evaluation of&nbsp;Savant with 11 blind participants demonstrated significant improvements in interaction efficiency and usability compared to current practices.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Assistive technology, Blind users, Computer Interaction, Large language models (LLMs), Uniform interaction', 'numpages': '14', 'articleno': '73', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind individuals, who by necessity depend on screen readers to interact with computers, face considerable challenges in navigating the diverse and complex graphical user interfaces of different computer applications. The heterogeneity of various application interfaces often requires blind users to remember different keyboard combinations and navigation methods to use each application effectively. To alleviate this significant interaction burden imposed by heterogeneous application interfaces, we present&nbsp;Savant, a novel assistive technology powered by large language models (LLMs) that allows blind screen reader users to interact uniformly with any application interface through natural language. Novelly, Savant can automate a series of tedious screen reader actions on the control elements of the application when prompted by a natural language command from the user. These commands can be flexible in the sense that the user is not strictly required to specify the exact names of the control elements in the command. A user study evaluation of&nbsp;Savant with 11 blind participants demonstrated significant improvements in interaction efficiency and usability compared to current practices.', 'doi': '10.1145/3663548.3675605', 'url': 'https://doi.org/10.1145/3663548.3675605', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models', 'author': 'Kodandaram, Satwik Ram and Uckun, Utku and Bi, Xiaojun and Ramakrishnan, IV and Ashok, Vikas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675605'}"
Development and Evaluation of the Mobile Tech Support Questionnaire for Older Adults,10.1145/3663548.3675661,"Despite the soaring rate of mobile device ownership among older adults, a common barrier to their continued mobile use is little to no tech support for learning or troubleshooting the complexities of mobile apps, features, and services. In this paper, using interviews (n = 23) and surveys (n = 259) with older adults, we develop and evaluate the mobile tech support questionnaire (MTSQ). MTSQ measures older adults’ preference for and perceived quality of support during continued mobile tech use. An exploratory factor analysis revealed two dimensions, helpful resources used on one’s own (self-reliant) and help from another person (social). Next, partial least squares structural equation modeling was used to explore the relationship between preference, quality, frequency, and ease of use of mobile tech support. Both preference for and quality of a support type positively influenced how frequently older adults used that type of support and perceived its ease of use.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Older adults, Questionnaire, Scale development, Support preference, Technology support', 'numpages': '18', 'articleno': '74', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite the soaring rate of mobile device ownership among older adults, a common barrier to their continued mobile use is little to no tech support for learning or troubleshooting the complexities of mobile apps, features, and services. In this paper, using interviews (n = 23) and surveys (n = 259) with older adults, we develop and evaluate the mobile tech support questionnaire (MTSQ). MTSQ measures older adults’ preference for and perceived quality of support during continued mobile tech use. An exploratory factor analysis revealed two dimensions, helpful resources used on one’s own (self-reliant) and help from another person (social). Next, partial least squares structural equation modeling was used to explore the relationship between preference, quality, frequency, and ease of use of mobile tech support. Both preference for and quality of a support type positively influenced how frequently older adults used that type of support and perceived its ease of use.', 'doi': '10.1145/3663548.3675661', 'url': 'https://doi.org/10.1145/3663548.3675661', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Development and Evaluation of the Mobile Tech Support Questionnaire for Older Adults', 'author': 'Sharifi, Hasti and Michaelis, Joseph E and Chattopadhyay, Debaleena', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3675661'}"
Informing Accessible Design of AI Literacy Apps through Practices of Blind Parents Reading with Sighted Children,10.1145/3663548.3688482,"Being involved in teaching children to read, especially to decode (i.e., to translate written words to oral speech) is important and crucial to development. There is an increasing number of AI tools and educational apps aimed at teaching sighted children to read. However, many commercial literacy apps are not accessible, few studies of such apps exist, and studies rarely include blind parents as participants. Thus, we conducted an exploratory interview study with four blind parents about their decoding practices with their sighted children, literacy app accessibility, and AI decoding apps. We found that blind parents are motivated to teach their children literacy skills such as decoding; leverage (largely inaccessible) technology and techniques to support decoding; and want to be able to teach alongside the AI literacy apps and to make the AI teach like they do. We conclude with a discussion of design implications for AI literacy apps.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AI, accessibility, blind, books, co-reading, literacy', 'numpages': '5', 'articleno': '75', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Being involved in teaching children to read, especially to decode (i.e., to translate written words to oral speech) is important and crucial to development. There is an increasing number of AI tools and educational apps aimed at teaching sighted children to read. However, many commercial literacy apps are not accessible, few studies of such apps exist, and studies rarely include blind parents as participants. Thus, we conducted an exploratory interview study with four blind parents about their decoding practices with their sighted children, literacy app accessibility, and AI decoding apps. We found that blind parents are motivated to teach their children literacy skills such as decoding; leverage (largely inaccessible) technology and techniques to support decoding; and want to be able to teach alongside the AI literacy apps and to make the AI teach like they do. We conclude with a discussion of design implications for AI literacy apps.', 'doi': '10.1145/3663548.3688482', 'url': 'https://doi.org/10.1145/3663548.3688482', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Informing Accessible Design of AI Literacy Apps through Practices of Blind Parents Reading with Sighted Children', 'author': 'Figueira, Isabela and Cisneros, Josahandi M and Leachman, Molly and Pe\\~{n}a, Elizabeth D and Branham, Stacy M', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688482'}"
Exploring Visual Scanning in Augmented Reality: Perspectives From Deaf and Hard of Hearing Users,10.1145/3663548.3688535,"Sensory-intensive and attention-demanding tasks like visual scanning, interacting with 3D objects, comprehending and following instructions, etc. are becoming more common in Augmented Reality (AR) environments as the technology expands through diverse fields. It is important to understand how these types of tasks are experienced by Deaf and Hard of Hearing (DHH) people, especially if those tasks involve any sound or compete with attention shifts (e.g., observing someone signing) in both real and virtual environments. Our current research specifically aims to identify the challenges that DHH users encounter when engaging in visual scanning in an AR environment. Using Angry Birds AR&nbsp;as a probe in our research, 11 DHH participants, with varying hearing abilities played seven rounds of the game, followed by a short structured interview and a long semi-structured interview. Our findings revealed that subtle audio cues and excessive visual indicators impacted participants’ performances negatively. Additionally, they positioned themselves strategically for maximum spatial awareness but faced challenges with AR visual cues due to the lighting conditions in the real environment. We further suggested design implications such as customizable, user-friendly haptic and textual feedback, and intelligent spatially aware mechanisms for AR.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Augmented Reality, Human-computer Interaction', 'numpages': '6', 'articleno': '76', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sensory-intensive and attention-demanding tasks like visual scanning, interacting with 3D objects, comprehending and following instructions, etc. are becoming more common in Augmented Reality (AR) environments as the technology expands through diverse fields. It is important to understand how these types of tasks are experienced by Deaf and Hard of Hearing (DHH) people, especially if those tasks involve any sound or compete with attention shifts (e.g., observing someone signing) in both real and virtual environments. Our current research specifically aims to identify the challenges that DHH users encounter when engaging in visual scanning in an AR environment. Using Angry Birds AR&nbsp;as a probe in our research, 11 DHH participants, with varying hearing abilities played seven rounds of the game, followed by a short structured interview and a long semi-structured interview. Our findings revealed that subtle audio cues and excessive visual indicators impacted participants’ performances negatively. Additionally, they positioned themselves strategically for maximum spatial awareness but faced challenges with AR visual cues due to the lighting conditions in the real environment. We further suggested design implications such as customizable, user-friendly haptic and textual feedback, and intelligent spatially aware mechanisms for AR.', 'doi': '10.1145/3663548.3688535', 'url': 'https://doi.org/10.1145/3663548.3688535', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring Visual Scanning in Augmented Reality: Perspectives From Deaf and Hard of Hearing Users', 'author': 'Luna, Sanzida Mojib and Tigwell, Garreth W. and Papangelis, Konstantinos and Xu, Jiangnan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688535'}"
Co-designing a 3D-Printed Tactile Campus Map With Blind and Low-Vision University Students,10.1145/3663548.3688537,"Blind and low-vision (BLV) university students often encounter campus accessibility challenges that impede their ability to navigate campus environments effectively. The lack of customization offered by some navigational-focused assistive technologies (ATs) often falls short in addressing their diverse and specific navigational needs. 3D printing, a promising tool for creating affordable and personalized aids, has been explored as a method to create customized tactile maps to aid BLV individuals with general navigation. However, the use of 3D-printed tactile maps by BLV university students and the impact of their direct involvement in the design process remain largely unexplored. We employed a participatory design (PD) approach to engage BLV students from a university in the United States (U.S.) through semi-structured interviews and a co-design session to create a prototype 3D-printed tactile map. Additionally, we consulted with a blind rehabilitation and independence expert for insight into their perspective on AT and, more specifically, tactile maps and showed the prototype to a group of visually impaired youth and instructors visiting our university for feedback. We present and discuss our findings, provide an overview of the prototype design process, and outline future work.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': '3D printing, assistive technology, higher education, participatory design', 'numpages': '6', 'articleno': '77', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind and low-vision (BLV) university students often encounter campus accessibility challenges that impede their ability to navigate campus environments effectively. The lack of customization offered by some navigational-focused assistive technologies (ATs) often falls short in addressing their diverse and specific navigational needs. 3D printing, a promising tool for creating affordable and personalized aids, has been explored as a method to create customized tactile maps to aid BLV individuals with general navigation. However, the use of 3D-printed tactile maps by BLV university students and the impact of their direct involvement in the design process remain largely unexplored. We employed a participatory design (PD) approach to engage BLV students from a university in the United States (U.S.) through semi-structured interviews and a co-design session to create a prototype 3D-printed tactile map. Additionally, we consulted with a blind rehabilitation and independence expert for insight into their perspective on AT and, more specifically, tactile maps and showed the prototype to a group of visually impaired youth and instructors visiting our university for feedback. We present and discuss our findings, provide an overview of the prototype design process, and outline future work.', 'doi': '10.1145/3663548.3688537', 'url': 'https://doi.org/10.1145/3663548.3688537', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Co-designing a 3D-Printed Tactile Campus Map With Blind and Low-Vision University Students', 'author': 'Crawford, Kirk Andrew and Posada, Jennifer and Okueso, Yetunde Esther and Higgins, Erin and Lachin, Laura and Hamidi, Foad', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688537'}"
Impact of Level-up Element in Development of Exergame for Preventing Prolonged Orthostatic Dysregulation,10.1145/3663548.3688484,"We developed an exergame to reduce exercise resistance and maintain motivation in adolescents with orthostatic dysregulation (OD). The 2D side-scrolling action game was played on a smartphone and synchronized with leg exercises in lying and sitting positions, which are considered effective in the treatment of OD. Furthermore, we conducted a three-week experiment with nine healthy participants to verify the relationship between the level-up element of the player character in the game and the players’ playing styles, including playing time and frequency.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'exergame, orthostatic dysregulation, serious game', 'numpages': '4', 'articleno': '78', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We developed an exergame to reduce exercise resistance and maintain motivation in adolescents with orthostatic dysregulation (OD). The 2D side-scrolling action game was played on a smartphone and synchronized with leg exercises in lying and sitting positions, which are considered effective in the treatment of OD. Furthermore, we conducted a three-week experiment with nine healthy participants to verify the relationship between the level-up element of the player character in the game and the players’ playing styles, including playing time and frequency.', 'doi': '10.1145/3663548.3688484', 'url': 'https://doi.org/10.1145/3663548.3688484', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Impact of Level-up Element in Development of Exergame for Preventing Prolonged Orthostatic Dysregulation', 'author': 'Miyazaki, Hitomi and Kurihara, Wataru and Han, Xu and Sakaguchi, Saki and Shibasaki, Mina and Kushiyama, Kumiko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688484'}"
Hevelius Report: Visualizing Web-Based Mobility Test Data For Clinical Decision and Learning Support,10.1145/3663548.3688490,"Hevelius, a web-based computer mouse test, measures arm movement and has been shown to accurately evaluate severity for patients with Parkinson’s disease and ataxias. A Hevelius session produces 32 numeric features, which may be hard to interpret, especially in time-constrained clinical settings. This work aims to support clinicians (and other stakeholders) in interpreting and connecting Hevelius features to clinical concepts. Through an iterative design process, we developed a visualization tool (Hevelius Report) that (1) abstracts six clinically relevant concepts from 32 features, (2) visualizes patient test results, and compares them to results from healthy controls and other patients, and (3) is an interactive app to meet the specific needs in different usage scenarios. Then, we conducted a preliminary user study through an online interview with three clinicians who were not involved in the project. They expressed interest in using Hevelius Report, especially for identifying subtle changes in their patients’ mobility that are hard to capture with existing clinical tests. Future work will integrate the visualization tool into the current clinical workflow of a neurology team and conduct systematic evaluations of the tool’s usefulness, usability, and effectiveness. Hevelius Report represents a promising solution for analyzing fine-motor test results and monitoring patients’ conditions and progressions.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Ataxia, Clinical decision-making, Digital phenotyping, Mobility impairment, Parkinson’s disease', 'numpages': '10', 'articleno': '79', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Hevelius, a web-based computer mouse test, measures arm movement and has been shown to accurately evaluate severity for patients with Parkinson’s disease and ataxias. A Hevelius session produces 32 numeric features, which may be hard to interpret, especially in time-constrained clinical settings. This work aims to support clinicians (and other stakeholders) in interpreting and connecting Hevelius features to clinical concepts. Through an iterative design process, we developed a visualization tool (Hevelius Report) that (1) abstracts six clinically relevant concepts from 32 features, (2) visualizes patient test results, and compares them to results from healthy controls and other patients, and (3) is an interactive app to meet the specific needs in different usage scenarios. Then, we conducted a preliminary user study through an online interview with three clinicians who were not involved in the project. They expressed interest in using Hevelius Report, especially for identifying subtle changes in their patients’ mobility that are hard to capture with existing clinical tests. Future work will integrate the visualization tool into the current clinical workflow of a neurology team and conduct systematic evaluations of the tool’s usefulness, usability, and effectiveness. Hevelius Report represents a promising solution for analyzing fine-motor test results and monitoring patients’ conditions and progressions.', 'doi': '10.1145/3663548.3688490', 'url': 'https://doi.org/10.1145/3663548.3688490', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Hevelius Report: Visualizing Web-Based Mobility Test Data For Clinical Decision and Learning Support', 'author': 'Lin, Hongjin and Han, Tessa and Gajos, Krzysztof Z. and Gupta, Anoopum S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688490'}"
Identifying Crucial Objects in Blind and Low-Vision Individuals' Navigation,10.1145/3663548.3688538,"This paper presents a curated list of 90 objects essential for the navigation of blind and low-vision (BLV) individuals, encompassing road, sidewalk, and indoor environments. We develop the initial list by analyzing 21 publicly available videos featuring BLV individuals navigating various settings. Then, we refine the list through feedback from a focus group study involving blind, low-vision, and sighted companions of BLV individuals. A subsequent analysis reveals that most contemporary datasets used to train recent computer vision models contain only a small subset of the objects in our proposed list. Furthermore, we provide detailed object labeling for these 90 objects across 31 video segments derived from the original 21 videos. Finally, we make the object list, the 21 videos, and object labeling in the 31 video segments publicly available. This paper aims to fill the existing gap and foster the development of more inclusive and effective navigation aids for the BLV community.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '8', 'articleno': '80', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents a curated list of 90 objects essential for the navigation of blind and low-vision (BLV) individuals, encompassing road, sidewalk, and indoor environments. We develop the initial list by analyzing 21 publicly available videos featuring BLV individuals navigating various settings. Then, we refine the list through feedback from a focus group study involving blind, low-vision, and sighted companions of BLV individuals. A subsequent analysis reveals that most contemporary datasets used to train recent computer vision models contain only a small subset of the objects in our proposed list. Furthermore, we provide detailed object labeling for these 90 objects across 31 video segments derived from the original 21 videos. Finally, we make the object list, the 21 videos, and object labeling in the 31 video segments publicly available. This paper aims to fill the existing gap and foster the development of more inclusive and effective navigation aids for the BLV community.', 'doi': '10.1145/3663548.3688538', 'url': 'https://doi.org/10.1145/3663548.3688538', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""Identifying Crucial Objects in Blind and Low-Vision Individuals' Navigation"", 'author': 'Islam, Md Touhidul and Kabir, Imran and Pearce, Elena Ariel and Reza, Md Alimoor and Billah, Syed Masum', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688538'}"
Exploring Older Adults' Reminiscing with ChatGPT and Text-to-Image Technology,10.1145/3663548.3688521,"As individuals enter their later years, they often reminisce about their past, which can significantly enhance their well-being. Current research on technology-mediated reminiscence in HCI tends to position older adults as passive subjects in reminiscence activities, with limited focus on their role as active narrators. In this study, we would to explore the potential of Generative AI, specifically through ""generative dialogue"" and ""text-to-image"" technologies, as a ""listener"" for older adults’ reminiscing storytelling. We conducted an experiment with seven older adults using ChatGPT to generate questions to elicit detailed narratives, and the stories were used to create corresponding images. We propose systematic influential factors and corresponding design guidelines tailored to the storytelling behaviors of older adults.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Generative AI, Older Adults, Reminiscing Storytelling', 'numpages': '7', 'articleno': '81', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'As individuals enter their later years, they often reminisce about their past, which can significantly enhance their well-being. Current research on technology-mediated reminiscence in HCI tends to position older adults as passive subjects in reminiscence activities, with limited focus on their role as active narrators. In this study, we would to explore the potential of Generative AI, specifically through ""generative dialogue"" and ""text-to-image"" technologies, as a ""listener"" for older adults’ reminiscing storytelling. We conducted an experiment with seven older adults using ChatGPT to generate questions to elicit detailed narratives, and the stories were used to create corresponding images. We propose systematic influential factors and corresponding design guidelines tailored to the storytelling behaviors of older adults.', 'doi': '10.1145/3663548.3688521', 'url': 'https://doi.org/10.1145/3663548.3688521', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""Exploring Older Adults' Reminiscing with ChatGPT and Text-to-Image Technology"", 'author': 'Zhai, Yuxiang and Zhang, Jiawen and Jeung, Jihong', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688521'}"
ZINinNGT: A Mobile Tool to Aid Hearing Parents Learning Dutch Sign Language,10.1145/3663548.3688529,"This study examines the potential of the ZINinNGT app, a mobile learning application designed to support hearing parents of deaf and hard-of-hearing (DHH) children in learning Dutch Sign Language. We conducted interviews with ten parents to investigate their current sign language learning experiences and to gather feedback on the ZINinNGT prototype. While results indicated that an app cannot overcome many of the challenges parents face, parents still expressed a very positive attitude towards using a sign language learning app. Feedback on the ZINinNGT prototype identified the need for enhanced usability and a desire to include quizzes and information on the handshapes of signs. Overall, feedback was very positive, indicating that a mobile app has the potential to support hearing parents by providing relevant content going beyond vocabulary level.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '82', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study examines the potential of the ZINinNGT app, a mobile learning application designed to support hearing parents of deaf and hard-of-hearing (DHH) children in learning Dutch Sign Language. We conducted interviews with ten parents to investigate their current sign language learning experiences and to gather feedback on the ZINinNGT prototype. While results indicated that an app cannot overcome many of the challenges parents face, parents still expressed a very positive attitude towards using a sign language learning app. Feedback on the ZINinNGT prototype identified the need for enhanced usability and a desire to include quizzes and information on the handshapes of signs. Overall, feedback was very positive, indicating that a mobile app has the potential to support hearing parents by providing relevant content going beyond vocabulary level.', 'doi': '10.1145/3663548.3688529', 'url': 'https://doi.org/10.1145/3663548.3688529', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'ZINinNGT: A Mobile Tool to Aid Hearing Parents Learning Dutch Sign Language', 'author': 'Ritmeester, Jos and S\\""{u}mer, Beyza and Boonstra, Marije and de Meulder, Maartje and van der Aa, Belinda and Roelofsen, Floris', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688529'}"
Experiencing Deaf Tech: A Deep Dive into the Concept of DeafWatch,10.1145/3663548.3688483,"In the era of ubiquitous information technologies shaping our everyday lives, the advancements of technologies ‘for the deaf’ have provided significant access for deaf users not only for participation in hearing-dominated environments but also within deaf communities. However, since these technologies have predominantly been developed through implicit hearing-centered design that puts deaf experiences second, they often require deaf users to adapt to them. This poster provokes the question: what would technologies look like if they centered on the experiences and desires of deaf people instead? By employing a case study from broader ongoing research on Deaf Tech, we investigate and discusse insights garnered from the concept of DeafWatch developed in one of the workshops. Through our analysis, we aim to tentatively move forward in providing different socio-technical narratives from a deaf-centered perspective.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Case Study, Deaf Technology, Design', 'numpages': '4', 'articleno': '83', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In the era of ubiquitous information technologies shaping our everyday lives, the advancements of technologies ‘for the deaf’ have provided significant access for deaf users not only for participation in hearing-dominated environments but also within deaf communities. However, since these technologies have predominantly been developed through implicit hearing-centered design that puts deaf experiences second, they often require deaf users to adapt to them. This poster provokes the question: what would technologies look like if they centered on the experiences and desires of deaf people instead? By employing a case study from broader ongoing research on Deaf Tech, we investigate and discusse insights garnered from the concept of DeafWatch developed in one of the workshops. Through our analysis, we aim to tentatively move forward in providing different socio-technical narratives from a deaf-centered perspective.', 'doi': '10.1145/3663548.3688483', 'url': 'https://doi.org/10.1145/3663548.3688483', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Experiencing Deaf Tech: A Deep Dive into the Concept of DeafWatch', 'author': 'Angelini, Robin and Spiel, Katta and De Meulder, Maartje', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688483'}"
Designing HMI for BVI Users in Fully Automated Vehicles: A Participatory and In-the-field Approach,10.1145/3663548.3688507,"Fully Automated Vehicles (FAVs) have the potential to provide blind and visually impaired (BVI) individuals with mobility independence. However, understanding their user experience in this new form of transportation presents challenges. Researchers in human-computer interaction and accessibility lack comprehensive guidance on conducting safe and ecologically valid studies with BVI participants. This poster reviews the literature and proposes a methodology for conducting field research with BVI users in automated vehicles, particularly in designing the human-machine interface (HMI) for FAVs. We present the participatory and in-the-field method with example study designs: a focus group for field study and an on-road driving study with a Wizard of Oz FAV. This method will assist researchers in gaining deeper insights into the interaction between BVI users and automated vehicles in the real world.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Fully automated vehicles, Wizard of Oz study, blind and visual impaired, focus group', 'numpages': '5', 'articleno': '84', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Fully Automated Vehicles (FAVs) have the potential to provide blind and visually impaired (BVI) individuals with mobility independence. However, understanding their user experience in this new form of transportation presents challenges. Researchers in human-computer interaction and accessibility lack comprehensive guidance on conducting safe and ecologically valid studies with BVI participants. This poster reviews the literature and proposes a methodology for conducting field research with BVI users in automated vehicles, particularly in designing the human-machine interface (HMI) for FAVs. We present the participatory and in-the-field method with example study designs: a focus group for field study and an on-road driving study with a Wizard of Oz FAV. This method will assist researchers in gaining deeper insights into the interaction between BVI users and automated vehicles in the real world.', 'doi': '10.1145/3663548.3688507', 'url': 'https://doi.org/10.1145/3663548.3688507', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Designing HMI for BVI Users in Fully Automated Vehicles: A Participatory and In-the-field Approach', 'author': 'Ma, Zhengtao and Schroeter, Ronald and Gomez, Rafael', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688507'}"
Exploring Conversations between a Practitioner and a Person with Dementia,10.1145/3663548.3688523,"In social service centers, practitioners engage in conversations with clients with dementia to facilitate their daily activities and provide support when they are distressed. However, the nature of the care demands the practitioner’s active engagement, which becomes difficult to deliver as the number of people who need care expands. Researchers have been investigating the efficacy of developing agents that assume conversational tasks to alleviate this work. To contribute to the future design of agents for caregiving, we collected and analyzed ten conversations between clients with mild dementia and practitioners who provide care. Our analyses of turn-taking dynamics and dialogue acts with 15k utterances uncovered patterns such as noticeable differences in clients’ and practitioners’ conversational dynamics and the prevalence of neutral-toned, question-oriented utterances by practitioners. We then prototyped a large language model-based script that generates responses to client utterances. We found potential approaches and challenges for making its utterance pattern more similar to that of a practitioner.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '85', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In social service centers, practitioners engage in conversations with clients with dementia to facilitate their daily activities and provide support when they are distressed. However, the nature of the care demands the practitioner’s active engagement, which becomes difficult to deliver as the number of people who need care expands. Researchers have been investigating the efficacy of developing agents that assume conversational tasks to alleviate this work. To contribute to the future design of agents for caregiving, we collected and analyzed ten conversations between clients with mild dementia and practitioners who provide care. Our analyses of turn-taking dynamics and dialogue acts with 15k utterances uncovered patterns such as noticeable differences in clients’ and practitioners’ conversational dynamics and the prevalence of neutral-toned, question-oriented utterances by practitioners. We then prototyped a large language model-based script that generates responses to client utterances. We found potential approaches and challenges for making its utterance pattern more similar to that of a practitioner.', 'doi': '10.1145/3663548.3688523', 'url': 'https://doi.org/10.1145/3663548.3688523', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring Conversations between a Practitioner and a Person with Dementia', 'author': 'Hara, Kotaro and Natalie, Rosiana and Cheong, Wei Soon and Gu, Jingjing and Xu, Qianli', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688523'}"
RAIS: Towards A Robotic Mapping and Assessment Tool for Indoor Accessibility Using Commodity Hardware,10.1145/3663548.3688512,"Mapping, assessing, and creating personalized routes of indoor spaces for people with disabilities remains a grand challenge in accessibility research. Drawing on recent work in robotics as well as emergent work in smartphone-based mapping, we introduce RAIS (Robotic Accessibility Indoor Scanner), a robotic-based indoor mapping and accessibility assessment system. As a rapid prototype, RAIS is constructed with off-the-shelf components including a vacuum robot, smartphone, and phone gimbal along with a modified version of our previous LiDAR-based accessibility scannar RASSAR. In a preliminary evaluation of three indoor spaces, we demonstrate RAIS’s ability to autonomously scan spaces, produce detailed 3D reconstructions, and find and highlight accessibility issues.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Indoor accessibility mapping, LiDAR, computer vision, indoor accessibility assessment, map generation', 'numpages': '5', 'articleno': '86', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Mapping, assessing, and creating personalized routes of indoor spaces for people with disabilities remains a grand challenge in accessibility research. Drawing on recent work in robotics as well as emergent work in smartphone-based mapping, we introduce RAIS (Robotic Accessibility Indoor Scanner), a robotic-based indoor mapping and accessibility assessment system. As a rapid prototype, RAIS is constructed with off-the-shelf components including a vacuum robot, smartphone, and phone gimbal along with a modified version of our previous LiDAR-based accessibility scannar RASSAR. In a preliminary evaluation of three indoor spaces, we demonstrate RAIS’s ability to autonomously scan spaces, produce detailed 3D reconstructions, and find and highlight accessibility issues.', 'doi': '10.1145/3663548.3688512', 'url': 'https://doi.org/10.1145/3663548.3688512', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'RAIS: Towards A Robotic Mapping and Assessment Tool for Indoor Accessibility Using Commodity Hardware', 'author': 'Su, Xia and Campos Zamora, Daniel and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688512'}"
Inclusive esports: Sense of Agency and Fairness through Pre-Training-Based Assistive Methods,10.1145/3663548.3688488,"Esports strengthen connections with society for people with disabilities. However, due to the competitive nature of the gaming industry, many games are not sufficiently playable for individuals with upper limb disabilities. Additionally, unlike non-esports games, esports involves competition through gaming, which means that unconditional assistance for players with disabilities can evoke a sense of unfairness among able-bodied players. To address this problem, we propose an esports support method for players with upper limb disabilities that provides skill assistance based on pre-training. The proposed method is designed so that the assistance is triggered by user actions, and the degree of assistance reflects the user’s prior training. This approach aims to reduce the perceived unfairness of assistance while preserving a sense of agency. Interview survey results suggest that appropriate assistance levels can maintain this sense of agency. However, achieving complete fairness remains challenging.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'esports, skill assistance, upper limb disabilities', 'numpages': '4', 'articleno': '87', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Esports strengthen connections with society for people with disabilities. However, due to the competitive nature of the gaming industry, many games are not sufficiently playable for individuals with upper limb disabilities. Additionally, unlike non-esports games, esports involves competition through gaming, which means that unconditional assistance for players with disabilities can evoke a sense of unfairness among able-bodied players. To address this problem, we propose an esports support method for players with upper limb disabilities that provides skill assistance based on pre-training. The proposed method is designed so that the assistance is triggered by user actions, and the degree of assistance reflects the user’s prior training. This approach aims to reduce the perceived unfairness of assistance while preserving a sense of agency. Interview survey results suggest that appropriate assistance levels can maintain this sense of agency. However, achieving complete fairness remains challenging.', 'doi': '10.1145/3663548.3688488', 'url': 'https://doi.org/10.1145/3663548.3688488', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Inclusive esports: Sense of Agency and Fairness through Pre-Training-Based Assistive Methods', 'author': 'Sako, Shuto and Ikeda, Tomoki and Aoki, Ryosuke and Miyata, Akihiro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688488'}"
Playing Without Barriers: Crafting Playful and Accessible VR Table-Tennis with and for Blind and Low-Vision Individuals,10.1145/3663548.3688526,"Virtual reality (VR) has been celebrated for its immersive experiences, yet its potential for creating accessible and enjoyable environments for Blind and Low-Vision (BLV) individuals remains underexplored. Our project addresses this gap by developing a VR table tennis game specifically designed for BLV players. Utilizing an autoethnographic approach, our mixed-ability team, including three BLV co-designers, prototyped the game through rapid iterative testing and evaluation over four months. We integrated multi-sensory feedback mechanisms, such as spatial audio, haptic feedback, and high-contrast visuals, to enhance navigation and interaction. Our findings highlight the effectiveness of combining these modalities to create an enjoyable and realistic VR sports experience. However, we also identified challenges, such as the need for balanced sensory feedback to avoid overload. This study emphasizes the importance of inclusive design in VR gaming, offering new recreational opportunities for BLV individuals and setting the stage for future advancements in accessible VR technology.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessible gaming, haptics, spatial computing, unity, virtual reality', 'numpages': '5', 'articleno': '88', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Virtual reality (VR) has been celebrated for its immersive experiences, yet its potential for creating accessible and enjoyable environments for Blind and Low-Vision (BLV) individuals remains underexplored. Our project addresses this gap by developing a VR table tennis game specifically designed for BLV players. Utilizing an autoethnographic approach, our mixed-ability team, including three BLV co-designers, prototyped the game through rapid iterative testing and evaluation over four months. We integrated multi-sensory feedback mechanisms, such as spatial audio, haptic feedback, and high-contrast visuals, to enhance navigation and interaction. Our findings highlight the effectiveness of combining these modalities to create an enjoyable and realistic VR sports experience. However, we also identified challenges, such as the need for balanced sensory feedback to avoid overload. This study emphasizes the importance of inclusive design in VR gaming, offering new recreational opportunities for BLV individuals and setting the stage for future advancements in accessible VR technology.', 'doi': '10.1145/3663548.3688526', 'url': 'https://doi.org/10.1145/3663548.3688526', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Playing Without Barriers: Crafting Playful and Accessible VR Table-Tennis with and for Blind and Low-Vision Individuals', 'author': 'Kamath, Sanchita S. and Zeidieh, Aziz and Khan, Omar and Sethi, Dhruv and Seo, JooYoung', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688526'}"
MULTICOLLAB-ASL: Towards Affective Computing for the Deaf Community,10.1145/3663548.3688500,"In American Sign Language (ASL), a prominent resource gap exists for affective computing datasets. This manuscript explores preliminary findings from an ongoing multimodal ASL corpus collection and analysis study, focusing on human-generated modalities (e.g., eye tracking, facial expression, head movement) and the expression of frustration and confusion among deaf and hard of hearing study participants. These affective states can be important for understanding user experiences in human-computer interaction or for offering system feedback towards enhancing AI-human collaboration. Expanding a data collection methodology from prior work involving English-speaking participants, this exploratory study seeks to discern characteristics associated with confused or frustrated affect states in collected signed language interactions. Such insights have the potential to facilitate the development of models capable of recognizing emotional expressions. Initial results reveal distinctions in the characteristics of self-annotated instances of participant frustration and confusion, with certain features showing some divergence between the two emotions.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ASL, affective computing, deaf and hard of hearing, multimodalilty', 'numpages': '5', 'articleno': '89', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In American Sign Language (ASL), a prominent resource gap exists for affective computing datasets. This manuscript explores preliminary findings from an ongoing multimodal ASL corpus collection and analysis study, focusing on human-generated modalities (e.g., eye tracking, facial expression, head movement) and the expression of frustration and confusion among deaf and hard of hearing study participants. These affective states can be important for understanding user experiences in human-computer interaction or for offering system feedback towards enhancing AI-human collaboration. Expanding a data collection methodology from prior work involving English-speaking participants, this exploratory study seeks to discern characteristics associated with confused or frustrated affect states in collected signed language interactions. Such insights have the potential to facilitate the development of models capable of recognizing emotional expressions. Initial results reveal distinctions in the characteristics of self-annotated instances of participant frustration and confusion, with certain features showing some divergence between the two emotions.', 'doi': '10.1145/3663548.3688500', 'url': 'https://doi.org/10.1145/3663548.3688500', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'MULTICOLLAB-ASL: Towards Affective Computing for the Deaf Community', 'author': 'Orr, Hayden and Peechatt, Michael and Alm, Cecilia Ovesdotter', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688500'}"
"""It's Better to be Grounded in Reality"": a Speculative Exploration of Patient-Centered Digital Phenotyping for Neurological Conditions",10.1145/3663548.3688486,"Digital phenotyping in clinical research provides objective measures when evaluating neurological conditions, such as ataxias and Parkinson’s disease. While the clinical validity of digital phenotyping data is yet to be fully determined, individual research results are not reported back to participants due to apprehension about how complex data types should be represented, the manner in which results should be communicated to patients, and the possibility of uncertain results being misinterpreted. However, researchers are calling for individual results to be made available to participants, respecting participants’ ownership of their quantified selves and improving transparency of research practices. To investigate how patients with progressive conditions might value seeing their data, we are conducting an interview study with neurology patients who have participated in digital phenotyping. We report initial findings from four participants, who expressed interest in using digital phenotyping data to 1) motivate their care, 2) make perception of their condition concrete, 3) reduce labor in tracking and communicating their condition, and 4) perceive their contributions to clinical research. This work points to exciting potential of patient-centered digital phenotyping to benefit patients’ understanding of themselves, and push forward a paradigm of ethical data report-back.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Ataxia, Digital phenotyping, Parkinson’s disease, ethics, mobility impairment, neurology', 'numpages': '5', 'articleno': '90', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Digital phenotyping in clinical research provides objective measures when evaluating neurological conditions, such as ataxias and Parkinson’s disease. While the clinical validity of digital phenotyping data is yet to be fully determined, individual research results are not reported back to participants due to apprehension about how complex data types should be represented, the manner in which results should be communicated to patients, and the possibility of uncertain results being misinterpreted. However, researchers are calling for individual results to be made available to participants, respecting participants’ ownership of their quantified selves and improving transparency of research practices. To investigate how patients with progressive conditions might value seeing their data, we are conducting an interview study with neurology patients who have participated in digital phenotyping. We report initial findings from four participants, who expressed interest in using digital phenotyping data to 1) motivate their care, 2) make perception of their condition concrete, 3) reduce labor in tracking and communicating their condition, and 4) perceive their contributions to clinical research. This work points to exciting potential of patient-centered digital phenotyping to benefit patients’ understanding of themselves, and push forward a paradigm of ethical data report-back.', 'doi': '10.1145/3663548.3688486', 'url': 'https://doi.org/10.1145/3663548.3688486', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': '""It\'s Better to be Grounded in Reality"": a Speculative Exploration of Patient-Centered Digital Phenotyping for Neurological Conditions', 'author': 'So, Jianna and Yang, Faye X. and Gupta, Anoopum S. and Gajos, Krzysztof Z.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688486'}"
"Receptive Design Methodologies: Human-Centered Design methodologies receptive to adaptation, accessibility and inclusion.",10.1145/3663548.3688530,"Designing for accessibility involves integrated theories from Human-Centered Design(HCD), accessibility research, disability studies, occupational therapy(OT) and assistive technology(AT) development. Aligning on a unified inclusive design process is challenging due to numerous roadblocks such as limited access to people with disabilities, insufficient tools and methodologies for designers and inadequate design training among clinicians. This paper explores the gaps in these interconnected fields and proposes a new approach to bridge these gaps. By focusing on designing based on body functions, the paper introduces new terminologies (functional affordances, breakdown scenarios) and methodologies (extended task analysis, task-ability statements, extended SCAMPER) to compliment ‘designing for many’ and ‘adapting for one’. ‘How do we adapt for many?’","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ADL, Accessibility, Adaptation, Assistive Technology, Design, Disability, Inclusion, Methodologies', 'numpages': '4', 'articleno': '91', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Designing for accessibility involves integrated theories from Human-Centered Design(HCD), accessibility research, disability studies, occupational therapy(OT) and assistive technology(AT) development. Aligning on a unified inclusive design process is challenging due to numerous roadblocks such as limited access to people with disabilities, insufficient tools and methodologies for designers and inadequate design training among clinicians. This paper explores the gaps in these interconnected fields and proposes a new approach to bridge these gaps. By focusing on designing based on body functions, the paper introduces new terminologies (functional affordances, breakdown scenarios) and methodologies (extended task analysis, task-ability statements, extended SCAMPER) to compliment ‘designing for many’ and ‘adapting for one’. ‘How do we adapt for many?’', 'doi': '10.1145/3663548.3688530', 'url': 'https://doi.org/10.1145/3663548.3688530', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Receptive Design Methodologies: Human-Centered Design methodologies receptive to adaptation, accessibility and inclusion.', 'author': 'Avadhana, Apoorva', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688530'}"
Workshop as an Educational Intervention: Improving the Knowledge and Understanding of Data Visualization Accessibility for Visualization Creators,10.1145/3663548.3688489,"Enhancing visualization creators’ knowledge and understanding of the accessibility of data visualizations remains a critical step toward reducing the digital divide screen-reader users experience. Recently, Sharif et al. shed light on the challenges visualization creators face with making data visualizations accessible to screen-reader users, identifying four technological interventions and one educational intervention (i.e., workshops) to minimize these challenges. Although they implemented the technological intervention and provided guidelines to conduct an effective workshop, they did not implement a workshop for creators. I extend their work by conducting a workshop for visualization creators based on their findings. My results show that the workshop improved the creators’ accessibility knowledge by 39\%, prioritization of implementing accessibility by 15\%, perceived importance of accessibility by 4\%, challenges with making visualizations accessible by 16\%, and desired frequency of conducting studies with screen-reader users by 157\%.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, creators, data visualization, screen reader, workshop', 'numpages': '6', 'articleno': '92', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Enhancing visualization creators’ knowledge and understanding of the accessibility of data visualizations remains a critical step toward reducing the digital divide screen-reader users experience. Recently, Sharif et al. shed light on the challenges visualization creators face with making data visualizations accessible to screen-reader users, identifying four technological interventions and one educational intervention (i.e., workshops) to minimize these challenges. Although they implemented the technological intervention and provided guidelines to conduct an effective workshop, they did not implement a workshop for creators. I extend their work by conducting a workshop for visualization creators based on their findings. My results show that the workshop improved the creators’ accessibility knowledge by 39\\%, prioritization of implementing accessibility by 15\\%, perceived importance of accessibility by 4\\%, challenges with making visualizations accessible by 16\\%, and desired frequency of conducting studies with screen-reader users by 157\\%.', 'doi': '10.1145/3663548.3688489', 'url': 'https://doi.org/10.1145/3663548.3688489', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Workshop as an Educational Intervention: Improving the Knowledge and Understanding of Data Visualization Accessibility for Visualization Creators', 'author': 'Sharif, Ather', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688489'}"
CARTGPT: Improving CART Captioning using Large Language Models,10.1145/3663548.3688494,"Communication Access Realtime Translation (CART) is a commonly used real-time captioning technology used by deaf and hard of hearing (DHH) people, due to its accuracy, reliability, and ability to provide a holistic view of the conversational environment (e.g., by displaying speaker names). However, in many real-world situations (e.g., noisy environments, long meetings), the CART captioning accuracy can considerably decline, thereby affecting the comprehension of DHH people. In this work-in-progress paper, we introduce CARTGPT, a system to assist CART captioners in improving their transcription accuracy. CARTGPT takes in errored CART captions and inaccurate automatic speech recognition (ASR) captions as input and uses a large language model to generate corrected captions in real-time. We quantified performance on a noisy speech dataset, showing that our system outperforms both CART (+5.6\% accuracy) and a state-of-the-art ASR model (+17.3\%). A preliminary evaluation with three DHH users further demonstrates the promise of our approach.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '93', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Communication Access Realtime Translation (CART) is a commonly used real-time captioning technology used by deaf and hard of hearing (DHH) people, due to its accuracy, reliability, and ability to provide a holistic view of the conversational environment (e.g., by displaying speaker names). However, in many real-world situations (e.g., noisy environments, long meetings), the CART captioning accuracy can considerably decline, thereby affecting the comprehension of DHH people. In this work-in-progress paper, we introduce CARTGPT, a system to assist CART captioners in improving their transcription accuracy. CARTGPT takes in errored CART captions and inaccurate automatic speech recognition (ASR) captions as input and uses a large language model to generate corrected captions in real-time. We quantified performance on a noisy speech dataset, showing that our system outperforms both CART (+5.6\\% accuracy) and a state-of-the-art ASR model (+17.3\\%). A preliminary evaluation with three DHH users further demonstrates the promise of our approach.', 'doi': '10.1145/3663548.3688494', 'url': 'https://doi.org/10.1145/3663548.3688494', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'CARTGPT: Improving CART Captioning using Large Language Models', 'author': 'Wu, Liang-Yuan and Kleiver, Andrea and Jain, Dhruv', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688494'}"
Predictive Anchoring: A Novel Interaction to Support Contextualized Suggestions for Grid Displays,10.1145/3663548.3688501,"Grid displays are the most common form of augmentative and alternative communication device recommended by speech-language pathologists for children. Grid displays present a large variety of vocabulary which can be beneficial for a users’ language development. However, the extensive navigation and cognitive overhead required of users of grid displays can negatively impact users’ ability to actively participate in social interactions, which is an important factor of their language development. We present a novel interaction technique for grid displays, Predictive Anchoring, based on user interaction theory and language development theory. Our design is informed by existing literature in AAC research, presented in the form of a set of design goals and a preliminary design sketch. Future work in user studies and interaction design are also discussed.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AAC, autism, generative AI, grid display, just-in-time programming', 'numpages': '6', 'articleno': '94', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Grid displays are the most common form of augmentative and alternative communication device recommended by speech-language pathologists for children. Grid displays present a large variety of vocabulary which can be beneficial for a users’ language development. However, the extensive navigation and cognitive overhead required of users of grid displays can negatively impact users’ ability to actively participate in social interactions, which is an important factor of their language development. We present a novel interaction technique for grid displays, Predictive Anchoring, based on user interaction theory and language development theory. Our design is informed by existing literature in AAC research, presented in the form of a set of design goals and a preliminary design sketch. Future work in user studies and interaction design are also discussed.', 'doi': '10.1145/3663548.3688501', 'url': 'https://doi.org/10.1145/3663548.3688501', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Predictive Anchoring: A Novel Interaction to Support Contextualized Suggestions for Grid Displays', 'author': 'Zastudil, Cynthia and Holyfield, Christine and Smith, June A. and Nguyen, Hannah and MacNeil, Stephen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688501'}"
Exploring the use of Generative AI to Support Automated Just-in-Time Programming for Visual Scene Displays,10.1145/3663548.3688502,"Millions of people worldwide rely on alternative and augmentative communication devices to communicate. Visual scene displays (VSDs) can enhance communication for these individuals by embedding communication options within contextualized images. However, existing VSDs often present default images that may lack relevance or require manual configuration, placing a significant burden on communication partners. In this study, we assess the feasibility of leveraging large multimodal models (LMM), such as GPT-4V, to automatically create communication options for VSDs. Communication options were sourced from a LMM and speech-language pathologists (SLPs) and AAC researchers (N=13) for evaluation through an expert assessment conducted by the SLPs and AAC researchers. We present the study’s findings, supplemented by insights from semi-structured interviews (N=5) about SLP’s and AAC researchers’ opinions on the use of generative AI in augmentative and alternative communication devices. Our results indicate that the communication options generated by the LMM were contextually relevant and often resembled those created by humans. However, vital questions remain that must be addressed before LMMs can be confidently implemented in AAC devices.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AAC, VSDs, autism, generative AI, just-in-time programming, visual screen displays', 'numpages': '6', 'articleno': '95', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Millions of people worldwide rely on alternative and augmentative communication devices to communicate. Visual scene displays (VSDs) can enhance communication for these individuals by embedding communication options within contextualized images. However, existing VSDs often present default images that may lack relevance or require manual configuration, placing a significant burden on communication partners. In this study, we assess the feasibility of leveraging large multimodal models (LMM), such as GPT-4V, to automatically create communication options for VSDs. Communication options were sourced from a LMM and speech-language pathologists (SLPs) and AAC researchers (N=13) for evaluation through an expert assessment conducted by the SLPs and AAC researchers. We present the study’s findings, supplemented by insights from semi-structured interviews (N=5) about SLP’s and AAC researchers’ opinions on the use of generative AI in augmentative and alternative communication devices. Our results indicate that the communication options generated by the LMM were contextually relevant and often resembled those created by humans. However, vital questions remain that must be addressed before LMMs can be confidently implemented in AAC devices.', 'doi': '10.1145/3663548.3688502', 'url': 'https://doi.org/10.1145/3663548.3688502', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring the use of Generative AI to Support Automated Just-in-Time Programming for Visual Scene Displays', 'author': 'Zastudil, Cynthia and Holyfield, Christine and Kapp, Christine and Crosland, Xandria and Lorah, Elizabeth R. and Zimmerman, Tara and MacNeil, Stephen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688502'}"
"Exploring the ""Freedom to be Me"" through Design Sprints with Neurodivergent Scholars",10.1145/3663548.3688527,"Social stigma negatively impacts the well-being of neurodivergent individuals. Specifically for autistic people, the social isolation and pressure to conform to normative ways of being can take a tremendous toll; such as a thwarted sense of belonging to the point of higher rates of suicide. Yet, few technologies are directly targeting the problem of stigma. Socio-technical systems have tremendous potential to shift public perception of traditionally marginalized populations. However, these systems are not consistently designed to reflect the values and needs of neurodivergent individuals. This work explores the use of design sprints to envision CT– a spectrum of technology that could reduce social stigma by increasing the public’s awareness, accommodations, acceptance, advocacy, and appreciation. This work reports on two design sprints across 25 HCI community members with varying lived experiences with neurodiversity and knowledge of design practice. The resulting design concepts were discussed in the groups and then analyzed to reflect on how they might combat stigma. Results reveal designs that support the freedom to be oneself via (1) safe spaces (2) public understanding, and (3) authentic expression of strengths, challenges, and needs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Celebratory Technology, Community Engagement, Design Sprints, Disability Justice, Neurodiversity, Salutogenesis', 'numpages': '6', 'articleno': '96', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social stigma negatively impacts the well-being of neurodivergent individuals. Specifically for autistic people, the social isolation and pressure to conform to normative ways of being can take a tremendous toll; such as a thwarted sense of belonging to the point of higher rates of suicide. Yet, few technologies are directly targeting the problem of stigma. Socio-technical systems have tremendous potential to shift public perception of traditionally marginalized populations. However, these systems are not consistently designed to reflect the values and needs of neurodivergent individuals. This work explores the use of design sprints to envision CT– a spectrum of technology that could reduce social stigma by increasing the public’s awareness, accommodations, acceptance, advocacy, and appreciation. This work reports on two design sprints across 25 HCI community members with varying lived experiences with neurodiversity and knowledge of design practice. The resulting design concepts were discussed in the groups and then analyzed to reflect on how they might combat stigma. Results reveal designs that support the freedom to be oneself via (1) safe spaces (2) public understanding, and (3) authentic expression of strengths, challenges, and needs.', 'doi': '10.1145/3663548.3688527', 'url': 'https://doi.org/10.1145/3663548.3688527', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring the ""Freedom to be Me"" through Design Sprints with Neurodivergent Scholars', 'author': 'Boyd, LouAnne and Zolyomi, Annuska and Hassan, Saad and Ibrahim, Seray B and Wu, Guande and Kender, Kay', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688527'}"
Towards Rapid Fabrication of Custom Tactile Surface Indicators for Indoor Navigation,10.1145/3663548.3688519,"Tactile surface indicators (TSIs) provide ground-based tactile cues to help pedestrians who are blind or low-vision safely and independently navigate different environments. For example, TSIs can serve as warnings for hazards (e.g., edge of a subway platforms) and directional guides (e.g., a route through a mall). In this exploratory work, we examine how digital fabrication technologies such as 3D printing, CNC milling, vacuum forming, and heat transfer melting can enable the production of custom TSIs. To compare different fabrication approaches, we designed and evaluated a series of prototypes with varied surface materials and design features (e.g., bump height). We then solicited feedback on our ideas and fabricated TSIS via two initial qualitative evaluations: one with a blind cane user and another with an Orientation and Mobility (O&amp;M) specialist. Our initial findings demonstrate that digital fabrication processes—primarily 3D printing and CNC milling—can produce salient and useful TSIs, and indicate interest in our approach and how highly customized, rapidly fabricable TSIs could support navigation in reconfigurable indoor spaces.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': '3D printing, Tactile surface indicators, blind and low vision, detectable warning surfaces, digital fabrication', 'numpages': '5', 'articleno': '97', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tactile surface indicators (TSIs) provide ground-based tactile cues to help pedestrians who are blind or low-vision safely and independently navigate different environments. For example, TSIs can serve as warnings for hazards (e.g., edge of a subway platforms) and directional guides (e.g., a route through a mall). In this exploratory work, we examine how digital fabrication technologies such as 3D printing, CNC milling, vacuum forming, and heat transfer melting can enable the production of custom TSIs. To compare different fabrication approaches, we designed and evaluated a series of prototypes with varied surface materials and design features (e.g., bump height). We then solicited feedback on our ideas and fabricated TSIS via two initial qualitative evaluations: one with a blind cane user and another with an Orientation and Mobility (O&amp;M) specialist. Our initial findings demonstrate that digital fabrication processes—primarily 3D printing and CNC milling—can produce salient and useful TSIs, and indicate interest in our approach and how highly customized, rapidly fabricable TSIs could support navigation in reconfigurable indoor spaces.', 'doi': '10.1145/3663548.3688519', 'url': 'https://doi.org/10.1145/3663548.3688519', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards Rapid Fabrication of Custom Tactile Surface Indicators for Indoor Navigation', 'author': 'Campos Zamora, Daniel and He, Liang and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688519'}"
Speech-based Mark for Data Sonification,10.1145/3663548.3688514,"Sonification serves as a powerful tool for data accessibility, especially for people with vision loss. Among various modalities, speech is a familiar means of communication similar to the role of text in visualization. However, speech-based sonification is underexplored. We introduce SpeechTone, a novel speech-based mark for data sonification and extension to the existing Erie declarative grammar for sonification. It encodes data into speech attributes such as pitch, speed, voice and speech content. We demonstrate the efficacy of SpeechTone through three examples.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Data Accessibility, Sonification, Speech', 'numpages': '5', 'articleno': '98', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sonification serves as a powerful tool for data accessibility, especially for people with vision loss. Among various modalities, speech is a familiar means of communication similar to the role of text in visualization. However, speech-based sonification is underexplored. We introduce SpeechTone, a novel speech-based mark for data sonification and extension to the existing Erie declarative grammar for sonification. It encodes data into speech attributes such as pitch, speed, voice and speech content. We demonstrate the efficacy of SpeechTone through three examples.', 'doi': '10.1145/3663548.3688514', 'url': 'https://doi.org/10.1145/3663548.3688514', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Speech-based Mark for Data Sonification', 'author': 'Zhao, Yichun and Lu, Jingyi and Nacenta, Miguel A', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688514'}"
Individuality-Preserving Speech Synthesis for Spinal Muscular Atrophy with a Tracheotomy,10.1145/3663548.3688518,"Aphasia and dysarthria are the two main language disorders that cause difficulty in speech. This study focuses on articulation disorders, particularly among individuals with spinal muscular atrophy (SMA) whose speech is challenging to comprehend. Specifically, it addresses communication support through text-to-speech synthesis technology that maintains the speaker’s individuality. Previous research on individuals with SMA who have undergone tracheotomy surgery has predominantly centered on postoperative care environments unrelated to speech communication, with few precedents in the study of communication support using speech synthesis technology. Therefore, this study aims to develop a speech synthesis system that preserves the speaker’s individuality while producing clearer speech. This is performed by fine-tuning a pre-trained speech synthesis model, initially trained on a large corpus of speech by those with no speech impediment, using a small amount of speech of the target person with SMA. Subjective evaluations using both actual and synthesized speech demonstrated that the system could adequately learn the speaker’s individuality and produce synthesized speech with slightly improved clarity.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Speech Synthesis, Spinal Muscular Atrophy, Tracheotomy', 'numpages': '5', 'articleno': '99', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Aphasia and dysarthria are the two main language disorders that cause difficulty in speech. This study focuses on articulation disorders, particularly among individuals with spinal muscular atrophy (SMA) whose speech is challenging to comprehend. Specifically, it addresses communication support through text-to-speech synthesis technology that maintains the speaker’s individuality. Previous research on individuals with SMA who have undergone tracheotomy surgery has predominantly centered on postoperative care environments unrelated to speech communication, with few precedents in the study of communication support using speech synthesis technology. Therefore, this study aims to develop a speech synthesis system that preserves the speaker’s individuality while producing clearer speech. This is performed by fine-tuning a pre-trained speech synthesis model, initially trained on a large corpus of speech by those with no speech impediment, using a small amount of speech of the target person with SMA. Subjective evaluations using both actual and synthesized speech demonstrated that the system could adequately learn the speaker’s individuality and produce synthesized speech with slightly improved clarity.', 'doi': '10.1145/3663548.3688518', 'url': 'https://doi.org/10.1145/3663548.3688518', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Individuality-Preserving Speech Synthesis for Spinal Muscular Atrophy with a Tracheotomy', 'author': 'Iwata, Minori and Takashima, Ryoichi and Sasaki, Chiho and Takiguchi, Tetsuya', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688518'}"
Grouping Effect for Bar Graph Summarization for People with Visual Impairments,10.1145/3663548.3688534,"When communicating numerical data to people with visual impairments (PVI), summaries provided by current data visualization solutions tend to lose important information during summarization. To address this issue, our work focuses on summarization through bar grouping in bar graphs. Neither the effect of grouping nor the appropriate granularity of grouping has been discussed so far. Therefore, we investigate the cognitive effects of grouping and its relationship to the number of groups. A user study involving nine PVI (five blind and four with low vision) revealed that summarization through bar grouping conveys information significantly more accurately compared to simply reading individual data points, despite the inherent error produced by grouping. Additionally, we propose a cognitive error model to explain the characteristics of the observed errors.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Bar graph, cognitive load, people with visual impairments, summarization', 'numpages': '6', 'articleno': '100', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'When communicating numerical data to people with visual impairments (PVI), summaries provided by current data visualization solutions tend to lose important information during summarization. To address this issue, our work focuses on summarization through bar grouping in bar graphs. Neither the effect of grouping nor the appropriate granularity of grouping has been discussed so far. Therefore, we investigate the cognitive effects of grouping and its relationship to the number of groups. A user study involving nine PVI (five blind and four with low vision) revealed that summarization through bar grouping conveys information significantly more accurately compared to simply reading individual data points, despite the inherent error produced by grouping. Additionally, we propose a cognitive error model to explain the characteristics of the observed errors.', 'doi': '10.1145/3663548.3688534', 'url': 'https://doi.org/10.1145/3663548.3688534', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Grouping Effect for Bar Graph Summarization for People with Visual Impairments', 'author': 'Kakehi, Banri and Iwamura, Masakazu and Minatani, Kazunori and Kise, Koichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688534'}"
Self-supervised learning using unlabeled speech with multiple types of speech disorder for disordered speech recognition,10.1145/3663548.3688536,"This paper investigates a training method of an automatic speech recognition (ASR) model for people with speech disorders. Because the characteristics of their speech differ significantly from those of the typical speech, in order to recognize the speech of a user with a disorder, the system needs to be trained with the user’s speech in advance. However, recording speech from people with disorders is a large burden for them, and therefore, it is difficult to collect a sufficient amount of speech for training. To address this issue, this study investigates the use of two types of speech as training data. The first type is unlabeled speech, which can be easily collected but lacks text labels (e.g., spontaneous speech in daily life). To utilize the unlabeled speech for training an ASR model, a self-supervised learning approach is employed. The second type involves utilizing speech data from individuals with different types of speech disorders. In our system, besides the user’s speech, the speech of individuals with the same type of disorder and even different types of disorders is also incorporated. Experimental results demonstrated that using unlabeled speech and speech from multiple types of disorders led to reduced recognition error rates.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'machine learning, neural network, self-supervised learning, speech disorder, speech recognition', 'numpages': '5', 'articleno': '101', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper investigates a training method of an automatic speech recognition (ASR) model for people with speech disorders. Because the characteristics of their speech differ significantly from those of the typical speech, in order to recognize the speech of a user with a disorder, the system needs to be trained with the user’s speech in advance. However, recording speech from people with disorders is a large burden for them, and therefore, it is difficult to collect a sufficient amount of speech for training. To address this issue, this study investigates the use of two types of speech as training data. The first type is unlabeled speech, which can be easily collected but lacks text labels (e.g., spontaneous speech in daily life). To utilize the unlabeled speech for training an ASR model, a self-supervised learning approach is employed. The second type involves utilizing speech data from individuals with different types of speech disorders. In our system, besides the user’s speech, the speech of individuals with the same type of disorder and even different types of disorders is also incorporated. Experimental results demonstrated that using unlabeled speech and speech from multiple types of disorders led to reduced recognition error rates.', 'doi': '10.1145/3663548.3688536', 'url': 'https://doi.org/10.1145/3663548.3688536', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Self-supervised learning using unlabeled speech with multiple types of speech disorder for disordered speech recognition', 'author': 'Takashima, Ryoichi and Otani, Takeru and Aihara, Ryo and Takiguchi, Tetsuya and Taguchi, Shinya', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688536'}"
Designing a Safe Auditory-Cued Archery Exertion Game for the Visually Impaired and Sighted to Enjoy Together,10.1145/3663548.3688510,"Most competitive exertion games are highly reliant on visual cues, presenting a certain risk for visually impaired players. These individuals not only need to exert more effort and courage to participate in these games but also face a higher risk of injury. Additionally, during competition with sighted players, concerns about injuries may prevent both parties from fully enjoying the game, diminishing the fun for everyone involved. Although many sports games have been adapted for visually impaired players, these games often fail to engage sighted individuals or might be perceived as dull by them. This study introduces an archery exertion game called “Hearing the Bullseye"", designed to provide a harmonious gaming environment for visually impaired players and their sighted family and friends. Utilizing bows equipped with infrared sensors, the game enables players to locate the invisible target through sound rather than sight. Our empirical research, involving 18 visually impaired and sighted participants, indicates that visually impaired players can quickly and safely master the game, ensuring a pleasant and friendly experience for all players.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Auditory feedback, Exergames, Visually Impaired', 'numpages': '6', 'articleno': '102', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most competitive exertion games are highly reliant on visual cues, presenting a certain risk for visually impaired players. These individuals not only need to exert more effort and courage to participate in these games but also face a higher risk of injury. Additionally, during competition with sighted players, concerns about injuries may prevent both parties from fully enjoying the game, diminishing the fun for everyone involved. Although many sports games have been adapted for visually impaired players, these games often fail to engage sighted individuals or might be perceived as dull by them. This study introduces an archery exertion game called “Hearing the Bullseye"", designed to provide a harmonious gaming environment for visually impaired players and their sighted family and friends. Utilizing bows equipped with infrared sensors, the game enables players to locate the invisible target through sound rather than sight. Our empirical research, involving 18 visually impaired and sighted participants, indicates that visually impaired players can quickly and safely master the game, ensuring a pleasant and friendly experience for all players.', 'doi': '10.1145/3663548.3688510', 'url': 'https://doi.org/10.1145/3663548.3688510', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Designing a Safe Auditory-Cued Archery Exertion Game for the Visually Impaired and Sighted to Enjoy Together', 'author': 'Luo, Shan and Liu, Jianan Johanna and Hu, Botao Amber', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688510'}"
Towards Fine-Grained Sidewalk Accessibility Assessment with Deep Learning: Initial Benchmarks and an Open Dataset,10.1145/3663548.3688531,"We examine the feasibility of using deep learning to infer 33 classes of sidewalk accessibility conditions in pre-cropped streetscape images, including bumpy, brick/cobblestone, cracks, height difference (uplifts), narrow, uneven/slanted, pole, and sign. We present two experiments: first, a comparison between two state-of-the-art computer vision models, Meta’s DINOv2 and OpenAI’s CLIP-ViT, on a cleaned dataset of ∼ 24k images; second, an examination of a larger but noisier crowdsourced dataset (∼ 87k images) on the best performing model from Experiment 1. Though preliminary, Experiment 1 shows that certain sidewalk conditions can be identified with high precision and recall, such as missing tactile warnings on curb ramps and grass grown on sidewalks, while Experiment 2 demonstrates that larger but noisier training data can have a detrimental effect on performance. We contribute an open dataset and classification benchmarks to advance this important area.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'DINOv2, Sidewalk accessibility, ViT-CLIP, computer vision, human mobility, obstacle detection', 'numpages': '12', 'articleno': '103', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We examine the feasibility of using deep learning to infer 33 classes of sidewalk accessibility conditions in pre-cropped streetscape images, including bumpy, brick/cobblestone, cracks, height difference (uplifts), narrow, uneven/slanted, pole, and sign. We present two experiments: first, a comparison between two state-of-the-art computer vision models, Meta’s DINOv2 and OpenAI’s CLIP-ViT, on a cleaned dataset of ∼ 24k images; second, an examination of a larger but noisier crowdsourced dataset (∼ 87k images) on the best performing model from Experiment 1. Though preliminary, Experiment 1 shows that certain sidewalk conditions can be identified with high precision and recall, such as missing tactile warnings on curb ramps and grass grown on sidewalks, while Experiment 2 demonstrates that larger but noisier training data can have a detrimental effect on performance. We contribute an open dataset and classification benchmarks to advance this important area.', 'doi': '10.1145/3663548.3688531', 'url': 'https://doi.org/10.1145/3663548.3688531', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards Fine-Grained Sidewalk Accessibility Assessment with Deep Learning: Initial Benchmarks and an Open Dataset', 'author': 'Liu, Xinlei and Wu, Kevin and Kulkarni, Minchu and Saugstad, Michael and Rapo, Peyton Anton and Freiburger, Jeremy and Hosseini, Maryam and Li, Chu and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688531'}"
The Looking-Glass Avatar: Representing Chronic Pain through Social Virtual Reality Avatar Movement,10.1145/3663548.3688485,"With recent movements toward disability as a social identity, we explore whether pain associated with chronic pain conditions (e.g., arthritis, Crohn’s disease, lupus) is also linked to identity and representation preferences. Prior work showed social VR users with invisible disabilities noted preliminary interest in using their avatar’s body language to represent their disability-related identities. We examined movement-based social virtual reality (VR) avatar representation preferences by conducting semi-structured interviews with five participants with such chronic pain conditions. Participants incorporated social norms, cultural considerations, and internalized self-stigma into their decision-making about pain disclosure and representation in different contexts. Aligning with previous work on self-presence and embodiment, in order to avoid discomfort, most participants wanted to avoid experiences where their avatar moved in ways that they did not, or could not, move in the physical world (i.e., jumping, bending over from the spine). Two participants also wanted to be able to represent their personal use of clothing and fashion as accommodation in the physical world. We believe this study will further our understanding of how disability-related identities should be represented in social VR spaces.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, avatar movement, avatars, chronic pain, customization, disability disclosure, invisible disabilities, social virtual reality, virtual reality', 'numpages': '5', 'articleno': '104', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'With recent movements toward disability as a social identity, we explore whether pain associated with chronic pain conditions (e.g., arthritis, Crohn’s disease, lupus) is also linked to identity and representation preferences. Prior work showed social VR users with invisible disabilities noted preliminary interest in using their avatar’s body language to represent their disability-related identities. We examined movement-based social virtual reality (VR) avatar representation preferences by conducting semi-structured interviews with five participants with such chronic pain conditions. Participants incorporated social norms, cultural considerations, and internalized self-stigma into their decision-making about pain disclosure and representation in different contexts. Aligning with previous work on self-presence and embodiment, in order to avoid discomfort, most participants wanted to avoid experiences where their avatar moved in ways that they did not, or could not, move in the physical world (i.e., jumping, bending over from the spine). Two participants also wanted to be able to represent their personal use of clothing and fashion as accommodation in the physical world. We believe this study will further our understanding of how disability-related identities should be represented in social VR spaces.', 'doi': '10.1145/3663548.3688485', 'url': 'https://doi.org/10.1145/3663548.3688485', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'The Looking-Glass Avatar: Representing Chronic Pain through Social Virtual Reality Avatar Movement', 'author': 'Gualano, Ria J. and Leonard, Cole and Zhang, Yahui and Trost, Zina and Azenkot, Shiri and Won, Andrea Stevenson', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688485'}"
A Preliminary Analysis of Older Adults' Reactions to Design Concepts for Physical Activity Support,10.1145/3663548.3688509,"Although older adults are motivated to engage in physical activity, their routines are often disrupted by a multitude of interrelated barriers, which are not addressed by current physical activity promoting technologies. To explore how technology might be better designed to promote physical activity in older adults living alone, we developed 15 design concepts envisioning digital and non-digital tools for supporting older adults in maintaining physical activity routines and then interviewed 15 participants on their preferences and reactions to the concepts. In this poster, we share preliminary findings on our participants’ reactions to the designs. While generally positive towards all concepts, participants identified most with a design aimed at providing alternative exercises in response to a health-related routine disruption and least with two concepts, which both involved sharing activity logs with others. As social accountability is a common feature of commercial tools, our findings help shed light on why existing physical activity promoting technologies have been critiqued by older adults as poorly aligned with their needs, further reinforcing calls for considering their unique needs for physical activity support.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '105', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Although older adults are motivated to engage in physical activity, their routines are often disrupted by a multitude of interrelated barriers, which are not addressed by current physical activity promoting technologies. To explore how technology might be better designed to promote physical activity in older adults living alone, we developed 15 design concepts envisioning digital and non-digital tools for supporting older adults in maintaining physical activity routines and then interviewed 15 participants on their preferences and reactions to the concepts. In this poster, we share preliminary findings on our participants’ reactions to the designs. While generally positive towards all concepts, participants identified most with a design aimed at providing alternative exercises in response to a health-related routine disruption and least with two concepts, which both involved sharing activity logs with others. As social accountability is a common feature of commercial tools, our findings help shed light on why existing physical activity promoting technologies have been critiqued by older adults as poorly aligned with their needs, further reinforcing calls for considering their unique needs for physical activity support.', 'doi': '10.1145/3663548.3688509', 'url': 'https://doi.org/10.1145/3663548.3688509', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""A Preliminary Analysis of Older Adults' Reactions to Design Concepts for Physical Activity Support"", 'author': 'Yang, Muhe and Moffatt, Karyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688509'}"
Tab to Autocomplete: The Effects of AI Coding Assistants on Web Accessibility,10.1145/3663548.3688513,"A long-standing challenge in accessible computing has been to get developers to produce the accessible UI code necessary for assistive technologies to work properly. AI coding assistants (e.g., Github Copilot) potentially offer a new opportunity to make UI code more accessible automatically, but it is unclear how their use impacts code accessibility and what developers need to know in order to use them effectively. In this paper, we report on a study where developers untrained in accessibility were tasked with building web UI components with and without an AI coding assistant. Our findings suggest that while current AI coding assistants show potential for creating more accessible UIs, they currently require accessibility awareness and expertise, limiting their expected impact.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'AI Coding Assistants, Empirical Studies in HCI, Web Accessibility', 'numpages': '6', 'articleno': '106', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A long-standing challenge in accessible computing has been to get developers to produce the accessible UI code necessary for assistive technologies to work properly. AI coding assistants (e.g., Github Copilot) potentially offer a new opportunity to make UI code more accessible automatically, but it is unclear how their use impacts code accessibility and what developers need to know in order to use them effectively. In this paper, we report on a study where developers untrained in accessibility were tasked with building web UI components with and without an AI coding assistant. Our findings suggest that while current AI coding assistants show potential for creating more accessible UIs, they currently require accessibility awareness and expertise, limiting their expected impact.', 'doi': '10.1145/3663548.3688513', 'url': 'https://doi.org/10.1145/3663548.3688513', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Tab to Autocomplete: The Effects of AI Coding Assistants on Web Accessibility', 'author': 'Mowar, Peya and Peng, Yi-Hao and Steinfeld, Aaron and Bigham, Jeffrey P', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688513'}"
Exploring the Accessibility of Social Virtual Reality for People with ADHD and Autism: Preliminary Insights,10.1145/3663548.3687134,"Social virtual reality (VR) has become one of the most popular forms of VR. However, despite years of research on how VR interventions can be useful as diagnostic or therapeutic tools for neurodivergent (ND) users, there has been little examination of how accessible social VR may be for such ND individuals. In this paper, we describe an ongoing user study with participants who self-identify with both autism and ADHD (AuDHD) and also self-identify with facing frequent challenges with social interaction. So far, we have recruited four AuDHD participants; we had each participant briefly explore a world on a popular commercial social VR platform and then reflect on this experience afterward in a longer interview section. Through this process, we uncovered various accessibility challenges in social VR, such as difficulties with navigating social norms or managing certain sensory inputs. We also noted ideas on potential accommodations, like a text-based prompt system that can suggest “appropriate” conversation responses. Our work outlines opportunities to improve the accessibility of social VR for an often-overlooked user group.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'ADHD, VR, accessibility, autism, neurodivergence', 'numpages': '5', 'articleno': '107', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social virtual reality (VR) has become one of the most popular forms of VR. However, despite years of research on how VR interventions can be useful as diagnostic or therapeutic tools for neurodivergent (ND) users, there has been little examination of how accessible social VR may be for such ND individuals. In this paper, we describe an ongoing user study with participants who self-identify with both autism and ADHD (AuDHD) and also self-identify with facing frequent challenges with social interaction. So far, we have recruited four AuDHD participants; we had each participant briefly explore a world on a popular commercial social VR platform and then reflect on this experience afterward in a longer interview section. Through this process, we uncovered various accessibility challenges in social VR, such as difficulties with navigating social norms or managing certain sensory inputs. We also noted ideas on potential accommodations, like a text-based prompt system that can suggest “appropriate” conversation responses. Our work outlines opportunities to improve the accessibility of social VR for an often-overlooked user group.', 'doi': '10.1145/3663548.3687134', 'url': 'https://doi.org/10.1145/3663548.3687134', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring the Accessibility of Social Virtual Reality for People with ADHD and Autism: Preliminary Insights', 'author': 'Collins, Jazmin and Ko, Woojin and Shende, Tanisha and Lin, Sharon Y and Jiang, Lucy and Stevenson Won, Andrea and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3687134'}"
Insights from Immersive Learning: Using Sentiment Analysis and Real-time Narration to Refine ASL Instruction in Virtual Reality,10.1145/3663548.3688503,"Immersive virtual reality presents a rich opportunity for learning signed languages, given the immersive environment’s ability to represent three-dimensional information. We developed a proof-of-concept American Sign Language (ASL) learning in immersive virtual reality (VR), named ASL Champ! Twelve hearing non- or novice signers played one full level of the game, during which they were asked to provide concurrent think-aloud (CTA) commentary, narrating their experience as they played in real time. We conducted a sentiment analysis from recordings of the CTA and subsequent open-ended questions and qualitatively assessed the narrations for salient themes. The analysis revealed specific aspects of the users’ experiences that were most likely to lead to positive or negative expressions during the CTA and the question session. The factors that had the most impact on user sentiment were the success of the sign recognition in the game and the extent to which users found the game intuitive or self-explanatory. We also found that users with more technology anxiety were more positive about the game. We also qualitatively examined user comments, revealing their real-time game experiences. This work provides insights into which aspects of an ASL learning VR game are most important for user experiences. We conclude with takeaway recommendations for future virtual or augmented reality sign language learning games.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Avatars, Sentiment analysis, Sign language, User experience, Virtual reality', 'numpages': '4', 'articleno': '108', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Immersive virtual reality presents a rich opportunity for learning signed languages, given the immersive environment’s ability to represent three-dimensional information. We developed a proof-of-concept American Sign Language (ASL) learning in immersive virtual reality (VR), named ASL Champ! Twelve hearing non- or novice signers played one full level of the game, during which they were asked to provide concurrent think-aloud (CTA) commentary, narrating their experience as they played in real time. We conducted a sentiment analysis from recordings of the CTA and subsequent open-ended questions and qualitatively assessed the narrations for salient themes. The analysis revealed specific aspects of the users’ experiences that were most likely to lead to positive or negative expressions during the CTA and the question session. The factors that had the most impact on user sentiment were the success of the sign recognition in the game and the extent to which users found the game intuitive or self-explanatory. We also found that users with more technology anxiety were more positive about the game. We also qualitatively examined user comments, revealing their real-time game experiences. This work provides insights into which aspects of an ASL learning VR game are most important for user experiences. We conclude with takeaway recommendations for future virtual or augmented reality sign language learning games.', 'doi': '10.1145/3663548.3688503', 'url': 'https://doi.org/10.1145/3663548.3688503', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Insights from Immersive Learning: Using Sentiment Analysis and Real-time Narration to Refine ASL Instruction in Virtual Reality', 'author': 'Alam, Md Shahinur and Palagano, Joseph and Quandt, Lorna C', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688503'}"
Exploring the Potential of Generative AI in DIY Assistive Technology Design by Occupational Therapists,10.1145/3663548.3688506,"This paper examines the potential integration of generative AI into the assistive technology (AT) making and adaptation process, with Occupational Therapists (OTs) as the primary beneficiaries, as they are often involved in designing ‘do-it-yourself assistive technology’ (DIY AT) to support independent living for individuals with disabilities. We initiated the study by considering the traditional AT-making processes performed by OTs and prototyped a web interface that incorporates generative AI to support these processes. Through a series of user studies, we collected OTs' preliminary insights on how generative AI could bridge the gap between clinical reasoning and technical design, potentially streamlining the AT creation and adaptation process while maintaining the crucial element of personalized AT solutions. The study's findings highlight several key benefits of generative AI in OT practice: 1) customization of AT solutions tailored to individual client needs, 2) improved visualization capabilities for client communication, 3) inspiration for new AT design ideas, and 4) potential for rapid prototyping and practice. However, key drawbacks were noted, including limitations in inputting measurements, which can lead to inaccurate outputs and necessitate substantial modifications to the created AT, along with challenges associated with the current state of generative AI.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '6', 'articleno': '109', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper examines the potential integration of generative AI into the assistive technology (AT) making and adaptation process, with Occupational Therapists (OTs) as the primary beneficiaries, as they are often involved in designing ‘do-it-yourself assistive technology’ (DIY AT) to support independent living for individuals with disabilities. We initiated the study by considering the traditional AT-making processes performed by OTs and prototyped a web interface that incorporates generative AI to support these processes. Through a series of user studies, we collected OTs' preliminary insights on how generative AI could bridge the gap between clinical reasoning and technical design, potentially streamlining the AT creation and adaptation process while maintaining the crucial element of personalized AT solutions. The study's findings highlight several key benefits of generative AI in OT practice: 1) customization of AT solutions tailored to individual client needs, 2) improved visualization capabilities for client communication, 3) inspiration for new AT design ideas, and 4) potential for rapid prototyping and practice. However, key drawbacks were noted, including limitations in inputting measurements, which can lead to inaccurate outputs and necessitate substantial modifications to the created AT, along with challenges associated with the current state of generative AI."", 'doi': '10.1145/3663548.3688506', 'url': 'https://doi.org/10.1145/3663548.3688506', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Exploring the Potential of Generative AI in DIY Assistive Technology Design by Occupational Therapists', 'author': 'Li, Mixuan and Aflatoony, Leila', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688506'}"
Speed-of-Light VR for Blind People: Conveying the Location of Arm-Reach Targets,10.1145/3663548.3688533,"Interacting with close-range objects in Virtual Reality (VR) is often prompted by visual cues, making it hard for visually impaired people to perceive their location and interact with them. To study how to enable blind users to locate and interact with close virtual objects, we adapted the arcade Speed-of-Light game as a blind-accessible VR application. We implemented three techniques: 1) Speech Feedback (e.g., “Top Right”), 2) Sonification, and 3) 2D Grid Position (e.g., “A3” for column and row); and conducted a user study with 15 blind participants aiming to provide insights into the design of non-visual techniques that convey information about targets at arm-reach. Speech Feedback was the most intuitive overall but verbose and the least flexible, while 2D Grid Position was found straightforward for regular spreadsheet users. Results also showed greater difficulty with Sonification, although it was valued by few participants who appreciated the challenge.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Nonvisual Feedback, Sonification., Virtual Reality, Visual Impairments', 'numpages': '5', 'articleno': '110', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Interacting with close-range objects in Virtual Reality (VR) is often prompted by visual cues, making it hard for visually impaired people to perceive their location and interact with them. To study how to enable blind users to locate and interact with close virtual objects, we adapted the arcade Speed-of-Light game as a blind-accessible VR application. We implemented three techniques: 1) Speech Feedback (e.g., “Top Right”), 2) Sonification, and 3) 2D Grid Position (e.g., “A3” for column and row); and conducted a user study with 15 blind participants aiming to provide insights into the design of non-visual techniques that convey information about targets at arm-reach. Speech Feedback was the most intuitive overall but verbose and the least flexible, while 2D Grid Position was found straightforward for regular spreadsheet users. Results also showed greater difficulty with Sonification, although it was valued by few participants who appreciated the challenge.', 'doi': '10.1145/3663548.3688533', 'url': 'https://doi.org/10.1145/3663548.3688533', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Speed-of-Light VR for Blind People: Conveying the Location of Arm-Reach Targets', 'author': ""Lan\\c{c}a, Diogo and Pi\\c{c}arra, Manuel and Gon\\c{c}alves, In\\^{e}s and Oh, Uran and Rodrigues, Andr\\'{e} and Guerreiro, Jo\\~{a}o"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688533'}"
Understanding the Visualization and Analytics Needs of Blind and Low-Vision Professionals,10.1145/3663548.3688496,"Inclusivity for blind and low vision (BLV) professionals in data science and analytics is limited by a gap in understanding their unique data analysis needs. We contribute to the literature by reporting on a two-step online survey delving into the experiences and challenges faced by BLV individuals engaged in data-related roles. Our findings highlight that despite expertise in programming and GUI-based analysis tools, BLV professionals faced accessibility issues at various points in the data analysis pipeline—issues ranging from data loading and transformation, availability and compatibility of data tools with assistive technology, and visualization authoring. The prevalent use of tools such as Excel, Python, and SAS alongside heavy reliance on assistive technologies highlights persistent accessibility challenges. Furthermore, frequent collaboration with sighted colleagues indicates compromised independence. These results underscore the urgent need for “born accessible” tools that ensure the inclusivity and autonomy of BLV professionals in the field of data science.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessible data visualization, blind and low vision users, inclusive data analysis', 'numpages': '5', 'articleno': '111', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Inclusivity for blind and low vision (BLV) professionals in data science and analytics is limited by a gap in understanding their unique data analysis needs. We contribute to the literature by reporting on a two-step online survey delving into the experiences and challenges faced by BLV individuals engaged in data-related roles. Our findings highlight that despite expertise in programming and GUI-based analysis tools, BLV professionals faced accessibility issues at various points in the data analysis pipeline—issues ranging from data loading and transformation, availability and compatibility of data tools with assistive technology, and visualization authoring. The prevalent use of tools such as Excel, Python, and SAS alongside heavy reliance on assistive technologies highlights persistent accessibility challenges. Furthermore, frequent collaboration with sighted colleagues indicates compromised independence. These results underscore the urgent need for “born accessible” tools that ensure the inclusivity and autonomy of BLV professionals in the field of data science.', 'doi': '10.1145/3663548.3688496', 'url': 'https://doi.org/10.1145/3663548.3688496', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Understanding the Visualization and Analytics Needs of Blind and Low-Vision Professionals', 'author': 'Chundury, Pramod and Thakkar, Urja and Reyazuddin, Yasmin and Jordan, J. Bern and Elmqvist, Niklas and Lazar, Jonathan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688496'}"
Building Collaborative Art Creation Environment for People with Intellectual Disabilities through Adaptive Fabric Art Workshops,10.1145/3663548.3688497,"This study focuses on designing and implementing adaptive fabric art workshops within a collaborative art creation environment tailored for individuals with intellectual disabilities. Conducted in an inclusive gallery setting, these workshops aimed to enhance self-expression for individuals with intellectual disabilities through simplified art-making processes and user-friendly materials and tools. Following these workshops, the created artworks were exhibited at the gallery. Based on reflections with stakeholders, we suggest the development of online sharing platforms that could facilitate ongoing learning and collaboration for supporters, ultimately promoting inclusivity and accessibility in community art activities for individuals with intellectual disabilities.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'adaptive art, art for disabilities, art therapy, collaborative art creation, inclusive education', 'numpages': '4', 'articleno': '112', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study focuses on designing and implementing adaptive fabric art workshops within a collaborative art creation environment tailored for individuals with intellectual disabilities. Conducted in an inclusive gallery setting, these workshops aimed to enhance self-expression for individuals with intellectual disabilities through simplified art-making processes and user-friendly materials and tools. Following these workshops, the created artworks were exhibited at the gallery. Based on reflections with stakeholders, we suggest the development of online sharing platforms that could facilitate ongoing learning and collaboration for supporters, ultimately promoting inclusivity and accessibility in community art activities for individuals with intellectual disabilities.', 'doi': '10.1145/3663548.3688497', 'url': 'https://doi.org/10.1145/3663548.3688497', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Building Collaborative Art Creation Environment for People with Intellectual Disabilities through Adaptive Fabric Art Workshops', 'author': 'Fu, Qianrong and Barbareschi, Giulia and Sato, Chihiro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688497'}"
A Place to Charge Your Wheels: Re-imagining the urban landscape for electric-wheelchair users through Design Fiction,10.1145/3663548.3688532,"While public charging infrastructure for Electric Vehicles (EVs) in the form of cars or vans attracts significant investment, charging infrastructure for electric wheelchairs and mobility scooters has been neglected. With the expansion of EV charging points over the past decade, local governments and mobility providers have only recently started to take note. Concurrently, municipal governments in the US and researchers in the EU have begun working with developers to envision an electric wheelchair (or equivalent mobility scooters) public charging infrastructure, while acknowledging the absence of current facilities. This is especially the case in the UK, where, at this time, there are no known public charging points for mobility vehicle users. As part of an international (student) research exchange event, we worked with community partners to capture the lived experience of electric wheelchair use in the urban environment, identifying key priorities and current barriers with them. Using a Design Fiction approach, we explored how speculative futures about public charging provision can help with awareness-raising and impact public policy in relation to this important issue.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Design Fiction, Electric Mobility Vehicle Charging, Mobility Scooter, Power Wheelchair', 'numpages': '5', 'articleno': '113', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'While public charging infrastructure for Electric Vehicles (EVs) in the form of cars or vans attracts significant investment, charging infrastructure for electric wheelchairs and mobility scooters has been neglected. With the expansion of EV charging points over the past decade, local governments and mobility providers have only recently started to take note. Concurrently, municipal governments in the US and researchers in the EU have begun working with developers to envision an electric wheelchair (or equivalent mobility scooters) public charging infrastructure, while acknowledging the absence of current facilities. This is especially the case in the UK, where, at this time, there are no known public charging points for mobility vehicle users. As part of an international (student) research exchange event, we worked with community partners to capture the lived experience of electric wheelchair use in the urban environment, identifying key priorities and current barriers with them. Using a Design Fiction approach, we explored how speculative futures about public charging provision can help with awareness-raising and impact public policy in relation to this important issue.', 'doi': '10.1145/3663548.3688532', 'url': 'https://doi.org/10.1145/3663548.3688532', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'A Place to Charge Your Wheels: Re-imagining the urban landscape for electric-wheelchair users through Design Fiction', 'author': 'Piedade, Patricia and Jang, Hope and Maddux, Joe and Chappell, Stewart and Maher, Jacqui and Dow, Andy and Conniss, Lynne R. and Kotter, Richard A and Conti, Matteo and Zilvetti, Marco and Nicolson, Suzanne and Rizwan, Ayman and Barrioz, Vincent and Farrell, Estelle Louise', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688532'}"
Crip Material Exploration as an Assistive Technology Research Framework: Situating Interdependence in Empowered Disabled Making,10.1145/3663548.3688508,"Human-Computer Interaction (HCI) scholars have grappled with the question of how to directly involve people with disabilities (PwDs) in assistive technology (AT) research. While there is recognition that PwDs possess unique expertise, this understanding often remains limited to an assumption that the bounds of this expertise end with the embodied knowledge related to their impairments. However, PwDs possess expertise that extends beyond this narrow definition. In navigating different contexts within their communities of care, PwDs build empowered expertise through interdependence. This knowledge, grounded in everyday material experiences, can significantly inform future AT design practices. I offer a new crip-material exploration (CME) framework to expand the understanding of PwD expertise. In doing so, future AT research can better encompass the full range of the social connections and material experimentation that enriches the lived experiences of PwDs. The connective, inter-group mediation that PwDs are skilled in throughout everyday interactions points toward the importance of creating new research approaches to engaging with that expertise. CME can be leveraged by HCI scholarship to understand how the empowered interdependence of PwDs strengthens current and future AT design. A workshop structure is proposed to help guide&nbsp;scholars in implementing CME into future research designs.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '114', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Human-Computer Interaction (HCI) scholars have grappled with the question of how to directly involve people with disabilities (PwDs) in assistive technology (AT) research. While there is recognition that PwDs possess unique expertise, this understanding often remains limited to an assumption that the bounds of this expertise end with the embodied knowledge related to their impairments. However, PwDs possess expertise that extends beyond this narrow definition. In navigating different contexts within their communities of care, PwDs build empowered expertise through interdependence. This knowledge, grounded in everyday material experiences, can significantly inform future AT design practices. I offer a new crip-material exploration (CME) framework to expand the understanding of PwD expertise. In doing so, future AT research can better encompass the full range of the social connections and material experimentation that enriches the lived experiences of PwDs. The connective, inter-group mediation that PwDs are skilled in throughout everyday interactions points toward the importance of creating new research approaches to engaging with that expertise. CME can be leveraged by HCI scholarship to understand how the empowered interdependence of PwDs strengthens current and future AT design. A workshop structure is proposed to help guide&nbsp;scholars in implementing CME into future research designs.', 'doi': '10.1145/3663548.3688508', 'url': 'https://doi.org/10.1145/3663548.3688508', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Crip Material Exploration as an Assistive Technology Research Framework: Situating Interdependence in Empowered Disabled Making', 'author': 'Parent, Alexander S.W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688508'}"
Drones for all: Creating an Authentic Programming Experience for Students with Visual Impairments,10.1145/3663548.3688516,"Programming has become a highly sought-after skill in STEM-related studies and careers, but it has only reached a fraction of students with visual impairments. Therefore, there is a need to explore new methods for teaching and learning. This study aims to understand the potential of using drones to create an authentic learning environment to help students with visual impairments learn programming. Based on a month-long engagement with five students with visual impairments, we present insights on using drones to support programming education for students with visual impairments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Drones, Human-Drone-Interaction, Inclusive Design, Programming, Students with Visual Impairments', 'numpages': '7', 'articleno': '115', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Programming has become a highly sought-after skill in STEM-related studies and careers, but it has only reached a fraction of students with visual impairments. Therefore, there is a need to explore new methods for teaching and learning. This study aims to understand the potential of using drones to create an authentic learning environment to help students with visual impairments learn programming. Based on a month-long engagement with five students with visual impairments, we present insights on using drones to support programming education for students with visual impairments.', 'doi': '10.1145/3663548.3688516', 'url': 'https://doi.org/10.1145/3663548.3688516', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Drones for all: Creating an Authentic Programming Experience for Students with Visual Impairments', 'author': 'Wei, Yize and Dubucq, Ma\\""{e}lle and de Zoysa, Malsha and Jouffrais, Christophe and Nanayakkara, Suranga and Ooi, Wei Tsang', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688516'}"
How Proficiency and Feelings impact the Preference and Perception of Mobile Technology Support in Older Adults,10.1145/3663548.3688520,"The kind of technology (tech) support that older adults prefer during continued mobile use varies widely. So does the perceived quality of that support. However, we know little about what influences these preferences and perceptions. We conducted an online survey with 138 U.S. older adults to understand how mobile device proficiency and feelings of anxiety and confidence during mobile use impact the preference for and perception of mobile tech support in older adults. Proficiency predicted a positive preference for self-reliant support but a negative preference for social support during continued mobile tech use. The effects of proficiency and confidence on the perceived quality of self-reliant mobile tech support in older adults were partially mediated by a preference for it.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Mobile use, Older adults, Support quality, Survey, Tech Support, Technology support, User preferences', 'numpages': '5', 'articleno': '116', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The kind of technology (tech) support that older adults prefer during continued mobile use varies widely. So does the perceived quality of that support. However, we know little about what influences these preferences and perceptions. We conducted an online survey with 138 U.S. older adults to understand how mobile device proficiency and feelings of anxiety and confidence during mobile use impact the preference for and perception of mobile tech support in older adults. Proficiency predicted a positive preference for self-reliant support but a negative preference for social support during continued mobile tech use. The effects of proficiency and confidence on the perceived quality of self-reliant mobile tech support in older adults were partially mediated by a preference for it.', 'doi': '10.1145/3663548.3688520', 'url': 'https://doi.org/10.1145/3663548.3688520', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'How Proficiency and Feelings impact the Preference and Perception of Mobile Technology Support in Older Adults', 'author': 'Sakhnini, Nina and Sharifi, Hasti and Chattopadhyay, Debaleena', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688520'}"
Establishing a Community-Driven Digital Library for the Visually Impaired,10.1145/3663548.3688524,"This research represents the initial stages of our efforts to establish a digital library run by visually impaired individuals. We use the Action Research (AR) methodology, which involves researchers and community members collaborating to solve real-world problems. Our study focuses on documenting the process of creating a non-profit organization (NPO), building a supportive community, and gathering insights through interviews with key stakeholders. Specifically, the lead author established an NPO registered under Article 37, Paragraph 3 of the Japanese Copyright Act and partnered with the National Diet Library to upload accessible e-books. The NPO expanded its network through local business events, university collaborations, and social entrepreneur communities. Interviews underscored a decline in Braille library volunteers and severe delays in accessibility resources for minority languages like Mongolian. These findings will shape our future efforts to improve accessibility and self-directed learning for visually impaired individuals.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Blind, Library', 'numpages': '4', 'articleno': '117', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This research represents the initial stages of our efforts to establish a digital library run by visually impaired individuals. We use the Action Research (AR) methodology, which involves researchers and community members collaborating to solve real-world problems. Our study focuses on documenting the process of creating a non-profit organization (NPO), building a supportive community, and gathering insights through interviews with key stakeholders. Specifically, the lead author established an NPO registered under Article 37, Paragraph 3 of the Japanese Copyright Act and partnered with the National Diet Library to upload accessible e-books. The NPO expanded its network through local business events, university collaborations, and social entrepreneur communities. Interviews underscored a decline in Braille library volunteers and severe delays in accessibility resources for minority languages like Mongolian. These findings will shape our future efforts to improve accessibility and self-directed learning for visually impaired individuals.', 'doi': '10.1145/3663548.3688524', 'url': 'https://doi.org/10.1145/3663548.3688524', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Establishing a Community-Driven Digital Library for the Visually Impaired', 'author': 'Matsumura, Tomoya and Iijima, Ryo and Miura, Takahiro and Matsuo, Masaki and Ochiai, Yoichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688524'}"
Investigating the Efficacy of Conference Room Webcams for Remote Group Sign Language Interpretation Sessions,10.1145/3663548.3688493,"Sign language interpreters play a crucial role in facilitating communication between Deaf individuals who primarily use sign language and people who use spoken language and lack proficiency in sign language. One method for providing this service is live video streaming, such as video remote interpreting (VRI) or video relay service (VRS) interpreting. In this case, during group sessions that involve multiple participants and various visual aids, interpreters often have limited access to the Deaf clients’ environment due to the constraints of their cameras’ field of view (FOV). This study examines whether enhancing interpreters’ access to a Deaf client’s environment using cameras with a wider FOV can improve the overall effectiveness of interpreting group sessions. To explore this, we developed an application using conference room webcams and conducted usability testing sessions with twenty experienced VRI/VRS interpreters, who evaluated different screen layouts through simulated group meetings. This paper presents the findings on nine different layout configurations, including screen layout, FOV, and the ability to observe the presenter’s movements during group sessions.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Deaf or hard of hearing, Field of view, Video relay service interpreting, Video remote interpreting', 'numpages': '4', 'articleno': '118', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sign language interpreters play a crucial role in facilitating communication between Deaf individuals who primarily use sign language and people who use spoken language and lack proficiency in sign language. One method for providing this service is live video streaming, such as video remote interpreting (VRI) or video relay service (VRS) interpreting. In this case, during group sessions that involve multiple participants and various visual aids, interpreters often have limited access to the Deaf clients’ environment due to the constraints of their cameras’ field of view (FOV). This study examines whether enhancing interpreters’ access to a Deaf client’s environment using cameras with a wider FOV can improve the overall effectiveness of interpreting group sessions. To explore this, we developed an application using conference room webcams and conducted usability testing sessions with twenty experienced VRI/VRS interpreters, who evaluated different screen layouts through simulated group meetings. This paper presents the findings on nine different layout configurations, including screen layout, FOV, and the ability to observe the presenter’s movements during group sessions.', 'doi': '10.1145/3663548.3688493', 'url': 'https://doi.org/10.1145/3663548.3688493', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Investigating the Efficacy of Conference Room Webcams for Remote Group Sign Language Interpretation Sessions', 'author': 'Mathew, Roshan and Dannels, Wendy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688493'}"
Toward Closed-Domain Conversational Item Listing Assistant for Improvement of Experiences of Older Adults in Customer-to-Customer (C2C) Marketplaces,10.1145/3663548.3688522,"Due to the increased availability of internet-based services, the number of e-commerce users among older adults is steadily growing. However, little is known about how older adults would adapt to modern e-commerce services, especially in the case of customer-to-customer (C2C) marketplaces as buyers and sellers. To address that, we propose a closed-domain conversational chatbot assistant that guides older adults through the product listing process. We evaluated the usability of our tool with 10 participants, consisting of a pre-test survey and a post-task interview. We found that while older adults proficiently operated with familiar functions such as text entry and photo taking, they faced challenges in understanding the purpose of each task and how tasks were related to each other. We suggest design implications for creating conversational chatbot assistants that help older adults sell items in C2C marketplaces.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'accessibility, chatbot assistant, conversational agents, e-commerce, older adults', 'numpages': '5', 'articleno': '119', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Due to the increased availability of internet-based services, the number of e-commerce users among older adults is steadily growing. However, little is known about how older adults would adapt to modern e-commerce services, especially in the case of customer-to-customer (C2C) marketplaces as buyers and sellers. To address that, we propose a closed-domain conversational chatbot assistant that guides older adults through the product listing process. We evaluated the usability of our tool with 10 participants, consisting of a pre-test survey and a post-task interview. We found that while older adults proficiently operated with familiar functions such as text entry and photo taking, they faced challenges in understanding the purpose of each task and how tasks were related to each other. We suggest design implications for creating conversational chatbot assistants that help older adults sell items in C2C marketplaces.', 'doi': '10.1145/3663548.3688522', 'url': 'https://doi.org/10.1145/3663548.3688522', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Toward Closed-Domain Conversational Item Listing Assistant for Improvement of Experiences of Older Adults in Customer-to-Customer (C2C) Marketplaces', 'author': 'Park, Subin and Jung, Hyunggu and Ryskeldiev, Bektur and Lee, Jihyun and Lee, Gwanhee and Jeong, Hyeonhak and Chun, Minki and Teramoto, Kentaro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688522'}"
"Record, Transcribe, Share: An Accessible Open-Source Video Platform for Deaf and Hard of Hearing Viewers",10.1145/3663548.3688495,"Providing accessible videos is crucial for enabling access to a diverse audience. However, creating and distributing such videos demands significant effort and technical expertise. While several commercial platforms offer all-in-one solutions with a strong user experience, their use can be hindered by privacy concerns and budget constraints, particularly in Higher Education settings. To address this issue, we present an open-source platform that integrates several open-source developments in Automatic Speech Recognition and real-time collaboration.1 The platform serves both as a production-ready system and as a testbed for exploring new technologies and ideas through user evaluations. It supports a seamless workflow from video capture to transcription and delivery in both offline and real-time scenarios. We describe the design of the system, the design decisions informed by previous studies, its implementation and, preliminary evaluation results. The platform can be used by educational institutions to provide accessible video content and by researchers for further development and experimentation.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'automatic speech recognition, collaboration, crowdsourcing, real-time, streaming', 'numpages': '6', 'articleno': '120', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Providing accessible videos is crucial for enabling access to a diverse audience. However, creating and distributing such videos demands significant effort and technical expertise. While several commercial platforms offer all-in-one solutions with a strong user experience, their use can be hindered by privacy concerns and budget constraints, particularly in Higher Education settings. To address this issue, we present an open-source platform that integrates several open-source developments in Automatic Speech Recognition and real-time collaboration.1 The platform serves both as a production-ready system and as a testbed for exploring new technologies and ideas through user evaluations. It supports a seamless workflow from video capture to transcription and delivery in both offline and real-time scenarios. We describe the design of the system, the design decisions informed by previous studies, its implementation and, preliminary evaluation results. The platform can be used by educational institutions to provide accessible video content and by researchers for further development and experimentation.', 'doi': '10.1145/3663548.3688495', 'url': 'https://doi.org/10.1145/3663548.3688495', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Record, Transcribe, Share: An Accessible Open-Source Video Platform for Deaf and Hard of Hearing Viewers', 'author': 'Kuhn, Korbinian and Reuter, Benedikt and Egger, Niklas and Zimmermann, Gottfried', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688495'}"
Pose-aware Large Language Model Interface for Providing Feedback to Sign Language Learners,10.1145/3663548.3688515,"Sign language learners often find it challenging to self-identify and correct mistakes, and so many turn to automated methods that provide sign language feedback. However, they find that existing methods either require specialized equipment or lack robustness. They, therefore, have to seek human tutors or give up on the inquiry altogether. To overcome the barriers in accessibility and robustness, we build a large language model (LLM)-based tool for that provide feedback to sign language learners. The tool can analyze videos from diverse camera and background settings without specialized equipment thanks to a sign language segmentation and keyframe identification model. Using a pose-aware LLM, the tool can then produce feedback in written language. We present our tool as a demo web application, opening its implementation into specialized learning applications.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Large Language Models, Learning Tool, Sign Language', 'numpages': '5', 'articleno': '121', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sign language learners often find it challenging to self-identify and correct mistakes, and so many turn to automated methods that provide sign language feedback. However, they find that existing methods either require specialized equipment or lack robustness. They, therefore, have to seek human tutors or give up on the inquiry altogether. To overcome the barriers in accessibility and robustness, we build a large language model (LLM)-based tool for that provide feedback to sign language learners. The tool can analyze videos from diverse camera and background settings without specialized equipment thanks to a sign language segmentation and keyframe identification model. Using a pose-aware LLM, the tool can then produce feedback in written language. We present our tool as a demo web application, opening its implementation into specialized learning applications.', 'doi': '10.1145/3663548.3688515', 'url': 'https://doi.org/10.1145/3663548.3688515', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Pose-aware Large Language Model Interface for Providing Feedback to Sign Language Learners', 'author': 'Knapp, Vaclav and Bohacek, Matyas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688515'}"
Supporting Sound Accessibility by Exploring Sound Augmentations in Virtual Reality,10.1145/3663548.3688525,"To increase VR sound accessibility for deaf and hard of hearing users, previous work has substituted sounds with visual or haptic feedback. However, many DHH people (e.g., those with partial hearing) can also benefit from modifying audio (e.g., changing volume based on priorities) instead of fully substituting it with another modality. In this demo paper, we present a toolkit that allows modifying sounds in VR to support DHH people. We designed and implemented 18 VR sound modification tools spanning four categories, including prioritizing sounds, modifying sound parameters, providing spatial assistance, and adding additional sounds. We present five demo scenarios with tools incorporated, covering common VR use cases.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '5', 'articleno': '122', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'To increase VR sound accessibility for deaf and hard of hearing users, previous work has substituted sounds with visual or haptic feedback. However, many DHH people (e.g., those with partial hearing) can also benefit from modifying audio (e.g., changing volume based on priorities) instead of fully substituting it with another modality. In this demo paper, we present a toolkit that allows modifying sounds in VR to support DHH people. We designed and implemented 18 VR sound modification tools spanning four categories, including prioritizing sounds, modifying sound parameters, providing spatial assistance, and adding additional sounds. We present five demo scenarios with tools incorporated, covering common VR use cases.', 'doi': '10.1145/3663548.3688525', 'url': 'https://doi.org/10.1145/3663548.3688525', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Supporting Sound Accessibility by Exploring Sound Augmentations in Virtual Reality', 'author': 'Cao, Xinyun and Jain, Dhruv', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688525'}"
Enhancing Accessibility in Collaborative Digital Whiteboards: A Demonstration of Innovative Features for Inclusive Real-Time Collaboration,10.1145/3663548.3688528,"The recent popularization of a new category of digital tools, based on real-time collaboration among multiple users on an infinite 2D canvas, presents novel challenges as well as interesting opportunities in the domain of accessibility. These platforms rely heavily on visual information and point-and-click interaction, incurring the risk of not being sufficiently inclusive and therefore actively contributing to the exclusion of people with disabilities from equal access and employment opportunities. Other disruptive paradigm changes in Human-Computer Interaction such as the transition from command line to graphical user interfaces in operating systems, or the progressive adoption of touchscreens over keypads and keyboards in mobile devices, have raised similar concerns in the past. Continuous improvement through proper design and consideration later refuted those concerns, leading to highly accessible user experiences. Visual collaboration platforms constitute an equally disruptive paradigm shift and offer the opportunity to make digital collaboration and innovation more accessible than ever before.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '3', 'articleno': '123', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The recent popularization of a new category of digital tools, based on real-time collaboration among multiple users on an infinite 2D canvas, presents novel challenges as well as interesting opportunities in the domain of accessibility. These platforms rely heavily on visual information and point-and-click interaction, incurring the risk of not being sufficiently inclusive and therefore actively contributing to the exclusion of people with disabilities from equal access and employment opportunities. Other disruptive paradigm changes in Human-Computer Interaction such as the transition from command line to graphical user interfaces in operating systems, or the progressive adoption of touchscreens over keypads and keyboards in mobile devices, have raised similar concerns in the past. Continuous improvement through proper design and consideration later refuted those concerns, leading to highly accessible user experiences. Visual collaboration platforms constitute an equally disruptive paradigm shift and offer the opportunity to make digital collaboration and innovation more accessible than ever before.', 'doi': '10.1145/3663548.3688528', 'url': 'https://doi.org/10.1145/3663548.3688528', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Enhancing Accessibility in Collaborative Digital Whiteboards: A Demonstration of Innovative Features for Inclusive Real-Time Collaboration', 'author': 'Strain, Philip and Baldan, Stefano', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688528'}"
Demonstration of CameraMouseAI: A Head-Based Mouse-Control System for People with Severe Motor Disabilities,10.1145/3663548.3688499,"We propose the mouse control system CameraMouseAI that includes real-time facial feature detection and new ways to map facial feature movements to mouse clicks. In addition to selecting items on the screen with the traditional dwell-time mechanism, users can perform mouse commands on the screen by opening their mouth or raising their eyebrows. The modular and open source design of CameraMouseAI enables developers to update the platform with new computer vision and machine learning models and extend its functionality. User experiments with the CameraMouseAI involved target selection, web browsing, and typing. A group of 12 adults without motor impairments and four adults with severe motor impairments were able to use the application to complete both target selection and web browsing tasks.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'facial landmarks, gestures, mouse control', 'numpages': '6', 'articleno': '124', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We propose the mouse control system CameraMouseAI that includes real-time facial feature detection and new ways to map facial feature movements to mouse clicks. In addition to selecting items on the screen with the traditional dwell-time mechanism, users can perform mouse commands on the screen by opening their mouth or raising their eyebrows. The modular and open source design of CameraMouseAI enables developers to update the platform with new computer vision and machine learning models and extend its functionality. User experiments with the CameraMouseAI involved target selection, web browsing, and typing. A group of 12 adults without motor impairments and four adults with severe motor impairments were able to use the application to complete both target selection and web browsing tasks.', 'doi': '10.1145/3663548.3688499', 'url': 'https://doi.org/10.1145/3663548.3688499', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Demonstration of CameraMouseAI: A Head-Based Mouse-Control System for People with Severe Motor Disabilities', 'author': 'Karimli, Farid and Yu, Hao and Jain, Srishti and Akosah, Emmanuel Sarpong and Betke, Margrit and Feng, Wenxin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688499'}"
Screen Reading Enabled by Large Language Models,10.1145/3663548.3688491,"Large language models (LLMs), such as the pioneering GPT technology by OpenAI, have undeniably become one of the most significant innovations in recent history. They have achieved phenomenal success across a broad spectrum of applications in numerous industries, transforming how we interact with the digital world. Notwithstanding these remarkable successes, applying LLMs within the realm of accessibility has largely been unexplored. We introduce&nbsp;Savant, as a demonstration of the potential of LLMs for accessibility. Specifically,&nbsp;Savant leverages the impressive text comprehension abilities of LLMs to provide uniform interaction for screen reader users across various applications, mitigating the significant interaction burden imposed by the heterogeneity in user interfaces for blind screen reader users.&nbsp;Savant automates screen reader actions on control elements like buttons, text fields, and drop-down menus via spoken natural language commands (NLCs). Interpreting the NLC, identifying the correct control element, and formulating the action sequence are facilitated by LLMs. Few-shot prompts supply context and guidance for the LLMs to produce appropriate responses, specifically converting the NLC into a correct series of actions on the user interface elements, which are then performed automatically. The demonstration will exhibit&nbsp;Savant’s capability across a variety of exemplar applications, emphasizing its versatility.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Assistive technology, Blind users, Computer Interaction, Large language models (LLMs), Uniform interaction', 'numpages': '5', 'articleno': '125', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Large language models (LLMs), such as the pioneering GPT technology by OpenAI, have undeniably become one of the most significant innovations in recent history. They have achieved phenomenal success across a broad spectrum of applications in numerous industries, transforming how we interact with the digital world. Notwithstanding these remarkable successes, applying LLMs within the realm of accessibility has largely been unexplored. We introduce&nbsp;Savant, as a demonstration of the potential of LLMs for accessibility. Specifically,&nbsp;Savant leverages the impressive text comprehension abilities of LLMs to provide uniform interaction for screen reader users across various applications, mitigating the significant interaction burden imposed by the heterogeneity in user interfaces for blind screen reader users.&nbsp;Savant automates screen reader actions on control elements like buttons, text fields, and drop-down menus via spoken natural language commands (NLCs). Interpreting the NLC, identifying the correct control element, and formulating the action sequence are facilitated by LLMs. Few-shot prompts supply context and guidance for the LLMs to produce appropriate responses, specifically converting the NLC into a correct series of actions on the user interface elements, which are then performed automatically. The demonstration will exhibit&nbsp;Savant’s capability across a variety of exemplar applications, emphasizing its versatility.', 'doi': '10.1145/3663548.3688491', 'url': 'https://doi.org/10.1145/3663548.3688491', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Screen Reading Enabled by Large Language Models', 'author': 'Ghosh, Anujay and Padma Reddy, Monalika and Kodandaram, Satwik Ram and Uckun, Utku and Ashok, Vikas and Bi, Xiaojun and Ramakrishnan, IV', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688491'}"
Towards a Rich Format for Closed-Captioning,10.1145/3663548.3688504,"Closed-captioning is an essential part of viewing audio-visual content for many people, including those who are D/deaf and Hard-of-Hearing. Traditional closed-captioning systems generally consist of a single track of timed text that offers limited options for personalization. Research into extending the capabilities of captioning, such as affective, poetic, and customizable captions has shown a desire among a subset of users for these features, but only in specific contexts. However, due to the difficulty in creating custom stimuli videos utilizing the custom captioning system, comparisons between systems and longitudinal studies have not been pursued. This demo paper introduces Rich Captions, a structured system that allows for a single closed-caption file to be tagged with additional information that can then be flexibly leveraged to render different customizable, creative, and poetic captions from the same file. Additionally, we introduce the Rich Caption Editor&nbsp;1, a free, open-source software system designed to author, edit, and render rich captions. The system design was informed by a formative design workshop with closed-captioning researchers and advocates. The current design allows researchers to generate reproducible stimuli for closed-captioning studies. Once the design space and user preferences are better understood, the rich captioning framework could be refined to serve a general audience.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Affective Captioning, Closed-Captioning, Creative Captioning, Subtitles', 'numpages': '5', 'articleno': '126', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Closed-captioning is an essential part of viewing audio-visual content for many people, including those who are D/deaf and Hard-of-Hearing. Traditional closed-captioning systems generally consist of a single track of timed text that offers limited options for personalization. Research into extending the capabilities of captioning, such as affective, poetic, and customizable captions has shown a desire among a subset of users for these features, but only in specific contexts. However, due to the difficulty in creating custom stimuli videos utilizing the custom captioning system, comparisons between systems and longitudinal studies have not been pursued. This demo paper introduces Rich Captions, a structured system that allows for a single closed-caption file to be tagged with additional information that can then be flexibly leveraged to render different customizable, creative, and poetic captions from the same file. Additionally, we introduce the Rich Caption Editor&nbsp;1, a free, open-source software system designed to author, edit, and render rich captions. The system design was informed by a formative design workshop with closed-captioning researchers and advocates. The current design allows researchers to generate reproducible stimuli for closed-captioning studies. Once the design space and user preferences are better understood, the rich captioning framework could be refined to serve a general audience.', 'doi': '10.1145/3663548.3688504', 'url': 'https://doi.org/10.1145/3663548.3688504', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Towards a Rich Format for Closed-Captioning', 'author': 'May, Lloyd and Williams, Alex and Hassan, Saad and Cartwright, Mark and Lee, Sooyeon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688504'}"
Musical Performances in Virtual Reality with Spatial and View-Dependent Audio Descriptions for Blind and Low-Vision Users,10.1145/3663548.3688492,"Virtual reality (VR), inherently reliant on spatial interaction, poses significant accessibility barriers for individuals who are blind or have low vision (BLV). Traditional audio descriptions (AD) typically provide a verbal explanation of visual elements in 2D or flat video media, facilitating access for BLV audiences but failing to convey the complex spatial information essential in VR. This shortfall is especially pronounced in musical performances, where understanding the spatial arrangement of the stage setup and movements of performers is crucial. To overcome these limitations, we have developed two AD approaches—Spatial AD for a dance performance and View-dependent AD for an instrumental performance—within VR-based 360° environments. Spatial AD employs spatial audio technology to align descriptions with corresponding visuals, dynamically adjusting to follow the visuals, such as the movements of performers in the dance performance. Meanwhile, View-dependent AD adapts descriptions based on the orientation of the VR headset, activating when particular visuals enter the central view of the camera, ensuring that the description aligns with the user’s attention directed to a particular location within the VR environment. These methods are designed as enhancements to traditional AD, aiming to improve spatial orientation and immersive experiences for BLV audiences. This demonstration showcases the potential of these AD approaches to improve interaction and engagement, furthering the development of inclusive virtual environments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Audio Descriptions, Musical Performances, Virtual Reality', 'numpages': '5', 'articleno': '127', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Virtual reality (VR), inherently reliant on spatial interaction, poses significant accessibility barriers for individuals who are blind or have low vision (BLV). Traditional audio descriptions (AD) typically provide a verbal explanation of visual elements in 2D or flat video media, facilitating access for BLV audiences but failing to convey the complex spatial information essential in VR. This shortfall is especially pronounced in musical performances, where understanding the spatial arrangement of the stage setup and movements of performers is crucial. To overcome these limitations, we have developed two AD approaches—Spatial AD for a dance performance and View-dependent AD for an instrumental performance—within VR-based 360° environments. Spatial AD employs spatial audio technology to align descriptions with corresponding visuals, dynamically adjusting to follow the visuals, such as the movements of performers in the dance performance. Meanwhile, View-dependent AD adapts descriptions based on the orientation of the VR headset, activating when particular visuals enter the central view of the camera, ensuring that the description aligns with the user’s attention directed to a particular location within the VR environment. These methods are designed as enhancements to traditional AD, aiming to improve spatial orientation and immersive experiences for BLV audiences. This demonstration showcases the potential of these AD approaches to improve interaction and engagement, furthering the development of inclusive virtual environments.', 'doi': '10.1145/3663548.3688492', 'url': 'https://doi.org/10.1145/3663548.3688492', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Musical Performances in Virtual Reality with Spatial and View-Dependent Audio Descriptions for Blind and Low-Vision Users', 'author': 'Dang, Khang and Lee, Sooyeon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688492'}"
Touchpad Mapper: Examining Information Consumption From 2D Digital Content Using Touchpads by Screen-Reader Users,10.1145/3663548.3688505,"Touchpads are used widely to interact with computers, yet they provide minimal utility for screen-reader users. We explore the utility of touchpads as input devices for screen-reader users through the development and preliminary evaluation of Touchpad Mapper. This system maps digital content (i.e., images and videos) to the physical coordinates of a touchpad. We examined two usage scenarios: (1) identification of objects and their relative positioning in an image and (2) controlling a video seek bar and slider with rewinding and fast-forwarding features. We conducted task-based semi-structured interviews with two screen-reader users to assess our system’s performance. The participants reported positive experiences, highlighting that they extracted information faster using our system than the conventional keyboard-only interaction.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'blind, interaction, non-visual, screen reader, touchpad, video', 'numpages': '4', 'articleno': '128', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Touchpads are used widely to interact with computers, yet they provide minimal utility for screen-reader users. We explore the utility of touchpads as input devices for screen-reader users through the development and preliminary evaluation of Touchpad Mapper. This system maps digital content (i.e., images and videos) to the physical coordinates of a touchpad. We examined two usage scenarios: (1) identification of objects and their relative positioning in an image and (2) controlling a video seek bar and slider with rewinding and fast-forwarding features. We conducted task-based semi-structured interviews with two screen-reader users to assess our system’s performance. The participants reported positive experiences, highlighting that they extracted information faster using our system than the conventional keyboard-only interaction.', 'doi': '10.1145/3663548.3688505', 'url': 'https://doi.org/10.1145/3663548.3688505', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Touchpad Mapper: Examining Information Consumption From 2D Digital Content Using Touchpads by Screen-Reader Users', 'author': 'Sharif, Ather and Potluri, Venkatesh and Ang, Jazz Rui Xia and Wobbrock, Jacob O. and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688505'}"
StereoMath: An Accessible and Musical Equation Editor,10.1145/3663548.3688487,"For blind and low-vision (BLV) individuals, digital math communication is uniquely difficult due to the lack of accessible tools. Currently, the state of the art is either code-based, like LaTeX, or WYSIWYG, like visual editors. However, both paradigms view math communication as primarily a visual typesetting problem, and may be accessible but difficult to use. In this paper, we present an equation editor that is built from the ground up with BLV accessibility in mind. Specifically, we notice that two of the biggest barriers with current technology are the high cognitive load and the lack of spatial relationships. Thus, we build an editor that uses spatial audio cues, muscle memory, tones, and more intuitive navigation to properly contextualize math equations. We discuss how this new paradigm can enable new levels of math communication, engagement, and literacy. Finally, we discuss natural next steps.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'LaTeX, blind, equation editor, low-vision, visual impairment', 'numpages': '5', 'articleno': '129', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'For blind and low-vision (BLV) individuals, digital math communication is uniquely difficult due to the lack of accessible tools. Currently, the state of the art is either code-based, like LaTeX, or WYSIWYG, like visual editors. However, both paradigms view math communication as primarily a visual typesetting problem, and may be accessible but difficult to use. In this paper, we present an equation editor that is built from the ground up with BLV accessibility in mind. Specifically, we notice that two of the biggest barriers with current technology are the high cognitive load and the lack of spatial relationships. Thus, we build an editor that uses spatial audio cues, muscle memory, tones, and more intuitive navigation to properly contextualize math equations. We discuss how this new paradigm can enable new levels of math communication, engagement, and literacy. Finally, we discuss natural next steps.', 'doi': '10.1145/3663548.3688487', 'url': 'https://doi.org/10.1145/3663548.3688487', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'StereoMath: An Accessible and Musical Equation Editor', 'author': 'Ge, Kenneth and Seo, JooYoung', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688487'}"
An AI Guide to Enhance Accessibility of Social Virtual Reality for Blind People,10.1145/3663548.3688498,"The rapid growth of virtual reality (VR) has led to increased use of social VR platforms for interaction. However, these platforms lack adequate features to support blind and low vision (BLV) users, posing significant challenges in navigation, visual interpretation, and social interaction. One promising approach to these challenges is employing human guides in VR. However, this approach faces limitations with a lack of availability of humans to serve as guides, or the inability to customize the guidance a user receives from the human guide. We introduce an AI-powered guide to address these limitations. The AI guide features six personas, each offering unique behaviors and appearances to meet diverse user needs, along with visual interpretation and navigation assistance. We aim to use this AI guide in the future to help us understand BLV users’ preferences for guide forms and functionalities.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'VR, accessibility, blind, low vision', 'numpages': '5', 'articleno': '130', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The rapid growth of virtual reality (VR) has led to increased use of social VR platforms for interaction. However, these platforms lack adequate features to support blind and low vision (BLV) users, posing significant challenges in navigation, visual interpretation, and social interaction. One promising approach to these challenges is employing human guides in VR. However, this approach faces limitations with a lack of availability of humans to serve as guides, or the inability to customize the guidance a user receives from the human guide. We introduce an AI-powered guide to address these limitations. The AI guide features six personas, each offering unique behaviors and appearances to meet diverse user needs, along with visual interpretation and navigation assistance. We aim to use this AI guide in the future to help us understand BLV users’ preferences for guide forms and functionalities.', 'doi': '10.1145/3663548.3688498', 'url': 'https://doi.org/10.1145/3663548.3688498', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'An AI Guide to Enhance Accessibility of Social Virtual Reality for Blind People', 'author': 'Collins, Jazmin and Nicholson, Kaylah Myranda and Khadir, Yusuf and Stevenson Won, Andrea and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688498'}"
Making 3D Printer Accessible for People with Visual Impairments by Reading Scrolling Text and Menus,10.1145/3663548.3688517,"3D printing has immense potential to enhance the lives of people with visual impairments (PVI) by enabling them to understand shapes and other details through touch that words alone cannot convey. Several initiatives have made 3D tactile models accessible to PVI, yet these models are typically created by sighted individuals. Our goal is to empower PVI to create 3D tactile models independently, making 3D printers accessible to them. The biggest bottleneck for PVI in using 3D printers is the inability to read text on their display. Our work specifically focuses on making scrolling text and menus readable. Through a user study with 13 PVI (five blind and eight with low vision), we confirmed the effectiveness of the implemented functions over conventional smartphone apps and wearable devices.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': '3D printer, menus, optical character reader (OCR), scrolling text', 'numpages': '4', 'articleno': '131', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': '3D printing has immense potential to enhance the lives of people with visual impairments (PVI) by enabling them to understand shapes and other details through touch that words alone cannot convey. Several initiatives have made 3D tactile models accessible to PVI, yet these models are typically created by sighted individuals. Our goal is to empower PVI to create 3D tactile models independently, making 3D printers accessible to them. The biggest bottleneck for PVI in using 3D printers is the inability to read text on their display. Our work specifically focuses on making scrolling text and menus readable. Through a user study with 13 PVI (five blind and eight with low vision), we confirmed the effectiveness of the implemented functions over conventional smartphone apps and wearable devices.', 'doi': '10.1145/3663548.3688517', 'url': 'https://doi.org/10.1145/3663548.3688517', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Making 3D Printer Accessible for People with Visual Impairments by Reading Scrolling Text and Menus', 'author': 'Tagawa, Naoya and Iwamura, Masakazu and Minatani, Kazunori and Kise, Koichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688517'}"
Echolocation as an Accessible Navigation Tool in a Virtual 3D Environment,10.1145/3663548.3688547,"The heavy reliance on visuals in virtual environments creates significant challenges for blind and low-vision (BLV) individuals, effectively preventing them from navigating these spaces. This study investigates the efficacy of an implementation of active echolocation in a 3D virtual environment. We conducted a user study with 13 BLV participants to evaluate the effectiveness and usability of our implementation across six levels of spatial difficulty. Our data analysis revealed distinct navigation strategies and approaches used by participants. Four participants had a spatial cognitive approach, three had a pragmatic approach, and six had an inconclusive approach. Our results highlight both the potential and limitations of the implemented echolocation. Our analysis identified several limitations with our implementation. We propose alternative designs to enhance the echolocation ability and sound simulation. Additionally, we suggest improvements for future work on accessibility and usability of active echolocation tools in 3D virtual environments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, blindness and low vision, echolocation., virtual environments', 'numpages': '9', 'articleno': '132', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The heavy reliance on visuals in virtual environments creates significant challenges for blind and low-vision (BLV) individuals, effectively preventing them from navigating these spaces. This study investigates the efficacy of an implementation of active echolocation in a 3D virtual environment. We conducted a user study with 13 BLV participants to evaluate the effectiveness and usability of our implementation across six levels of spatial difficulty. Our data analysis revealed distinct navigation strategies and approaches used by participants. Four participants had a spatial cognitive approach, three had a pragmatic approach, and six had an inconclusive approach. Our results highlight both the potential and limitations of the implemented echolocation. Our analysis identified several limitations with our implementation. We propose alternative designs to enhance the echolocation ability and sound simulation. Additionally, we suggest improvements for future work on accessibility and usability of active echolocation tools in 3D virtual environments.', 'doi': '10.1145/3663548.3688547', 'url': 'https://doi.org/10.1145/3663548.3688547', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Echolocation as an Accessible Navigation Tool in a Virtual 3D Environment', 'author': 'Th\\o{}gersen, Mai Ricaplaza and Kjeldsen, Rasmus Jens Fr\\o{}lich', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688547'}"
“I'm treating it kind of like a diary”: Characterizing How Users with Disabilities Use AI Chatbots,10.1145/3663548.3688549,"Marginalized and underrepresented groups, including the disability community, are at risk of being harmed by bias and underserved by emerging technologies, such as Large Language Models (LLMs) and their downstream applications. While previous work has identified types of harm LLM technologies imposed on the disability community, there is a gap in research understanding the use cases and needs of people with disabilities when interacting with such technologies. To fill this knowledge gap, our study seeks to investigate real-life interactions between people with disabilities and LLM-based chatbots. Grounded in the Disability Justice Principle of following the leadership of the “the most impacted,” we interviewed 30 people with disabilities to learn about their current uses of chatbots. We analyzed 18 interviews and characterized distinct use cases, such as navigating social interactions, revising written work, and playing games, into nine broader categories. Our discussion contemplates how the presented chatbot use cases can serve as a foundation for further disability representation work with LLMs.&nbsp;","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'numpages': '7', 'articleno': '133', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Marginalized and underrepresented groups, including the disability community, are at risk of being harmed by bias and underserved by emerging technologies, such as Large Language Models (LLMs) and their downstream applications. While previous work has identified types of harm LLM technologies imposed on the disability community, there is a gap in research understanding the use cases and needs of people with disabilities when interacting with such technologies. To fill this knowledge gap, our study seeks to investigate real-life interactions between people with disabilities and LLM-based chatbots. Grounded in the Disability Justice Principle of following the leadership of the “the most impacted,” we interviewed 30 people with disabilities to learn about their current uses of chatbots. We analyzed 18 interviews and characterized distinct use cases, such as navigating social interactions, revising written work, and playing games, into nine broader categories. Our discussion contemplates how the presented chatbot use cases can serve as a foundation for further disability representation work with LLMs.&nbsp;', 'doi': '10.1145/3663548.3688549', 'url': 'https://doi.org/10.1145/3663548.3688549', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': ""“I'm treating it kind of like a diary”: Characterizing How Users with Disabilities Use AI Chatbots"", 'author': 'Mullen, Kayla and Xue, Wenhan and Kudumu, Manasa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688549'}"
Accessible Bus Stop Preview for Visually Impaired,10.1145/3663548.3688548,"This proposed research aims to advance inclusive audiovisual aids for outdoor navigation and public transportation by leveraging insights gained from state-of-the-art research on maps for visually impaired individuals. We surveyed twenty participants with vision impairments to gather insights and then created a prototype based on their feedback. Additionally, we evaluated the prototype with ten participants with vision impairments by previewing the accessibility of bus stop areas and their surroundings to improve inclusive public transportation. Our research also involved analyzing bus routes to ensure they meet accessibility standards and enhance navigation for users with vision impairments.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Digital Mapping, Public Transportation, Visually Impaired', 'numpages': '6', 'articleno': '134', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This proposed research aims to advance inclusive audiovisual aids for outdoor navigation and public transportation by leveraging insights gained from state-of-the-art research on maps for visually impaired individuals. We surveyed twenty participants with vision impairments to gather insights and then created a prototype based on their feedback. Additionally, we evaluated the prototype with ten participants with vision impairments by previewing the accessibility of bus stop areas and their surroundings to improve inclusive public transportation. Our research also involved analyzing bus routes to ensure they meet accessibility standards and enhance navigation for users with vision impairments.', 'doi': '10.1145/3663548.3688548', 'url': 'https://doi.org/10.1145/3663548.3688548', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Accessible Bus Stop Preview for Visually Impaired', 'author': 'Erdemli, Mahmut', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688548'}"
The Future of Urban Accessibility: The Role of AI,10.1145/3663548.3688550,"We have entered a new era of computing—one where AI permeates every aspect of society from education to healthcare. In this workshop, we examine the emerging role of AI in the design of equitable and accessible cities, transportation systems, and interactive tools for mapping and navigation. We will solicit short papers around key Urban AI + disability themes, including autonomous vehicles, intelligent wheelchairs, assistive human-robotic interaction, assessing and navigating pedestrian pathways, indoor accessibility, and overarching challenges related to ethics, bias, and data privacy and security. We invite both traditional HCI and accessibility researchers as well as scholars and practitioners from other disciplines relevant to this workshop, including disability studies, gerontology, social work, community psychology, and law. Our overarching goal is to identify open challenges, share current work across disciplines, and spur new collaborations related to AI and urban accessibility.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Urban accessibility, autonomous vehicles, built environment, human mobility, sidewalks, smart cities, urban AI', 'numpages': '6', 'articleno': '135', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We have entered a new era of computing—one where AI permeates every aspect of society from education to healthcare. In this workshop, we examine the emerging role of AI in the design of equitable and accessible cities, transportation systems, and interactive tools for mapping and navigation. We will solicit short papers around key Urban AI + disability themes, including autonomous vehicles, intelligent wheelchairs, assistive human-robotic interaction, assessing and navigating pedestrian pathways, indoor accessibility, and overarching challenges related to ethics, bias, and data privacy and security. We invite both traditional HCI and accessibility researchers as well as scholars and practitioners from other disciplines relevant to this workshop, including disability studies, gerontology, social work, community psychology, and law. Our overarching goal is to identify open challenges, share current work across disciplines, and spur new collaborations related to AI and urban accessibility.', 'doi': '10.1145/3663548.3688550', 'url': 'https://doi.org/10.1145/3663548.3688550', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'The Future of Urban Accessibility: The Role of AI', 'author': 'Froehlich, Jon E. and Li, Chu and Hosseini, Maryam and Miranda, Fabio and Sevtsuk, Andres and Eisenberg, Yochai', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688550'}"
"Teaching Accessibility in Different Disciplines: Topics, Approaches, Resources, Challenges",10.1145/3663548.3688553,"Teaching accessibility is crucial to ensuring that accessibility principles are integrated into the design and adoption of software and other aspects of lives. The existing literature on accessibility education is largely siloed, appearing primarily in computer science and related disciplines. Understanding the similarities and differences in teaching accessibility across different disciplines is vital for enhancing educational effectiveness by leveraging lessons learned from each field. This workshop aims to serve as an interdisciplinary forum for researchers and education practitioners to discuss topics taught, approaches taken, resources utilized, and challenges encountered when teaching accessibility in different disciplines.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Assistive Technologies, Education', 'numpages': '4', 'articleno': '136', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Teaching accessibility is crucial to ensuring that accessibility principles are integrated into the design and adoption of software and other aspects of lives. The existing literature on accessibility education is largely siloed, appearing primarily in computer science and related disciplines. Understanding the similarities and differences in teaching accessibility across different disciplines is vital for enhancing educational effectiveness by leveraging lessons learned from each field. This workshop aims to serve as an interdisciplinary forum for researchers and education practitioners to discuss topics taught, approaches taken, resources utilized, and challenges encountered when teaching accessibility in different disciplines.', 'doi': '10.1145/3663548.3688553', 'url': 'https://doi.org/10.1145/3663548.3688553', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Teaching Accessibility in Different Disciplines: Topics, Approaches, Resources, Challenges', 'author': 'Zhou, Kyrie Zhixuan and Adler, Rachel F. and Almendral, Caterina and Choi, Soyoung and Kletenik, Devorah and Oro, Bruno and Seo, JooYoung', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688553'}"
Challenges and Considerations for Accessibility Research Across Cultures and Regions,10.1145/3663548.3688552,"Postcolonial and decolonial computing examines how technology design and adoption can perpetuate subtle dimensions of coloniality, under-represent certain regions (e.g., the Global South, non-Western regions, Indigenous societies), and marginalize them. There has been a growing interest in interdisciplinary research focusing on marginalized communities, including accessibility and participatory research. Despite the rapid expansion of accessibility research in the last decades, little focus is placed on accessibility issues within marginalized societies, hindering them from effectively benefiting from accessibility research discussions and outcomes. The accessibility and HCI communities still lack comprehensive knowledge on conducting interdisciplinary research that includes diverse cultures and experiences from some of the systematically marginalized regions. This workshop will explore the intersection of accessibility, HCI, and cross-regional studies, bringing together researchers and practitioners to foster collaborations, identify under-explored research areas, and develop guidelines to support inclusive research practices.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Accessibility, Cross-cultural Studies, Cross-regional Studies, Global South, HCI', 'numpages': '6', 'articleno': '137', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Postcolonial and decolonial computing examines how technology design and adoption can perpetuate subtle dimensions of coloniality, under-represent certain regions (e.g., the Global South, non-Western regions, Indigenous societies), and marginalize them. There has been a growing interest in interdisciplinary research focusing on marginalized communities, including accessibility and participatory research. Despite the rapid expansion of accessibility research in the last decades, little focus is placed on accessibility issues within marginalized societies, hindering them from effectively benefiting from accessibility research discussions and outcomes. The accessibility and HCI communities still lack comprehensive knowledge on conducting interdisciplinary research that includes diverse cultures and experiences from some of the systematically marginalized regions. This workshop will explore the intersection of accessibility, HCI, and cross-regional studies, bringing together researchers and practitioners to foster collaborations, identify under-explored research areas, and develop guidelines to support inclusive research practices.', 'doi': '10.1145/3663548.3688552', 'url': 'https://doi.org/10.1145/3663548.3688552', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'Challenges and Considerations for Accessibility Research Across Cultures and Regions', 'author': 'Nourian, Laleh and Goldenberg, Yulia and Adamu, Muhammad and Cannanure, Vikram Kamath and Holloway, Catherine and Kumar, Neha and Reinecke, Katharina and Tigwell, Garreth W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688552'}"
accessFinTech: Designing Accessible Financial Technology,10.1145/3663548.3688551,"Financial technology (fintech) has a growing impact on economic and social participation due to the increasing adoption of online banking and digital payments in everyday life. As fintech interests emerge in academic and industry work across the globe, critical needs and opportunities arise for ASSETS communities to lead and shape the discourse on accessible fintech. This workshop will bring together a diverse group of researchers and practitioners interested in developing a research agenda on designing accessible and inclusive fintech. We will take a timely step towards building a community to support continued discussion on the complex cultural and social contexts around fintech.","{'series': ""ASSETS '24"", 'location': ""St. John's, NL, Canada"", 'keywords': 'Financial technology (fintech), accessibility, banking, currency, payment', 'numpages': '5', 'articleno': '138', 'booktitle': 'Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Financial technology (fintech) has a growing impact on economic and social participation due to the increasing adoption of online banking and digital payments in everyday life. As fintech interests emerge in academic and industry work across the globe, critical needs and opportunities arise for ASSETS communities to lead and shape the discourse on accessible fintech. This workshop will bring together a diverse group of researchers and practitioners interested in developing a research agenda on designing accessible and inclusive fintech. We will take a timely step towards building a community to support continued discussion on the complex cultural and social contexts around fintech.', 'doi': '10.1145/3663548.3688551', 'url': 'https://doi.org/10.1145/3663548.3688551', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400706776', 'year': '2024', 'title': 'accessFinTech: Designing Accessible Financial Technology', 'author': ""Dai, Jiamin and Gorman, Benjamin M. and Tigwell, Garreth W. and Lyhme, Helena Marie and Barros Pena, Bel\\'{e}n and Moffatt, Karyn and Latulipe, Celine"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3663548.3688551'}"