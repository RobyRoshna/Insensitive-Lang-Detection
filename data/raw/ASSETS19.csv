Title,DOI,Abstract,BibTeX
"My Algorithms Have Determined You're Not Human: AI-ML, Reverse Turing-Tests, and the Disability Experience",10.1145/3308561.3353812,"The past decade has seen an exponential growth in the capabilities and deployment of artificial intelligence systems based on deep neural networks. These are visible through the speech recognition and natural language processing of Alexa/Siri/Google that structure many of our everyday interactions, and the promise of SAE Level 5 autonomous driving provided by Tesla and Waze. Aside from these shiny and visible applications of AI-ML are many other uses that are more subtle: AI-ML is now being used to screen job applicants as well as determine which web ads we are shown. And while many vendors of AI-ML technologies have promised that these tools provide for greater access and freedom from human prejudice, disabled users have found that these tools can embed and deploy newer, subtler forms of discrimination against disabled people. At their worst, AI-ML systems can deny disabled people their humanity.The explosion of AI-ML technologies in the last decade has been driven by at least three factors. First, the deep neural networks algorithms that currently drive much machine learning have been improved dramatically through the use of backpropagation [1], generative adversarial nets [2], and convolution [3], allowing for their deployment across a broad variety of datasets. Second, the cost of computing hardware (especially GPUs) has dropped dramatically while large scale cloud computing facilities and widespread fiber/ broadband/4G has provided for universal availability. Finally, large datasets have come online to aid in the training of the neural nets - for example, the image datasets provided through Google and Facebook, the large natural language datasets driving Amazon Alexa, and so forth.Deep neural networks themselves have two key features or flaws, depending on the perspective. First, they are highly dependent on the diversity of the training dataset used. Second, their internal operations when deployed are entirely opaque not only to the end-user but also to the designers of the system itself.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'artificial intelligence, bias, deep neural networks, disabilities, race', 'numpages': '2', 'pages': '1–2', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The past decade has seen an exponential growth in the capabilities and deployment of artificial intelligence systems based on deep neural networks. These are visible through the speech recognition and natural language processing of Alexa/Siri/Google that structure many of our everyday interactions, and the promise of SAE Level 5 autonomous driving provided by Tesla and Waze. Aside from these shiny and visible applications of AI-ML are many other uses that are more subtle: AI-ML is now being used to screen job applicants as well as determine which web ads we are shown. And while many vendors of AI-ML technologies have promised that these tools provide for greater access and freedom from human prejudice, disabled users have found that these tools can embed and deploy newer, subtler forms of discrimination against disabled people. At their worst, AI-ML systems can deny disabled people their humanity.The explosion of AI-ML technologies in the last decade has been driven by at least three factors. First, the deep neural networks algorithms that currently drive much machine learning have been improved dramatically through the use of backpropagation [1], generative adversarial nets [2], and convolution [3], allowing for their deployment across a broad variety of datasets. Second, the cost of computing hardware (especially GPUs) has dropped dramatically while large scale cloud computing facilities and widespread fiber/ broadband/4G has provided for universal availability. Finally, large datasets have come online to aid in the training of the neural nets - for example, the image datasets provided through Google and Facebook, the large natural language datasets driving Amazon Alexa, and so forth.Deep neural networks themselves have two key features or flaws, depending on the perspective. First, they are highly dependent on the diversity of the training dataset used. Second, their internal operations when deployed are entirely opaque not only to the end-user but also to the designers of the system itself.', 'doi': '10.1145/3308561.3353812', 'url': 'https://doi.org/10.1145/3308561.3353812', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': ""My Algorithms Have Determined You're Not Human: AI-ML, Reverse Turing-Tests, and the Disability Experience"", 'author': 'Nakamura, Karen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353812'}"
"Voice Telephony for Individuals with Hearing Loss: The Effects of Audio Bandwidth, Bit Rate and Packet Loss",10.1145/3308561.3353796,"This paper describes three studies conducted with a total of 114 individuals with hearing loss and 12 hearing controls, with the goal of investigating the impact of audio quality parameters on the accessibility of voice telecommunications. Three categories of parameters are covered: (1) narrowband (NB) versus wideband (WB) audio; (2) encoding audio at varying bit rates, ranging from typical rates used in today's telecom networks to the highest quality supported by these audio codecs; and (3) absence of packet loss to worst-case packet loss in VoIP telephony. With WB audio, individuals with hearing loss exhibit better speech recognition, expend less perceived mental effort, and rate speech quality higher than with NB audio. Bit rate affects speech recognition for NB audio, and speech quality ratings for both NB and WB audio. Packet loss affects all of speech recognition, mental effort, and speech quality ratings. WB versus NB audio also affects hearing individuals, especially under packet loss.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'audio codec, bit rate, cochlear implant, hard of hearing, hearing aid, hearing loss, narrowband audio, packet loss, telecommunications, voice telephony, wideband audio', 'numpages': '13', 'pages': '3–15', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper describes three studies conducted with a total of 114 individuals with hearing loss and 12 hearing controls, with the goal of investigating the impact of audio quality parameters on the accessibility of voice telecommunications. Three categories of parameters are covered: (1) narrowband (NB) versus wideband (WB) audio; (2) encoding audio at varying bit rates, ranging from typical rates used in today's telecom networks to the highest quality supported by these audio codecs; and (3) absence of packet loss to worst-case packet loss in VoIP telephony. With WB audio, individuals with hearing loss exhibit better speech recognition, expend less perceived mental effort, and rate speech quality higher than with NB audio. Bit rate affects speech recognition for NB audio, and speech quality ratings for both NB and WB audio. Packet loss affects all of speech recognition, mental effort, and speech quality ratings. WB versus NB audio also affects hearing individuals, especially under packet loss."", 'doi': '10.1145/3308561.3353796', 'url': 'https://doi.org/10.1145/3308561.3353796', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Voice Telephony for Individuals with Hearing Loss: The Effects of Audio Bandwidth, Bit Rate and Packet Loss', 'author': 'Kozma-Spytek, Linda and Tucker, Paula and Vogler, Christian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353796'}"
"Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective",10.1145/3308561.3353774,"Developing successful sign language recognition, generation, and translation systems requires expertise in a wide range of fields, including computer vision, computer graphics, natural language processing, human-computer interaction, linguistics, and Deaf culture. Despite the need for deep interdisciplinary knowledge, existing research occurs in separate disciplinary silos, and tackles separate portions of the sign language processing pipeline. This leads to three key questions: 1) What does an interdisciplinary view of the current landscape reveal? 2) What are the biggest challenges facing the field? and 3) What are the calls to action for people working in the field? To help answer these questions, we brought together a diverse group of experts for a two-day workshop. This paper presents the results of that interdisciplinary workshop, providing key background that is often overlooked by computer scientists, a review of the state-of-the-art, a set of pressing challenges, and a call to action for the research community.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'and generation, asl, recognition, sign language, translation', 'numpages': '16', 'pages': '16–31', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Developing successful sign language recognition, generation, and translation systems requires expertise in a wide range of fields, including computer vision, computer graphics, natural language processing, human-computer interaction, linguistics, and Deaf culture. Despite the need for deep interdisciplinary knowledge, existing research occurs in separate disciplinary silos, and tackles separate portions of the sign language processing pipeline. This leads to three key questions: 1) What does an interdisciplinary view of the current landscape reveal? 2) What are the biggest challenges facing the field? and 3) What are the calls to action for people working in the field? To help answer these questions, we brought together a diverse group of experts for a two-day workshop. This paper presents the results of that interdisciplinary workshop, providing key background that is often overlooked by computer scientists, a review of the state-of-the-art, a set of pressing challenges, and a call to action for the research community.', 'doi': '10.1145/3308561.3353774', 'url': 'https://doi.org/10.1145/3308561.3353774', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective', 'author': 'Bragg, Danielle and Koller, Oscar and Bellard, Mary and Berke, Larwan and Boudreault, Patrick and Braffort, Annelies and Caselli, Naomi and Huenerfauth, Matt and Kacorri, Hernisa and Verhoef, Tessa and Vogler, Christian and Ringel Morris, Meredith', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353774'}"
Exploration of Automatic Speech Recognition for Deaf and Hard of Hearing Students in Higher Education Classes,10.1145/3308561.3353772,"Automatic speech recognition (ASR) programs that generate real-time speech-to-text captions can be provided as supplemental access technologies for deaf and hard of hearing (DHH) students in higher education classes. As part of a pilot program, we implemented ASR as a supplemental access service in biology, statistics, and other courses at our university. To identify the benefits and limitations of ASR as an access technology, we surveyed 26 DHH students and interviewed 8 of these students about their experiences with ASR in their mainstream classes. Participants believed that ASR was beneficial despite the errors that ASR continued to generate; however, the accuracy and readability of ASR need to improve so that students can better access spoken information through ASR. This paper reviews points for researchers to consider when designing and providing ASR as a supplemental access service in educational settings.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'automatic speech recognition, deaf and hard of hearing, feedback, real-time captions', 'numpages': '11', 'pages': '32–42', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Automatic speech recognition (ASR) programs that generate real-time speech-to-text captions can be provided as supplemental access technologies for deaf and hard of hearing (DHH) students in higher education classes. As part of a pilot program, we implemented ASR as a supplemental access service in biology, statistics, and other courses at our university. To identify the benefits and limitations of ASR as an access technology, we surveyed 26 DHH students and interviewed 8 of these students about their experiences with ASR in their mainstream classes. Participants believed that ASR was beneficial despite the errors that ASR continued to generate; however, the accuracy and readability of ASR need to improve so that students can better access spoken information through ASR. This paper reviews points for researchers to consider when designing and providing ASR as a supplemental access service in educational settings.', 'doi': '10.1145/3308561.3353772', 'url': 'https://doi.org/10.1145/3308561.3353772', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Exploration of Automatic Speech Recognition for Deaf and Hard of Hearing Students in Higher Education Classes', 'author': 'Butler, Janine and Trager, Brian and Behm, Byron', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353772'}"
Evaluating the Benefit of Highlighting Key Words in Captions for People who are Deaf or Hard of Hearing,10.1145/3308561.3353781,"Recent research has investigated automatic methods for identifying how important each word in a text is for the overall message, in the context of people who are Deaf and Hard of Hearing (DHH) viewing video with captions. We examine whether DHH users report benefits from visual highlighting of important words in video captions. In formative interview and prototype studies, users indicated a preference for underlining of 5\%-15\% of words in a caption text to indicate that they are important, and they expressed an interest for such text markup in the context of educational lecture videos. In a subsequent user study, 30 DHH participants viewed lecture videos in two forms: with and without such visual markup. Users indicated that the videos with captions containing highlighted words were easier to read and follow, with lower perceived task-load ratings, compared to the videos without highlighting. This study motivates future research on caption highlighting in online educational videos, and it provides a foundation for how to evaluate the efficacy of such systems with users.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'caption highlighting, captioning system, deaf and hard of hearing, feedback, text highlighting, user study', 'numpages': '13', 'pages': '43–55', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Recent research has investigated automatic methods for identifying how important each word in a text is for the overall message, in the context of people who are Deaf and Hard of Hearing (DHH) viewing video with captions. We examine whether DHH users report benefits from visual highlighting of important words in video captions. In formative interview and prototype studies, users indicated a preference for underlining of 5\\%-15\\% of words in a caption text to indicate that they are important, and they expressed an interest for such text markup in the context of educational lecture videos. In a subsequent user study, 30 DHH participants viewed lecture videos in two forms: with and without such visual markup. Users indicated that the videos with captions containing highlighted words were easier to read and follow, with lower perceived task-load ratings, compared to the videos without highlighting. This study motivates future research on caption highlighting in online educational videos, and it provides a foundation for how to evaluate the efficacy of such systems with users.', 'doi': '10.1145/3308561.3353781', 'url': 'https://doi.org/10.1145/3308561.3353781', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Evaluating the Benefit of Highlighting Key Words in Captions for People who are Deaf or Hard of Hearing', 'author': 'Kafle, Sushant and Yeung, Peter and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353781'}"
Effect of Automatic Sign Recognition Performance on the Usability of Video-Based Search Interfaces for Sign Language Dictionaries,10.1145/3308561.3353791,"Researchers have investigated various methods to help users search for the meaning of an unfamiliar word in American Sign Language (ASL). Some are based on sign-recognition technology, e.g. a user performs a word into a webcam and obtains a list of possible matches in the dictionary. However, developers of such technology report the performance of their systems inconsistently, and prior research has not examined the relationship between the performance of search technology and users' subjective judgements for this task. We conducted two studies using a Wizard-of-Oz prototype of a webcam-based ASL dictionary search system to investigate the relationship between the performance of such a system and user judgements. We found that in addition to the position of the desired word in a list of results, which is what is often reported in literature; the similarity of the other words in the results list also affected users' judgements of the system. We also found that metrics that incorporate the precision of the overall list correlated better with users' judgements than did metrics currently reported in prior ASL dictionary research.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'american sign language (asl), dictionary, search', 'numpages': '12', 'pages': '56–67', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Researchers have investigated various methods to help users search for the meaning of an unfamiliar word in American Sign Language (ASL). Some are based on sign-recognition technology, e.g. a user performs a word into a webcam and obtains a list of possible matches in the dictionary. However, developers of such technology report the performance of their systems inconsistently, and prior research has not examined the relationship between the performance of search technology and users' subjective judgements for this task. We conducted two studies using a Wizard-of-Oz prototype of a webcam-based ASL dictionary search system to investigate the relationship between the performance of such a system and user judgements. We found that in addition to the position of the desired word in a list of results, which is what is often reported in literature; the similarity of the other words in the results list also affected users' judgements of the system. We also found that metrics that incorporate the precision of the overall list correlated better with users' judgements than did metrics currently reported in prior ASL dictionary research."", 'doi': '10.1145/3308561.3353791', 'url': 'https://doi.org/10.1145/3308561.3353791', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Effect of Automatic Sign Recognition Performance on the Usability of Video-Based Search Interfaces for Sign Language Dictionaries', 'author': 'Alonzo, Oliver and Glasser, Abraham and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353791'}"
CaBot: Designing and Evaluating an Autonomous Navigation Robot for Blind People,10.1145/3308561.3353771,"Navigation robots have the potential to overcome some of the limitations of traditional navigation aids for blind people, specially in unfamiliar environments. In this paper, we present the design of CaBot (Carry-on roBot), an autonomous suitcase-shaped navigation robot that is able to guide blind users to a destination while avoiding obstacles on their path. We conducted a user study where ten blind users evaluated specific functionalities of CaBot, such as a vibro-tactile handle to convey directional feedback; experimented to find their comfortable walking speed; and performed navigation tasks to provide feedback about their overall experience. We found that CaBot's performance highly exceeded users' expectations, who often compared it to navigating with a guide dog or sighted guide. Users' high confidence, sense of safety, and trust on CaBot poses autonomous navigation robots as a promising solution to increase the mobility and independence of blind people, in particular in unfamiliar environments.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'blind navigation, guide robot, human-robot interaction, mobility, obstacle avoidance', 'numpages': '15', 'pages': '68–82', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Navigation robots have the potential to overcome some of the limitations of traditional navigation aids for blind people, specially in unfamiliar environments. In this paper, we present the design of CaBot (Carry-on roBot), an autonomous suitcase-shaped navigation robot that is able to guide blind users to a destination while avoiding obstacles on their path. We conducted a user study where ten blind users evaluated specific functionalities of CaBot, such as a vibro-tactile handle to convey directional feedback; experimented to find their comfortable walking speed; and performed navigation tasks to provide feedback about their overall experience. We found that CaBot's performance highly exceeded users' expectations, who often compared it to navigating with a guide dog or sighted guide. Users' high confidence, sense of safety, and trust on CaBot poses autonomous navigation robots as a promising solution to increase the mobility and independence of blind people, in particular in unfamiliar environments."", 'doi': '10.1145/3308561.3353771', 'url': 'https://doi.org/10.1145/3308561.3353771', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'CaBot: Designing and Evaluating an Autonomous Navigation Robot for Blind People', 'author': 'Guerreiro, Jo\\~{a}o and Sato, Daisuke and Asakawa, Saki and Dong, Huixu and Kitani, Kris M. and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353771'}"
Revisiting Blind Photography in the Context of Teachable Object Recognizers,10.1145/3308561.3353799,"For people with visual impairments, photography is essential in identifying objects through remote sighted help and image recognition apps. This is especially the case for teachable object recognizers, where recognition models are trained on user's photos. Here, we propose real-time feedback for communicating the location of an object of interest in the camera frame. Our audio-haptic feedback is powered by a deep learning model that estimates the object center location based on its proximity to the user's hand. To evaluate our approach, we conducted a user study in the lab, where participants with visual impairments (N=9) used our feedback to train and test their object recognizer in vanilla and cluttered environments. We found that very few photos did not include the object (2\% in the vanilla and 8\% in the cluttered) and the recognition performance was promising even for participants with no prior camera experience. Participants tended to trust the feedback even though they know it can be wrong. Our cluster analysis indicates that better feedback is associated with photos that include the entire object. Our results provide insights into factors that can degrade feedback and recognition performance in teachable interfaces.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'hand, object recognition, sonification, visual impairments', 'numpages': '13', 'pages': '83–95', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""For people with visual impairments, photography is essential in identifying objects through remote sighted help and image recognition apps. This is especially the case for teachable object recognizers, where recognition models are trained on user's photos. Here, we propose real-time feedback for communicating the location of an object of interest in the camera frame. Our audio-haptic feedback is powered by a deep learning model that estimates the object center location based on its proximity to the user's hand. To evaluate our approach, we conducted a user study in the lab, where participants with visual impairments (N=9) used our feedback to train and test their object recognizer in vanilla and cluttered environments. We found that very few photos did not include the object (2\\% in the vanilla and 8\\% in the cluttered) and the recognition performance was promising even for participants with no prior camera experience. Participants tended to trust the feedback even though they know it can be wrong. Our cluster analysis indicates that better feedback is associated with photos that include the entire object. Our results provide insights into factors that can degrade feedback and recognition performance in teachable interfaces."", 'doi': '10.1145/3308561.3353799', 'url': 'https://doi.org/10.1145/3308561.3353799', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Revisiting Blind Photography in the Context of Teachable Object Recognizers', 'author': 'Lee, Kyungjun and Hong, Jonggi and Pimento, Simone and Jarjue, Ebrima and Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353799'}"
DarkReader: Bridging the Gap Between Perception and Reality of Power Consumption in Smartphones for Blind Users,10.1145/3308561.3353806,"This paper presents a user study with 10 blind participants to understand their perception of power consumption in smartphones. We found that a widely used power saving mechanism for smartphones--pressing the power button to put the smartphone to sleep--has a serious usability issue for blind screen reader users. Among other findings, our study also unearthed several usage patterns and misconceptions of blind users that contribute to excessive battery drainage. Informed by the first user study, this paper proposes DarkReader, a screen reader developed in Android that bridges users' perception of power consumption to reality. DarkReader darkens the screen by truly turning it off, but allows users to interact with their smartphones. A second user study with 10 blind participants shows that participants perceived no difference in completion times in performing routine tasks using DarkReader and default screen reader. Yet DarkReader saves 24\% to 52\% power depending on tasks and screen brightness.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'android, battery, blind, brightness, curtain mode, ios, low-power, privacy, screen, screen readers, shoulder-surfing, talkback, vision impairment', 'numpages': '9', 'pages': '96–104', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper presents a user study with 10 blind participants to understand their perception of power consumption in smartphones. We found that a widely used power saving mechanism for smartphones--pressing the power button to put the smartphone to sleep--has a serious usability issue for blind screen reader users. Among other findings, our study also unearthed several usage patterns and misconceptions of blind users that contribute to excessive battery drainage. Informed by the first user study, this paper proposes DarkReader, a screen reader developed in Android that bridges users' perception of power consumption to reality. DarkReader darkens the screen by truly turning it off, but allows users to interact with their smartphones. A second user study with 10 blind participants shows that participants perceived no difference in completion times in performing routine tasks using DarkReader and default screen reader. Yet DarkReader saves 24\\% to 52\\% power depending on tasks and screen brightness."", 'doi': '10.1145/3308561.3353806', 'url': 'https://doi.org/10.1145/3308561.3353806', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'DarkReader: Bridging the Gap Between Perception and Reality of Power Consumption in Smartphones for Blind Users', 'author': 'Xu, Jian and Billah, Syed Masum and Shilkrot, Roy and Balasubramanian, Aruna', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353806'}"
"Disability, ICT and eLearning Platforms: Faculty-Facing Embedded Work Tools in Learning Management Systems",10.1145/3308561.3355620,"This paper contributes to the current discussion in the field of human-computer interaction design (HCI) on the accessibility and design of eLearning tools embedded in the online platforms for higher education. Presenting the preliminary results of a longitudinal study of the accessibility of the faculty-facing pages of Canvas learning management system, it aims at drawing the attention of designers, developers, and manufacturers to the barriers erected by the ableist LMS designs for disabled faculty. The paper asks for improvements in design processes by embracing participatory design methods and by paying attention to the recommendations included in this paper.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility of faculty-facing canvas pages, accessibility of learning management systems (lms), accessibility problems in speedgrader, design of accessible e-platforms, empirical studies in hci, human-computer interaction design (hci), interaction techniques, participatory design, sensory substitution', 'numpages': '7', 'pages': '105–111', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper contributes to the current discussion in the field of human-computer interaction design (HCI) on the accessibility and design of eLearning tools embedded in the online platforms for higher education. Presenting the preliminary results of a longitudinal study of the accessibility of the faculty-facing pages of Canvas learning management system, it aims at drawing the attention of designers, developers, and manufacturers to the barriers erected by the ableist LMS designs for disabled faculty. The paper asks for improvements in design processes by embracing participatory design methods and by paying attention to the recommendations included in this paper.', 'doi': '10.1145/3308561.3355620', 'url': 'https://doi.org/10.1145/3308561.3355620', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Disability, ICT and eLearning Platforms: Faculty-Facing Embedded Work Tools in Learning Management Systems', 'author': 'Oswal, Sushil K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3355620'}"
GestureCalc: An Eyes-Free Calculator for Touch Screens,10.1145/3308561.3353783,"A digital calculator is one of the most frequently used touch screen applications. However, keypad-based character input in existing calculator applications requires precise, targeted key presses that are time-consuming and error-prone for many screen readers users. We introduce GestureCalc, a digital calculator that uses target-free gestures for arithmetic tasks. It allows eyes-free target-less input of digits and operations through taps and directional swipes with one to three fingers, guided by minimal audio feedback. We conducted a mixed methods longitudinal study with eight screen reader users and found that they entered characters with GestureCalc 40.5\% faster on average than with a typical touch screen calculator. Participants made more mistakes but also corrected more errors with GestureCalc, resulting in 52.2\% fewer erroneous calculations than the baseline. Over the three sessions in the study, participants were able to learn the GestureCalc gestures and efficiently perform short calculations. From our interviews after the second session, participants recognized the effort in learning a new gesture set, yet reported confidence in their ability to become fluent in practice.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'digital calculator, eyes-free entry, gesture input, mobile devices, touch screen', 'numpages': '12', 'pages': '112–123', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A digital calculator is one of the most frequently used touch screen applications. However, keypad-based character input in existing calculator applications requires precise, targeted key presses that are time-consuming and error-prone for many screen readers users. We introduce GestureCalc, a digital calculator that uses target-free gestures for arithmetic tasks. It allows eyes-free target-less input of digits and operations through taps and directional swipes with one to three fingers, guided by minimal audio feedback. We conducted a mixed methods longitudinal study with eight screen reader users and found that they entered characters with GestureCalc 40.5\\% faster on average than with a typical touch screen calculator. Participants made more mistakes but also corrected more errors with GestureCalc, resulting in 52.2\\% fewer erroneous calculations than the baseline. Over the three sessions in the study, participants were able to learn the GestureCalc gestures and efficiently perform short calculations. From our interviews after the second session, participants recognized the effort in learning a new gesture set, yet reported confidence in their ability to become fluent in practice.', 'doi': '10.1145/3308561.3353783', 'url': 'https://doi.org/10.1145/3308561.3353783', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'GestureCalc: An Eyes-Free Calculator for Touch Screens', 'author': 'Chaudhuri, Bindita and Perlmutter, Leah and Petelka, Justin and Garrison, Philip and Fogarty, James and Wobbrock, Jacob O. and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353783'}"
CHIMELIGHT: Augmenting Instruments in Interactive Music Therapy for Children with Neurodevelopmental Disorders,10.1145/3308561.3353784,"In this paper, we propose a new mobile system to support therapists for teaching and tracking socio-communicative behaviors in children with neurodevelopmental disorders during music therapy sessions. The CHIMELIGHT system was designed to deal with the current issues in conventional therapies, such as the difficulty in both evaluating the performance and maintaining engagement of these children during therapeutic activities. The system evaluated movements made by a child with neurodevelopmental disorders playing a musical instrument while delivering contingent visual feedback based on real-time motion analysis. A set of metrics was implemented to evaluate the performance during the therapy activity and quantify specific target behaviors. An evaluation study performed during music therapy group sessions showed that the CHIMELIGHT-delivered visual feedback increased the engagement of children in the activity and decreased targeted negative behaviors. In some participants, we observed potential changes in their positive behaviors. Interviews and questionnaires provided to therapists showed that the developed system was effective for supporting evidence-based music therapy. Accordingly, our research enables new methods for both interactive therapy and mediation of the interaction between therapists and children with neurodevelopmental disorders.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive technology, interactive therapy, iot, music therapy, neurodevelopmental disorders, social playware, socio-communicative behaviors', 'numpages': '12', 'pages': '124–135', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we propose a new mobile system to support therapists for teaching and tracking socio-communicative behaviors in children with neurodevelopmental disorders during music therapy sessions. The CHIMELIGHT system was designed to deal with the current issues in conventional therapies, such as the difficulty in both evaluating the performance and maintaining engagement of these children during therapeutic activities. The system evaluated movements made by a child with neurodevelopmental disorders playing a musical instrument while delivering contingent visual feedback based on real-time motion analysis. A set of metrics was implemented to evaluate the performance during the therapy activity and quantify specific target behaviors. An evaluation study performed during music therapy group sessions showed that the CHIMELIGHT-delivered visual feedback increased the engagement of children in the activity and decreased targeted negative behaviors. In some participants, we observed potential changes in their positive behaviors. Interviews and questionnaires provided to therapists showed that the developed system was effective for supporting evidence-based music therapy. Accordingly, our research enables new methods for both interactive therapy and mediation of the interaction between therapists and children with neurodevelopmental disorders.', 'doi': '10.1145/3308561.3353784', 'url': 'https://doi.org/10.1145/3308561.3353784', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'CHIMELIGHT: Augmenting Instruments in Interactive Music Therapy for Children with Neurodevelopmental Disorders', 'author': 'Lobo, Joana and Matsuda, Soichiro and Futamata, Izumi and Sakuta, Ryoichi and Suzuki, Kenji', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353784'}"
Gender and Help Seeking by Older Adults When Learning New Technologies,10.1145/3308561.3353807,"A gender stereotype that has some basis in research is that men are more reluctant to ask for directions than women. We wanted to investigate whether this stereotype applies to technology-related contexts, affecting older adults' abilities to learn new technologies. To explore how help seeking and gender might relate for older adults, we conducted a controlled experiment with 36 individuals, of whom 18 identified as men and 18 identified as women, and observed how often they asked for help when learning new applications. We also conducted post-experiment interviews with participants. We found that although most participants stereotyped older men as being reluctant to ask for help in the interview, the gender difference was minimal in the experiment. Instead, individual differences had a greater effect: older participants took longer to complete tasks and participants with lower technology self-efficacy asked significantly more questions.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'gender, help seeking, older adults, technology use', 'numpages': '7', 'pages': '136–142', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""A gender stereotype that has some basis in research is that men are more reluctant to ask for directions than women. We wanted to investigate whether this stereotype applies to technology-related contexts, affecting older adults' abilities to learn new technologies. To explore how help seeking and gender might relate for older adults, we conducted a controlled experiment with 36 individuals, of whom 18 identified as men and 18 identified as women, and observed how often they asked for help when learning new applications. We also conducted post-experiment interviews with participants. We found that although most participants stereotyped older men as being reluctant to ask for help in the interview, the gender difference was minimal in the experiment. Instead, individual differences had a greater effect: older participants took longer to complete tasks and participants with lower technology self-efficacy asked significantly more questions."", 'doi': '10.1145/3308561.3353807', 'url': 'https://doi.org/10.1145/3308561.3353807', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Gender and Help Seeking by Older Adults When Learning New Technologies', 'author': 'Franz, Rachel L. and Findlater, Leah and Barbosa Neves, Barbara and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353807'}"
Leveraging Participation: Supporting Skills Development of Young Adults with Intellectual Disability Using Social Media,10.1145/3308561.3353793,"Young adults with intellectual disability are keen users of social media. However, there is little understanding about how their skills and participation in social media might be leveraged to support further skills development. Employing a participatory approach through workshops with eleven participants and interviews with eight parents, we investigated what skills young adults desire and how they might be able to leverage their participation in YouTube and Facebook to develop these skills. We found that young adults want to develop social skills of such as playing sports or learning languages, but that leveraging social media participation to do this goes beyond their typical use, and requires both collaborative support and accessible design. Based on these findings, we propose and discuss a collaboration-in-the-loop framework that integrates support through personal networks and an accessible user interface design. We conclude with a reflection on designing to leverage participation, interests and competencies to support people with intellectual disability.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'competencies, intellectual disability, participation, skills development, social media, social skills, techshops', 'numpages': '13', 'pages': '143–155', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Young adults with intellectual disability are keen users of social media. However, there is little understanding about how their skills and participation in social media might be leveraged to support further skills development. Employing a participatory approach through workshops with eleven participants and interviews with eight parents, we investigated what skills young adults desire and how they might be able to leverage their participation in YouTube and Facebook to develop these skills. We found that young adults want to develop social skills of such as playing sports or learning languages, but that leveraging social media participation to do this goes beyond their typical use, and requires both collaborative support and accessible design. Based on these findings, we propose and discuss a collaboration-in-the-loop framework that integrates support through personal networks and an accessible user interface design. We conclude with a reflection on designing to leverage participation, interests and competencies to support people with intellectual disability.', 'doi': '10.1145/3308561.3353793', 'url': 'https://doi.org/10.1145/3308561.3353793', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Leveraging Participation: Supporting Skills Development of Young Adults with Intellectual Disability Using Social Media', 'author': 'Bayor, Andrew A. and Sitbon, Laurianne and Ploderer, Bernd and Bircanin, Filip and Koplick, Stewart and Brereton, Margot', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353793'}"
Understanding Mental Ill-health as Psychosocial Disability: Implications for Assistive Technology,10.1145/3308561.3353785,"Psychosocial disability involves actual or perceived impairment due to a diversity of mental, emotional, or cognitive experiences. While assistive technology for psychosocial disabilities has been understudied in communities such as ASSETS, advances in computing have opened up a number of new avenues for assisting those with psychosocial disabilities beyond the clinic. However, these tools continue to emerge primarily within the framework of ""treatment,"" emphasizing resolution or improvement of mental health symptoms. This work considers what it means to adopt a social model lens from disability studies and incorporate the expertise of assistive technology researchers in relation to mental health. Our investigation draws on interviews conducted with 18 individuals who have complex health needs that include mental health symptoms. This work highlights the potential role for assistive technology in supporting psychosocial disability outside of a clinical or medical framework.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'anxiety, depression, mental health, psychosocial disability, social model of disability', 'numpages': '15', 'pages': '156–170', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Psychosocial disability involves actual or perceived impairment due to a diversity of mental, emotional, or cognitive experiences. While assistive technology for psychosocial disabilities has been understudied in communities such as ASSETS, advances in computing have opened up a number of new avenues for assisting those with psychosocial disabilities beyond the clinic. However, these tools continue to emerge primarily within the framework of ""treatment,"" emphasizing resolution or improvement of mental health symptoms. This work considers what it means to adopt a social model lens from disability studies and incorporate the expertise of assistive technology researchers in relation to mental health. Our investigation draws on interviews conducted with 18 individuals who have complex health needs that include mental health symptoms. This work highlights the potential role for assistive technology in supporting psychosocial disability outside of a clinical or medical framework.', 'doi': '10.1145/3308561.3353785', 'url': 'https://doi.org/10.1145/3308561.3353785', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Understanding Mental Ill-health as Psychosocial Disability: Implications for Assistive Technology', 'author': 'Ringland, Kathryn E. and Nicholas, Jennifer and Kornfield, Rachel and Lattie, Emily G. and Mohr, David C. and Reddy, Madhu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353785'}"
Turning Heads: Designing Engaging Immersive Video Experiences to Support People with Intellectual Disability when Learning Everyday Living Skills,10.1145/3308561.3353787,"As head mounted displays and 360° video cameras are becoming affordable, they offer opportunities to personalise immersive learning experiences to local contexts and individuals. In this paper, we present lessons learnt from a participatory design process focused on understanding engagement and preferences of users with intellectual disability viewing 360° videos. Over 4 iterations involving re-designs informed by interviews and observations of two to four participants with intellectual disability, we have established that: participants are more comfortable with using the technology if they are first introduced to a familiar scene before seeing anything new, they prefer to be 'accompanied' by an in-video facilitator, and participants engage more with the immersive visual environment when prompted to look around from within the video. We have also established a number of guidelines for filming with a 360° camera with regards to movement and viewpoint.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': '360 video, intellectual disability, lifeskills training', 'numpages': '12', 'pages': '171–182', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""As head mounted displays and 360° video cameras are becoming affordable, they offer opportunities to personalise immersive learning experiences to local contexts and individuals. In this paper, we present lessons learnt from a participatory design process focused on understanding engagement and preferences of users with intellectual disability viewing 360° videos. Over 4 iterations involving re-designs informed by interviews and observations of two to four participants with intellectual disability, we have established that: participants are more comfortable with using the technology if they are first introduced to a familiar scene before seeing anything new, they prefer to be 'accompanied' by an in-video facilitator, and participants engage more with the immersive visual environment when prompted to look around from within the video. We have also established a number of guidelines for filming with a 360° camera with regards to movement and viewpoint."", 'doi': '10.1145/3308561.3353787', 'url': 'https://doi.org/10.1145/3308561.3353787', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Turning Heads: Designing Engaging Immersive Video Experiences to Support People with Intellectual Disability when Learning Everyday Living Skills', 'author': 'Sitbon, Laurianne and Brown, Ross and Fell, Lauren', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353787'}"
3D Printed Maps and Icons for Inclusion: Testing in the Wild by People who are Blind or have Low Vision,10.1145/3308561.3353790,"The difficulty and consequent fear of travel is one of the most disabling consequences of blindness and severe vision impairment, affecting confidence and quality of life. Traditional tactile graphics are vital in the Orientation and Mobility training process, however 3D printing may have the capacity to enable production of more meaningful and inclusive maps. This study explored the use of 3D printed maps on site at a public event to examine their suitability and to identify guidelines for the design of future 3D maps. An iterative design process was used in the production of the 3D maps, with feedback from visitors who are blind or have low vision informing the recommendations for their design and use. For example, it was found that many representational 3D icons could be recognised by touch without the need for a key and that such a map helped form mental models of the event space. Complex maps, however, require time to explore and should be made available before an event or at the entrance in a comfortable position. The maps were found to support the orientation and mobility process, and importantly to also promote a positive message about inclusion and accessibility.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': '3d printing, blind, low vision, maps, orientation \\&amp; mobility, vision impairment', 'numpages': '13', 'pages': '183–195', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The difficulty and consequent fear of travel is one of the most disabling consequences of blindness and severe vision impairment, affecting confidence and quality of life. Traditional tactile graphics are vital in the Orientation and Mobility training process, however 3D printing may have the capacity to enable production of more meaningful and inclusive maps. This study explored the use of 3D printed maps on site at a public event to examine their suitability and to identify guidelines for the design of future 3D maps. An iterative design process was used in the production of the 3D maps, with feedback from visitors who are blind or have low vision informing the recommendations for their design and use. For example, it was found that many representational 3D icons could be recognised by touch without the need for a key and that such a map helped form mental models of the event space. Complex maps, however, require time to explore and should be made available before an event or at the entrance in a comfortable position. The maps were found to support the orientation and mobility process, and importantly to also promote a positive message about inclusion and accessibility.', 'doi': '10.1145/3308561.3353790', 'url': 'https://doi.org/10.1145/3308561.3353790', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': '3D Printed Maps and Icons for Inclusion: Testing in the Wild by People who are Blind or have Low Vision', 'author': 'Holloway, Leona and Marriott, Kim and Butler, Matthew and Reinders, Samuel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353790'}"
Deep Learning for Automatically Detecting Sidewalk Accessibility Problems Using Streetscape Imagery,10.1145/3308561.3353798,"Recent work has applied machine learning methods to automatically find and/or assess pedestrian infrastructure in online map imagery (e.g., satellite photos, streetscape panoramas). While promising, these methods have been limited by two interrelated issues: small training sets and the choice of machine learning model. In this paper, aided by the recently released Project Sidewalk dataset of 300,000+ image-based sidewalk accessibility labels, we present the first examination of deep learning to automatically assess sidewalks in Google Street View (GSV) panoramas. Specifically, we investigate two application areas: automatically validating crowdsourced labels and automatically labeling sidewalk accessibility issues. For both tasks, we introduce and use a residual neural network (ResNet) modified to support both image and non-image (contextual) features (e.g., geography). We present an analysis of performance, the effect of our non-image features and training set size, and cross-city generalizability. Our results significantly improve on prior automated methods and, in some cases, meet or exceed human labeling performance.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, computer vision, neural networks, sidewalks', 'numpages': '14', 'pages': '196–209', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Recent work has applied machine learning methods to automatically find and/or assess pedestrian infrastructure in online map imagery (e.g., satellite photos, streetscape panoramas). While promising, these methods have been limited by two interrelated issues: small training sets and the choice of machine learning model. In this paper, aided by the recently released Project Sidewalk dataset of 300,000+ image-based sidewalk accessibility labels, we present the first examination of deep learning to automatically assess sidewalks in Google Street View (GSV) panoramas. Specifically, we investigate two application areas: automatically validating crowdsourced labels and automatically labeling sidewalk accessibility issues. For both tasks, we introduce and use a residual neural network (ResNet) modified to support both image and non-image (contextual) features (e.g., geography). We present an analysis of performance, the effect of our non-image features and training set size, and cross-city generalizability. Our results significantly improve on prior automated methods and, in some cases, meet or exceed human labeling performance.', 'doi': '10.1145/3308561.3353798', 'url': 'https://doi.org/10.1145/3308561.3353798', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Deep Learning for Automatically Detecting Sidewalk Accessibility Problems Using Streetscape Imagery', 'author': 'Weld, Galen and Jang, Esther and Li, Anthony and Zeng, Aileen and Heimerl, Kurtis and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353798'}"
Leveraging Augmented Reality to Create Apps for People with Visual Disabilities: A Case Study in Indoor Navigation,10.1145/3308561.3353788,"The introduction of augmented reality technology to iOS and Android enables, for the first time, mainstream smartphones to estimate their own motion in 3D space with high accuracy. For assistive technology researchers, this development presents a potential opportunity. In this spirit, we present our work leveraging these technologies to create a smartphone app to empower people who are visually impaired to more easily navigate indoor environments. Our app, Clew, allows users to record routes and then load them, at any time, providing automatic guidance (using haptic, speech, and sound feedback) along the route. We present our user-centered design process, Clew's system architecture and technical details, and both small and large-scale evaluations of the app. We discuss opportunities, pitfalls, and design guidelines for utilizing augmented reality for orientation and mobility apps. Our work expands the capabilities of technology for orientation and mobility that can be distributed on a mass scale.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive tech, augmented reality, orientation and mobility', 'numpages': '12', 'pages': '210–221', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The introduction of augmented reality technology to iOS and Android enables, for the first time, mainstream smartphones to estimate their own motion in 3D space with high accuracy. For assistive technology researchers, this development presents a potential opportunity. In this spirit, we present our work leveraging these technologies to create a smartphone app to empower people who are visually impaired to more easily navigate indoor environments. Our app, Clew, allows users to record routes and then load them, at any time, providing automatic guidance (using haptic, speech, and sound feedback) along the route. We present our user-centered design process, Clew's system architecture and technical details, and both small and large-scale evaluations of the app. We discuss opportunities, pitfalls, and design guidelines for utilizing augmented reality for orientation and mobility apps. Our work expands the capabilities of technology for orientation and mobility that can be distributed on a mass scale."", 'doi': '10.1145/3308561.3353788', 'url': 'https://doi.org/10.1145/3308561.3353788', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Leveraging Augmented Reality to Create Apps for People with Visual Disabilities: A Case Study in Indoor Navigation', 'author': 'Yoon, Chris and Louie, Ryan and Ryan, Jeremy and Vu, MinhKhang and Bang, Hyegi and Derksen, William and Ruvolo, Paul', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353788'}"
Closing the Gap: Designing for the Last-Few-Meters Wayfinding Problem for People with Visual Impairments,10.1145/3308561.3353776,"Despite the major role of Global Positioning Systems (GPS) as a navigation tool for people with visual impairments (VI), a crucial missing aspect of point-to-point navigation with these systems is the last-few-meters wayfinding problem. Due to GPS inaccuracy and inadequate map data, systems often bring a user to the vicinity of a destination but not to the exact location, causing challenges such as difficulty locating building entrances or a specific storefront from a series of stores. In this paper, we study this problem space in two parts: (1) A formative study (N=22) to understand challenges, current resolution techniques, and user needs; and (2) A design probe study (N=13) using a novel, vision-based system called Landmark AI to understand how technology can better address aspects of this problem. Based on these investigations, we articulate a design space for systems addressing this challenge, along with implications for future systems to support precise navigation for people with VI.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blindness, landmarks, wayfinding', 'numpages': '14', 'pages': '222–235', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite the major role of Global Positioning Systems (GPS) as a navigation tool for people with visual impairments (VI), a crucial missing aspect of point-to-point navigation with these systems is the last-few-meters wayfinding problem. Due to GPS inaccuracy and inadequate map data, systems often bring a user to the vicinity of a destination but not to the exact location, causing challenges such as difficulty locating building entrances or a specific storefront from a series of stores. In this paper, we study this problem space in two parts: (1) A formative study (N=22) to understand challenges, current resolution techniques, and user needs; and (2) A design probe study (N=13) using a novel, vision-based system called Landmark AI to understand how technology can better address aspects of this problem. Based on these investigations, we articulate a design space for systems addressing this challenge, along with implications for future systems to support precise navigation for people with VI.', 'doi': '10.1145/3308561.3353776', 'url': 'https://doi.org/10.1145/3308561.3353776', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Closing the Gap: Designing for the Last-Few-Meters Wayfinding Problem for People with Visual Impairments', 'author': 'Saha, Manaswi and Fiannaca, Alexander J. and Kneisel, Melanie and Cutrell, Edward and Morris, Meredith Ringel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353776'}"
Autoethnography of a Hard of Hearing Traveler,10.1145/3308561.3353800,"Travel experiences offer a diverse view into an individual's interactions with different cultures, societies, and places. In this paper, we present a 2.5-year autoethnographic travel account of a hard of hearing individual-Jain. Through retrospective journals and field notes, we reveal the tensions and nuances in his travel, including the magnified difficulty of social conversations, issues with navigating unfamiliar environments and cultural contexts, and changes in the relationship to personal assistive technologies. By exploring the longitudinal travel experiences of a single individual, we uncover evocative and personal insights rarely available through participant-based research methods. Based on these lived experiences and post hoc reflections, we present two design explorations of personalized technology the autoethnographer created for aiding his travel. Finally, we offer reflections for customized travel technologies for deaf and hard of hearing users, and methodological guidelines for performing first-person research in the context of disability.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, autobiographical design, autoethnography, deaf, hard of hearing, personalized technology, travel', 'numpages': '13', 'pages': '236–248', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Travel experiences offer a diverse view into an individual's interactions with different cultures, societies, and places. In this paper, we present a 2.5-year autoethnographic travel account of a hard of hearing individual-Jain. Through retrospective journals and field notes, we reveal the tensions and nuances in his travel, including the magnified difficulty of social conversations, issues with navigating unfamiliar environments and cultural contexts, and changes in the relationship to personal assistive technologies. By exploring the longitudinal travel experiences of a single individual, we uncover evocative and personal insights rarely available through participant-based research methods. Based on these lived experiences and post hoc reflections, we present two design explorations of personalized technology the autoethnographer created for aiding his travel. Finally, we offer reflections for customized travel technologies for deaf and hard of hearing users, and methodological guidelines for performing first-person research in the context of disability."", 'doi': '10.1145/3308561.3353800', 'url': 'https://doi.org/10.1145/3308561.3353800', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Autoethnography of a Hard of Hearing Traveler', 'author': 'Jain, Dhruv and Desjardins, Audrey and Findlater, Leah and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353800'}"
The Design Space of Nonvisual Word Completion,10.1145/3308561.3353786,"Word completion interfaces are ubiquitously available in mobile virtual keyboards; however, there is no prior research on how to design these interfaces for screen reader users. In addressing this, we propose a design space for nonvisual representation of word completions. The design space covers seven categories aiming to identify challenges and opportunities for interaction design in an unexplored research topic. It is intended to guide the design of novel interaction techniques, serving as a framework for researchers and practitioners working on nonvisual word completion. To demonstrate its potential, we engaged blind users in an exploration of the design space, to create their own bespoke word completion solutions. Through this study we found that users create alternative interfaces that extended current screen readers' capabilities. Resulting interfaces are less conservative than mainstream solutions on notification frequency and cardinality. Customization decisions were based on perceived benefits/costs and varied depending on multiple factors such as users' perceived prediction accuracy, potential keystroke gains, and situational restrictions.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'blind, design space, mobile, screen reader, text entry, touchscreen, word completion, word prediction', 'numpages': '13', 'pages': '249–261', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Word completion interfaces are ubiquitously available in mobile virtual keyboards; however, there is no prior research on how to design these interfaces for screen reader users. In addressing this, we propose a design space for nonvisual representation of word completions. The design space covers seven categories aiming to identify challenges and opportunities for interaction design in an unexplored research topic. It is intended to guide the design of novel interaction techniques, serving as a framework for researchers and practitioners working on nonvisual word completion. To demonstrate its potential, we engaged blind users in an exploration of the design space, to create their own bespoke word completion solutions. Through this study we found that users create alternative interfaces that extended current screen readers' capabilities. Resulting interfaces are less conservative than mainstream solutions on notification frequency and cardinality. Customization decisions were based on perceived benefits/costs and varied depending on multiple factors such as users' perceived prediction accuracy, potential keystroke gains, and situational restrictions."", 'doi': '10.1145/3308561.3353786', 'url': 'https://doi.org/10.1145/3308561.3353786', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'The Design Space of Nonvisual Word Completion', 'author': ""Nicolau, Hugo and Rodrigues, Andr\\'{e} and Santos, Andr\\'{e} and Guerreiro, Tiago and Montague, Kyle and Guerreiro, Jo\\~{a}o"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353786'}"
Prefigurative Politics and Passionate Witnessing,10.1145/3308561.3355617,"SIGACCESS and SIGCHI are being shaped by new members as they integrate feminist theory, critical race theory, postcolonial studies, and critical disability studies into the field. What happens when we begin to hold each other accountable to the impact our work has on marginalized users and communities? How do we develop a community of collaborative personal growth and institutional transformation? In this experience report, the authors retell the tangled events that brought them together. Through the passionate witnessing of critical analysis and critique, what might have been a contentious adversarial relationship became a potent partnership devoted to pushing the field toward a transformative future. From our story, we present reflections for the ""Prefigurative Politics"" of socially conscious computing.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'collaboration, critical disability studies, humanities in hci, professional development, research reform', 'numpages': '5', 'pages': '262–266', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'SIGACCESS and SIGCHI are being shaped by new members as they integrate feminist theory, critical race theory, postcolonial studies, and critical disability studies into the field. What happens when we begin to hold each other accountable to the impact our work has on marginalized users and communities? How do we develop a community of collaborative personal growth and institutional transformation? In this experience report, the authors retell the tangled events that brought them together. Through the passionate witnessing of critical analysis and critique, what might have been a contentious adversarial relationship became a potent partnership devoted to pushing the field toward a transformative future. From our story, we present reflections for the ""Prefigurative Politics"" of socially conscious computing.', 'doi': '10.1145/3308561.3355617', 'url': 'https://doi.org/10.1145/3308561.3355617', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Prefigurative Politics and Passionate Witnessing', 'author': 'Williams, Rua M. and Boyd, LouAnne E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3355617'}"
Perception and Adoption of Mobile Accessibility Features by Older Adults Experiencing Ability Changes,10.1145/3308561.3353780,"To investigate how older adults perceive ability changes (e.g., sensory, physical, cognitive) and how attitudes toward those changes affect perception and adoption of built-in mobile accessibility features (such as those found on Apple iOS and Google Android smartphones and tablets), we conducted an interview study with 14 older adults and six of their family members. Accessibility features were difficult for participants to find and configure, which were issues compounded by a reluctance to use trial-and-error. At 4-6 weeks after the interview, however, some participants had adopted new accessibility features that we had showed them, suggesting a willingness to adopt once features are made visible. The older adults who did already use accessibility features had experienced a disability earlier in life, suggesting that those experiencing progressive ability changes later in life might not be as aware of accessibility features, or might not have the know-how to adapt technologies to their changing needs. Our findings provide support for creating technologies that can detect older adults' abilities and recommend or enact interface changes to match.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'ability-based design, accessibility, changing abilities, interviews, mobile devices, older adults, smartphones', 'numpages': '12', 'pages': '267–278', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""To investigate how older adults perceive ability changes (e.g., sensory, physical, cognitive) and how attitudes toward those changes affect perception and adoption of built-in mobile accessibility features (such as those found on Apple iOS and Google Android smartphones and tablets), we conducted an interview study with 14 older adults and six of their family members. Accessibility features were difficult for participants to find and configure, which were issues compounded by a reluctance to use trial-and-error. At 4-6 weeks after the interview, however, some participants had adopted new accessibility features that we had showed them, suggesting a willingness to adopt once features are made visible. The older adults who did already use accessibility features had experienced a disability earlier in life, suggesting that those experiencing progressive ability changes later in life might not be as aware of accessibility features, or might not have the know-how to adapt technologies to their changing needs. Our findings provide support for creating technologies that can detect older adults' abilities and recommend or enact interface changes to match."", 'doi': '10.1145/3308561.3353780', 'url': 'https://doi.org/10.1145/3308561.3353780', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Perception and Adoption of Mobile Accessibility Features by Older Adults Experiencing Ability Changes', 'author': 'Franz, Rachel L. and Wobbrock, Jacob O. and Cheng, Yi and Findlater, Leah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353780'}"
Making Nonvisually: Lessons from the Field,10.1145/3308561.3355619,"The Maker movement promises access to activities from crafting to digital fabrication for anyone to invent and customize technology. But people with disabilities, who could benefit from Making, still encounter significant barriers to do so. In response, we share our personal experiences Making nonvisually and supporting its instruction. Specifically, we draw on examples from a series of workshops where we introduced Arduino to blind hobbyists and guided assembly of an accessible voltmeter prototype [24]. In so doing, we offer future directions for accessible Making research and application.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, arduino, blind, making', 'numpages': '7', 'pages': '279–285', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The Maker movement promises access to activities from crafting to digital fabrication for anyone to invent and customize technology. But people with disabilities, who could benefit from Making, still encounter significant barriers to do so. In response, we share our personal experiences Making nonvisually and supporting its instruction. Specifically, we draw on examples from a series of workshops where we introduced Arduino to blind hobbyists and guided assembly of an accessible voltmeter prototype [24]. In so doing, we offer future directions for accessible Making research and application.', 'doi': '10.1145/3308561.3355619', 'url': 'https://doi.org/10.1145/3308561.3355619', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Making Nonvisually: Lessons from the Field', 'author': 'Bennett, Cynthia L. and Stangl, Abigale and Siu, Alexa F. and Miele, Joshua A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3355619'}"
Ageing is Not a Disease: Pitfalls for the Acceptance of Self-Management Health Systems Supporting Healthy Ageing,10.1145/3308561.3353794,"Recently, a shift from curative to preventive care is promoted, by which patients are expected to become active and use diverse forms of self-management health systems (SMHS), i.e., integrated solutions that present data from multiple sensors and/or self-reports, possibly enhanced with risk assessment and decision support, to perform health-related actions. This is promoted as contributing to living longer and healthier, assisting ageing-in-place. Hence, older adults have also become a potential target of SMHS. While studies are performed on uses and attitudes of specific patient groups towards SMHS, studies that focus on older, including the oldest, adults are scarce. Therefore, we report on a qualitative study with 20 older adults (mean age = 80). Through thematic analysis, we identified four themes (i.e., enforced use of technology; need for support in technology use; equivocal stance towards sharing data; hypothetical value of technology for healthy ageing) to provide a deeper understanding of older adults' attitudes and engagement with information- and communication technologies (ICT) in general and SMHS in particular. We also present four pitfalls, unified by a central concept ""Ageing is not a disease'', along with design considerations for future SMHS.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'attitudes, older adults, self-management health systems, thematic analysis', 'numpages': '13', 'pages': '286–298', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Recently, a shift from curative to preventive care is promoted, by which patients are expected to become active and use diverse forms of self-management health systems (SMHS), i.e., integrated solutions that present data from multiple sensors and/or self-reports, possibly enhanced with risk assessment and decision support, to perform health-related actions. This is promoted as contributing to living longer and healthier, assisting ageing-in-place. Hence, older adults have also become a potential target of SMHS. While studies are performed on uses and attitudes of specific patient groups towards SMHS, studies that focus on older, including the oldest, adults are scarce. Therefore, we report on a qualitative study with 20 older adults (mean age = 80). Through thematic analysis, we identified four themes (i.e., enforced use of technology; need for support in technology use; equivocal stance towards sharing data; hypothetical value of technology for healthy ageing) to provide a deeper understanding of older adults\' attitudes and engagement with information- and communication technologies (ICT) in general and SMHS in particular. We also present four pitfalls, unified by a central concept ""Ageing is not a disease\'\', along with design considerations for future SMHS.', 'doi': '10.1145/3308561.3353794', 'url': 'https://doi.org/10.1145/3308561.3353794', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Ageing is Not a Disease: Pitfalls for the Acceptance of Self-Management Health Systems Supporting Healthy Ageing', 'author': ""D'Haeseleer, Ine and Gerling, Kathrin and Schreurs, Dominique and Vanrumste, Bart and Vanden Abeele, Vero"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353794'}"
Go That Way: Exploring Supplementary Physical Movements by a Stationary Robot When Providing Navigation Instructions,10.1145/3308561.3353805,"We describe an exploration of how kiosk-type stationary robots might provide navigation instructions for blind people. Inspired by a technique used by Orientation \&amp; Mobility experts in which a route is traced out on a person's palm, we developed five methods that supplement verbal instructions with physical movements. We explored the usability, strengths, and limitations of each of our methods in two exploratory studies with blind participants. One method, in which the robot used its entire arm to create path gestures while participants held its gripper, was preferred by 5 out of 8 blind participants and performed comparably on a recall task as a verbal-only instruction method. A closer approximation of the original palm method failed. We analyzed interview data to understand the reasons behind the failures and successes. We discuss the lessons learned from our studies about instruction methods, how robots in public settings can be useful for blind people, and the challenges of deploying such systems in public.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive robots, blindness, human-robot interaction, navigation instructions', 'numpages': '13', 'pages': '299–311', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We describe an exploration of how kiosk-type stationary robots might provide navigation instructions for blind people. Inspired by a technique used by Orientation \\&amp; Mobility experts in which a route is traced out on a person's palm, we developed five methods that supplement verbal instructions with physical movements. We explored the usability, strengths, and limitations of each of our methods in two exploratory studies with blind participants. One method, in which the robot used its entire arm to create path gestures while participants held its gripper, was preferred by 5 out of 8 blind participants and performed comparably on a recall task as a verbal-only instruction method. A closer approximation of the original palm method failed. We analyzed interview data to understand the reasons behind the failures and successes. We discuss the lessons learned from our studies about instruction methods, how robots in public settings can be useful for blind people, and the challenges of deploying such systems in public."", 'doi': '10.1145/3308561.3353805', 'url': 'https://doi.org/10.1145/3308561.3353805', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Go That Way: Exploring Supplementary Physical Movements by a Stationary Robot When Providing Navigation Instructions', 'author': 'Tan, Xiang Zhi and Carter, Elizabeth J. and Reig, Samantha and Steinfeld, Aaron', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353805'}"
μGraph: Haptic Exploration and Editing of 3D Chemical Diagrams,10.1145/3308561.3353811,"People with visual impairments or blindness (VIB) encounter difficulties in exploring graphical representations that are widely used for the study of STEM subjects. In particular, graphs are used to represent many different scientific notations: flowcharts, automata, cognitive maps, and more. Among these, structural chemical formulae are characterized by a complex, often 3-dimensional structure, which makes them hard to access and author with traditional assistive tools.We propose MuGraph, a multimodal system that combines haptic and speech feedback to enable people with VIB to explore and edit structural chemical formulae. Two main contributions are presented: (i) a novel, non-visual interaction paradigm for exploring graphs and its implementation in the MuGraph system, and (ii) an extensive evaluation of the proposed system with 10 participants with VIB showing that MuGraph is thoroughly accessible and that the haptic feedback enhances understanding of the geometric properties of a graph.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'graph accessibility, stem education, visual impairment', 'numpages': '6', 'pages': '312–317', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with visual impairments or blindness (VIB) encounter difficulties in exploring graphical representations that are widely used for the study of STEM subjects. In particular, graphs are used to represent many different scientific notations: flowcharts, automata, cognitive maps, and more. Among these, structural chemical formulae are characterized by a complex, often 3-dimensional structure, which makes them hard to access and author with traditional assistive tools.We propose MuGraph, a multimodal system that combines haptic and speech feedback to enable people with VIB to explore and edit structural chemical formulae. Two main contributions are presented: (i) a novel, non-visual interaction paradigm for exploring graphs and its implementation in the MuGraph system, and (ii) an extensive evaluation of the proposed system with 10 participants with VIB showing that MuGraph is thoroughly accessible and that the haptic feedback enhances understanding of the geometric properties of a graph.', 'doi': '10.1145/3308561.3353811', 'url': 'https://doi.org/10.1145/3308561.3353811', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'μGraph: Haptic Exploration and Editing of 3D Chemical Diagrams', 'author': 'Bernareggi, Cristian and Ahmetovic, Dragan and Mascetti, Sergio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353811'}"
RoboGraphics: Dynamic Tactile Graphics Powered by Mobile Robots,10.1145/3308561.3353804,"Tactile graphics are a common way to present information to people with vision impairments. Tactile graphics can be used to explore a broad range of static visual content but aren't well suited to representing animation or interactivity. We introduce a new approach to creating dynamic tactile graphics that combines a touch screen tablet, static tactile overlays, and small mobile robots. We introduce a prototype system called RoboGraphics and several proof-of-concept applications. We evaluated our prototype with seven participants with varying levels of vision, comparing the RoboGraphics approach to a flat screen, audio-tactile interface. Our results show that dynamic tactile graphics can help visually impaired participants explore data quickly and accurately.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blindness, education, robots, tactile, tangible user interfaces', 'numpages': '11', 'pages': '318–328', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Tactile graphics are a common way to present information to people with vision impairments. Tactile graphics can be used to explore a broad range of static visual content but aren't well suited to representing animation or interactivity. We introduce a new approach to creating dynamic tactile graphics that combines a touch screen tablet, static tactile overlays, and small mobile robots. We introduce a prototype system called RoboGraphics and several proof-of-concept applications. We evaluated our prototype with seven participants with varying levels of vision, comparing the RoboGraphics approach to a flat screen, audio-tactile interface. Our results show that dynamic tactile graphics can help visually impaired participants explore data quickly and accurately."", 'doi': '10.1145/3308561.3353804', 'url': 'https://doi.org/10.1145/3308561.3353804', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'RoboGraphics: Dynamic Tactile Graphics Powered by Mobile Robots', 'author': 'Guinness, Darren and Muehlbradt, Annika and Szafir, Daniel and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353804'}"
Defining Problems of Practices to Advance Inclusive Tactile Media Consumption and Production,10.1145/3308561.3353778,"Tactile media are important resources for people who are blind or have low vision (BLV) to access visual or graphical information as well as to develop tactile acuity. In this paper we present findings from a social learning design that was guided by the question, ""What are the factors or issues that impact the tactile media consumption and production practices of BLV and other invested stakeholders?"" From data collected during three Tactile Arts and Graphics Symposia-that gathered (N=64) BLV and sighted practitioners, researchers, and educators invested making information and experiences accessible through touch-we identified 34 issues that fall under four problems of practice, that impact tactile media practices. Based on these four problems of practice (and 34 underlying issues), we share recommendations to support the development of socio-technical systems that improve tactile access to information and full inclusion of people who are BLV in tactile media consumption and production.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessible art, blind, consumption, inclusion, low vision, problems of practice, production, social learning, tactile art, tactile graphics, tactile literacy., tactile media, visually impaired', 'numpages': '13', 'pages': '329–341', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tactile media are important resources for people who are blind or have low vision (BLV) to access visual or graphical information as well as to develop tactile acuity. In this paper we present findings from a social learning design that was guided by the question, ""What are the factors or issues that impact the tactile media consumption and production practices of BLV and other invested stakeholders?"" From data collected during three Tactile Arts and Graphics Symposia-that gathered (N=64) BLV and sighted practitioners, researchers, and educators invested making information and experiences accessible through touch-we identified 34 issues that fall under four problems of practice, that impact tactile media practices. Based on these four problems of practice (and 34 underlying issues), we share recommendations to support the development of socio-technical systems that improve tactile access to information and full inclusion of people who are BLV in tactile media consumption and production.', 'doi': '10.1145/3308561.3353778', 'url': 'https://doi.org/10.1145/3308561.3353778', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Defining Problems of Practices to Advance Inclusive Tactile Media Consumption and Production', 'author': 'Stangl, Abigale and Cunningham, Ann and Blake, Lou Ann and Yeh, Tom', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353778'}"
shapeCAD: An Accessible 3D Modelling Workflow for the Blind and Visually-Impaired Via 2.5D Shape Displays,10.1145/3308561.3353782,"Affordable rapid 3D printing technologies have become key enablers of the Maker Movement by giving individuals the ability to create physical finished products. However, existing computer-aided design (CAD) tools that allow authoring and editing of 3D models are mostly visually reliant and limit access to people with blindness and visual impairment (BVI). Through a series of co-design sessions with three blind users of mixed programming ability, we identify accessibility challenges in existing 3D modelling scripting tools and design interactions to support dynamic feedback of scripts using a 2.5D tactile shape display. With these insights, we implement shapeCAD. Interacting with shapeCAD, BVI users are able to leverage the low resolution output from a 2.5D shape display to complement programming of 3D models. shapeCAD allows users to haptically explore and modify existing models, and to author new models. We further validate usability and user experience through an evaluation with five BVI programmers. In a short period of time, novices were able to design a range of new objects. BVI users can bring a valuable perspective to design and it is imperative to increase accessibility in tools that enable this community to also participate as designers.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': '2.5d shape displays, accessible 3d printing, accessible authoring tools, haptics, tactile displays, tactile graphics', 'numpages': '13', 'pages': '342–354', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Affordable rapid 3D printing technologies have become key enablers of the Maker Movement by giving individuals the ability to create physical finished products. However, existing computer-aided design (CAD) tools that allow authoring and editing of 3D models are mostly visually reliant and limit access to people with blindness and visual impairment (BVI). Through a series of co-design sessions with three blind users of mixed programming ability, we identify accessibility challenges in existing 3D modelling scripting tools and design interactions to support dynamic feedback of scripts using a 2.5D tactile shape display. With these insights, we implement shapeCAD. Interacting with shapeCAD, BVI users are able to leverage the low resolution output from a 2.5D shape display to complement programming of 3D models. shapeCAD allows users to haptically explore and modify existing models, and to author new models. We further validate usability and user experience through an evaluation with five BVI programmers. In a short period of time, novices were able to design a range of new objects. BVI users can bring a valuable perspective to design and it is imperative to increase accessibility in tools that enable this community to also participate as designers.', 'doi': '10.1145/3308561.3353782', 'url': 'https://doi.org/10.1145/3308561.3353782', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'shapeCAD: An Accessible 3D Modelling Workflow for the Blind and Visually-Impaired Via 2.5D Shape Displays', 'author': 'Siu, Alexa F. and Kim, Son and Miele, Joshua A. and Follmer, Sean', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353782'}"
Automatic Generation and Evaluation of Usable and Secure Audio reCAPTCHA,10.1145/3308561.3353777,"CAPTCHAs are challenge-response tests to differentiate humans from automated agents, with tasks that are easy for humans but difficult for computers. The most common CAPTCHAs require humans to decipher characters from an image and are unsuitable for visually impaired people. As an alternative, audio CAPTCHA was proposed, which require deciphering spoken digits/letters. However, current audio CAPTCHAs suffer from low usability and are insecure against Automatic Speech Recognition (ASR) attacks. In this work, we propose reCAPGen, a system that uses ASR for generating secure CAPTCHAs. We evaluated four audio CAPTCHA schemes with 60 sighted and 19 visually impaired participants. We found that our proposed Last Two Words scheme was the most usable with success rate of &gt;78.2\% and low response time of &lt;14.5s. Furthermore, solving our audio CAPTCHAs can transcribe unknown words with &gt;82\% accuracy.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'blind, captcha, evaluation, mturk, visually impaired', 'numpages': '12', 'pages': '355–366', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'CAPTCHAs are challenge-response tests to differentiate humans from automated agents, with tasks that are easy for humans but difficult for computers. The most common CAPTCHAs require humans to decipher characters from an image and are unsuitable for visually impaired people. As an alternative, audio CAPTCHA was proposed, which require deciphering spoken digits/letters. However, current audio CAPTCHAs suffer from low usability and are insecure against Automatic Speech Recognition (ASR) attacks. In this work, we propose reCAPGen, a system that uses ASR for generating secure CAPTCHAs. We evaluated four audio CAPTCHA schemes with 60 sighted and 19 visually impaired participants. We found that our proposed Last Two Words scheme was the most usable with success rate of &gt;78.2\\% and low response time of &lt;14.5s. Furthermore, solving our audio CAPTCHAs can transcribe unknown words with &gt;82\\% accuracy.', 'doi': '10.1145/3308561.3353777', 'url': 'https://doi.org/10.1145/3308561.3353777', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Automatic Generation and Evaluation of Usable and Secure Audio reCAPTCHA', 'author': 'Jain, Mohit and Tripathi, Rohun and Bhansali, Ishita and Kumar, Pratyush', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353777'}"
Making Memes Accessible,10.1145/3308561.3353792,"Images on social media platforms are inaccessible to people with vision impairments due to a lack of descriptions that can be read by screen readers. Providing accurate alternative text for all visual content on social media is not yet feasible, but certain subsets of images, such as internet memes, offer affordances for automatic or semi-automatic generation of alternative text. We present two methods for making memes accessible semi-automatically through (1) the generation of rich alternative text descriptions and (2) the creation of audio macro memes. Meme authors create alternative text templates or audio meme templates, and insert placeholders instead of the meme text. When a meme with the same image is encountered again, it is automatically recognized from a database of meme templates. Text is then extracted and either inserted into the alternative text template or rendered in the audio template using text-to-speech. In our evaluation of meme formats with 10 Twitter users with vision impairments, we found that most users preferred alternative text memes because the description of the visual content conveys the emotional tone of the character. As the preexisting templates can be automatically matched to memes using the same visual image, this combined approach can make a large subset of images on the web accessible, while preserving the emotion and tone inherent in the image memes.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'alternative text, audio, blind, image description, low vision, meme, social media', 'numpages': '10', 'pages': '367–376', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Images on social media platforms are inaccessible to people with vision impairments due to a lack of descriptions that can be read by screen readers. Providing accurate alternative text for all visual content on social media is not yet feasible, but certain subsets of images, such as internet memes, offer affordances for automatic or semi-automatic generation of alternative text. We present two methods for making memes accessible semi-automatically through (1) the generation of rich alternative text descriptions and (2) the creation of audio macro memes. Meme authors create alternative text templates or audio meme templates, and insert placeholders instead of the meme text. When a meme with the same image is encountered again, it is automatically recognized from a database of meme templates. Text is then extracted and either inserted into the alternative text template or rendered in the audio template using text-to-speech. In our evaluation of meme formats with 10 Twitter users with vision impairments, we found that most users preferred alternative text memes because the description of the visual content conveys the emotional tone of the character. As the preexisting templates can be automatically matched to memes using the same visual image, this combined approach can make a large subset of images on the web accessible, while preserving the emotion and tone inherent in the image memes.', 'doi': '10.1145/3308561.3353792', 'url': 'https://doi.org/10.1145/3308561.3353792', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Making Memes Accessible', 'author': 'Gleason, Cole and Pavel, Amy and Liu, Xingyu and Carrington, Patrick and Chilton, Lydia B. and Bigham, Jeffrey P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353792'}"
Evaluating Instructor Strategy and Student Learning Through Digital Accessibility Course Enhancements,10.1145/3308561.3353795,"University students graduating and entering into technology design and development fields are underprepared to support digital accessibility due to a lack of awareness and training. Teach Access is a consortium of 10 industry partners, 5 advocacy groups, and 20 university partners working to address this issue. In an attempt to bridge the gap between what is taught to students and the increasing demand from industry, the initiative described here was aimed at awarding instructor grants to support the development of accessibility modules in tech-related courses. In our study we surveyed student attitudes toward accessibility pre- and post-instruction of these modules, as well as, instructor strategy. We found that across all courses, student confidence in accessibility-related concepts increased. The largest increases were found in student confidence in defining the Americans with Disabilities Act (ADA) and the Web Content Accessibility Guidelines (WCAG). Our work makes the following contributions: 1) A detailed description of how accessibility was integrated into 18 different university and college courses 2) Instructional delivery methods found to be effective by participating instructors 3) Insights for resource materials development.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, higher education', 'numpages': '12', 'pages': '377–388', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'University students graduating and entering into technology design and development fields are underprepared to support digital accessibility due to a lack of awareness and training. Teach Access is a consortium of 10 industry partners, 5 advocacy groups, and 20 university partners working to address this issue. In an attempt to bridge the gap between what is taught to students and the increasing demand from industry, the initiative described here was aimed at awarding instructor grants to support the development of accessibility modules in tech-related courses. In our study we surveyed student attitudes toward accessibility pre- and post-instruction of these modules, as well as, instructor strategy. We found that across all courses, student confidence in accessibility-related concepts increased. The largest increases were found in student confidence in defining the Americans with Disabilities Act (ADA) and the Web Content Accessibility Guidelines (WCAG). Our work makes the following contributions: 1) A detailed description of how accessibility was integrated into 18 different university and college courses 2) Instructional delivery methods found to be effective by participating instructors 3) Insights for resource materials development.', 'doi': '10.1145/3308561.3353795', 'url': 'https://doi.org/10.1145/3308561.3353795', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Evaluating Instructor Strategy and Student Learning Through Digital Accessibility Course Enhancements', 'author': 'Kearney-Volpe, Claire and Kletenik, Devorah and Sonka, Kate and Sturm, Deborah and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353795'}"
X-Ray: Screenshot Accessibility via Embedded Metadata,10.1145/3308561.3353808,"Screenshots are frequently shared on social media, via personal communications, and in academic papers. Unfortunately, existing screenshot tools strip away semantics useful for making the content accessible, leaving only pixels. For example, a screenshot of a table removes the structural information useful for conveying it. We quantify the scale of the problem via a study of academic papers, showing that a large number of images included in academic papers are screenshots, and validate this via qualitative interviews with researchers about their figure generation process. We then introduce X-Ray, a system that captures and embeds the semantics of the underlying content into images. Using the X-Ray screenshot tool, semantic information is captured and stored in the Exif data of the resulting image, allowing it to ""tag along"" as the image is shared and reposted. We demonstrate that our approach retains accessibility for screen reader users via a study with five blind participants. More generally, our approach suggests a method for embedding accessibility metadata into otherwise inaccessible formats, enabling them to retain the more accessible representations that are present at capture time.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, alt text, large-scale analysis, pdf, runtime modification, screen readers, screenshot, vision impairment', 'numpages': '7', 'pages': '389–395', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Screenshots are frequently shared on social media, via personal communications, and in academic papers. Unfortunately, existing screenshot tools strip away semantics useful for making the content accessible, leaving only pixels. For example, a screenshot of a table removes the structural information useful for conveying it. We quantify the scale of the problem via a study of academic papers, showing that a large number of images included in academic papers are screenshots, and validate this via qualitative interviews with researchers about their figure generation process. We then introduce X-Ray, a system that captures and embeds the semantics of the underlying content into images. Using the X-Ray screenshot tool, semantic information is captured and stored in the Exif data of the resulting image, allowing it to ""tag along"" as the image is shared and reposted. We demonstrate that our approach retains accessibility for screen reader users via a study with five blind participants. More generally, our approach suggests a method for embedding accessibility metadata into otherwise inaccessible formats, enabling them to retain the more accessible representations that are present at capture time.', 'doi': '10.1145/3308561.3353808', 'url': 'https://doi.org/10.1145/3308561.3353808', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'X-Ray: Screenshot Accessibility via Embedded Metadata', 'author': 'Pareddy, Sujeath and Guo, Anhong and Bigham, Jeffrey P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353808'}"
Delivering Sign Language in a Live Planetarium Show Using Head-Mounted Displays and Infrared Light,10.1145/3308561.3353809,Sign language narration is difficult to view at live planetarium shows because the room is dark and the signer is not located near images projected onto the planetarium dome. We have designed and implemented a system using head-mounted displays (HMDs) and infrared light to support viewing real-time sign language narration of live planetarium shows. Results from a series of 3 studies involving 29 students who are deaf or hard-of-hearing suggest that viewing properly configured video of sign language narration in an HMD may increase learning in this setting. Participants expressed no single preference regarding signer position in the video feed but did indicate that the relative brightness of the HMD must be tuned to match the apparent brightness of images broadcast on the planetarium dome. We also identified other issues related to HMD fit and the appearance of the signer in the video.,"{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'head mounted display, planetarium, sign language', 'numpages': '6', 'pages': '396–401', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sign language narration is difficult to view at live planetarium shows because the room is dark and the signer is not located near images projected onto the planetarium dome. We have designed and implemented a system using head-mounted displays (HMDs) and infrared light to support viewing real-time sign language narration of live planetarium shows. Results from a series of 3 studies involving 29 students who are deaf or hard-of-hearing suggest that viewing properly configured video of sign language narration in an HMD may increase learning in this setting. Participants expressed no single preference regarding signer position in the video feed but did indicate that the relative brightness of the HMD must be tuned to match the apparent brightness of images broadcast on the planetarium dome. We also identified other issues related to HMD fit and the appearance of the signer in the video.', 'doi': '10.1145/3308561.3353809', 'url': 'https://doi.org/10.1145/3308561.3353809', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Delivering Sign Language in a Live Planetarium Show Using Head-Mounted Displays and Infrared Light', 'author': 'Jones, Michael D. and Lawler, M. Jeannette', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353809'}"
WatchOut: Obstacle Sonification for People with Visual Impairment or Blindness,10.1145/3308561.3353779,"Independent mobility is one of the main challenges for blind or visually impaired (BVI) people. In particular, BVI people often need to identify and avoid nearby obstacles, for example a bicycle parked on the sidewalk. This is generally achieved with a combination of residual vision, hearing and haptic sensing using the white cane. However, in many cases, BVI people can only perceive obstacles at short distance (typically about 1m, i.e., the white cane detection range), in other situations obstacles are hard to detect (e.g., those elevated from the ground), while others should not be hit by the white cane (e.g., a standing person). Thus, some time and effort are required to identify the object in order to understand how to avoid it. A solution to these problems can be found in recent computer vision techniques that can run on mobile and wearable devices to detect obstacles at a distance. However, in addition to detecting obstacles, it is also necessary to convey information about them to a BVI user. This contribution presents WatchOut, a sonification technique for conveying real-time information about the main characteristics of an obstacle to a BVI person, who can then use this additional feedback to safely navigate in the environment. WatchOut was designed with a user-centric approach, involving two iterations of online questionnaires with BVI participants in order to define, improve and evaluate the sonification technique. WatchOut was implemented and tested as a module of a mobile app that detects obstacles using state-of-the-art computer vision technology. Results show that the system is considered usable, and can guide the users to avoid more than 85\% of the obstacles.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'navigation assistive technologies, obstacle avoidance, sonification, visual impairment', 'numpages': '12', 'pages': '402–413', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Independent mobility is one of the main challenges for blind or visually impaired (BVI) people. In particular, BVI people often need to identify and avoid nearby obstacles, for example a bicycle parked on the sidewalk. This is generally achieved with a combination of residual vision, hearing and haptic sensing using the white cane. However, in many cases, BVI people can only perceive obstacles at short distance (typically about 1m, i.e., the white cane detection range), in other situations obstacles are hard to detect (e.g., those elevated from the ground), while others should not be hit by the white cane (e.g., a standing person). Thus, some time and effort are required to identify the object in order to understand how to avoid it. A solution to these problems can be found in recent computer vision techniques that can run on mobile and wearable devices to detect obstacles at a distance. However, in addition to detecting obstacles, it is also necessary to convey information about them to a BVI user. This contribution presents WatchOut, a sonification technique for conveying real-time information about the main characteristics of an obstacle to a BVI person, who can then use this additional feedback to safely navigate in the environment. WatchOut was designed with a user-centric approach, involving two iterations of online questionnaires with BVI participants in order to define, improve and evaluate the sonification technique. WatchOut was implemented and tested as a module of a mobile app that detects obstacles using state-of-the-art computer vision technology. Results show that the system is considered usable, and can guide the users to avoid more than 85\\% of the obstacles.', 'doi': '10.1145/3308561.3353779', 'url': 'https://doi.org/10.1145/3308561.3353779', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'WatchOut: Obstacle Sonification for People with Visual Impairment or Blindness', 'author': 'Presti, Giorgio and Ahmetovic, Dragan and Ducci, Mattia and Bernareggi, Cristian and Ludovico, Luca and Barat\\`{e}, Adriano and Avanzini, Federico and Mascetti, Sergio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353779'}"
VERSE: Bridging Screen Readers and Voice Assistants for Enhanced Eyes-Free Web Search,10.1145/3308561.3353773,"People with visual impairments often rely on screen readers when interacting with computer systems. Increasingly, these individuals also make extensive use of voice-based virtual assistants (VAs). We conducted a survey of 53 people who are legally blind to identify the strengths and weaknesses of both technologies, and the unmet opportunities at their intersection. We learned that virtual assistants are convenient and accessible, but lack the ability to deeply engage with content (e.g., read beyond the first few sentences of an article), and the ability to get a quick overview of the landscape (e.g., list alternative search results and suggestions). In contrast, screen readers allow for deep engagement with content (when content is accessible), and provide fine-grained navigation and control, but at the cost of reduced walk-up-and-use convenience. Based on these findings, we implemented VERSE (Voice Exploration, Retrieval, and SEarch), a prototype that extends a VA with screen-reader-inspired capabilities, and allows other devices (e.g., smartwatches) to serve as optional input accelerators. In a usability study with 12 blind screen reader users we found that VERSE meaningfully extended VA functionality. Participants especially valued having access to multiple search results and search verticals.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'non-visual search, voice search', 'numpages': '13', 'pages': '414–426', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with visual impairments often rely on screen readers when interacting with computer systems. Increasingly, these individuals also make extensive use of voice-based virtual assistants (VAs). We conducted a survey of 53 people who are legally blind to identify the strengths and weaknesses of both technologies, and the unmet opportunities at their intersection. We learned that virtual assistants are convenient and accessible, but lack the ability to deeply engage with content (e.g., read beyond the first few sentences of an article), and the ability to get a quick overview of the landscape (e.g., list alternative search results and suggestions). In contrast, screen readers allow for deep engagement with content (when content is accessible), and provide fine-grained navigation and control, but at the cost of reduced walk-up-and-use convenience. Based on these findings, we implemented VERSE (Voice Exploration, Retrieval, and SEarch), a prototype that extends a VA with screen-reader-inspired capabilities, and allows other devices (e.g., smartwatches) to serve as optional input accelerators. In a usability study with 12 blind screen reader users we found that VERSE meaningfully extended VA functionality. Participants especially valued having access to multiple search results and search verticals.', 'doi': '10.1145/3308561.3353773', 'url': 'https://doi.org/10.1145/3308561.3353773', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'VERSE: Bridging Screen Readers and Voice Assistants for Enhanced Eyes-Free Web Search', 'author': 'Vtyurina, Alexandra and Fourney, Adam and Morris, Meredith Ringel and Findlater, Leah and White, Ryen W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353773'}"
Typing Slowly but Screen-Free: Exploring Navigation over Entirely Auditory Keyboards,10.1145/3308561.3353789,"Accessible onscreen keyboards require people who are blind to keep out their phone at all times to search for visual affordances they cannot see. Is it possible to re-imagine text entry without a reference screen? To explore this question, we introduce screenless keyboards as aural flows (keyflows): rapid auditory streams of Text-To-Speech (TTS) characters controllable by hand gestures. In a study, 20 screen-reader users experienced keyflows to perform initial text entry. Typing took inordinately longer than current screen-based keyboards, but most participants preferred screen-free text entry to current methods, especially for short messages on-the-go. We model navigation strategies that participants enacted to aurally browse entirely auditory keyboards and discuss their limitation and benefits for daily access. Our work points to trade-offs in user performance and user experience for situations when blind users may trade typing speed with the benefit of being untethered from the screen.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessible text entry, aural navigation, screen-reader users', 'numpages': '13', 'pages': '427–439', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Accessible onscreen keyboards require people who are blind to keep out their phone at all times to search for visual affordances they cannot see. Is it possible to re-imagine text entry without a reference screen? To explore this question, we introduce screenless keyboards as aural flows (keyflows): rapid auditory streams of Text-To-Speech (TTS) characters controllable by hand gestures. In a study, 20 screen-reader users experienced keyflows to perform initial text entry. Typing took inordinately longer than current screen-based keyboards, but most participants preferred screen-free text entry to current methods, especially for short messages on-the-go. We model navigation strategies that participants enacted to aurally browse entirely auditory keyboards and discuss their limitation and benefits for daily access. Our work points to trade-offs in user performance and user experience for situations when blind users may trade typing speed with the benefit of being untethered from the screen.', 'doi': '10.1145/3308561.3353789', 'url': 'https://doi.org/10.1145/3308561.3353789', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Typing Slowly but Screen-Free: Exploring Navigation over Entirely Auditory Keyboards', 'author': 'Mathur, Reeti and Sheth, Aishwarya and Vyas, Parimal and Bolchini, Davide', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353789'}"
Research to Market Transition of Mobile Assistive Technologies for People with Visual Impairments,10.1145/3308561.3355618,"Mobile devices are accessible to people with visual impairments and hence they are convenient platforms to support assistive technologies. Indeed, in the last years many scientific contributions proposed assistive applications for mobile devices. However, few of these solutions were eventually delivered to end-users, depriving people with disabilities of important assistive tools. The underlying problem is that a number of challenges need to be faced for transitioning assistive mobile applications from research to market.This contribution reports authors' experience in the academic research and successive distribution of three mobile assistive applications for people with visual impairment. As a general message, we describe the relevant characteristics of the target population, analyze different models of transition from academic research to end-users distribution and show how the transitioning process has a positive impact on research.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'mobile assistive technologies, technology transfer', 'numpages': '6', 'pages': '440–445', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Mobile devices are accessible to people with visual impairments and hence they are convenient platforms to support assistive technologies. Indeed, in the last years many scientific contributions proposed assistive applications for mobile devices. However, few of these solutions were eventually delivered to end-users, depriving people with disabilities of important assistive tools. The underlying problem is that a number of challenges need to be faced for transitioning assistive mobile applications from research to market.This contribution reports authors' experience in the academic research and successive distribution of three mobile assistive applications for people with visual impairment. As a general message, we describe the relevant characteristics of the target population, analyze different models of transition from academic research to end-users distribution and show how the transitioning process has a positive impact on research."", 'doi': '10.1145/3308561.3355618', 'url': 'https://doi.org/10.1145/3308561.3355618', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Research to Market Transition of Mobile Assistive Technologies for People with Visual Impairments', 'author': 'Mascetti, Sergio and Ahmetovic, Dragan and Bernareggi, Cristian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3355618'}"
Reading Between the Guidelines: How Commercial Voice Assistant Guidelines Hinder Accessibility for Blind Users,10.1145/3308561.3353797,"Voice-Activated Personal Assistants (VAPAs)-like Apple Siri and Amazon Alexa - have rapidly become common features on mobile devices and in homes of millions of people around the world. They have proven to be particularly valuable to people with disabilities, chiefly among people with visual impairments. Yet, we still know relatively little about the fundamental metaphors and guidelines for designing voice assistants, and how they might empower and constrain visually impaired users. To address this need, we conducted a qualitative document review of VAPA design guidelines published by top commercial vendors Amazon, Google, Microsoft, Apple and Alibaba. We found that guidelines have many commonalities that surface an underlying assumption that VAPA interfaces should be modeled after human-human conversation. We draw on prior work about needs of people with visual impairments to critique this taken-for-granted human-human conversation metaphor and offer amendments to prevailing design guidelines that can make this now-pervasive platform more fully achieve its potential to become universally usable.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blindness, conversation, design guidelines, voice assistant', 'numpages': '13', 'pages': '446–458', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Voice-Activated Personal Assistants (VAPAs)-like Apple Siri and Amazon Alexa - have rapidly become common features on mobile devices and in homes of millions of people around the world. They have proven to be particularly valuable to people with disabilities, chiefly among people with visual impairments. Yet, we still know relatively little about the fundamental metaphors and guidelines for designing voice assistants, and how they might empower and constrain visually impaired users. To address this need, we conducted a qualitative document review of VAPA design guidelines published by top commercial vendors Amazon, Google, Microsoft, Apple and Alibaba. We found that guidelines have many commonalities that surface an underlying assumption that VAPA interfaces should be modeled after human-human conversation. We draw on prior work about needs of people with visual impairments to critique this taken-for-granted human-human conversation metaphor and offer amendments to prevailing design guidelines that can make this now-pervasive platform more fully achieve its potential to become universally usable.', 'doi': '10.1145/3308561.3353797', 'url': 'https://doi.org/10.1145/3308561.3353797', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Reading Between the Guidelines: How Commercial Voice Assistant Guidelines Hinder Accessibility for Blind Users', 'author': 'Branham, Stacy M. and Mukkath Roy, Antony Rishin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353797'}"
See-Thru: Towards Minimally Obstructive Eye-Controlled Wheelchair Interfaces,10.1145/3308561.3353802,"Eye-tracking interfaces increase the communication bandwidth between humans and computers when using hands is not possible. For some, eyes are the only available input modality to control and interact with the various devices that enable their independence. The goal of this work is to develop and evaluate an eye-controlled wheelchair navigation interface that minimizes obstruction to the user's field of view by removing the conventional use of a computer screen as a feedback mechanism. We present See-Thru, an eye-tracking interface that provides feedback to the user without a screen while simultaneously providing a clear view of the path ahead. Our prototype is evaluated against a screen-based state of the art interface in a study with three navigation tasks completed by seven power wheelchair users. Our results show that a majority of the participants not only prefer using the See-Thru interface, but perform better at driving tasks when using it. This supports the notion that users favor minimally obstructive interfaces in navigational contexts.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'eye gaze, eye tracking, field of view (fov), gaze control, navigation, power wheelchair, user interfaces', 'numpages': '11', 'pages': '459–469', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Eye-tracking interfaces increase the communication bandwidth between humans and computers when using hands is not possible. For some, eyes are the only available input modality to control and interact with the various devices that enable their independence. The goal of this work is to develop and evaluate an eye-controlled wheelchair navigation interface that minimizes obstruction to the user's field of view by removing the conventional use of a computer screen as a feedback mechanism. We present See-Thru, an eye-tracking interface that provides feedback to the user without a screen while simultaneously providing a clear view of the path ahead. Our prototype is evaluated against a screen-based state of the art interface in a study with three navigation tasks completed by seven power wheelchair users. Our results show that a majority of the participants not only prefer using the See-Thru interface, but perform better at driving tasks when using it. This supports the notion that users favor minimally obstructive interfaces in navigational contexts."", 'doi': '10.1145/3308561.3353802', 'url': 'https://doi.org/10.1145/3308561.3353802', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'See-Thru: Towards Minimally Obstructive Eye-Controlled Wheelchair Interfaces', 'author': 'Singer, Corten Clemente and Hartmann, Bj\\""{o}rn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353802'}"
Leveraging Shared Control to Empower People with Tetraplegia to Participate in Extreme Sports,10.1145/3308561.3353775,"Outdoor recreation improves quality of life for individuals with tetraplegia, however providing safe opportunities to engage in these sports has many challenges. We describe the iterative design and field evaluation of Tetra-Ski, a novel power-assisted ski chair. Users control Tetra-Ski with a joystick or Sip-and-Puff controller either independently or collaboratively with a tethered skier through our novel shared-control scheme. We also developed a training simulator to help prepare users prior to their skiing experience. A field study with eight participants and interviews with three trainers who used Tetra-Ski showed that Tetra-Ski is usable, enjoyable, and that the experience has a positive psychosocial effect on users. Furthermore, the shared-control scheme developed for Tetra-Ski proved crucial for supporting the unique abilities of different users, suggesting that a shared-control approach could enable broader access to less-dependent forms of outdoor recreation in the future.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'adaptive skiing, shared control, ski chair, spinal cord injury/disorder, tetra-ski, tetraplegia', 'numpages': '12', 'pages': '470–481', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Outdoor recreation improves quality of life for individuals with tetraplegia, however providing safe opportunities to engage in these sports has many challenges. We describe the iterative design and field evaluation of Tetra-Ski, a novel power-assisted ski chair. Users control Tetra-Ski with a joystick or Sip-and-Puff controller either independently or collaboratively with a tethered skier through our novel shared-control scheme. We also developed a training simulator to help prepare users prior to their skiing experience. A field study with eight participants and interviews with three trainers who used Tetra-Ski showed that Tetra-Ski is usable, enjoyable, and that the experience has a positive psychosocial effect on users. Furthermore, the shared-control scheme developed for Tetra-Ski proved crucial for supporting the unique abilities of different users, suggesting that a shared-control approach could enable broader access to less-dependent forms of outdoor recreation in the future.', 'doi': '10.1145/3308561.3353775', 'url': 'https://doi.org/10.1145/3308561.3353775', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Leveraging Shared Control to Empower People with Tetraplegia to Participate in Extreme Sports', 'author': 'Alsaleem, Ahmad and Imburgia, Ross and Godinez, Mateo and Merryweather, Andrew and Altizer, Roger and Denning, Tamara and Rosenbluth, Jeffery and Trapp, Stephen and Wiese, Jason', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353775'}"
A Community-Centered Design Framework for Robot-Assisted Feeding Systems,10.1145/3308561.3353803,"Robot-assisted feeding (RAF) systems offer enormous potential benefits to community-centered care-giving environments. However, developers of RAF technologies often focus on evaluating their standard transactional functionality, omitting the impact of such technologies in contexts that extend past the interaction of the robot and food receiver. RAF technologies have complex social, cultural and self-identity implications, since a ""meal"" extends well beyond the simple provisioning of nourishment. To better understand these implications we conducted a contextual inquiry in an assisted-living community with five potential care recipients and five caregivers, as well as interviews with fifteen domain experts including occupational therapists and feeding specialists. Based on our findings from these studies, we developed a new framework for RAF technologies that formulates this vital task as a community-centered relational service. We then use this framework to qualitatively and quantitatively assess three existing feeding systems and identify areas of improvement. Our work reveals new insights about stakeholders of RAF technologies and provides a roadmap for technology developers to better serve the needs of these stakeholders.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive feeding, assistive robotics', 'numpages': '13', 'pages': '482–494', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Robot-assisted feeding (RAF) systems offer enormous potential benefits to community-centered care-giving environments. However, developers of RAF technologies often focus on evaluating their standard transactional functionality, omitting the impact of such technologies in contexts that extend past the interaction of the robot and food receiver. RAF technologies have complex social, cultural and self-identity implications, since a ""meal"" extends well beyond the simple provisioning of nourishment. To better understand these implications we conducted a contextual inquiry in an assisted-living community with five potential care recipients and five caregivers, as well as interviews with fifteen domain experts including occupational therapists and feeding specialists. Based on our findings from these studies, we developed a new framework for RAF technologies that formulates this vital task as a community-centered relational service. We then use this framework to qualitatively and quantitatively assess three existing feeding systems and identify areas of improvement. Our work reveals new insights about stakeholders of RAF technologies and provides a roadmap for technology developers to better serve the needs of these stakeholders.', 'doi': '10.1145/3308561.3353803', 'url': 'https://doi.org/10.1145/3308561.3353803', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Community-Centered Design Framework for Robot-Assisted Feeding Systems', 'author': 'Bhattacharjee, Tapomayukh and Cabrera, Maria E. and Caspi, Anat and Cakmak, Maya and Srinivasa, Siddhartha S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353803'}"
Identifying Comfort Areas in 3D Space for Persons with Upper Extremity Mobility Impairments Using Virtual Reality,10.1145/3308561.3353810,"We present a method to extract workspace comfort areas for ergonomic placement of assistive technologies for persons with upper extremity mobility impairments Currently, areas of comfort are determined using multiple physical prototypes over several iterations which is expensive and time consuming. Our method utilizes a virtual reality exergame to obtain user-specific end effector motion data which is then combined with kernel density estimation to identify areas of frequent motion. Levels of comfort were confirmed by calculating shoulder joint forces necessary to reach these frequented areas and validated through a user study. Identifying areas of comfort in the workspace allows for optimal positioning and training of input devices for numerous applications.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'comfort areas, ergonomics, joint forces, mixed reality, mobility impairments, virtual reality', 'numpages': '5', 'pages': '495–499', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present a method to extract workspace comfort areas for ergonomic placement of assistive technologies for persons with upper extremity mobility impairments Currently, areas of comfort are determined using multiple physical prototypes over several iterations which is expensive and time consuming. Our method utilizes a virtual reality exergame to obtain user-specific end effector motion data which is then combined with kernel density estimation to identify areas of frequent motion. Levels of comfort were confirmed by calculating shoulder joint forces necessary to reach these frequented areas and validated through a user study. Identifying areas of comfort in the workspace allows for optimal positioning and training of input devices for numerous applications.', 'doi': '10.1145/3308561.3353810', 'url': 'https://doi.org/10.1145/3308561.3353810', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Identifying Comfort Areas in 3D Space for Persons with Upper Extremity Mobility Impairments Using Virtual Reality', 'author': 'Palaniappan, Shanmugam Muruga and Zhang, Ting and Duerstock, Bradley S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353810'}"
Am I Too Old to Drive? Opinions of Older Adults on Self-Driving Vehicles,10.1145/3308561.3353801,"Fully autonomous or ""self-driving"" vehicles are an emerging technology that may hold significant mobility potential for both disabled persons and for older adults unable to operate a conventional motor vehicle. It can be argued, however, that the needs, preferences and concerns of older adults and disabled persons regarding this technology have been insufficiently explored. Using focus group methodology, this study explores the sentiments of 39 older adults (55+) regarding self driving vehicle technology. Discussions from the focus groups revealed that although participants believed that self-driving vehicles can enhance their mobility and independence, they were concerned about their reliability and safety. Participants expressed additional concerns regarding their ability to purchase such a vehicle and the training required to operate it. Opinions were mixed regarding the consideration of older adults in the design of the technology.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'autonomous vehicles, older adults, self-driving vehicles', 'numpages': '10', 'pages': '500–509', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Fully autonomous or ""self-driving"" vehicles are an emerging technology that may hold significant mobility potential for both disabled persons and for older adults unable to operate a conventional motor vehicle. It can be argued, however, that the needs, preferences and concerns of older adults and disabled persons regarding this technology have been insufficiently explored. Using focus group methodology, this study explores the sentiments of 39 older adults (55+) regarding self driving vehicle technology. Discussions from the focus groups revealed that although participants believed that self-driving vehicles can enhance their mobility and independence, they were concerned about their reliability and safety. Participants expressed additional concerns regarding their ability to purchase such a vehicle and the training required to operate it. Opinions were mixed regarding the consideration of older adults in the design of the technology.', 'doi': '10.1145/3308561.3353801', 'url': 'https://doi.org/10.1145/3308561.3353801', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Am I Too Old to Drive? Opinions of Older Adults on Self-Driving Vehicles', 'author': 'Huff, Earl W. and DellaMaria, Natalie and Posadas, Brianna and Brinkley, Julian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3353801'}"
Unlocking Accessible Escape Rooms,10.1145/3308561.3354602,"Escape rooms are popular recreational activities. Players are locked in a room and must solve a series of puzzles in order to 'escape'. To date there has been no research conducted to examine the accessibility of escape rooms for individuals with disabilities. Escape room designers and players completed an online questionnaire exploring the use of technology and the accessibility of escape rooms. Results show that accessibility remains a key challenge in the design and implementation of escape rooms, despite the inclusion of technology that could be used to improve the experience of users with disabilities","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, escape room, player experience, technology', 'numpages': '3', 'pages': '510–512', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Escape rooms are popular recreational activities. Players are locked in a room and must solve a series of puzzles in order to 'escape'. To date there has been no research conducted to examine the accessibility of escape rooms for individuals with disabilities. Escape room designers and players completed an online questionnaire exploring the use of technology and the accessibility of escape rooms. Results show that accessibility remains a key challenge in the design and implementation of escape rooms, despite the inclusion of technology that could be used to improve the experience of users with disabilities"", 'doi': '10.1145/3308561.3354602', 'url': 'https://doi.org/10.1145/3308561.3354602', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Unlocking Accessible Escape Rooms', 'author': 'Menzies, Rachel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354602'}"
"Dueto: Accessible, Gaze-Operated Musical Expression",10.1145/3308561.3354603,"Gaze-tracking technologies can enable computer access for users who are unable to use standard input devices. However, using gaze as input poses challenges for interactions that require visual planning, like playing a digital instrument. We explore how multimodality can support eye-controlled musical expression by designing different multi-modal gaze interactions around a digital instrument we call Dueto. We tackle three design goals: creating an instrument that is explorable, easy to learn, and allows feature controllability. We showcase three different multimodal interactions for music playing such as eye gaze only, gaze + switch, and gaze + partner mode.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, eye tracking, gaze input, motor impairments, multimodal interaction, musical interfaces', 'numpages': '3', 'pages': '513–515', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Gaze-tracking technologies can enable computer access for users who are unable to use standard input devices. However, using gaze as input poses challenges for interactions that require visual planning, like playing a digital instrument. We explore how multimodality can support eye-controlled musical expression by designing different multi-modal gaze interactions around a digital instrument we call Dueto. We tackle three design goals: creating an instrument that is explorable, easy to learn, and allows feature controllability. We showcase three different multimodal interactions for music playing such as eye gaze only, gaze + switch, and gaze + partner mode.', 'doi': '10.1145/3308561.3354603', 'url': 'https://doi.org/10.1145/3308561.3354603', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Dueto: Accessible, Gaze-Operated Musical Expression', 'author': 'Valencia, Stephanie and Lamb, Dwayne and Williams, Shane and Kulkarni, Harish S. and Paradiso, Ann and Ringel Morris, Meredith', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354603'}"
Teacher Perspectives on Math E-Learning Tools for Students with Specific Learning Disabilities,10.1145/3308561.3354607,"Students with specific learning disabilities (SLD) typically struggle in their K-12 math classes, limiting the likelihood of success in STEM fields. Private tutoring is reported to be effective at helping them succeed in math, but it is not a scalable solution. While many recent e-learning tools have aimed at personalizing math support in ways that might be scalable, there remains much to be done. To better understand the gaps between current tools and the particular needs of students with SLD (and of their teachers), we conducted semi-structured interviews with 10 middle school math teachers. Our findings shed light on both the learning challenges faced by students with SLD and on the instructional challenges their teachers experience with e-learning tools. Further, we came to appreciate the importance of harnessing teacher perspectives in the design of effective e-learning tools for special students.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'edtech, learning disabilities, special ed, stem ed', 'numpages': '3', 'pages': '516–518', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Students with specific learning disabilities (SLD) typically struggle in their K-12 math classes, limiting the likelihood of success in STEM fields. Private tutoring is reported to be effective at helping them succeed in math, but it is not a scalable solution. While many recent e-learning tools have aimed at personalizing math support in ways that might be scalable, there remains much to be done. To better understand the gaps between current tools and the particular needs of students with SLD (and of their teachers), we conducted semi-structured interviews with 10 middle school math teachers. Our findings shed light on both the learning challenges faced by students with SLD and on the instructional challenges their teachers experience with e-learning tools. Further, we came to appreciate the importance of harnessing teacher perspectives in the design of effective e-learning tools for special students.', 'doi': '10.1145/3308561.3354607', 'url': 'https://doi.org/10.1145/3308561.3354607', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Teacher Perspectives on Math E-Learning Tools for Students with Specific Learning Disabilities', 'author': 'Wen, Zikai Alex and Amog, Anjelika Lynne S. and Azenkot, Shiri and Garnett, Katherine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354607'}"
Computational Thinking as Play: Experiences of Children who are Blind or Low Vision in India,10.1145/3308561.3354608,"Torino is a tangible programming environment designed for teaching the computational thinking curriculum in the UK to children who are blind or low vision (henceforth, just children) in an inclusive setting. In this paper we describe the experience of children in Bangalore, India, when Torino was introduced to them as a toy for creating and sharing stories, songs and music. We conducted 12 play sessions with 12 children (4 girls and 8 boys) with diverse backgrounds belonging to three different schools for the blind. We briefly present the reasons for play being central to our effort of bringing computational thinking to children who are blind and low vision in India, and share some experiences of the children and some insights that we have gathered so far: Children not only enjoyed every session, they rapidly moved from playing with pre-created examples, to making changes, to demanding that their favorite stories be told. In observing such play, we could infer that they have grasped the basic concepts of computational thinking? flow of control, variables, loops? though not articulated in that vocabulary.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'digital skills, pedagogy, primary school', 'numpages': '4', 'pages': '519–522', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Torino is a tangible programming environment designed for teaching the computational thinking curriculum in the UK to children who are blind or low vision (henceforth, just children) in an inclusive setting. In this paper we describe the experience of children in Bangalore, India, when Torino was introduced to them as a toy for creating and sharing stories, songs and music. We conducted 12 play sessions with 12 children (4 girls and 8 boys) with diverse backgrounds belonging to three different schools for the blind. We briefly present the reasons for play being central to our effort of bringing computational thinking to children who are blind and low vision in India, and share some experiences of the children and some insights that we have gathered so far: Children not only enjoyed every session, they rapidly moved from playing with pre-created examples, to making changes, to demanding that their favorite stories be told. In observing such play, we could infer that they have grasped the basic concepts of computational thinking? flow of control, variables, loops? though not articulated in that vocabulary.', 'doi': '10.1145/3308561.3354608', 'url': 'https://doi.org/10.1145/3308561.3354608', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Computational Thinking as Play: Experiences of Children who are Blind or Low Vision in India', 'author': 'India, Gesu and Ramakrishna, Geetha and Bisht, Jyoti and Swaminathan, Manohar', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354608'}"
Addressing the Stigma of Epilepsy in Saudi Arabia for Co-Design,10.1145/3308561.3354609,"People with epilepsy in Saudi Arabia confront prejudice against their disease, which results in secrecy, misunderstandings, and social exclusion. While there is significant merit in adopting current technologies for individuals with epilepsy and their caregivers to monitor seizure patterns and notify caregivers of epileptic episodes, little effort has been made to address the user requirements of such technologies in relation to stigma-related concerns. This poster describes the preliminary stages of a co-design study that seeks to design a seizure-monitoring and notification device. This stage of the exploratory study addressed several concerns relating to the stigma of epilepsy in the Saudi Arabian community, particularly the visibility of the device and social power. The poster also presents several considerations to be taken into account for the co-design session planned for the future.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'co-design, epilepsy, participatory design, stigma., wearables', 'numpages': '3', 'pages': '523–525', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with epilepsy in Saudi Arabia confront prejudice against their disease, which results in secrecy, misunderstandings, and social exclusion. While there is significant merit in adopting current technologies for individuals with epilepsy and their caregivers to monitor seizure patterns and notify caregivers of epileptic episodes, little effort has been made to address the user requirements of such technologies in relation to stigma-related concerns. This poster describes the preliminary stages of a co-design study that seeks to design a seizure-monitoring and notification device. This stage of the exploratory study addressed several concerns relating to the stigma of epilepsy in the Saudi Arabian community, particularly the visibility of the device and social power. The poster also presents several considerations to be taken into account for the co-design session planned for the future.', 'doi': '10.1145/3308561.3354609', 'url': 'https://doi.org/10.1145/3308561.3354609', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Addressing the Stigma of Epilepsy in Saudi Arabia for Co-Design', 'author': 'Al-Megren, Shiroq and Al-Othman, Shaikha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354609'}"
Weaving Accessibility Through an Undergraduate Degree,10.1145/3308561.3354611,"Globally, increasing numbers of people experience accessibility issues related to technology use. At the University ofDundee, we have developed a degree programme that aims to graduate socially-aware computing scientists who can develop for a range of access needs. To achieve this, we engage our students on a supported pathway of exploration, empathy and understanding. Students collaborate with user groups of older adults, adults with aphasia, and users of Alternative and Augmentative Communication (AAC). This practical experience leads to an understanding of the needs of the end-user and the need to develop for 'people who are not like me'","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, ageing, disabilities, education, empathy', 'numpages': '4', 'pages': '526–529', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Globally, increasing numbers of people experience accessibility issues related to technology use. At the University ofDundee, we have developed a degree programme that aims to graduate socially-aware computing scientists who can develop for a range of access needs. To achieve this, we engage our students on a supported pathway of exploration, empathy and understanding. Students collaborate with user groups of older adults, adults with aphasia, and users of Alternative and Augmentative Communication (AAC). This practical experience leads to an understanding of the needs of the end-user and the need to develop for 'people who are not like me'"", 'doi': '10.1145/3308561.3354611', 'url': 'https://doi.org/10.1145/3308561.3354611', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Weaving Accessibility Through an Undergraduate Degree', 'author': 'Menzies, Rachel and Tigwell, Garreth W. and Tamhane, Mandar and Waller, Annalu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354611'}"
Tactiled: Towards More and Better Tactile Graphics Using Machine Learning,10.1145/3308561.3354613,"Tactile graphics (TG) can help people with visual disabilities access visual concepts. However, the number of TGs available to users is considerably limited because they need to be created by designers and teachers of the visually impaired (TVIs) with extensive experience. High-quality images can be transformed into TGs. In order to increase the availability of TGs, we trained a machine learning (ML) model that identifies suitable and unsuitable images for TG transformation (See Figure 1). This model would help users identify high-quality images that can be transformed into TGs. The poster presents (1) the ML model trained with 800 images collected from the American Printing House tactile Library and the researchers, (2) a web application that lets TVIs retrain the model by feeding new images and helping with the classification. This system can then be used by anyone, especially parents and teachers, as a filter to produce new TGs.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'machine learning, tactile graphics, teachers of the visually impaired', 'numpages': '3', 'pages': '530–532', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tactile graphics (TG) can help people with visual disabilities access visual concepts. However, the number of TGs available to users is considerably limited because they need to be created by designers and teachers of the visually impaired (TVIs) with extensive experience. High-quality images can be transformed into TGs. In order to increase the availability of TGs, we trained a machine learning (ML) model that identifies suitable and unsuitable images for TG transformation (See Figure 1). This model would help users identify high-quality images that can be transformed into TGs. The poster presents (1) the ML model trained with 800 images collected from the American Printing House tactile Library and the researchers, (2) a web application that lets TVIs retrain the model by feeding new images and helping with the classification. This system can then be used by anyone, especially parents and teachers, as a filter to produce new TGs.', 'doi': '10.1145/3308561.3354613', 'url': 'https://doi.org/10.1145/3308561.3354613', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Tactiled: Towards More and Better Tactile Graphics Using Machine Learning', 'author': 'Gonzalez, Ricardo and Gonzalez, Carlos and Guerra-Gomez, John A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354613'}"
Design and Analysis of Interoperable Data Logs for Augmentative Communication Practice,10.1145/3308561.3354614,"mHealth is becoming increasingly data-driven in healthcare professions. Clinicians use a variety of data collection methods to capture the language use and communication performance of clients with complex communication needs. One solution for collecting and analyzing augmentative and alternative communication (AAC) data is through automatic data logging from high-tech AAC devices, also known as speech generating devices (SGDs). However, there is no interoperable method to analyze data logs across various SGDs. To address this, our work presents an interoperable data log format and a parser as a prototype solution. The prototype was used successfully to analyze two common AAC data log formats, and can easily be extended to other formats. This approach has significant potential to improve AAC outcome measurement for individual users, as well as comparison of outcomes across multiple users and devices.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'aac, augmentative and alternative communication, data analysis, ebp, evidence-based practice, outcome measures', 'numpages': '3', 'pages': '533–535', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'mHealth is becoming increasingly data-driven in healthcare professions. Clinicians use a variety of data collection methods to capture the language use and communication performance of clients with complex communication needs. One solution for collecting and analyzing augmentative and alternative communication (AAC) data is through automatic data logging from high-tech AAC devices, also known as speech generating devices (SGDs). However, there is no interoperable method to analyze data logs across various SGDs. To address this, our work presents an interoperable data log format and a parser as a prototype solution. The prototype was used successfully to analyze two common AAC data log formats, and can easily be extended to other formats. This approach has significant potential to improve AAC outcome measurement for individual users, as well as comparison of outcomes across multiple users and devices.', 'doi': '10.1145/3308561.3354614', 'url': 'https://doi.org/10.1145/3308561.3354614', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Design and Analysis of Interoperable Data Logs for Augmentative Communication Practice', 'author': 'Chen, Szu-Han Kay and Wadhwa, Soumya and Nyberg, Eric', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354614'}"
Tactile Code Skimmer: A Tool to Help Blind Programmers Feel the Structure of Code,10.1145/3308561.3354616,"Skimming new code with a screen reader can be a time-consuming task for blind and visually impaired programmers. Screen readers aid with code navigation, but dictate code line-by-line and read spaces and tabs individually. This often provides more information than is needed. In this work, we present the Tactile Code Skimmer (TCS), a tool to aid blind and visually impaired programmers with skimming code. The device physically reflects the indentation levels of code with actuated slide potentiometers, thus helping reduce the ""hearing load"" that often accompanies screen readers. We describe the TCS design and implementation. Based on feedback from participants obtained through demos and an in-depth session, we discuss some considerations for tactile tools that aid with code skimming.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blind programmers, code structure, tactile aids, visually impaired', 'numpages': '3', 'pages': '536–538', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Skimming new code with a screen reader can be a time-consuming task for blind and visually impaired programmers. Screen readers aid with code navigation, but dictate code line-by-line and read spaces and tabs individually. This often provides more information than is needed. In this work, we present the Tactile Code Skimmer (TCS), a tool to aid blind and visually impaired programmers with skimming code. The device physically reflects the indentation levels of code with actuated slide potentiometers, thus helping reduce the ""hearing load"" that often accompanies screen readers. We describe the TCS design and implementation. Based on feedback from participants obtained through demos and an in-depth session, we discuss some considerations for tactile tools that aid with code skimming.', 'doi': '10.1145/3308561.3354616', 'url': 'https://doi.org/10.1145/3308561.3354616', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Tactile Code Skimmer: A Tool to Help Blind Programmers Feel the Structure of Code', 'author': 'Falase, Olutayo and Siu, Alexa F. and Follmer, Sean', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354616'}"
Towards a Standardized Grammar for Navigation Systems for Persons with Visual Impairments,10.1145/3308561.3354618,"Pedestrian navigation systems are rarely accessible or suit the needs of persons with visual impairments. They usually lack a standardized grammar for their speech instructions, forcing users to learn new types of instructions for each new system. Thus, we propose (1) a German grammar with syntax rules and vocabulary for mobile pedestrian navigation systems that take into account the special requirements of people with visual impairments. (2) a set of rules for specifying what should be spoken and when, given GPS accuracy in a city [18]. We describe (3) the methodology used to obtain the grammar as well as (4) a qualitative evaluation with orientation and mobility experts and with people with visual impairments who deployed our grammar during a user study. Our approach is the first of its kind, as there is no such grammar neither for German nor for English, as far as we know. It serves as a contribution to standardize pedestrian navigation speech instructions for people with visual impairments.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'german language, grammar, mobile pedestrian navigation, syntax, visual impairments', 'numpages': '3', 'pages': '539–541', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Pedestrian navigation systems are rarely accessible or suit the needs of persons with visual impairments. They usually lack a standardized grammar for their speech instructions, forcing users to learn new types of instructions for each new system. Thus, we propose (1) a German grammar with syntax rules and vocabulary for mobile pedestrian navigation systems that take into account the special requirements of people with visual impairments. (2) a set of rules for specifying what should be spoken and when, given GPS accuracy in a city [18]. We describe (3) the methodology used to obtain the grammar as well as (4) a qualitative evaluation with orientation and mobility experts and with people with visual impairments who deployed our grammar during a user study. Our approach is the first of its kind, as there is no such grammar neither for German nor for English, as far as we know. It serves as a contribution to standardize pedestrian navigation speech instructions for people with visual impairments.', 'doi': '10.1145/3308561.3354618', 'url': 'https://doi.org/10.1145/3308561.3354618', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Towards a Standardized Grammar for Navigation Systems for Persons with Visual Impairments', 'author': 'Constantinescu, Angela and Petrausch, Vanessa and M\\""{u}ller, Karin and Stiefelhagen, Rainer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354618'}"
CityGuide: A Seamless Indoor-Outdoor Wayfinding System for People With Vision Impairments,10.1145/3308561.3354621,"GPS accuracy is poor in indoor environments and around buildings. Thus, reading and following signs still remains the most common mechanism for providing and receiving wayfinding information in such spaces. This puts individuals who are blind or visually impaired (BVI) at a great disadvantage. This work designs, implements, and evaluates a wayfinding system and smartphone application called CityGuide that can be used by BVI individuals to navigate their surroundings beyond what is possible with just a GPS-based system. CityGuide enables an individual to query and get turn-by-turn shortest route directions from an indoor location to an outdoor location. CityGuide leverages recently developed indoor wayfinding solutions in conjunction with GPS signals to provide a seamless indoor-outdoor navigation and wayfinding system that guides a BVI individual to their desired destination through the shortest route. Evaluations of CityGuide with BVI human subjects navigating between an indoor starting point to an outdoor destination within an unfamiliar university campus scenario showed it to be effective in reducing end-to-end navigation times and distances of almost all participants.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, navigation and wayfinding, vision impairments', 'numpages': '3', 'pages': '542–544', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'GPS accuracy is poor in indoor environments and around buildings. Thus, reading and following signs still remains the most common mechanism for providing and receiving wayfinding information in such spaces. This puts individuals who are blind or visually impaired (BVI) at a great disadvantage. This work designs, implements, and evaluates a wayfinding system and smartphone application called CityGuide that can be used by BVI individuals to navigate their surroundings beyond what is possible with just a GPS-based system. CityGuide enables an individual to query and get turn-by-turn shortest route directions from an indoor location to an outdoor location. CityGuide leverages recently developed indoor wayfinding solutions in conjunction with GPS signals to provide a seamless indoor-outdoor navigation and wayfinding system that guides a BVI individual to their desired destination through the shortest route. Evaluations of CityGuide with BVI human subjects navigating between an indoor starting point to an outdoor destination within an unfamiliar university campus scenario showed it to be effective in reducing end-to-end navigation times and distances of almost all participants.', 'doi': '10.1145/3308561.3354621', 'url': 'https://doi.org/10.1145/3308561.3354621', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'CityGuide: A Seamless Indoor-Outdoor Wayfinding System for People With Vision Impairments', 'author': 'Cheraghi, Seyed Ali and Almadan, Ali and Namboodiri, Vinod', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354621'}"
Simulation of Motor Impairment with,10.1145/3308561.3354623,"Testing software with individuals who have differing abili­ ties such as motor impairments allows developers to create more accessible applications. Unfortunately, these individuals are not always available to assist with research or software development testing. To help address this issue, we propose a system which simulates the difficulties demonstrated by a motor-impaired user interacting with a head-controlled mouse pointer system. Through an evaluation using a Fitts' law ex­ periment, we compare the throughput rate in bits per second and percent error rate of our system between users with and without motor impairments.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': ""accessibility, angle mouse, camera mouse, fitts' law, head-controlled mouse pointer, motor impairments, simulation"", 'numpages': '3', 'pages': '545–547', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Testing software with individuals who have differing abili\xad ties such as motor impairments allows developers to create more accessible applications. Unfortunately, these individuals are not always available to assist with research or software development testing. To help address this issue, we propose a system which simulates the difficulties demonstrated by a motor-impaired user interacting with a head-controlled mouse pointer system. Through an evaluation using a Fitts' law ex\xad periment, we compare the throughput rate in bits per second and percent error rate of our system between users with and without motor impairments."", 'doi': '10.1145/3308561.3354623', 'url': 'https://doi.org/10.1145/3308561.3354623', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Simulation of Motor Impairment with', 'author': 'Papy, Mariah and Calder, Duncan and Dang, Ngu and McLaughlin, Aidan and Desrochers, Breanna and Magee, John', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354623'}"
Dynamic Sensor Orientation Unit for the Intelligent Mobility Cane,10.1145/3308561.3354627,"Numerous studies have been conducted to improve the features of the ""smart"" canes. However, there is insufficient research performed to develop the guidelines to create a usable smart cane. In this paper, a Dynamic Sensor Orientation Unit (DSOU) is introduced to maintain a detection distance irrespective of the angle of the cane. The paper also aims to outline guidelines for placement of the Obstacle Detection System (ODS) and the sensor angle to be used in our Intelligent Mobility Cane (IMC) prototypes. A usability test with 11 people who use a white cane for daily navigation was conducted to study the users' preference and behavior with a fixed sensor angle IMC. The analysis revealed the angle of the sensor is dependent on the participant's height and how users hold the canes. The results suggest requirements for sensor angle orientation and outline guidelines for ODS designs on future IMCs.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, dynamic orientation, intelligent mobility cane, sensor angle, smartcane, ultrasonic sensors, visually impaired', 'numpages': '3', 'pages': '548–550', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Numerous studies have been conducted to improve the features of the ""smart"" canes. However, there is insufficient research performed to develop the guidelines to create a usable smart cane. In this paper, a Dynamic Sensor Orientation Unit (DSOU) is introduced to maintain a detection distance irrespective of the angle of the cane. The paper also aims to outline guidelines for placement of the Obstacle Detection System (ODS) and the sensor angle to be used in our Intelligent Mobility Cane (IMC) prototypes. A usability test with 11 people who use a white cane for daily navigation was conducted to study the users\' preference and behavior with a fixed sensor angle IMC. The analysis revealed the angle of the sensor is dependent on the participant\'s height and how users hold the canes. The results suggest requirements for sensor angle orientation and outline guidelines for ODS designs on future IMCs.', 'doi': '10.1145/3308561.3354627', 'url': 'https://doi.org/10.1145/3308561.3354627', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Dynamic Sensor Orientation Unit for the Intelligent Mobility Cane', 'author': 'Suresh, Manu and Pariti, Jagannadh and Oh, Tae', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354627'}"
Twitter A11y: A Browser Extension to Describe Images,10.1145/3308561.3354629,"Twitter is integral to many people's lives for news, entertainment, and communication. While people increasingly post images to Twitter, a large majority of images remain inaccessible to people with vision impairments due to a lack of image descriptions (i.e. alternative text). We present Twitter A11y (pronounced ally), a browser extension to make images accessible through a set of strategies tailored to the platform. For example, screenshots of text that exceed the Twitter character limit are common, so we detect textual images, and automatically add alternative text using optical character recognition. Tweet images apart from screenshots and link previews receive descriptions from crowd workers. Based on an evaluation of the timelines of 50 self-identified blind Twitter users, Twitter A11y increases automatic alt text coverage from 2.6\% to 25.6\%, before crowdsourcing the remaining images.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, screen reader, social media, twitter', 'numpages': '3', 'pages': '551–553', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Twitter is integral to many people's lives for news, entertainment, and communication. While people increasingly post images to Twitter, a large majority of images remain inaccessible to people with vision impairments due to a lack of image descriptions (i.e. alternative text). We present Twitter A11y (pronounced ally), a browser extension to make images accessible through a set of strategies tailored to the platform. For example, screenshots of text that exceed the Twitter character limit are common, so we detect textual images, and automatically add alternative text using optical character recognition. Tweet images apart from screenshots and link previews receive descriptions from crowd workers. Based on an evaluation of the timelines of 50 self-identified blind Twitter users, Twitter A11y increases automatic alt text coverage from 2.6\\% to 25.6\\%, before crowdsourcing the remaining images."", 'doi': '10.1145/3308561.3354629', 'url': 'https://doi.org/10.1145/3308561.3354629', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Twitter A11y: A Browser Extension to Describe Images', 'author': 'Low, Christina and McCamey, Emma and Gleason, Cole and Carrington, Patrick and Bigham, Jeffrey P. and Pavel, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354629'}"
Using Modules to Teach Accessibility in a User-Centered Design Course,10.1145/3308561.3354632,"Courses in user-centered design, where students learn about centering design on the needs of individuals, is one natural point in which accessibility content can be injected into the curriculum. We describe the approach we have taken with sections in the undergraduate User-Centered Design Course at the University of Maryland, College Park. We initially introduced disability and accessibility in four modules: 1) websites and design portfolios, 2) introduction to understanding user needs, 3) prototyping, and 4) UX evaluation. We present a description of this content that was taught as an extended version in one Fall 2018 section and as an abbreviated version in all sections in Spring 2019. Survey results indicate that students' understanding of accessibility and assistive technology increased with the introduction of these modules.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'course design, curricula, user centered design', 'numpages': '3', 'pages': '554–556', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Courses in user-centered design, where students learn about centering design on the needs of individuals, is one natural point in which accessibility content can be injected into the curriculum. We describe the approach we have taken with sections in the undergraduate User-Centered Design Course at the University of Maryland, College Park. We initially introduced disability and accessibility in four modules: 1) websites and design portfolios, 2) introduction to understanding user needs, 3) prototyping, and 4) UX evaluation. We present a description of this content that was taught as an extended version in one Fall 2018 section and as an abbreviated version in all sections in Spring 2019. Survey results indicate that students' understanding of accessibility and assistive technology increased with the introduction of these modules."", 'doi': '10.1145/3308561.3354632', 'url': 'https://doi.org/10.1145/3308561.3354632', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Using Modules to Teach Accessibility in a User-Centered Design Course', 'author': 'Lazar, Amanda and Lazar, Jonathan and Pradhan, Alisha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354632'}"
Gauging Interest in Digital Personalized Simulations of Hearing Loss For Parents of DHH Children,10.1145/3308561.3354634,"It can be difficult for parents to understand how their children perceive the world, especially when they have different sensory capabilities (e.g., hearing loss). Personalized simulations of other sensory impairments have been shown to improve understanding, so digital personalized simulations of hearing loss might improve understanding for hearing parents of d/Deaf and hard of hearing (DHH) children, but only if there is demand for it. We surveyed six hearing parents of DHH children to assess factors that might influence this demand, as well as the base demand itself. We found that there is indeed demand, even in the presence of two potentially confounding factors (parent hope for regained hearing and high parent empathy).","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'deaf and hard-of-hearing, hearing loss, simulation', 'numpages': '3', 'pages': '557–559', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'It can be difficult for parents to understand how their children perceive the world, especially when they have different sensory capabilities (e.g., hearing loss). Personalized simulations of other sensory impairments have been shown to improve understanding, so digital personalized simulations of hearing loss might improve understanding for hearing parents of d/Deaf and hard of hearing (DHH) children, but only if there is demand for it. We surveyed six hearing parents of DHH children to assess factors that might influence this demand, as well as the base demand itself. We found that there is indeed demand, even in the presence of two potentially confounding factors (parent hope for regained hearing and high parent empathy).', 'doi': '10.1145/3308561.3354634', 'url': 'https://doi.org/10.1145/3308561.3354634', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Gauging Interest in Digital Personalized Simulations of Hearing Loss For Parents of DHH Children', 'author': ""Heyko, Dar'ya and Flatla, David R."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354634'}"
Strength-Based ICT Design Supporting Individuals with Autism,10.1145/3308561.3354637,"While sociocommunicative behaviors of the autistic population are frequently pathologized, the researchers find evidence supporting strength-based (SB) approaches which utilize the natural talents, strengths, interests and communication styles of individuals with autism, resulting in higher degrees of well-being. Information and Communication Technologies (ICTs) founded in SB approaches are visually designed, simple to use, and are also complex in functionality. Because of the heterogeneity of individuals with autism, personalization and customization are key features for applications to be accessible to a wide variety of user-experiences and needs. By using natural autistic communication-orientation and design preferences, it is possible that learned skills will become more generalizable and that other outcome types will be encouraged. As a key feature of SB approaches, ICT development must incorporate and collaborate with the autistic community these technologies seek to support.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'autism spectrum disorder, information and communication technology, strengths, talents, user-centered design', 'numpages': '3', 'pages': '560–562', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'While sociocommunicative behaviors of the autistic population are frequently pathologized, the researchers find evidence supporting strength-based (SB) approaches which utilize the natural talents, strengths, interests and communication styles of individuals with autism, resulting in higher degrees of well-being. Information and Communication Technologies (ICTs) founded in SB approaches are visually designed, simple to use, and are also complex in functionality. Because of the heterogeneity of individuals with autism, personalization and customization are key features for applications to be accessible to a wide variety of user-experiences and needs. By using natural autistic communication-orientation and design preferences, it is possible that learned skills will become more generalizable and that other outcome types will be encouraged. As a key feature of SB approaches, ICT development must incorporate and collaborate with the autistic community these technologies seek to support.', 'doi': '10.1145/3308561.3354637', 'url': 'https://doi.org/10.1145/3308561.3354637', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Strength-Based ICT Design Supporting Individuals with Autism', 'author': 'Navedo, Jessica and Espiritu-Santo, Amelia and Ahmed, Shameem', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354637'}"
Motor Accessibility of Smartwatch Touch and Bezel Input,10.1145/3308561.3354638,"Smartwatches present inherent input difficulties due to the small touchscreen. In a controlled experiment with 14 participants with upper body motor impairments, we compared smartwatch touchscreen input to input on the bezel of the watch, the latter of which should at least theoretically stabilize user input due to its hard edge. Results demonstrate a speed-accuracy tradeoff whereby the touchscreen is faster but the bezel is more accurate.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, motor impairment, smartwatch, touchscreen', 'numpages': '3', 'pages': '563–565', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Smartwatches present inherent input difficulties due to the small touchscreen. In a controlled experiment with 14 participants with upper body motor impairments, we compared smartwatch touchscreen input to input on the bezel of the watch, the latter of which should at least theoretically stabilize user input due to its hard edge. Results demonstrate a speed-accuracy tradeoff whereby the touchscreen is faster but the bezel is more accurate.', 'doi': '10.1145/3308561.3354638', 'url': 'https://doi.org/10.1145/3308561.3354638', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Motor Accessibility of Smartwatch Touch and Bezel Input', 'author': 'Malu, Meethu and Chundury, Pramod and Findlater, Leah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354638'}"
CBConv: Service for Automatic Conversion of Chinese Characters into Braille with High Accuracy,10.1145/3308561.3354639,"The conversion of Chinese Characters into Braille faces the challenges of Braille word segmentation, pronunciation determination, and tone marking. In this paper, we present the CBConv service for automatic conversion of Chinese characters into Braille with high accuracy. The service supports two modes: real-time conversion of Chinese strings and asynchronous conversion of documents. To address the challenges described above, an end-to-end deep learning framework is proposed, which can perform pronunciation determination, word segmentation and tone marking simultaneously using a deep neural network. Accuracy evaluation and user study are conducted, which demonstrate the usability of the proposed system.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'automatic conversion, chinese braille, deep learning, rnn', 'numpages': '3', 'pages': '566–568', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The conversion of Chinese Characters into Braille faces the challenges of Braille word segmentation, pronunciation determination, and tone marking. In this paper, we present the CBConv service for automatic conversion of Chinese characters into Braille with high accuracy. The service supports two modes: real-time conversion of Chinese strings and asynchronous conversion of documents. To address the challenges described above, an end-to-end deep learning framework is proposed, which can perform pronunciation determination, word segmentation and tone marking simultaneously using a deep neural network. Accuracy evaluation and user study are conducted, which demonstrate the usability of the proposed system.', 'doi': '10.1145/3308561.3354639', 'url': 'https://doi.org/10.1145/3308561.3354639', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'CBConv: Service for Automatic Conversion of Chinese Characters into Braille with High Accuracy', 'author': 'Wang, Xiangdong and Zhong, Jinghua and Cai, Jia and Liu, Hong and Qian, Yueliang', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354639'}"
A Classroom Accessibility Analysis App for Deaf Students,10.1145/3308561.3354640,"Deaf and hard of hearing (DHH) individuals do not have equal access to audio information in most educational settings, even with visual translation accommodations such as sign language interpreters or captioners. As a result, their learning and retention rates lag behind in comparison with their hearing peers. Research shows DHH individuals lose lecture information due to two main factors largely unaddressed by the traditional accommodations: 1) increased cognitive load associated with processing the visual translation of audio simultaneously with other visual information sources, and 2) visual attention limits associated with viewing layouts that have widely dispersed visuals that may be far away or at awkward viewing angles. We discuss the impact of architectural visuals on the DHH student, accommodation team and discuss an automatic measure of a simple accessibility app and scale using face and body identification from a 360-degree video snapshot.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'american sign language (asl), deaf, design', 'numpages': '3', 'pages': '569–571', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Deaf and hard of hearing (DHH) individuals do not have equal access to audio information in most educational settings, even with visual translation accommodations such as sign language interpreters or captioners. As a result, their learning and retention rates lag behind in comparison with their hearing peers. Research shows DHH individuals lose lecture information due to two main factors largely unaddressed by the traditional accommodations: 1) increased cognitive load associated with processing the visual translation of audio simultaneously with other visual information sources, and 2) visual attention limits associated with viewing layouts that have widely dispersed visuals that may be far away or at awkward viewing angles. We discuss the impact of architectural visuals on the DHH student, accommodation team and discuss an automatic measure of a simple accessibility app and scale using face and body identification from a 360-degree video snapshot.', 'doi': '10.1145/3308561.3354640', 'url': 'https://doi.org/10.1145/3308561.3354640', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Classroom Accessibility Analysis App for Deaf Students', 'author': 'Kushalnagar, Raja', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354640'}"
DanceCraft: A Whole-body Interactive System for Children with Autism,10.1145/3308561.3354604,"Children with autism often have sensory processing differences that can lead to a myriad of challenges, including difficulty with awareness of how their bodies occupy physical space. Natural User Interfaces (NUI) can help augment therapies to support these children. We developed DanceCraft, a whole-body interface to augment dance therapy for children with autism. In a pilot study, we deployed DanceCraft to nine homes for one week for children with autism to use. We received feedback on both the system's central activity (dance), as well as elements of its design and set up, offering lessons to guide future field deployments of such systems.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, autism, children, dance, disability, therapy, whole-body interfaces', 'numpages': '3', 'pages': '572–574', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Children with autism often have sensory processing differences that can lead to a myriad of challenges, including difficulty with awareness of how their bodies occupy physical space. Natural User Interfaces (NUI) can help augment therapies to support these children. We developed DanceCraft, a whole-body interface to augment dance therapy for children with autism. In a pilot study, we deployed DanceCraft to nine homes for one week for children with autism to use. We received feedback on both the system's central activity (dance), as well as elements of its design and set up, offering lessons to guide future field deployments of such systems."", 'doi': '10.1145/3308561.3354604', 'url': 'https://doi.org/10.1145/3308561.3354604', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'DanceCraft: A Whole-body Interactive System for Children with Autism', 'author': 'Ringland, Kathryn E. and Wolf, Christine T. and Boyd, LouAnne and Brown, Jamie K. and Palermo, Andrew and Lakes, Kimberley and Hayes, Gillian R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354604'}"
Voice Assistant Strategies and Opportunities for People with Tetraplegia,10.1145/3308561.3354605,"To help both designers and people with tetraplegia fully realize the benefts of voice assistant technology, we conducted interviews with fve people with tetraplegia in the home to understand how this population currently uses voice-based interfaces as well as other technologies in their everyday tasks. We found that people with tetraplegia use voice assistants in specifc places, such as in their beds, or when traveling in their wheelchair. In addition, we note the inefciencies for people with tetraplegia when using voice assistance.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive technology, design research, tetraplegia, voice agents, voice user interfaces', 'numpages': '3', 'pages': '575–577', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'To help both designers and people with tetraplegia fully realize the benefts of voice assistant technology, we conducted interviews with fve people with tetraplegia in the home to understand how this population currently uses voice-based interfaces as well as other technologies in their everyday tasks. We found that people with tetraplegia use voice assistants in specifc places, such as in their beds, or when traveling in their wheelchair. In addition, we note the inefciencies for people with tetraplegia when using voice assistance.', 'doi': '10.1145/3308561.3354605', 'url': 'https://doi.org/10.1145/3308561.3354605', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Voice Assistant Strategies and Opportunities for People with Tetraplegia', 'author': 'Friedman, Natalie and Cuadra, Andrea and Patel, Ruchi and Azenkot, Shiri and Stein, Joel and Ju, Wendy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354605'}"
Evaluating Automatic Speech Recognition for Child Speech Therapy Applications,10.1145/3308561.3354606,"Automatic speech recognition (ASR) technology can be a useful tool in mobile apps for child speech therapy, empowering children to complete their practice with limited caregiver supervision. However, little is known about the feasibility of performing ASR on mobile devices, particularly when training data is limited. In this study, we investigated the performance of two low-resource ASR systems on disordered speech from children. We compared the open-source PocketSphinx (PS) recognizer using adapted acoustic models and a custom template-matching (TM) recognizer. TM and the adapted models significantly out-perform the default PS model. On average, maximum likelihood linear regression and maximum a posteriori adaptation increased PS accuracy from 59.4\% to 63.8\% and 80.0\%, respectively, suggesting that the models successfully captured speaker-specific word production variations. TM reached a mean accuracy of 75.8\%","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive technology, computer-assisted pronunciation training (capt)', 'numpages': '3', 'pages': '578–580', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Automatic speech recognition (ASR) technology can be a useful tool in mobile apps for child speech therapy, empowering children to complete their practice with limited caregiver supervision. However, little is known about the feasibility of performing ASR on mobile devices, particularly when training data is limited. In this study, we investigated the performance of two low-resource ASR systems on disordered speech from children. We compared the open-source PocketSphinx (PS) recognizer using adapted acoustic models and a custom template-matching (TM) recognizer. TM and the adapted models significantly out-perform the default PS model. On average, maximum likelihood linear regression and maximum a posteriori adaptation increased PS accuracy from 59.4\\% to 63.8\\% and 80.0\\%, respectively, suggesting that the models successfully captured speaker-specific word production variations. TM reached a mean accuracy of 75.8\\%', 'doi': '10.1145/3308561.3354606', 'url': 'https://doi.org/10.1145/3308561.3354606', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Evaluating Automatic Speech Recognition for Child Speech Therapy Applications', 'author': 'Hair, Adam and Ballard, Kirrie J. and Ahmed, Beena and Gutierrez-Osuna, Ricardo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354606'}"
Designing Tactile Schematics: Improving Electronic Circuit Accessibility,10.1145/3308561.3354610,"Schematics are a visual language used to describe the relationships between components in an electronic circuit and present accessibility challenges for blind, low vision, and tactile learners. Creating discernible tactile schematics using low-cost microcapsule fusers (which create raised surfaces on paper) is non-trivial as circuit diagrams contain small elements, complex relationships, and must follow industry standards. We conducted iterative design activities with tactile graphic experts, blind and low vision students wanting to learn schematics, graphic designers, and physical computing instructors to create an improved set of tactile schematic symbols and nine guidelines for novices to create readable tactile graphics for schematics.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, electronic circuits, human-centered design, schematics, tactile graphics', 'numpages': '3', 'pages': '581–583', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Schematics are a visual language used to describe the relationships between components in an electronic circuit and present accessibility challenges for blind, low vision, and tactile learners. Creating discernible tactile schematics using low-cost microcapsule fusers (which create raised surfaces on paper) is non-trivial as circuit diagrams contain small elements, complex relationships, and must follow industry standards. We conducted iterative design activities with tactile graphic experts, blind and low vision students wanting to learn schematics, graphic designers, and physical computing instructors to create an improved set of tactile schematic symbols and nine guidelines for novices to create readable tactile graphics for schematics.', 'doi': '10.1145/3308561.3354610', 'url': 'https://doi.org/10.1145/3308561.3354610', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Designing Tactile Schematics: Improving Electronic Circuit Accessibility', 'author': 'Race, Lauren and Fleet, Chancey and Miele, Joshua A. and Igoe, Tom and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354610'}"
30 Years Later: Has CVD Research Changed the World?,10.1145/3308561.3354612,"It is arguable that academics working in accessibility want to improve lives. Last year marked 30 years since the first accessible computing publication [46] on supporting people with Color Vision Deficiency (CVD - commonly called colorblindness), making it a great time to review the CVD academic research that has been completed since then and assess its broad availability to the general population. In this paper, we identify seven central themes in the CVD academic literature, and employ a novel technique (PDI - Persona Driven Inquiry) to explore if and how that literature is available to the general public. Subject to some limitations, we found that this research is indeed available.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'color vision deficiency, persona driven inquiry', 'numpages': '7', 'pages': '584–590', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'It is arguable that academics working in accessibility want to improve lives. Last year marked 30 years since the first accessible computing publication [46] on supporting people with Color Vision Deficiency (CVD - commonly called colorblindness), making it a great time to review the CVD academic research that has been completed since then and assess its broad availability to the general population. In this paper, we identify seven central themes in the CVD academic literature, and employ a novel technique (PDI - Persona Driven Inquiry) to explore if and how that literature is available to the general public. Subject to some limitations, we found that this research is indeed available.', 'doi': '10.1145/3308561.3354612', 'url': 'https://doi.org/10.1145/3308561.3354612', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': '30 Years Later: Has CVD Research Changed the World?', 'author': 'Li, Wanda and Flatla, David R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354612'}"
Just Ask Me: Comparing Older and Younger Individuals' Knowledge of Their Optimal Touchscreen Target Sizes,10.1145/3308561.3354615,"To understand whether people can identify their optimal touchscreen target sizes, we asked older and younger adults to identify optimal target sizes on a questionnaire and compared these chosen sizes to performance on a target acquisition task. We found that older individuals (60+) were better than younger adults at choosing their optimal target sizes. In fact, younger adults underestimated the smallest target size they could accurately touch by almost 6mm. This study suggests that older adults may be able to better configure target size settings than younger adults.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility settings, older adults, questionnaire', 'numpages': '3', 'pages': '591–593', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'To understand whether people can identify their optimal touchscreen target sizes, we asked older and younger adults to identify optimal target sizes on a questionnaire and compared these chosen sizes to performance on a target acquisition task. We found that older individuals (60+) were better than younger adults at choosing their optimal target sizes. In fact, younger adults underestimated the smallest target size they could accurately touch by almost 6mm. This study suggests that older adults may be able to better configure target size settings than younger adults.', 'doi': '10.1145/3308561.3354615', 'url': 'https://doi.org/10.1145/3308561.3354615', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': ""Just Ask Me: Comparing Older and Younger Individuals' Knowledge of Their Optimal Touchscreen Target Sizes"", 'author': 'Franz, Rachel L. and Findlater, Leah and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354615'}"
A Closer Look: Multi-Sensory Accessible Art Translations,10.1145/3308561.3354617,"Providing people who are blind or have low vision with accessible versions of artworks is important not just for equity, but also for inclusion, greater engagement with the community at large, and raising awareness about these issues. In 2018, a value-sensitive design methodology was used with the Bendigo Art Gallery and key stakeholders to develop a model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As a pilot implementation of the model, we developed different tactile representations of key artworks using tactile graphics, laser-cut layered graphics, 3D printed models, soundscapes, role plays, and a website featuring information and representations requested by workshop participants. To highlight the work, this paper will present two of the key works in more detail to highlight different representations that should be considered when presenting accessible artworks.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': '3d printing, accessibility, art, blindness, low vision', 'numpages': '3', 'pages': '594–596', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Providing people who are blind or have low vision with accessible versions of artworks is important not just for equity, but also for inclusion, greater engagement with the community at large, and raising awareness about these issues. In 2018, a value-sensitive design methodology was used with the Bendigo Art Gallery and key stakeholders to develop a model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As a pilot implementation of the model, we developed different tactile representations of key artworks using tactile graphics, laser-cut layered graphics, 3D printed models, soundscapes, role plays, and a website featuring information and representations requested by workshop participants. To highlight the work, this paper will present two of the key works in more detail to highlight different representations that should be considered when presenting accessible artworks.', 'doi': '10.1145/3308561.3354617', 'url': 'https://doi.org/10.1145/3308561.3354617', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Closer Look: Multi-Sensory Accessible Art Translations', 'author': 'Butler, Matthew and Holloway, Leona and Marriott, Kim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354617'}"
Building Capacity: eTextile Tactile Storybook Workshops,10.1145/3308561.3354619,"The first step to literacy is engagement with books and the printed word. This is even more important for children who are blind or have severe low vision, as active touch is required for exposure to meaning through tactile books. ETextiles offer an affordable and innovative method for enhancing tactile book pages with sensory inputs and interaction to encourage engagement. We explored the training requirements for people to incorporate eTextiles into tactile story books, even without prior experience or skills. Through the process of creating sample materials and training adults and children at public workshops, we developed a set of guiding principles for facilitating workshops on creating tactile story books with eTextiles to encourage tactile engagement in children with vision impairments.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blind, children, etextiles, interaction, tactile, vision impairment, workshops', 'numpages': '3', 'pages': '597–599', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The first step to literacy is engagement with books and the printed word. This is even more important for children who are blind or have severe low vision, as active touch is required for exposure to meaning through tactile books. ETextiles offer an affordable and innovative method for enhancing tactile book pages with sensory inputs and interaction to encourage engagement. We explored the training requirements for people to incorporate eTextiles into tactile story books, even without prior experience or skills. Through the process of creating sample materials and training adults and children at public workshops, we developed a set of guiding principles for facilitating workshops on creating tactile story books with eTextiles to encourage tactile engagement in children with vision impairments.', 'doi': '10.1145/3308561.3354619', 'url': 'https://doi.org/10.1145/3308561.3354619', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Building Capacity: eTextile Tactile Storybook Workshops', 'author': 'Holloway, Leona and Ellis, Kirsten and Curtin, Louise', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354619'}"
Supporting Object-level Exploration of Artworks by Touch for People with Visual Impairments,10.1145/3308561.3354620,"One of the reasons that people with visual impairments have difficulties in enjoying artworks is the limited number of accessible artworks. To enable people with visual impairments to explore and understand various artworks independently, we built a touchscreen-based mobile application as a prototype focusing on 2D paintings which plays object-level verbal descriptions upon users' touch. To confirm the needs and to collect initial feedback from potential users of such a system, we conducted an exploratory study with 8 participants with visual impairments using the prototype as a design probe. Overall, participants appreciated the prototype as they can learn artworks with less physical and time constraints while listening for details of contents as they explore each painting by touch.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'art paintings, explore-by-touch, image understanding, visual impairment', 'numpages': '3', 'pages': '600–602', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""One of the reasons that people with visual impairments have difficulties in enjoying artworks is the limited number of accessible artworks. To enable people with visual impairments to explore and understand various artworks independently, we built a touchscreen-based mobile application as a prototype focusing on 2D paintings which plays object-level verbal descriptions upon users' touch. To confirm the needs and to collect initial feedback from potential users of such a system, we conducted an exploratory study with 8 participants with visual impairments using the prototype as a design probe. Overall, participants appreciated the prototype as they can learn artworks with less physical and time constraints while listening for details of contents as they explore each painting by touch."", 'doi': '10.1145/3308561.3354620', 'url': 'https://doi.org/10.1145/3308561.3354620', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Supporting Object-level Exploration of Artworks by Touch for People with Visual Impairments', 'author': 'Kwon, Nahyun and Koh, Youngji and Oh, Uran', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354620'}"
Evaluation of Why Individuals with ADHD Struggle to Find Effective Digital Time Management Tools,10.1145/3308561.3354622,"After a long history of being viewed as a children's disorder, it is now recognized that Attention-Deficit/Hyperactivity Disorder (ADHD) can affect adults as well. Individuals with ADHD often exhibit work habits significantly different from neurotypical individuals. This paper investigates the use of time management tools among adults with ADHD with the goal of determining where there may be room for improvement in current digital tools so that they may better assist our target demographic. We present findings from a survey of adults with and without ADHD. Our findings indicate dissatisfaction among ADHD adults with the tools currently available to them and highlight key areas for potential development.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'adhd, assistive technology, attention-deficit/hyperactivity disorder, organization, survey, time management', 'numpages': '3', 'pages': '603–605', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""After a long history of being viewed as a children's disorder, it is now recognized that Attention-Deficit/Hyperactivity Disorder (ADHD) can affect adults as well. Individuals with ADHD often exhibit work habits significantly different from neurotypical individuals. This paper investigates the use of time management tools among adults with ADHD with the goal of determining where there may be room for improvement in current digital tools so that they may better assist our target demographic. We present findings from a survey of adults with and without ADHD. Our findings indicate dissatisfaction among ADHD adults with the tools currently available to them and highlight key areas for potential development."", 'doi': '10.1145/3308561.3354622', 'url': 'https://doi.org/10.1145/3308561.3354622', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Evaluation of Why Individuals with ADHD Struggle to Find Effective Digital Time Management Tools', 'author': 'Desrochers, Breanna and Tuson, Ella and Magee, John', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354622'}"
Syncing Pre-Recorded Audio Description to a Live Musical Theater Performance Using a Reference Audio Recording,10.1145/3308561.3354624,"Audio description, an accessibility service used by blind or visually impaired individuals, provides spoken descriptions of visual content. This accommodation allows those with low or no vision the ability to access information that sighted people obtain visually. A method for deploying pre-recorded audio description in a live musical theater environment is presented here. This method uses a reference audio recording and an online time warping algorithm to automatically align audio description with repeated live performances of a theatrical production. This system is used in two evaluation experiments that show the method successfully aligns multiple recordings of works of musical theater in order to automatically trigger pre-recorded, descriptive audio in real time.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'audio description, blind, live theater, time warping, visually impaired', 'numpages': '3', 'pages': '606–608', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Audio description, an accessibility service used by blind or visually impaired individuals, provides spoken descriptions of visual content. This accommodation allows those with low or no vision the ability to access information that sighted people obtain visually. A method for deploying pre-recorded audio description in a live musical theater environment is presented here. This method uses a reference audio recording and an online time warping algorithm to automatically align audio description with repeated live performances of a theatrical production. This system is used in two evaluation experiments that show the method successfully aligns multiple recordings of works of musical theater in order to automatically trigger pre-recorded, descriptive audio in real time.', 'doi': '10.1145/3308561.3354624', 'url': 'https://doi.org/10.1145/3308561.3354624', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Syncing Pre-Recorded Audio Description to a Live Musical Theater Performance Using a Reference Audio Recording', 'author': 'Vander Wilt, Dirk and Farbood, Morwaread Mary', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354624'}"
"Sidewalk, A Wayfinding Message Syntax for People with a Visual Impairment",10.1145/3308561.3354625,"Traditional turn-by-turn navigation approaches often do not provide sufficiently detailed information to help people with a visual impairment (PVI) to successfully navigate through an urban environment. To provide PVI with clear and supportive navigation information we created Sidewalk, a new wayfinding message syntax for mobile applications. Sidewalk proposes a consistent structure for detailed wayfinding instructions, short instructions and alerts. We tested Sidewalk with six PVI in the urban center of Amsterdam, the Netherlands. Results show that our approach to wayfinding was positively valued by the participants.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assistive technology, natural language, navigation, smartphone, spoken messages, visually impaired, wayfinding', 'numpages': '3', 'pages': '609–611', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Traditional turn-by-turn navigation approaches often do not provide sufficiently detailed information to help people with a visual impairment (PVI) to successfully navigate through an urban environment. To provide PVI with clear and supportive navigation information we created Sidewalk, a new wayfinding message syntax for mobile applications. Sidewalk proposes a consistent structure for detailed wayfinding instructions, short instructions and alerts. We tested Sidewalk with six PVI in the urban center of Amsterdam, the Netherlands. Results show that our approach to wayfinding was positively valued by the participants.', 'doi': '10.1145/3308561.3354625', 'url': 'https://doi.org/10.1145/3308561.3354625', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Sidewalk, A Wayfinding Message Syntax for People with a Visual Impairment', 'author': 'van der Bie, Joey and Jaschinski, Christina and Ben Allouch, Somaya', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354625'}"
A Multi-Modal Approach for Blind and Visually Impaired Developers to Edit Webpage Designs,10.1145/3308561.3354626,"Blind and visually impaired (BVI) individuals are increasingly creating visual content online; however, there is a lack of tools that allow these individuals to modify the visual attributes of the content and verify the validity of those modifications. In this poster paper, we discuss the design and preliminary exploration of a multi-modal and accessible approach for BVI developers to edit visual layouts of webpages while maintaining visual aesthetics.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessible programming, blind and visually impaired, visual design, web', 'numpages': '3', 'pages': '612–614', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind and visually impaired (BVI) individuals are increasingly creating visual content online; however, there is a lack of tools that allow these individuals to modify the visual attributes of the content and verify the validity of those modifications. In this poster paper, we discuss the design and preliminary exploration of a multi-modal and accessible approach for BVI developers to edit visual layouts of webpages while maintaining visual aesthetics.', 'doi': '10.1145/3308561.3354626', 'url': 'https://doi.org/10.1145/3308561.3354626', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Multi-Modal Approach for Blind and Visually Impaired Developers to Edit Webpage Designs', 'author': 'Potluri, Venkatesh and He, Liang and Chen, Christine and Froehlich, Jon E. and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354626'}"
Supporting Older Adults in the Use of Smart Devices for Personal Health Management,10.1145/3308561.3354628,"A rapid proliferation of specialized consumer tech gadgets (e.g., Fitbits) demands attention to the challenges that individuals face in learning to use them. Help Kiosk (HK) was initially conceived to support older adults in independently learning to use a smartphone, but it was only ever examined for this one context. Its design also required users to divide their attention between different areas of an augmented display and their smartphone. We introduce HK 2.0, which leverages a 40"" tabletop display to integrate support into one visual space, while also supporting older adults in learning how to use multiple smart devices that must be configured to work together (e.g., a smartwatch synched to a tablet). Our new system also builds on the self-directed learning environment of the initial HK by introducing a collaborative learning feature to provide remote support by family and friends. We share the design of HK 2.0, including design requirements, features, and learning topics.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'health, large display, learning, older adults, personal wearables, seniors, smartwatches, tablets, user manuals', 'numpages': '3', 'pages': '615–617', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A rapid proliferation of specialized consumer tech gadgets (e.g., Fitbits) demands attention to the challenges that individuals face in learning to use them. Help Kiosk (HK) was initially conceived to support older adults in independently learning to use a smartphone, but it was only ever examined for this one context. Its design also required users to divide their attention between different areas of an augmented display and their smartphone. We introduce HK 2.0, which leverages a 40"" tabletop display to integrate support into one visual space, while also supporting older adults in learning how to use multiple smart devices that must be configured to work together (e.g., a smartwatch synched to a tablet). Our new system also builds on the self-directed learning environment of the initial HK by introducing a collaborative learning feature to provide remote support by family and friends. We share the design of HK 2.0, including design requirements, features, and learning topics.', 'doi': '10.1145/3308561.3354628', 'url': 'https://doi.org/10.1145/3308561.3354628', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Supporting Older Adults in the Use of Smart Devices for Personal Health Management', 'author': 'Wang, Collin and Pang, Carolyn and Moffatt, Karyn and Leung, Rock and McGrenere, Joanna', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354628'}"
Exploration of Multi-fingered Access to 2D Spatial Information,10.1145/3308561.3354630,"The use of touchscreen devices with tactile and/or auditory feedback is increasingly being considered for providing refreshable graphics for individuals who are blind or visually impaired. Typically, with these devices, only a single finger is used to explore, limiting the perceptual field of view and, potentially, performance. This paper describes a study examining the possibilities of improving performance using simultaneous feedback for each of multiple exploring fingers. Preliminary results suggest that the benefit of providing feedback to multiple fingers may be dependent on modality and user characteristics.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'blind, nonvisual diagrams, visually impaired', 'numpages': '3', 'pages': '618–620', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The use of touchscreen devices with tactile and/or auditory feedback is increasingly being considered for providing refreshable graphics for individuals who are blind or visually impaired. Typically, with these devices, only a single finger is used to explore, limiting the perceptual field of view and, potentially, performance. This paper describes a study examining the possibilities of improving performance using simultaneous feedback for each of multiple exploring fingers. Preliminary results suggest that the benefit of providing feedback to multiple fingers may be dependent on modality and user characteristics.', 'doi': '10.1145/3308561.3354630', 'url': 'https://doi.org/10.1145/3308561.3354630', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Exploration of Multi-fingered Access to 2D Spatial Information', 'author': 'Parker, David and Pawluk, Dianne', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354630'}"
Auxiliary Location-Based Services for Persons with Disabilities: What do City Planners and Non-Profit Agencies Think?,10.1145/3308561.3354631,Deploying auxiliary location-based services to complement GPS-based services has been a recent phenomenon to enable greater independence in navigation and wayfinding for persons with disabilities in unfamiliar environments. All work in this domain has been technical in nature with little known about the perceptions of city planners and non-profit agencies about the long-term sustainability and impact of such technologies on their communities. This work presents results and insights from a study on the perceptions of both city planners and non-profit agency personnel from a medium-sized city in the U.S.A about the importance of auxiliary location-based services and their potential impact.,"{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'community perspectives, impact, navigation, wayfinding', 'numpages': '3', 'pages': '621–623', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Deploying auxiliary location-based services to complement GPS-based services has been a recent phenomenon to enable greater independence in navigation and wayfinding for persons with disabilities in unfamiliar environments. All work in this domain has been technical in nature with little known about the perceptions of city planners and non-profit agencies about the long-term sustainability and impact of such technologies on their communities. This work presents results and insights from a study on the perceptions of both city planners and non-profit agency personnel from a medium-sized city in the U.S.A about the importance of auxiliary location-based services and their potential impact.', 'doi': '10.1145/3308561.3354631', 'url': 'https://doi.org/10.1145/3308561.3354631', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Auxiliary Location-Based Services for Persons with Disabilities: What do City Planners and Non-Profit Agencies Think?', 'author': 'Joseph, Siny and Namboodiri, Vinod', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354631'}"
Exploring Invisible Disability Disclosure in the Sharing Economy,10.1145/3308561.3354633,"Sharing economy platforms enable people-including those with disabilities-to engage in flexible work outside of traditional workplaces. Though gender and race have been studied, discrimination against service providers with disabilities has not been explored. In this poster, we conducted a 2 - 3 between-group experiment to study whether disability status and work type would affect perceptions of credibility and hiring. We found mixed results: there is no significant statistical difference on credibility perception of service providers and hiring decisions. In the open-end response analysis, we grouped three important factors impacting customers' hiring decision toward service providers with disabilities, including platform, work-related attributes, and personal traits.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'disability discrimination, invisible disabilities, self-disclosure, sharing economy', 'numpages': '3', 'pages': '624–626', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Sharing economy platforms enable people-including those with disabilities-to engage in flexible work outside of traditional workplaces. Though gender and race have been studied, discrimination against service providers with disabilities has not been explored. In this poster, we conducted a 2 - 3 between-group experiment to study whether disability status and work type would affect perceptions of credibility and hiring. We found mixed results: there is no significant statistical difference on credibility perception of service providers and hiring decisions. In the open-end response analysis, we grouped three important factors impacting customers' hiring decision toward service providers with disabilities, including platform, work-related attributes, and personal traits."", 'doi': '10.1145/3308561.3354633', 'url': 'https://doi.org/10.1145/3308561.3354633', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Exploring Invisible Disability Disclosure in the Sharing Economy', 'author': 'Dai, Zhengyan and Brady, Erin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354633'}"
Developmental Personal Health Libraries: Supporting Independence through Design,10.1145/3308561.3354635,"This paper summarizes the findings of an ongoing qualitative study on information seeking and exchange among autistic individuals [1], and suggests considerations for development of a developmental personal health library (D-PHL). The D-PHL focuses on supporting gradual development of health literacy, health information \&amp; data literacy, and management skills for autistic individuals. Emergent themes included trustworthiness, flexibility in formatting, use of multimedia, multiple modes of communication, cost, and accommodations for special interests. The paper discusses design implications related to each theme.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'disability, information seeking, personal health libraries', 'numpages': '3', 'pages': '627–629', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper summarizes the findings of an ongoing qualitative study on information seeking and exchange among autistic individuals [1], and suggests considerations for development of a developmental personal health library (D-PHL). The D-PHL focuses on supporting gradual development of health literacy, health information \\&amp; data literacy, and management skills for autistic individuals. Emergent themes included trustworthiness, flexibility in formatting, use of multimedia, multiple modes of communication, cost, and accommodations for special interests. The paper discusses design implications related to each theme.', 'doi': '10.1145/3308561.3354635', 'url': 'https://doi.org/10.1145/3308561.3354635', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Developmental Personal Health Libraries: Supporting Independence through Design', 'author': 'Gibson, Amelia N. and Bowen, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354635'}"
Thermo-haptic Earable Display for the Hearing and Visually Impaired,10.1145/3308561.3354636,"Earables/hearables (ear-worn devices) are on the rise as next-generation wearables which are capable of streaming audio, modifying soundscapes, and collecting body vitals. This paper introduces a novel concept of an earable device that can provide thermal (hot and cold) haptic cues at multiple areas around the ear. The concept with discrete thermal encoding can help the hearing and visually impaired individuals to obtain directional and other notifications from mobile and IoT devices. Embedding thermal haptic feedback into an earable form factor have a better edge in terms of privacy of notifications when compared to audio, visual, and vibrohaptic modalities. We conducted a pilot study using a proof-of-concept prototype and confirmed the feasibility of the concept.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'earable display, earable interfaces, thermal earable, thermal wearable', 'numpages': '3', 'pages': '630–632', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Earables/hearables (ear-worn devices) are on the rise as next-generation wearables which are capable of streaming audio, modifying soundscapes, and collecting body vitals. This paper introduces a novel concept of an earable device that can provide thermal (hot and cold) haptic cues at multiple areas around the ear. The concept with discrete thermal encoding can help the hearing and visually impaired individuals to obtain directional and other notifications from mobile and IoT devices. Embedding thermal haptic feedback into an earable form factor have a better edge in terms of privacy of notifications when compared to audio, visual, and vibrohaptic modalities. We conducted a pilot study using a proof-of-concept prototype and confirmed the feasibility of the concept.', 'doi': '10.1145/3308561.3354636', 'url': 'https://doi.org/10.1145/3308561.3354636', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Thermo-haptic Earable Display for the Hearing and Visually Impaired', 'author': 'Nasser, Arshad and Zhu, Kening and Wiseman, Sarah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354636'}"
Connection: Assisting Neurodiverse Individuals in Forming Lasting Relationships Through a Digital Medium,10.1145/3308561.3354641,"Many neurodiverse individuals experience isolation in adult life with a significant percentage reporting never engaging in long term romantic relationships. Such social isolation can result in critical behavioral and mental health problems such as anxiety, addiction, and depression. Online socialization platforms can aid in relationship building as they are void of many complexities present in face-to-face communication. We conducted an exploratory study (N=10) with neurodiverse and neurotypical young adults to investigate how to design online socialization platforms that enables creating and maintaining lasting relationships, especially for neurodiverse individuals. We focused on understanding their experiences surrounding online socialization platforms, challenges in using them, and unmet needs. To elicit requirements, we designed a prototype socialization platform, Connection. Our findings reveal that there is indeed a great desire for such platforms among neurotypical and neurodiverse individuals.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'autism spectrum disorder (asd), neurodiverse, neurotypical, relationships., social media', 'numpages': '3', 'pages': '633–635', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many neurodiverse individuals experience isolation in adult life with a significant percentage reporting never engaging in long term romantic relationships. Such social isolation can result in critical behavioral and mental health problems such as anxiety, addiction, and depression. Online socialization platforms can aid in relationship building as they are void of many complexities present in face-to-face communication. We conducted an exploratory study (N=10) with neurodiverse and neurotypical young adults to investigate how to design online socialization platforms that enables creating and maintaining lasting relationships, especially for neurodiverse individuals. We focused on understanding their experiences surrounding online socialization platforms, challenges in using them, and unmet needs. To elicit requirements, we designed a prototype socialization platform, Connection. Our findings reveal that there is indeed a great desire for such platforms among neurotypical and neurodiverse individuals.', 'doi': '10.1145/3308561.3354641', 'url': 'https://doi.org/10.1145/3308561.3354641', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Connection: Assisting Neurodiverse Individuals in Forming Lasting Relationships Through a Digital Medium', 'author': 'Fox, Elliot and Baden, Shane and Greene, Justin and Ziegler, Nick and Sharmin, Moushumi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354641'}"
Still Not Readable? An Interactive Tool for Recommending Color Pairs with Sufficient Contrast based on Existing Visual Designs,10.1145/3308561.3354585,"Most contrast checking tools allow designers to verify if a set of colors satisfy the minimum contrast requirements for text and background colors. However, such tools usually do not provide the designer with any clues on how the colors should be adjusted to ensure enough contrast. This demo shows our web-based contrast tool which suggests how existing set of colors could be adjusted to satisfy minimum contrast requirements while maintaining the gist of the original visual design.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'color contrast, low vision, readability, web design', 'numpages': '3', 'pages': '636–638', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most contrast checking tools allow designers to verify if a set of colors satisfy the minimum contrast requirements for text and background colors. However, such tools usually do not provide the designer with any clues on how the colors should be adjusted to ensure enough contrast. This demo shows our web-based contrast tool which suggests how existing set of colors could be adjusted to satisfy minimum contrast requirements while maintaining the gist of the original visual design.', 'doi': '10.1145/3308561.3354585', 'url': 'https://doi.org/10.1145/3308561.3354585', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Still Not Readable? An Interactive Tool for Recommending Color Pairs with Sufficient Contrast based on Existing Visual Designs', 'author': 'Hansen, Fredrik and Krivan, Josef Jan and Sandnes, Frode Eika', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354585'}"
GraVVITAS 2.0: A Framework For Digital Accessible Content Provision,10.1145/3308561.3354586,"Access to information is a fundamental problem for people with vision impairment (PVI). Textual information are considerably more accessible with the use of screen readers that work on desktop and mobile devices. However, access to graphical information is still a challenging problem. There are different technologies to present graphics to PVI, but almost all of them suffer from practicality and portability. This paper describes the GraVVITAS (Graphics Viewer using Vibration Interactive Touch and Speech) framework which aims to be a complementary system for other assistive technologies; a solution that can be carried in one's pocket.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessible graphics, assistive technologies, content generation, multi-touch screens, visual impairment', 'numpages': '3', 'pages': '639–641', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Access to information is a fundamental problem for people with vision impairment (PVI). Textual information are considerably more accessible with the use of screen readers that work on desktop and mobile devices. However, access to graphical information is still a challenging problem. There are different technologies to present graphics to PVI, but almost all of them suffer from practicality and portability. This paper describes the GraVVITAS (Graphics Viewer using Vibration Interactive Touch and Speech) framework which aims to be a complementary system for other assistive technologies; a solution that can be carried in one's pocket."", 'doi': '10.1145/3308561.3354586', 'url': 'https://doi.org/10.1145/3308561.3354586', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'GraVVITAS 2.0: A Framework For Digital Accessible Content Provision', 'author': 'Goncu, Cagatay and Marriott, Kim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354586'}"
WordMelodies: Supporting Children with Visual Impairment in Learning Literacy,10.1145/3308561.3354587,"We present WordMelodies, an inclusive, cross platform, mobile app that supports children with visual impairments in the acquisition of basic literacy skills through 8 different exercises. WordMelodies has been designed and evaluated by three domain experts in assistive technologies and education for children with visual impairments. After three design and evaluation iterations the app is fully accessible, except for one limitation of the cross platform development toolkit used.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, education, literacy, visual impairment', 'numpages': '3', 'pages': '642–644', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present WordMelodies, an inclusive, cross platform, mobile app that supports children with visual impairments in the acquisition of basic literacy skills through 8 different exercises. WordMelodies has been designed and evaluated by three domain experts in assistive technologies and education for children with visual impairments. After three design and evaluation iterations the app is fully accessible, except for one limitation of the cross platform development toolkit used.', 'doi': '10.1145/3308561.3354587', 'url': 'https://doi.org/10.1145/3308561.3354587', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'WordMelodies: Supporting Children with Visual Impairment in Learning Literacy', 'author': 'Mascetti, Sergio and Leontini, Giovanni and Bernareggi, Cristian and Ahmetovic, Dragan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354587'}"
Demo: Expanding Blocks4All with Variables and Functions,10.1145/3308561.3354588,"Blocks-based programming environments are often inaccessible for children with visual impairments who cannot interact with their visual components. We present our work on expanding Blocks4All, a touchscreen-based blocks-based programming environment that is accessible with screen readers, to improve its accessibility and expand its functionality. We describe our designs to support more complex functionality such as modifiable blocks, variables and functions and provide our code to encourage others to make their own environments accessible. We plan to evaluate the updated interface with children with low vision participating in a robotics competition","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blocks-based programming, educational technology, motor impairments, touchscreen interactions, visual impairments', 'numpages': '3', 'pages': '645–647', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blocks-based programming environments are often inaccessible for children with visual impairments who cannot interact with their visual components. We present our work on expanding Blocks4All, a touchscreen-based blocks-based programming environment that is accessible with screen readers, to improve its accessibility and expand its functionality. We describe our designs to support more complex functionality such as modifiable blocks, variables and functions and provide our code to encourage others to make their own environments accessible. We plan to evaluate the updated interface with children with low vision participating in a robotics competition', 'doi': '10.1145/3308561.3354588', 'url': 'https://doi.org/10.1145/3308561.3354588', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Demo: Expanding Blocks4All with Variables and Functions', 'author': 'Ong, Jacqueline Shao Yi and Amoah, Nana Adwoa O. and Garrett-Engele, Alison E. and Page, Mariella Irene and McCarthy, Katherine R. and Milne, Lauren R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354588'}"
Making the Blockly Library Accessible via Touchscreen,10.1145/3308561.3354589,"Block-based programming environments are a popular way to learn programming. Many of these libraries, including Scratch and MIT's App Inventor, are built on the Blockly library from Google. Unfortunately, programs built with the Blockly library are currently not accessible for people with visual impairments. We describe two designs to make the Blockly library accessible using a screen reader on a touchscreen device.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, aria, audio interfaces, blind users, block languages, block-based programming environment, education', 'numpages': '3', 'pages': '648–650', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Block-based programming environments are a popular way to learn programming. Many of these libraries, including Scratch and MIT's App Inventor, are built on the Blockly library from Google. Unfortunately, programs built with the Blockly library are currently not accessible for people with visual impairments. We describe two designs to make the Blockly library accessible using a screen reader on a touchscreen device."", 'doi': '10.1145/3308561.3354589', 'url': 'https://doi.org/10.1145/3308561.3354589', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Making the Blockly Library Accessible via Touchscreen', 'author': 'Caraco, Logan B. and Deibel, Sebastian and Ma, Yufan and Milne, Lauren R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354589'}"
Non-Visual Beats: Redesigning the Groove Pizza,10.1145/3308561.3354590,"Unlike past eras in which select few had the means and con- nections to compose music, today almost anyone can engage in meaningful music making and craft their own compositions thanks in part to the ubiquity of affordable and easy-to-use music software. However, this advancement has not fully extended to non-sighted users as evidenced by online com- munities seeking and offering help and third party companies that have stepped in to fill a void of accessibility features. To address the lack of alternative input modalities and pervasive visual design of music creation software, we redesigned the Groove Pizza, a popular online rhythm application. This work describes our implementation and its use of custom key- board mappings for sequencing rhythm, screen reader output using text-to-speech and sonification, and global audio settings designed for different use cases.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blindness, music creation, music technology, visual impairments', 'numpages': '4', 'pages': '651–654', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Unlike past eras in which select few had the means and con- nections to compose music, today almost anyone can engage in meaningful music making and craft their own compositions thanks in part to the ubiquity of affordable and easy-to-use music software. However, this advancement has not fully extended to non-sighted users as evidenced by online com- munities seeking and offering help and third party companies that have stepped in to fill a void of accessibility features. To address the lack of alternative input modalities and pervasive visual design of music creation software, we redesigned the Groove Pizza, a popular online rhythm application. This work describes our implementation and its use of custom key- board mappings for sequencing rhythm, screen reader output using text-to-speech and sonification, and global audio settings designed for different use cases.', 'doi': '10.1145/3308561.3354590', 'url': 'https://doi.org/10.1145/3308561.3354590', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Non-Visual Beats: Redesigning the Groove Pizza', 'author': 'Payne, William and Xu, Alex and Hurst, Amy and Ruthmann, S. Alex', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354590'}"
Development of a Real-time Bionic Voice Generation System based on Statistical Excitation Prediction,10.1145/3308561.3354591,"Despite the emergent progress in many fields of bionics, larynx amputees still lack a functional Bionic Voice source to overcome their voice disability. We have established the Pneumatic Bionic Voice (PBV) as a promising technology to generate a voice for larynx amputees. This summary provides an overview of our efforts to implement the PBV system in real-time together with a demonstration of its results. The PBV is an electronic adaptation of an old school mechanical voice source called the Pneumatic Artificial Larynx (PAL). The PAL is a non-invasive voice prosthesis, with an exceptionally high-quality voice, driven exclusively by respiration. This work proposes an approach to statistically model the PAL's voice generation mechanism from the respiration and to implement it in a real-time PBV system that larynx amputees can use to generate voice in continuous speech.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'laryngectomy., pal, pneumatic artificial larynx, pneumatic bionic voice, voice conversion, voice prosthesis', 'numpages': '3', 'pages': '655–657', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Despite the emergent progress in many fields of bionics, larynx amputees still lack a functional Bionic Voice source to overcome their voice disability. We have established the Pneumatic Bionic Voice (PBV) as a promising technology to generate a voice for larynx amputees. This summary provides an overview of our efforts to implement the PBV system in real-time together with a demonstration of its results. The PBV is an electronic adaptation of an old school mechanical voice source called the Pneumatic Artificial Larynx (PAL). The PAL is a non-invasive voice prosthesis, with an exceptionally high-quality voice, driven exclusively by respiration. This work proposes an approach to statistically model the PAL's voice generation mechanism from the respiration and to implement it in a real-time PBV system that larynx amputees can use to generate voice in continuous speech."", 'doi': '10.1145/3308561.3354591', 'url': 'https://doi.org/10.1145/3308561.3354591', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Development of a Real-time Bionic Voice Generation System based on Statistical Excitation Prediction', 'author': 'Ahmadi, Farzaneh and Kobayashi, Kazuhiro and Toda, Tomoki', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354591'}"
AfricaSign -- A Crowd-sourcing Platform for the Documentation of STEM Vocabulary in African Sign Languages,10.1145/3308561.3354592,"Research in sign languages, in general, is still a relatively new topic of study when compared to research into spoken languages. Most of African sign languages are endangered and severely under-studied [11]. In an attempt to (lexically) document as many endangered sign languages in Africa as possible, we have developed a low-barrier, online crowd-sourcing platform (AfricaSign) that enables the African deaf communities to document their sign languages. AfricaSign offers to users multiple input modes, accommodates regional variation in multiple sign languages and allows the use of avatar technology to describe signs. It is likely that this research will uncover typological features exhibited by African sign languages. Documentation of STEM vocabulary will also help facilitate access to education for the Deaf community.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'africa, avatar technology, documentation, sign language, stem', 'numpages': '3', 'pages': '658–660', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Research in sign languages, in general, is still a relatively new topic of study when compared to research into spoken languages. Most of African sign languages are endangered and severely under-studied [11]. In an attempt to (lexically) document as many endangered sign languages in Africa as possible, we have developed a low-barrier, online crowd-sourcing platform (AfricaSign) that enables the African deaf communities to document their sign languages. AfricaSign offers to users multiple input modes, accommodates regional variation in multiple sign languages and allows the use of avatar technology to describe signs. It is likely that this research will uncover typological features exhibited by African sign languages. Documentation of STEM vocabulary will also help facilitate access to education for the Deaf community.', 'doi': '10.1145/3308561.3354592', 'url': 'https://doi.org/10.1145/3308561.3354592', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'AfricaSign -- A Crowd-sourcing Platform for the Documentation of STEM Vocabulary in African Sign Languages', 'author': 'Soudi, Abdelhadi and Van Laerhoven, Kristof and Bou-Souf, Elmostafa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354592'}"
Supporting Older Adults in Using Complex User Interfaces with Augmented Reality,10.1145/3308561.3354593,"Using complex interfaces has been shown to be challenging for older adults. Existing tutorial systems can be cumbersome, and sometimes difficult to use. To solve this problem, we present a system to support older adults in using visual interfaces by providing step-by-step visual guidance with augmented reality. Using the Apple ARKit platform, our system detects the interface in a phone camera view, and provides visual guidance for users to access the interface following a generated sequence of interactions based on pre-specified tasks and prior knowledge of the interface.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'augmented reality, cognitive support, interfaces, older adults', 'numpages': '3', 'pages': '661–663', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Using complex interfaces has been shown to be challenging for older adults. Existing tutorial systems can be cumbersome, and sometimes difficult to use. To solve this problem, we present a system to support older adults in using visual interfaces by providing step-by-step visual guidance with augmented reality. Using the Apple ARKit platform, our system detects the interface in a phone camera view, and provides visual guidance for users to access the interface following a generated sequence of interactions based on pre-specified tasks and prior knowledge of the interface.', 'doi': '10.1145/3308561.3354593', 'url': 'https://doi.org/10.1145/3308561.3354593', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Supporting Older Adults in Using Complex User Interfaces with Augmented Reality', 'author': 'Kong, Junhan and Guo, Anhong and Bigham, Jeffrey P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354593'}"
A Demonstration of Molder: An Accessible Design Tool for Tactile Maps,10.1145/3308561.3354594,"Tactile maps are important tools for people with visual impairments (VIs). Teachers and orientation and mobility (O&amp;M) specialists often design tactile maps to help their VI students and clients learn about geographic areas. To design these maps, a designer must use modeling software applications, which require professional training and rely on visual feedback. However, most teachers and O&amp;M specialists do not have professional modeling skills, and many have visual impairments. The complexity and inaccessibility of current modeling tools thus become major barriers for TVIs and O&amp;M specialists when designing tactile maps. We present Molder, an accessible design tool for tactile maps. A designer creates a draft map model using Molder and prints the model. Then, she uses Molder to modify the draft model by directly interacting with it. Molder provides auditory feedback and high-contrast visuals to assist the designer in the design process.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'design tool, tactile maps, visual impairments', 'numpages': '3', 'pages': '664–666', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tactile maps are important tools for people with visual impairments (VIs). Teachers and orientation and mobility (O&amp;M) specialists often design tactile maps to help their VI students and clients learn about geographic areas. To design these maps, a designer must use modeling software applications, which require professional training and rely on visual feedback. However, most teachers and O&amp;M specialists do not have professional modeling skills, and many have visual impairments. The complexity and inaccessibility of current modeling tools thus become major barriers for TVIs and O&amp;M specialists when designing tactile maps. We present Molder, an accessible design tool for tactile maps. A designer creates a draft map model using Molder and prints the model. Then, she uses Molder to modify the draft model by directly interacting with it. Molder provides auditory feedback and high-contrast visuals to assist the designer in the design process.', 'doi': '10.1145/3308561.3354594', 'url': 'https://doi.org/10.1145/3308561.3354594', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Demonstration of Molder: An Accessible Design Tool for Tactile Maps', 'author': 'Shi, Lei and Zhao, Yuhang and Kupferstein, Elizabeth and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354594'}"
Demonstration of GestureCalc: An Eyes-Free Calculator for Touch Screens,10.1145/3308561.3354595,"Keypad-based character input in existing digital calculator applications on touch screen devices requires precise, targeted key presses that are time-consuming and error-prone for many screen reader users. We demonstrate GestureCalc, a digital calculator that uses target-free gestures for arithmetic tasks. It allows eyes-free target-less input of digits and operations through taps and directional swipes with one to three fingers, guided by minimal audio feedback. A study of the effectiveness of GestureCalc for screen reader users appears in a full paper by the authors at this conference.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'digital calculator, eyes-free entry, gesture input, mobile devices, touch screen', 'numpages': '3', 'pages': '667–669', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Keypad-based character input in existing digital calculator applications on touch screen devices requires precise, targeted key presses that are time-consuming and error-prone for many screen reader users. We demonstrate GestureCalc, a digital calculator that uses target-free gestures for arithmetic tasks. It allows eyes-free target-less input of digits and operations through taps and directional swipes with one to three fingers, guided by minimal audio feedback. A study of the effectiveness of GestureCalc for screen reader users appears in a full paper by the authors at this conference.', 'doi': '10.1145/3308561.3354595', 'url': 'https://doi.org/10.1145/3308561.3354595', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Demonstration of GestureCalc: An Eyes-Free Calculator for Touch Screens', 'author': 'Perlmutter, Leah and Chaudhuri, Bindita and Petelka, Justin and Garrison, Philip and Fogarty, James and Wobbrock, Jacob O. and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354595'}"
A Tangible Math Game for Visually Impaired Children,10.1145/3308561.3354596,"We present iCETA, an inclusive interactive system for math learning, that enables children to autonomously engage and solve additive composition tasks. It was designed through a set of participatory sessions with visually impaired children and their educators, and supports math learning through the combination of tangible interaction with haptic and auditory feedback. Tangible blocks representing numbers 1 to 5 were used to add or subtract and correctly solve the task embedded in a computerized game. Our approach aims to provide better scaffolding for understanding the abstract concept of a number by working with different representations of that number, as the size of the block, Braille, color and audio feedback.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'cognitive training, multimodal, tangibles, visually impaired', 'numpages': '3', 'pages': '670–672', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present iCETA, an inclusive interactive system for math learning, that enables children to autonomously engage and solve additive composition tasks. It was designed through a set of participatory sessions with visually impaired children and their educators, and supports math learning through the combination of tangible interaction with haptic and auditory feedback. Tangible blocks representing numbers 1 to 5 were used to add or subtract and correctly solve the task embedded in a computerized game. Our approach aims to provide better scaffolding for understanding the abstract concept of a number by working with different representations of that number, as the size of the block, Braille, color and audio feedback.', 'doi': '10.1145/3308561.3354596', 'url': 'https://doi.org/10.1145/3308561.3354596', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Tangible Math Game for Visually Impaired Children', 'author': 'Pires, Ana Cristina and Marichal, Sebastian and Gonzalez-Perilli, Fernando and Bakala, Ewelina and Fleischer, Bruno and Sansone, Gustavo and Guerreiro, Tiago', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354596'}"
RoboGraphics: Using Mobile Robots to Create Dynamic Tactile Graphics,10.1145/3308561.3354597,"Tactile graphics are a common way to present information to people with vision impairments. Tactile graphics can be used to explore a broad range of content including presenting data, telling stories, and conveying map information, but aren't well suited to representing dynamic or moving information. We introduce and demonstrate a new approach RoboGraphics for creating dynamic tactile graphics by combining static tactile overlays, touch screen tablets, and off-the-shelf tangible robots. To evaluate the RoboGraphics approach for conveying information to blind users, we created a set of reference applications, including an interface for exploring graph data, braille characters, the story of the tortoise and the hare, the analog clock, and the ruminant digestive process. A design probe demonstrated that haptic graphics can be used to help people with vision impairments explore data using the audio-tactile display.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blindness, education, robots, tactile, tangible user interfaces', 'numpages': '3', 'pages': '673–675', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Tactile graphics are a common way to present information to people with vision impairments. Tactile graphics can be used to explore a broad range of content including presenting data, telling stories, and conveying map information, but aren't well suited to representing dynamic or moving information. We introduce and demonstrate a new approach RoboGraphics for creating dynamic tactile graphics by combining static tactile overlays, touch screen tablets, and off-the-shelf tangible robots. To evaluate the RoboGraphics approach for conveying information to blind users, we created a set of reference applications, including an interface for exploring graph data, braille characters, the story of the tortoise and the hare, the analog clock, and the ruminant digestive process. A design probe demonstrated that haptic graphics can be used to help people with vision impairments explore data using the audio-tactile display."", 'doi': '10.1145/3308561.3354597', 'url': 'https://doi.org/10.1145/3308561.3354597', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'RoboGraphics: Using Mobile Robots to Create Dynamic Tactile Graphics', 'author': 'Guinness, Darren and Muehlbradt, Annika and Szafir, Daniel and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354597'}"
"AccessMap Website Demonstration: Individualized, Accessible Pedestrian Trip Planning at Scale",10.1145/3308561.3354598,"Despite significant heterogeneity in pedestrian mobility, maps and trip planning services have traditionally treated pedestrians as a monolithic, limited extension to street traffic-centric approaches. Here, we present a demonstration of the AccessMap website, an open source, city-scale, interactive web map based on open data that provides individualized pedestrian infrastructure information and automatic trip planning services. Via the AccessMap website, customizable settings instigate real-time visual feedback of infrastructure accessibility and are used to automatically generate bespoke trip plans via an open API.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, accessible mapping, pedestrian, sidewalks', 'numpages': '3', 'pages': '676–678', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite significant heterogeneity in pedestrian mobility, maps and trip planning services have traditionally treated pedestrians as a monolithic, limited extension to street traffic-centric approaches. Here, we present a demonstration of the AccessMap website, an open source, city-scale, interactive web map based on open data that provides individualized pedestrian infrastructure information and automatic trip planning services. Via the AccessMap website, customizable settings instigate real-time visual feedback of infrastructure accessibility and are used to automatically generate bespoke trip plans via an open API.', 'doi': '10.1145/3308561.3354598', 'url': 'https://doi.org/10.1145/3308561.3354598', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'AccessMap Website Demonstration: Individualized, Accessible Pedestrian Trip Planning at Scale', 'author': 'Bolten, Nicholas and Caspi, Anat', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354598'}"
GoDonnie: A Robot Programming Language to Improve Orientation and Mobility Skills in People Who are Visually Impaired,10.1145/3308561.3354599,"This work presents GoDonnie a programming language to command a robot to improve orientation and mobility(O&amp;M) skills in people who are visually impaired (PVI). The GoDonnie programming language is based on the Logo language. GoDonnie runs in a programming environment called Donnie. This environment has a 2D graphic simulator with a virtual robot, in which one can visualise and receive sound feedback from the execution of the language commands for moving the virtual robot in the environment. GoDonnie has been evaluated with PVI to verify its usability and support to O&amp;M. The results indicate that GoDonnie has good usability, supports the development of O&amp;M in PVI and meets the expectations regarding the programming environment. A video of GoDonnie execution is available in https://youtu.be/HE__sAgfNBo","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'orientation and mobility, programming language, usability, visual impairment', 'numpages': '3', 'pages': '679–681', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This work presents GoDonnie a programming language to command a robot to improve orientation and mobility(O&amp;M) skills in people who are visually impaired (PVI). The GoDonnie programming language is based on the Logo language. GoDonnie runs in a programming environment called Donnie. This environment has a 2D graphic simulator with a virtual robot, in which one can visualise and receive sound feedback from the execution of the language commands for moving the virtual robot in the environment. GoDonnie has been evaluated with PVI to verify its usability and support to O&amp;M. The results indicate that GoDonnie has good usability, supports the development of O&amp;M in PVI and meets the expectations regarding the programming environment. A video of GoDonnie execution is available in https://youtu.be/HE__sAgfNBo', 'doi': '10.1145/3308561.3354599', 'url': 'https://doi.org/10.1145/3308561.3354599', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'GoDonnie: A Robot Programming Language to Improve Orientation and Mobility Skills in People Who are Visually Impaired', 'author': ""Oliveira, Juliana Damasio and Campos, M\\'{a}rcia de Borba and Amory, Alexandre and Bordini, Rafael H."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354599'}"
Jido: A Conversational Tactile Map for Blind People,10.1145/3308561.3354600,"Jido is a conversational tactile map and a mobile application prototype to improve the orientation and mobility of visually impaired people. The tactile map can identify the user's touch gestures and their locations during tactile exploration to provide feedback. Users can verbally interact with a conversational agent through their mobile device to receive confirmation, request information of points of interest, and receive step-by-step instructions that can be later reviewed during navigation. In this work, we describe opportunities and challenges faced by tactile map users and present the findings on the preliminary evaluation of our prototype.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'assitive technologies, blind people, navigation, tactile map, voice interaction', 'numpages': '3', 'pages': '682–684', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Jido is a conversational tactile map and a mobile application prototype to improve the orientation and mobility of visually impaired people. The tactile map can identify the user's touch gestures and their locations during tactile exploration to provide feedback. Users can verbally interact with a conversational agent through their mobile device to receive confirmation, request information of points of interest, and receive step-by-step instructions that can be later reviewed during navigation. In this work, we describe opportunities and challenges faced by tactile map users and present the findings on the preliminary evaluation of our prototype."", 'doi': '10.1145/3308561.3354600', 'url': 'https://doi.org/10.1145/3308561.3354600', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Jido: A Conversational Tactile Map for Blind People', 'author': ""Cavazos Quero, Luis and Iranzo Bartolom\\'{e}, Jorge and Lee, Dongmyeong and Lee, Yerin and Lee, Sangwon and Cho, Jundong"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354600'}"
Personalization and Layering to Simplify Computer Accessibility,10.1145/3308561.3354601,"Access to digital interfaces is a growing concern due to its increasing role in all aspects of our lives. Those who cannot access and use digital technologies will not be able to participate in the society or even live independently in smart or non-smart homes as they are currently evolving. This includes many who face barriers due to their disability, literacy, or digital literacy. Solutions exist but are often not installed, buried, hard to find, and difficult to understand and use. A new extension to the operating system that combines auto-personalization, layering, enhanced discovery, and Install on Demand (IoD) seeks to make computers easier to use by those who have difficulty learning and understanding them, and also make it easier to set up and use assistive technologies. Key to its utility is the ability to have these features and capabilities appear on any computer they encounter and want to use at school, work, library, community center, etc. Pilot testing is being launched in libraries, job centers and a community college.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, assistive technologies, auto-personalization, inclusive design, layering, morphic', 'numpages': '3', 'pages': '685–687', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Access to digital interfaces is a growing concern due to its increasing role in all aspects of our lives. Those who cannot access and use digital technologies will not be able to participate in the society or even live independently in smart or non-smart homes as they are currently evolving. This includes many who face barriers due to their disability, literacy, or digital literacy. Solutions exist but are often not installed, buried, hard to find, and difficult to understand and use. A new extension to the operating system that combines auto-personalization, layering, enhanced discovery, and Install on Demand (IoD) seeks to make computers easier to use by those who have difficulty learning and understanding them, and also make it easier to set up and use assistive technologies. Key to its utility is the ability to have these features and capabilities appear on any computer they encounter and want to use at school, work, library, community center, etc. Pilot testing is being launched in libraries, job centers and a community college.', 'doi': '10.1145/3308561.3354601', 'url': 'https://doi.org/10.1145/3308561.3354601', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Personalization and Layering to Simplify Computer Accessibility', 'author': 'Vanderheiden, Gregg and Jordan, J. Bern', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3354601'}"
BrailleBlocks: Braille Toys for Cross-Ability Collaboration,10.1145/3308561.3356104,"Less than 10\% of blind people in the United States are Braille readers, yet Braille literacy remains crucial for education and employment [2,3]. BrailleBlocks is a system to help blind or visually impaired children learn Braille with a sighted parent. BrailleBlocks comprises a set of wooden blocks and pegs, each block representing a Braille cell, and an interface with games for parents. We conducted user studies with five sighted parents and six blind or visually impaired children. Children preferred games with sound effects, specifically Hangman and the Animal Name Game. Parents commended the system as a spelling tool and found the screen display of Braille letters to be a helpful reference. Children created new ways to use the system beyond the games we provided, like story-telling and stacking blocks into structures. We identified concrete ways to improve the system, including generating progress reports for parents and creating a portable version.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, blind, braille, children, collaboration, education, visually impaired', 'numpages': '3', 'pages': '688–690', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Less than 10\\% of blind people in the United States are Braille readers, yet Braille literacy remains crucial for education and employment [2,3]. BrailleBlocks is a system to help blind or visually impaired children learn Braille with a sighted parent. BrailleBlocks comprises a set of wooden blocks and pegs, each block representing a Braille cell, and an interface with games for parents. We conducted user studies with five sighted parents and six blind or visually impaired children. Children preferred games with sound effects, specifically Hangman and the Animal Name Game. Parents commended the system as a spelling tool and found the screen display of Braille letters to be a helpful reference. Children created new ways to use the system beyond the games we provided, like story-telling and stacking blocks into structures. We identified concrete ways to improve the system, including generating progress reports for parents and creating a portable version.', 'doi': '10.1145/3308561.3356104', 'url': 'https://doi.org/10.1145/3308561.3356104', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'BrailleBlocks: Braille Toys for Cross-Ability Collaboration', 'author': 'Gadiraju, Vinitha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356104'}"
Designing a Low-cost Finger Wearable Audio-tactile Device,10.1145/3308561.3356105,"This paper describes the design process of ColorTact, a finger wearable device for accessing audio annotations on tactile diagrams. It is designed to cater a seamless audio experience while exploring the tactile images. The device consists of a color sensor which can sense the discrete color tagged areas on the diagrams and can give the corresponding audio/sound output saved in the color-to-audio mapping profile. It also allows users to use both hands to probe tactile images without restricting the movement and the tactile sensation of finger tips. It is standalone, easy to setup, low cost, and does not use any of the complex hardware or back-end image processing methods.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, audio-tactile, finger wearable, visually impaired', 'numpages': '3', 'pages': '691–693', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes the design process of ColorTact, a finger wearable device for accessing audio annotations on tactile diagrams. It is designed to cater a seamless audio experience while exploring the tactile images. The device consists of a color sensor which can sense the discrete color tagged areas on the diagrams and can give the corresponding audio/sound output saved in the color-to-audio mapping profile. It also allows users to use both hands to probe tactile images without restricting the movement and the tactile sensation of finger tips. It is standalone, easy to setup, low cost, and does not use any of the complex hardware or back-end image processing methods.', 'doi': '10.1145/3308561.3356105', 'url': 'https://doi.org/10.1145/3308561.3356105', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Designing a Low-cost Finger Wearable Audio-tactile Device', 'author': 'Nasser, Arshad', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356105'}"
An Intelligent Decision Support System for Stroke Rehabilitation Assessment,10.1145/3308561.3356106,"Assessment of rehabilitation exercises is important to determine an adequate rehabilitation intervention. However, this assessment is costly as it requires the presence of a therapist. This paper presents an interactive multimodal approach that automatically assesses exercise performance, identifies salient features of assessment, and iteratively present user-specific analysis to support therapist's decision making on personalized rehabilitation assessment. This approach can achieve good agreement level with therapist's evaluation (i.e. an average of 0.8565 F1-scores on three upper-limb exercises), which is higher than non-interactive, unimodal models.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'human-ai interaction, interactive machine learning, stroke rehabilitation assessment', 'numpages': '3', 'pages': '694–696', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Assessment of rehabilitation exercises is important to determine an adequate rehabilitation intervention. However, this assessment is costly as it requires the presence of a therapist. This paper presents an interactive multimodal approach that automatically assesses exercise performance, identifies salient features of assessment, and iteratively present user-specific analysis to support therapist's decision making on personalized rehabilitation assessment. This approach can achieve good agreement level with therapist's evaluation (i.e. an average of 0.8565 F1-scores on three upper-limb exercises), which is higher than non-interactive, unimodal models."", 'doi': '10.1145/3308561.3356106', 'url': 'https://doi.org/10.1145/3308561.3356106', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'An Intelligent Decision Support System for Stroke Rehabilitation Assessment', 'author': 'Lee, Min Hun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356106'}"
HowToApp: Supporting Life Skills Development of Young Adults with Intellectual Disability,10.1145/3308561.3356107,"Towards supporting an expressed interest of young adults with Intellectual Disability (ID) and their proxies to develop their social participation skills, this research investigated and co-designed the HowToApp (Fig 1), an app that queries and present young adults YouTube videos of their skills development interests on an accessible User Interface (UI). The app's design adapted social media design features and icons as a mechanism of leveraging the competencies and skills participants have developed from using them. Findings show that participants associated functional familiarity with the app's social media-inspired design icons and features, such as sharing, which fostered usability and mediated engagement between participants and their networks. Based on the findings, this paper reflects on a competency-based design approach that leverages the existing technology participation competencies and skills of people with ID in designing to support self-determination.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'competency-based design, howtoapp, intellectual disability', 'numpages': '3', 'pages': '697–699', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Towards supporting an expressed interest of young adults with Intellectual Disability (ID) and their proxies to develop their social participation skills, this research investigated and co-designed the HowToApp (Fig 1), an app that queries and present young adults YouTube videos of their skills development interests on an accessible User Interface (UI). The app's design adapted social media design features and icons as a mechanism of leveraging the competencies and skills participants have developed from using them. Findings show that participants associated functional familiarity with the app's social media-inspired design icons and features, such as sharing, which fostered usability and mediated engagement between participants and their networks. Based on the findings, this paper reflects on a competency-based design approach that leverages the existing technology participation competencies and skills of people with ID in designing to support self-determination."", 'doi': '10.1145/3308561.3356107', 'url': 'https://doi.org/10.1145/3308561.3356107', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'HowToApp: Supporting Life Skills Development of Young Adults with Intellectual Disability', 'author': 'Bayor, Andrew A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356107'}"
User Perspectives on Robotics for Post-stroke Hand Rehabilitation,10.1145/3308561.3356108,"Despite the importance of user perception of rehabilitative devices, few studies have been done to understand patients' subjective experience in robot-assisted rehabilitation. In this preliminary study, we investigate the user perception of an exoskeleton robotic device for post-stroke hand rehabilitation. Through semi-structured interviews and questionnaires, we gathered opinions from stroke patients, caregivers and biomedical researchers in terms of the subjective perception for the robotic device. Our results show split attitudes across stakeholders.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'exoskeleton, motivation, rehabilitation, robotic, stroke', 'numpages': '3', 'pages': '700–702', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Despite the importance of user perception of rehabilitative devices, few studies have been done to understand patients' subjective experience in robot-assisted rehabilitation. In this preliminary study, we investigate the user perception of an exoskeleton robotic device for post-stroke hand rehabilitation. Through semi-structured interviews and questionnaires, we gathered opinions from stroke patients, caregivers and biomedical researchers in terms of the subjective perception for the robotic device. Our results show split attitudes across stakeholders."", 'doi': '10.1145/3308561.3356108', 'url': 'https://doi.org/10.1145/3308561.3356108', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'User Perspectives on Robotics for Post-stroke Hand Rehabilitation', 'author': 'Ng, Chloe', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356108'}"
A Wearable Input Mechanism for Blind Users of Computers Based on Mental Mapping of Thumb-To-Phalanx Distances,10.1145/3308561.3356109,"As computers become common in different work environments, more accessible forms of interaction are required so that blind people may cost-effectively perform computer-based tasks requiring precise input. The human hand has 14 digital bones called phalanges. We propose an affordable mechanism for entering input into a computer which maps individual keys to the phalanges of each finger but the thumb. Our study shows that this mechanism can be used as a plausible input method in workspaces. We show that participants can achieve entry rates of up to 6.0 Words Per Minute (WPM) and have an average Character Error Rate of 3.58\% with up to 100 minutes of practice.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'blind, distance, finger, glove, keyboard, phalanx, thumb', 'numpages': '3', 'pages': '703–705', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'As computers become common in different work environments, more accessible forms of interaction are required so that blind people may cost-effectively perform computer-based tasks requiring precise input. The human hand has 14 digital bones called phalanges. We propose an affordable mechanism for entering input into a computer which maps individual keys to the phalanges of each finger but the thumb. Our study shows that this mechanism can be used as a plausible input method in workspaces. We show that participants can achieve entry rates of up to 6.0 Words Per Minute (WPM) and have an average Character Error Rate of 3.58\\% with up to 100 minutes of practice.', 'doi': '10.1145/3308561.3356109', 'url': 'https://doi.org/10.1145/3308561.3356109', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'A Wearable Input Mechanism for Blind Users of Computers Based on Mental Mapping of Thumb-To-Phalanx Distances', 'author': 'Naik, Yash', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356109'}"
Insights for More Usable VR for People with Amblyopia,10.1145/3308561.3356110,"Amblyopia, or ""lazy eye"" is the world's most common neurological eye disorder. Yet, very little has been done looking into how to make virtual reality (VR) more usable for people with Amblyopia. Furthermore, a trend of using VR for Amblyopia therapy has arisen, making such a study more essential than ever. Our study asks our user base of people with Amblyopia questions through two surveys, verbal feedback, and interviews about their experience with our VR video game Amblyopia therapy. We found patterns encoded in this information, which we use to create preliminary hypotheses for making VR experiences as usable as possible for people with Amblyopia.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'accessibility, amblyopia, game design, serious video games, therapy, usability, virtual reality', 'numpages': '3', 'pages': '706–708', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Amblyopia, or ""lazy eye"" is the world\'s most common neurological eye disorder. Yet, very little has been done looking into how to make virtual reality (VR) more usable for people with Amblyopia. Furthermore, a trend of using VR for Amblyopia therapy has arisen, making such a study more essential than ever. Our study asks our user base of people with Amblyopia questions through two surveys, verbal feedback, and interviews about their experience with our VR video game Amblyopia therapy. We found patterns encoded in this information, which we use to create preliminary hypotheses for making VR experiences as usable as possible for people with Amblyopia.', 'doi': '10.1145/3308561.3356110', 'url': 'https://doi.org/10.1145/3308561.3356110', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Insights for More Usable VR for People with Amblyopia', 'author': 'Hurd, Ocean and Kurniawan, Sri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356110'}"
Exploring Haptic Colour Identification Aids,10.1145/3308561.3356111,"Colour identification is an important component of perception, but people with Colour Vision Deficiency (CVD) have trouble with colour identification tasks. Haptic colour identification aids exist but are slow to learn. To address this, we developed two new colour identification aids - ColourWrist and ColourVest. Colour-Wrist is a wrist-based aid that maps any single RGB input to 16 unique colour category patterns displayed on the wrist using four solenoids and a vibration motor. ColourVest is a back-based aid that uses a back-mounted 10 x 8 2D vibrotactile array to notify the user of the general location of a user-selected colour category (of 16 possible choices). We compared both tools to a control condition with two participants with CVD, and show that participants found ColourWrist and ColourVest ""intuitive"" and ""useful"". Based on participants' feedback, we next plan improvements for ColourWrist and ColourVest, as well as plan to study how they perform in real-world applications.","{'series': ""ASSETS '19"", 'location': 'Pittsburgh, PA, USA', 'keywords': 'colour identification, colour vision deficiency, haptic output', 'numpages': '3', 'pages': '709–711', 'booktitle': 'Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Colour identification is an important component of perception, but people with Colour Vision Deficiency (CVD) have trouble with colour identification tasks. Haptic colour identification aids exist but are slow to learn. To address this, we developed two new colour identification aids - ColourWrist and ColourVest. Colour-Wrist is a wrist-based aid that maps any single RGB input to 16 unique colour category patterns displayed on the wrist using four solenoids and a vibration motor. ColourVest is a back-based aid that uses a back-mounted 10 x 8 2D vibrotactile array to notify the user of the general location of a user-selected colour category (of 16 possible choices). We compared both tools to a control condition with two participants with CVD, and show that participants found ColourWrist and ColourVest ""intuitive"" and ""useful"". Based on participants\' feedback, we next plan improvements for ColourWrist and ColourVest, as well as plan to study how they perform in real-world applications.', 'doi': '10.1145/3308561.3356111', 'url': 'https://doi.org/10.1145/3308561.3356111', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366762', 'year': '2019', 'title': 'Exploring Haptic Colour Identification Aids', 'author': 'Nguyen, Richard and Geddes, Connor', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3308561.3356111'}"