Title,DOI,Abstract,BibTeX
Universal designs versus assistive technologies: research agendas and practical applications,10.1145/1090785.1090788,Abstract not available,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'universal design, research and practice, assistive technologies', 'numpages': '2', 'pages': '2–3', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1090785.1090788', 'url': 'https://doi.org/10.1145/1090785.1090788', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Universal designs versus assistive technologies: research agendas and practical applications', 'author': 'Law, Chris and Jacko, Julie and Peterson, Bill and Tobias, Jim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090788'}"
What help do older people need? constructing a functional design space of electronic assistive technology applications,10.1145/1090785.1090790,"In times of ageing populations and shrinking care resources, electronic assistive technology (EAT) has the potential of contributing to guaranteeing frail older people a continued high quality of life. This paper provides users and designers of EAT with an instrument for choosing and producing relevant and useful EAT applications in the form of a functional design space. We present the field study that led to the design space, and give advice on using the tool.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'user involvement, software components, older adults, needs, interactive agents, field study, design space', 'numpages': '8', 'pages': '4–11', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In times of ageing populations and shrinking care resources, electronic assistive technology (EAT) has the potential of contributing to guaranteeing frail older people a continued high quality of life. This paper provides users and designers of EAT with an instrument for choosing and producing relevant and useful EAT applications in the form of a functional design space. We present the field study that led to the design space, and give advice on using the tool.', 'doi': '10.1145/1090785.1090790', 'url': 'https://doi.org/10.1145/1090785.1090790', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'What help do older people need? constructing a functional design space of electronic assistive technology applications', 'author': 'Maciuszek, Dennis and Aberg, Johan and Shahmehri, Nahid', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090790'}"
An exploratory investigation of handheld computer interaction for older adults with visual impairments,10.1145/1090785.1090791,"This study explores factors affecting handheld computer interaction for older adults with Age-related Macular Degeneration (AMD). This is largely uncharted territory, as empirical investigations of human-computer interaction (HCI) concerning users with visual dysfunction and/or older adults have focused primarily on desktop computers. For this study, participants with AMD and visually-healthy controls used a handheld computer to search, select and manipulate familiar playing card icons under varied icon set sizes, inter-icon spacing and auditory feedback conditions. While all participants demonstrated a high rate of task completion, linear regression revealed several relationships between task efficiency and the interface, user characteristics and ocular factors. Two ocular measures, severity of AMD and contrast sensitivity, were found to be highly predictive of efficiency. The outcomes of this work reveal that users with visual impairments can effectively interact with GUIs on small displays in the presence of low-cost, easily implemented design interventions. This study presents a rich data set and is intended to inspire future work exploring the interactions of individuals with visual impairments with non-traditional information technology platforms, such as handheld computers.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'visual impairment, older adults, mobile computing, macular degeneration, icons, drag and drop, dpacing, auditory feedback', 'numpages': '8', 'pages': '12–19', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study explores factors affecting handheld computer interaction for older adults with Age-related Macular Degeneration (AMD). This is largely uncharted territory, as empirical investigations of human-computer interaction (HCI) concerning users with visual dysfunction and/or older adults have focused primarily on desktop computers. For this study, participants with AMD and visually-healthy controls used a handheld computer to search, select and manipulate familiar playing card icons under varied icon set sizes, inter-icon spacing and auditory feedback conditions. While all participants demonstrated a high rate of task completion, linear regression revealed several relationships between task efficiency and the interface, user characteristics and ocular factors. Two ocular measures, severity of AMD and contrast sensitivity, were found to be highly predictive of efficiency. The outcomes of this work reveal that users with visual impairments can effectively interact with GUIs on small displays in the presence of low-cost, easily implemented design interventions. This study presents a rich data set and is intended to inspire future work exploring the interactions of individuals with visual impairments with non-traditional information technology platforms, such as handheld computers.', 'doi': '10.1145/1090785.1090791', 'url': 'https://doi.org/10.1145/1090785.1090791', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'An exploratory investigation of handheld computer interaction for older adults with visual impairments', 'author': 'Leonard, V. Kathlene and Jacko, Julie A. and Pizzimenti, Joseph J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090791'}"
Programmer-focused website accessibility evaluations,10.1145/1090785.1090792,"Suggested methods for conducting website accessibility evaluations have typically focused on the needs of end-users who have disabilities. However, programmers, not people with disabilities, are the end-users of evaluations reports generated by accessibility specialists. Programmers' capacity and resource needs are seldom met by the voluminous reports and long lists of individual website fixes commonly produced using earlier methods. The rationale for the need to consider the whole website development process, and the social characteristics of programmers and project managers is presented. A new programmer-centric Streamlined Evaluation and Reporting Process for Accessibility (SERPA) is described in detail.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'reporting, internet, evaluation, accessibility', 'numpages': '8', 'pages': '20–27', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Suggested methods for conducting website accessibility evaluations have typically focused on the needs of end-users who have disabilities. However, programmers, not people with disabilities, are the end-users of evaluations reports generated by accessibility specialists. Programmers' capacity and resource needs are seldom met by the voluminous reports and long lists of individual website fixes commonly produced using earlier methods. The rationale for the need to consider the whole website development process, and the social characteristics of programmers and project managers is presented. A new programmer-centric Streamlined Evaluation and Reporting Process for Accessibility (SERPA) is described in detail."", 'doi': '10.1145/1090785.1090792', 'url': 'https://doi.org/10.1145/1090785.1090792', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Programmer-focused website accessibility evaluations', 'author': 'Law, Chris and Jacko, Julie and Edwards, Paula', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090792'}"
The information-theoretic analysis of unimodal interfaces and their multimodal counterparts,10.1145/1090785.1090793,"That multimodal interfaces have benefits over unimodal ones has often been asserted. Several such benefits have been described informally, but, to date, few have actually been formalized or quantified. In this paper, the hypothesized benefits of semantically redundant multimodal input actions are described formally and are quantified using the formalisms provided by Information Theory. A reinterpretation of Keates and Robinson's empirical data (1998) shows that their criticism of multimodal interfaces was, in part, unfounded.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'voice output communication aids (VOCA), speech generating devices (SGD), multimodal interfaces, interventions for communication disorders, interface evaluation, augmentative and alternative communication (AAC)', 'numpages': '8', 'pages': '28–35', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""That multimodal interfaces have benefits over unimodal ones has often been asserted. Several such benefits have been described informally, but, to date, few have actually been formalized or quantified. In this paper, the hypothesized benefits of semantically redundant multimodal input actions are described formally and are quantified using the formalisms provided by Information Theory. A reinterpretation of Keates and Robinson's empirical data (1998) shows that their criticism of multimodal interfaces was, in part, unfounded."", 'doi': '10.1145/1090785.1090793', 'url': 'https://doi.org/10.1145/1090785.1090793', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'The information-theoretic analysis of unimodal interfaces and their multimodal counterparts', 'author': 'Baljko, Melanie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090793'}"
Wizard-of-Oz test of ARTUR: a computer-based speech training system with articulation correction,10.1145/1090785.1090795,"This study has been performed in order to test the human-machine interface of a computer-based speech training aid named ARTUR with the main feature that it can give suggestions on how to improve articulation. Two user groups were involved: three children aged 9-14 with extensive experience of speech training, and three children aged 6. All children had general language disorders.The study indicates that the present interface is usable without prior training or instructions, even for the younger children, although it needs some improvement to fit illiterate children. The granularity of the mesh that classifies mispronunciations was satisfactory, but can be developed further.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'user interface, computer-based speech training system, Wizard-of-Oz', 'numpages': '8', 'pages': '36–43', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study has been performed in order to test the human-machine interface of a computer-based speech training aid named ARTUR with the main feature that it can give suggestions on how to improve articulation. Two user groups were involved: three children aged 9-14 with extensive experience of speech training, and three children aged 6. All children had general language disorders.The study indicates that the present interface is usable without prior training or instructions, even for the younger children, although it needs some improvement to fit illiterate children. The granularity of the mesh that classifies mispronunciations was satisfactory, but can be developed further.', 'doi': '10.1145/1090785.1090795', 'url': 'https://doi.org/10.1145/1090785.1090795', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Wizard-of-Oz test of ARTUR: a computer-based speech training system with articulation correction', 'author': 'B\\""{a}lter, Olle and Engwall, Olov and \\""{O}ster, Anne-Marie and Kjellstr\\""{o}m, Hedvig', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090795'}"
Representing coordination and non-coordination in an american sign language animation,10.1145/1090785.1090796,"While strings and syntax trees are used by the Natural Language Processing community to represent the structure of spoken languages, these encodings are difficult to adapt to a signed language like American Sign Language (ASL). In particular, the multichannel nature of an ASL performance makes it difficult to encode in a linear single-channel string. This paper will introduce the Partition/Constitute (P/C) Formalism, a new method of computationally representing a linguistic signal containing multiple channels. The formalism allows coordination and non-coordination relationships to be encoded between different portions of a signal. The P/C formalism will be compared to representations used in related research in gesture animation. The way in which P/C is used by this project to build an English-to-ASL machine translation system will also be discussed.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'multimodal generation, gesture generation, american sign language, accessibility technology for the deaf', 'numpages': '8', 'pages': '44–51', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'While strings and syntax trees are used by the Natural Language Processing community to represent the structure of spoken languages, these encodings are difficult to adapt to a signed language like American Sign Language (ASL). In particular, the multichannel nature of an ASL performance makes it difficult to encode in a linear single-channel string. This paper will introduce the Partition/Constitute (P/C) Formalism, a new method of computationally representing a linguistic signal containing multiple channels. The formalism allows coordination and non-coordination relationships to be encoded between different portions of a signal. The P/C formalism will be compared to representations used in related research in gesture animation. The way in which P/C is used by this project to build an English-to-ASL machine translation system will also be discussed.', 'doi': '10.1145/1090785.1090796', 'url': 'https://doi.org/10.1145/1090785.1090796', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Representing coordination and non-coordination in an american sign language animation', 'author': 'Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090796'}"
Visualizing non-speech sounds for the deaf,10.1145/1090785.1090797,"Sounds constantly occur around us, keeping us aware of our surroundings. People who are deaf have difficulty maintaining an awareness of these ambient sounds. We present an investigation of peripheral, visual displays to help people who are deaf maintain an awareness of sounds in the environment. Our contribution is twofold. First, we present a set of visual design preferences and functional requirements for peripheral visualizations of non-speech audio that will help improve future applications. Visual design preferences include ease of interpretation, glance-ability, and appropriate distractions. Functional requirements include the ability to identify what sound occurred, view a history of displayed sounds, customize the information that is shown, and determine the accuracy of displayed information. Second, we designed, implemented, and evaluated two fully functioning prototypes that embody these preferences and requirements, serving as examples for future designers and furthering progress toward understanding how to best provide peripheral audio awareness for the deaf.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'sound visualization, peripheral display, deaf', 'numpages': '8', 'pages': '52–59', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sounds constantly occur around us, keeping us aware of our surroundings. People who are deaf have difficulty maintaining an awareness of these ambient sounds. We present an investigation of peripheral, visual displays to help people who are deaf maintain an awareness of sounds in the environment. Our contribution is twofold. First, we present a set of visual design preferences and functional requirements for peripheral visualizations of non-speech audio that will help improve future applications. Visual design preferences include ease of interpretation, glance-ability, and appropriate distractions. Functional requirements include the ability to identify what sound occurred, view a history of displayed sounds, customize the information that is shown, and determine the accuracy of displayed information. Second, we designed, implemented, and evaluated two fully functioning prototypes that embody these preferences and requirements, serving as examples for future designers and furthering progress toward understanding how to best provide peripheral audio awareness for the deaf.', 'doi': '10.1145/1090785.1090797', 'url': 'https://doi.org/10.1145/1090785.1090797', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Visualizing non-speech sounds for the deaf', 'author': 'Matthews, Tara and Fong, Janette and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090797'}"
Accuracy and frequency analysis of multitouch interfaces for individuals with Parkinsonian and essential hand tremor,10.1145/1090785.1090799,"In this study, the accuracy of an optical mouse, optical trackball, isotonic joystick, and a FingerWorks MultiTouch Surface (MTS) are compared for users suffering from Parkinsonian tremor and essential tremor. Using a data acquisition program, WinFitts, created at the University of Oregon's HCI Lab, data collected from five subjects with Parkinsonian tremor, five with essential tremor, and eleven with no tremor is analyzed and compared. Both temporal and spatial analyses are obtained from all of the subject data. The time-based measures of performance for each device include the uses of Fitts' law and the Proximity Movement Time, while the spatially-based measures include the use of the Deviation Accuracy and the Click Histogram. A statistical analysis is performed using a t-test to show the differences between the resulting means of some of the measures. By using the MUSIC spectral estimation technique, an analysis of the frequency and the amplitude of the tremor showed how certain devices performed in hand tremor suppression.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': ""multitouch surfaces, human-computer interaction, essential tremor, Parkinson's disease, Fitts' law"", 'numpages': '8', 'pages': '60–67', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this study, the accuracy of an optical mouse, optical trackball, isotonic joystick, and a FingerWorks MultiTouch Surface (MTS) are compared for users suffering from Parkinsonian tremor and essential tremor. Using a data acquisition program, WinFitts, created at the University of Oregon's HCI Lab, data collected from five subjects with Parkinsonian tremor, five with essential tremor, and eleven with no tremor is analyzed and compared. Both temporal and spatial analyses are obtained from all of the subject data. The time-based measures of performance for each device include the uses of Fitts' law and the Proximity Movement Time, while the spatially-based measures include the use of the Deviation Accuracy and the Click Histogram. A statistical analysis is performed using a t-test to show the differences between the resulting means of some of the measures. By using the MUSIC spectral estimation technique, an analysis of the frequency and the amplitude of the tremor showed how certain devices performed in hand tremor suppression."", 'doi': '10.1145/1090785.1090799', 'url': 'https://doi.org/10.1145/1090785.1090799', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Accuracy and frequency analysis of multitouch interfaces for individuals with Parkinsonian and essential hand tremor', 'author': 'Frett, Eric J. and Barner, Kenneth E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090799'}"
Effect of age and Parkinson's disease on cursor positioning using a mouse,10.1145/1090785.1090800,"Point-and-click tasks are known to present difficulties to users with physical impairments, particularly motor- or vision-based, and to older adults. This paper presents the results of a study to quantify and understand the effects of age and impairment on the ability to perform such tasks. Results from four separate user groups are presented and compared using metrics that describe the features of the movements made. Distinct differences in behaviour between all of the user groups are observed and the reasons for those differences are discussed.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'performance measurement, mouse, disability, cursor positioning tasks, cursor, age', 'numpages': '8', 'pages': '68–75', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Point-and-click tasks are known to present difficulties to users with physical impairments, particularly motor- or vision-based, and to older adults. This paper presents the results of a study to quantify and understand the effects of age and impairment on the ability to perform such tasks. Results from four separate user groups are presented and compared using metrics that describe the features of the movements made. Distinct differences in behaviour between all of the user groups are observed and the reasons for those differences are discussed.', 'doi': '10.1145/1090785.1090800', 'url': 'https://doi.org/10.1145/1090785.1090800', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': ""Effect of age and Parkinson's disease on cursor positioning using a mouse"", 'author': 'Keates, Simeon and Trewin, Shari', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090800'}"
The migratory cursor: accurate speech-based cursor movement by moving multiple ghost cursors using non-verbal vocalizations,10.1145/1090785.1090801,"We present the migratory cursor, which is an interactive interface that enables users to move a cursor to any desired position quickly and accurately using voice alone. The migratory cursor combines discrete specification that allows a user to specify a location quickly, but approximately, with continuous specification that allows the user to specify a location more precisely, but slowly. The migratory cursor displays multiple ghost cursors that are aligned vertically or horizontally with the actual cursor. The user quickly specifies an approximate position by referring to the ghost cursor nearest the desired position, and then uses non-verbal vocalizations to move the ghost cursors continuously until one is on the desired position. The time spent using the continuous specification which is slow to use is short, since it is used just for fine refinement. In addition, the migratory cursor employs only two directional movements: vertical and horizontal, so that the user can move it quickly to any desired position. Moreover, the user can easily and accurately stop cursor movements by becoming silent when the cursor reaches the desired position. We tested the usefulness of the migratory cursor, and showed that users could move the cursor to a desired position quickly and accurately.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'speech-based cursor movement, non-verbal voice input', 'numpages': '8', 'pages': '76–83', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present the migratory cursor, which is an interactive interface that enables users to move a cursor to any desired position quickly and accurately using voice alone. The migratory cursor combines discrete specification that allows a user to specify a location quickly, but approximately, with continuous specification that allows the user to specify a location more precisely, but slowly. The migratory cursor displays multiple ghost cursors that are aligned vertically or horizontally with the actual cursor. The user quickly specifies an approximate position by referring to the ghost cursor nearest the desired position, and then uses non-verbal vocalizations to move the ghost cursors continuously until one is on the desired position. The time spent using the continuous specification which is slow to use is short, since it is used just for fine refinement. In addition, the migratory cursor employs only two directional movements: vertical and horizontal, so that the user can move it quickly to any desired position. Moreover, the user can easily and accurately stop cursor movements by becoming silent when the cursor reaches the desired position. We tested the usefulness of the migratory cursor, and showed that users could move the cursor to a desired position quickly and accurately.', 'doi': '10.1145/1090785.1090801', 'url': 'https://doi.org/10.1145/1090785.1090801', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'The migratory cursor: accurate speech-based cursor movement by moving multiple ghost cursors using non-verbal vocalizations', 'author': 'Mihara, Yoshiyuki and Shibayama, Etsuya and Takahashi, Shin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090801'}"
"Toward Goldilocks' pointing device: determining a ""just right"" gain setting for users with physical impairments",10.1145/1090785.1090802,"We designed and evaluated an agent that recommends a pointing device gain for a given user, with mixed success. 12 participants with physical impairments used the Input Device Agent (IDA), to determine a recommended gain based on their performance over a series of target acquisition trials. IDA recommended a gain other than the Windows default for 9 of 12 subjects. Subsequent performance using the IDA gain showed no meaningful differences as compared to the default setting or users' pre-study settings. Across all gains used by these subjects, however, gain did have a significant effect on throughput, percent of error-free trials, cursor entries, and overshoot. Linear models of gain's effect on performance showed that its effect on throughput is relatively small, with only a 13\% difference from highest throughput (at gain = 10) to lowest throughput (at gain = 6). Cursor entries were more strongly affected, showing a steady increase with increasing gain.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'physical impairment, computer pointing devices, assistive technology, adaptive computer interfaces', 'numpages': '6', 'pages': '84–89', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We designed and evaluated an agent that recommends a pointing device gain for a given user, with mixed success. 12 participants with physical impairments used the Input Device Agent (IDA), to determine a recommended gain based on their performance over a series of target acquisition trials. IDA recommended a gain other than the Windows default for 9 of 12 subjects. Subsequent performance using the IDA gain showed no meaningful differences as compared to the default setting or users' pre-study settings. Across all gains used by these subjects, however, gain did have a significant effect on throughput, percent of error-free trials, cursor entries, and overshoot. Linear models of gain's effect on performance showed that its effect on throughput is relatively small, with only a 13\\% difference from highest throughput (at gain = 10) to lowest throughput (at gain = 6). Cursor entries were more strongly affected, showing a steady increase with increasing gain."", 'doi': '10.1145/1090785.1090802', 'url': 'https://doi.org/10.1145/1090785.1090802', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Toward Goldilocks\' pointing device: determining a ""just right"" gain setting for users with physical impairments', 'author': 'Koester, Heidi Horstmann and LoPresti, Edmund and Simpson, Richard C.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090802'}"
Gist summaries for visually impaired surfers,10.1145/1090785.1090804,"Anecdotal evidence suggests that Web document summaries provide the sighted reader with a basis for making decisions regarding the route to take within non-linear text; and additional research shows that sighted people use 'Gist' summaries as decision points to bolster their browsing behaviour. Other studies have found that visually impaired users are hindered in their cognition of the content of Web-pages because users must wait for an entire Web-page to be read before deciding on it's usefulness to their current task. In these cases, we draw similarities between sighted and visually impaired users, in that sighted users cannot see the target of a Web Anchor and are therefore 'handicapped'1 by the technology. Previously, we have investigate four simple summarisation algorithms against each other and a manually created summary; producing empirical evidence as a formative evaluation. This evaluation concludes that users prefer simple automatically generated 'gist' summaries thereby reducing cognitive overload and increasing awareness of the focus of the Web-page under investigation. In this paper we focus on the development of 'FireFox' based tool which creates a summary of a Web page 'on-the-fly'. The algorithm used to create this summary is based on the results of our formative evaluation which automatically and dynamically annotates Web pages with the generated 'gist' summary. In this way visually impaired users are supported in their decisions as the relevancy of the page at hand.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'web, visual impairment, tools, document engineering', 'numpages': '8', 'pages': '90–97', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Anecdotal evidence suggests that Web document summaries provide the sighted reader with a basis for making decisions regarding the route to take within non-linear text; and additional research shows that sighted people use 'Gist' summaries as decision points to bolster their browsing behaviour. Other studies have found that visually impaired users are hindered in their cognition of the content of Web-pages because users must wait for an entire Web-page to be read before deciding on it's usefulness to their current task. In these cases, we draw similarities between sighted and visually impaired users, in that sighted users cannot see the target of a Web Anchor and are therefore 'handicapped'1 by the technology. Previously, we have investigate four simple summarisation algorithms against each other and a manually created summary; producing empirical evidence as a formative evaluation. This evaluation concludes that users prefer simple automatically generated 'gist' summaries thereby reducing cognitive overload and increasing awareness of the focus of the Web-page under investigation. In this paper we focus on the development of 'FireFox' based tool which creates a summary of a Web page 'on-the-fly'. The algorithm used to create this summary is based on the results of our formative evaluation which automatically and dynamically annotates Web pages with the generated 'gist' summary. In this way visually impaired users are supported in their decisions as the relevancy of the page at hand."", 'doi': '10.1145/1090785.1090804', 'url': 'https://doi.org/10.1145/1090785.1090804', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Gist summaries for visually impaired surfers', 'author': 'Harper, Simon and Patel, Neha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090804'}"
Talking braille: a wireless ubiquitous computing network for orientation and wayfinding,10.1145/1090785.1090805,"An ubiquitous computing network is being developed to assist persons with vision loss in finding their way around buildings and other indoor public spaces. It is based on the ""Cyber Crumb"" concept: the idea that tiny, inexpensive solar-powered digital chips can be used to store relevant pieces of information that can be placed along building walkways like a trail of crumbs to follow. A wireless network of ""crumbs"" provides access from any point in the building to a central server that provides orientation and wayfinding information. Initial hardware and consumer tests verify feasibility and benefit.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'wayfinding, orientation, mobility aid, blindness', 'numpages': '8', 'pages': '98–105', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'An ubiquitous computing network is being developed to assist persons with vision loss in finding their way around buildings and other indoor public spaces. It is based on the ""Cyber Crumb"" concept: the idea that tiny, inexpensive solar-powered digital chips can be used to store relevant pieces of information that can be placed along building walkways like a trail of crumbs to follow. A wireless network of ""crumbs"" provides access from any point in the building to a central server that provides orientation and wayfinding information. Initial hardware and consumer tests verify feasibility and benefit.', 'doi': '10.1145/1090785.1090805', 'url': 'https://doi.org/10.1145/1090785.1090805', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Talking braille: a wireless ubiquitous computing network for orientation and wayfinding', 'author': 'Ross, David A. and Lightman, Alexander', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090805'}"
A wearable face recognition system for individuals with visual impairments,10.1145/1090785.1090806,"This paper describes the iCare Interaction Assistant, an assistive device for helping the individuals who are visually impaired during social interactions. The research presented here addresses the problems encountered in implementing real-time face recognition algorithms on a wearable device. Face recognition is the initial step towards building a comprehensive social interaction assistant that will identify and interpret facial expressions, emotions and gestures. Experiments conducted for selecting a face recognition algorithm that works despite changes in facial pose and illumination angle are reported. Performance details of the face recognition algorithms tested on the device are presented along with the overall performance of the system. The specifics of the hardware components used in the wearable device are mentioned and the block diagram of the wearable system is explained in detail.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'wearable computing, social interaction aide, face recognition, assistive device for visually impaired', 'numpages': '8', 'pages': '106–113', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes the iCare Interaction Assistant, an assistive device for helping the individuals who are visually impaired during social interactions. The research presented here addresses the problems encountered in implementing real-time face recognition algorithms on a wearable device. Face recognition is the initial step towards building a comprehensive social interaction assistant that will identify and interpret facial expressions, emotions and gestures. Experiments conducted for selecting a face recognition algorithm that works despite changes in facial pose and illumination angle are reported. Performance details of the face recognition algorithms tested on the device are presented along with the overall performance of the system. The specifics of the hardware components used in the wearable device are mentioned and the block diagram of the wearable system is explained in detail.', 'doi': '10.1145/1090785.1090806', 'url': 'https://doi.org/10.1145/1090785.1090806', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'A wearable face recognition system for individuals with visual impairments', 'author': 'Krishna, Sreekar and Little, Greg and Black, John and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090806'}"
Sparsha: a comprehensive indian language toolset for the blind,10.1145/1090785.1090807,"Braille and audio feedback based systems have vastly improved the lives of the visually impaired across a wide majority of the globe. However, more than 13 million visually impaired people in the Indian sub-continent could not benefit much from such systems. This was primarily due to the difference in the technology required for Indian languages compared to those corresponding to other popular languages of the world. In this paper, we describe the Sparsha toolset. The contribution made by this research has enabled the visually impaired to read and write in Indian vernaculars with the help of a computer.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'visual impairment, braille, audio feedback, Indian languages', 'numpages': '7', 'pages': '114–120', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Braille and audio feedback based systems have vastly improved the lives of the visually impaired across a wide majority of the globe. However, more than 13 million visually impaired people in the Indian sub-continent could not benefit much from such systems. This was primarily due to the difference in the technology required for Indian languages compared to those corresponding to other popular languages of the world. In this paper, we describe the Sparsha toolset. The contribution made by this research has enabled the visually impaired to read and write in Indian vernaculars with the help of a computer.', 'doi': '10.1145/1090785.1090807', 'url': 'https://doi.org/10.1145/1090785.1090807', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Sparsha: a comprehensive indian language toolset for the blind', 'author': 'Lahiri, Anirban and Chattopadhyay, Satya Jyoti and Basu, Anupam', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090807'}"
Semantic knowledge in word completion,10.1145/1090785.1090809,"We propose an integrated approach to interactive word-completion for users with linguistic disabilities in which semantic knowledge combines with $n$-gram probabilities to predict semantically more-appropriate words than $n$-gram methods alone. First, semantic relatives are found for English words, specifically for nouns, and they form the semantic knowledge base. The selection process for these semantically related words is first to rank the pointwise mutual information of co-occurring words in a large corpus and then to identify the semantic relatedness of these words by a Lesk-like filter. Then, the semantic knowledge is used to measure the semantic association of completion candidates with the context. Those that are semantically appropriate to the context are promoted to the top positions in prediction lists due to their high association with context. Experimental results show a performance improvement when using the integrated model for the completion of nouns.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'word completion, pointwise mutual information, linguistic semantics', 'numpages': '8', 'pages': '121–128', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We propose an integrated approach to interactive word-completion for users with linguistic disabilities in which semantic knowledge combines with $n$-gram probabilities to predict semantically more-appropriate words than $n$-gram methods alone. First, semantic relatives are found for English words, specifically for nouns, and they form the semantic knowledge base. The selection process for these semantically related words is first to rank the pointwise mutual information of co-occurring words in a large corpus and then to identify the semantic relatedness of these words by a Lesk-like filter. Then, the semantic knowledge is used to measure the semantic association of completion candidates with the context. Those that are semantically appropriate to the context are promoted to the top positions in prediction lists due to their high association with context. Experimental results show a performance improvement when using the integrated model for the completion of nouns.', 'doi': '10.1145/1090785.1090809', 'url': 'https://doi.org/10.1145/1090785.1090809', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Semantic knowledge in word completion', 'author': 'Li, Jianhua and Hirst, Graeme', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090809'}"
Research-derived web design guidelines for older people,10.1145/1090785.1090810,"This paper presents the development of a set of research-derived ageing-centred Web design guidelines. An initial set of guidelines was first developed through an extensive review of the HCI and ageing literature and through employing a series of classification methods (card sorting and affinity diagrams) were employed as a means for obtaining a revised and more robust set of guidelines. A group of older Web users were then involved in evaluating the usefulness of the guidelines. To provide evaluation context for these users, two websites targeted to older people were used. This study makes several contributions to the field. First, it is perhaps the first manuscript that proposes ageing-friendly guidelines that are for most part backed by published studies. Second, the guidelines proposed in this study have been thoroughly examined through a series of expert and user verifications, which should give users of these guidelines confidence of their validity.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'web design guidelines, seniors, elderly, ageing, HCI', 'numpages': '7', 'pages': '129–135', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents the development of a set of research-derived ageing-centred Web design guidelines. An initial set of guidelines was first developed through an extensive review of the HCI and ageing literature and through employing a series of classification methods (card sorting and affinity diagrams) were employed as a means for obtaining a revised and more robust set of guidelines. A group of older Web users were then involved in evaluating the usefulness of the guidelines. To provide evaluation context for these users, two websites targeted to older people were used. This study makes several contributions to the field. First, it is perhaps the first manuscript that proposes ageing-friendly guidelines that are for most part backed by published studies. Second, the guidelines proposed in this study have been thoroughly examined through a series of expert and user verifications, which should give users of these guidelines confidence of their validity.', 'doi': '10.1145/1090785.1090810', 'url': 'https://doi.org/10.1145/1090785.1090810', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Research-derived web design guidelines for older people', 'author': 'Kurniawan, Sri and Zaphiris, Panayiotis', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090810'}"
Autism/excel study,10.1145/1090785.1090811,"Five high school students with ASD (autistic spectrum disorder) participating in the Excel/Autism study were able to demonstrate mastery of a set of Excel topics. The Excel curriculum covered approximately the same topics as are covered in the Excel portion of Computer Business Applications, a class for regular education students at Fox Chapel Area High School, a high school in suburban Pittsburgh. The students with ASD were provided with one-on-one tutoring support. Two of the five ASD participants self-initiated activities and engaged in generative thinking to a substantial degree over the course of the eight instructional sessions for which data was recorded. Two others demonstrated lesser amounts of this behavior, and one participant did not demonstrate any. The ASD experimental participants, as compared to a treatment group of three students with ASD who did not receive instruction in Excel, demonstrated improvement in a multi-step planning task which was significant.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'spreadsheets, multi-step planning, generative thinking, autism, adapted computer curriculum', 'numpages': '6', 'pages': '136–141', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Five high school students with ASD (autistic spectrum disorder) participating in the Excel/Autism study were able to demonstrate mastery of a set of Excel topics. The Excel curriculum covered approximately the same topics as are covered in the Excel portion of Computer Business Applications, a class for regular education students at Fox Chapel Area High School, a high school in suburban Pittsburgh. The students with ASD were provided with one-on-one tutoring support. Two of the five ASD participants self-initiated activities and engaged in generative thinking to a substantial degree over the course of the eight instructional sessions for which data was recorded. Two others demonstrated lesser amounts of this behavior, and one participant did not demonstrate any. The ASD experimental participants, as compared to a treatment group of three students with ASD who did not receive instruction in Excel, demonstrated improvement in a multi-step planning task which was significant.', 'doi': '10.1145/1090785.1090811', 'url': 'https://doi.org/10.1145/1090785.1090811', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Autism/excel study', 'author': 'Hart, Mary', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090811'}"
Requirements gathering with alzheimer's patients and caregivers,10.1145/1090785.1090812,"Technology may be able to play a role in improving the quality of life for Alzheimer's patients and their caregivers. We are evaluating the feasibility of an information appliance with the goal of alleviating repetitive questioning behaviour, a contributing factor to caregiver stress. Interviews were conducted with persons with Alzheimer's disease and their caregivers to determine the nature of the repetitive questioning behaviour, the information needs of patients, and the interaction abilities of both the patients and the caregivers. We report results of these interviews and discuss the challenges of requirements gathering with persons with Alzheimer's disease and the feasibility of introducing an information appliance to this population.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': ""user-centered design, information appliance, cognitive aging, assistive technology, alzheimer's disease"", 'numpages': '8', 'pages': '142–149', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Technology may be able to play a role in improving the quality of life for Alzheimer's patients and their caregivers. We are evaluating the feasibility of an information appliance with the goal of alleviating repetitive questioning behaviour, a contributing factor to caregiver stress. Interviews were conducted with persons with Alzheimer's disease and their caregivers to determine the nature of the repetitive questioning behaviour, the information needs of patients, and the interaction abilities of both the patients and the caregivers. We report results of these interviews and discuss the challenges of requirements gathering with persons with Alzheimer's disease and the feasibility of introducing an information appliance to this population."", 'doi': '10.1145/1090785.1090812', 'url': 'https://doi.org/10.1145/1090785.1090812', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': ""Requirements gathering with alzheimer's patients and caregivers"", 'author': 'Hawkey, Kirstie and Inkpen, Kori M. and Rockwood, Kenneth and McAllister, Michael and Slonim, Jacob', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090812'}"
Automating tactile graphics translation,10.1145/1090785.1090814,"Access to graphical images (bar charts, diagrams, line graphs, etc.) that are in a tactile form (representation through which content can be accessed by touch) is inadequate for students who are blind and take mathematics, science, and engineering courses. We describe our analysis of the current work practices of tactile graphics specialists who create tactile forms of graphical images. We propose automated means by which to improve the efficiency of current work practices.We describe the implementation of various components of this new automated process, which includes image classification, segmentation, simplification, and layout. We summarize our development of the tactile graphics assistant, which will enable tactile graphics specialists to be more efficient in creating tactile graphics both in batches and individually. We describe our unique team of researchers, practitioners, and student consultants who are blind, all of whom are needed to successfully develop this new way of translating tactile graphics.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'user study, tactile graphics, machine learning, image processing, disability, braille, accessibility', 'numpages': '8', 'pages': '150–157', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Access to graphical images (bar charts, diagrams, line graphs, etc.) that are in a tactile form (representation through which content can be accessed by touch) is inadequate for students who are blind and take mathematics, science, and engineering courses. We describe our analysis of the current work practices of tactile graphics specialists who create tactile forms of graphical images. We propose automated means by which to improve the efficiency of current work practices.We describe the implementation of various components of this new automated process, which includes image classification, segmentation, simplification, and layout. We summarize our development of the tactile graphics assistant, which will enable tactile graphics specialists to be more efficient in creating tactile graphics both in batches and individually. We describe our unique team of researchers, practitioners, and student consultants who are blind, all of whom are needed to successfully develop this new way of translating tactile graphics.', 'doi': '10.1145/1090785.1090814', 'url': 'https://doi.org/10.1145/1090785.1090814', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Automating tactile graphics translation', 'author': 'Ladner, Richard E. and Ivory, Melody Y. and Rao, Rajesh and Burgstahler, Sheryl and Comden, Dan and Hahn, Sangyun and Renzelmann, Matthew and Krisnandi, Satria and Ramasamy, Mahalakshmi and Slabosky, Beverly and Martin, Andrew and Lacenski, Amelia and Olsen, Stuart and Groce, Dmitri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090814'}"
SmartColor: disambiguation framework for the colorblind,10.1145/1090785.1090815,"Failure in visual communication between the author and the colorblind reader is caused when color effects that the author expects for the reader to experience are not observed by the reader. The proposed framework allows the author to annotate his/her intended color effects to the colored document. They are used to generate a repainted document that let the colorblind enjoy similar color effects that normal color vision person does for the original document. The annotations are formulated as a set of mathematical constraints that can describe several commonly used color effects. Constraints are defined over the normal vision color space. Then they are projected onto the restricted color space that corresponds to the one that the colorblind perceives. Finally, the projected constraints are resolved for the search of best repainting of the document that most successfully presents to the colorblind person the color effects experienced by the normal vision person on the original document. Effectiveness of the proposal is shown by colorblind simulation.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'vision, constraint system, colorblindness', 'numpages': '8', 'pages': '158–165', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Failure in visual communication between the author and the colorblind reader is caused when color effects that the author expects for the reader to experience are not observed by the reader. The proposed framework allows the author to annotate his/her intended color effects to the colored document. They are used to generate a repainted document that let the colorblind enjoy similar color effects that normal color vision person does for the original document. The annotations are formulated as a set of mathematical constraints that can describe several commonly used color effects. Constraints are defined over the normal vision color space. Then they are projected onto the restricted color space that corresponds to the one that the colorblind perceives. Finally, the projected constraints are resolved for the search of best repainting of the document that most successfully presents to the colorblind person the color effects experienced by the normal vision person on the original document. Effectiveness of the proposal is shown by colorblind simulation.', 'doi': '10.1145/1090785.1090815', 'url': 'https://doi.org/10.1145/1090785.1090815', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'SmartColor: disambiguation framework for the colorblind', 'author': 'Wakita, Ken and Shimamura, Kenta', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090815'}"
Automatic production of tactile graphics from scalable vector graphics,10.1145/1090785.1090816,"This paper presents a method to convert vector graphics into tactile representations for the blind. Generating tactile pictures from vector graphics is an important effort to bring more accessibility to the WWW as well as other means of communications since vector graphics are an increasing trend in web based graphics. Prior research has investigated methods that extracts object boundaries from images to produce raised-line tactile pictures. The proposed method extends this idea for vector graphics, producing tactile pictures where important outlines are emphasized. Important outlines are determined by using the hierarchical structure of a vector graphic. A Braille printer is used where raised dots are embossed for the outlining boundaries. Important and detail boundaries are embossed with dots of larger and smaller height, respectively, while all other regions contain no raised dots. Results testing a person's ability to discriminate, identify, and comprehend tactile pictures shows the proposed methods' advantage over two other methods.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'tactile pictures, tactile images, scalable vector graphics, edge/boundary detection, braille embosser, blindness', 'numpages': '7', 'pages': '166–172', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper presents a method to convert vector graphics into tactile representations for the blind. Generating tactile pictures from vector graphics is an important effort to bring more accessibility to the WWW as well as other means of communications since vector graphics are an increasing trend in web based graphics. Prior research has investigated methods that extracts object boundaries from images to produce raised-line tactile pictures. The proposed method extends this idea for vector graphics, producing tactile pictures where important outlines are emphasized. Important outlines are determined by using the hierarchical structure of a vector graphic. A Braille printer is used where raised dots are embossed for the outlining boundaries. Important and detail boundaries are embossed with dots of larger and smaller height, respectively, while all other regions contain no raised dots. Results testing a person's ability to discriminate, identify, and comprehend tactile pictures shows the proposed methods' advantage over two other methods."", 'doi': '10.1145/1090785.1090816', 'url': 'https://doi.org/10.1145/1090785.1090816', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Automatic production of tactile graphics from scalable vector graphics', 'author': 'Krufka, Stephen E. and Barner, Kenneth E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090816'}"
3D sound interactive environments for problem solving,10.1145/1090785.1090817,"Audio-based virtual environments have been increasingly used to foster cognitive and learning skills. A number of studies have also highlighted that the use of technology can help learners to develop affective skills such as motivation and self-esteem. This study presents the design and usability of 3D interactive environments for children with visual disabilities to help them to solve problems related with the Chilean geography and culture. We introduce AudioChile, a virtual environment that can be navigated through 3D sound to enhance spatiality and immersion throughout the environment. 3D sound is used to orientate, avoid obstacles, and identify the position of diverse personages and objects within the environment. We have found during usability evaluation that sound can be fundamental for attention and motivation purposes during interaction. Learners identified and differentiated clearly environmental sounds to solve everyday problems, spatial orientation, and laterality.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'virtual world, role-playing game, problem solving, hyperstories, 3D sound', 'numpages': '7', 'pages': '173–179', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Audio-based virtual environments have been increasingly used to foster cognitive and learning skills. A number of studies have also highlighted that the use of technology can help learners to develop affective skills such as motivation and self-esteem. This study presents the design and usability of 3D interactive environments for children with visual disabilities to help them to solve problems related with the Chilean geography and culture. We introduce AudioChile, a virtual environment that can be navigated through 3D sound to enhance spatiality and immersion throughout the environment. 3D sound is used to orientate, avoid obstacles, and identify the position of diverse personages and objects within the environment. We have found during usability evaluation that sound can be fundamental for attention and motivation purposes during interaction. Learners identified and differentiated clearly environmental sounds to solve everyday problems, spatial orientation, and laterality.', 'doi': '10.1145/1090785.1090817', 'url': 'https://doi.org/10.1145/1090785.1090817', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': '3D sound interactive environments for problem solving', 'author': ""S\\'{a}nchez, Jaime and S\\'{a}enz, Mauricio"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090817'}"
Online focus groups used as an accessible participatory research method,10.1145/1090785.1090819,"Participatory research methods are being used internationally to gather data on complex social, cultural, and political concerns that effect the use of technology [4]. Researchers have found it difficult to include people with disabilities in these studies [5, 6, 7]. The Accessible Learning Through Text-to-Speech Project will utilize online focus groups as a method of integrating people with disabilities into a participatory research project. The Alt-Learning Project will have three primary target populations; users of screen readers with vision, users of screen readers who are blind, and professionals responsible for the delivery of assistive technology. The online focus groups will allow the observation and collection of data as a participant would normally utilize their screen reader applications at home, school, or workplace.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'universal accessibility, participatory research, accessibility', 'numpages': '2', 'pages': '180–181', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Participatory research methods are being used internationally to gather data on complex social, cultural, and political concerns that effect the use of technology [4]. Researchers have found it difficult to include people with disabilities in these studies [5, 6, 7]. The Accessible Learning Through Text-to-Speech Project will utilize online focus groups as a method of integrating people with disabilities into a participatory research project. The Alt-Learning Project will have three primary target populations; users of screen readers with vision, users of screen readers who are blind, and professionals responsible for the delivery of assistive technology. The online focus groups will allow the observation and collection of data as a participant would normally utilize their screen reader applications at home, school, or workplace.', 'doi': '10.1145/1090785.1090819', 'url': 'https://doi.org/10.1145/1090785.1090819', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Online focus groups used as an accessible participatory research method', 'author': 'Wattenberg, Ted L.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090819'}"
PLUMB: displaying graphs to the blind using an active auditory interface,10.1145/1090785.1090820,"We present our ongoing research in the communication of graphs and relational information to blind users. We have developed a system called exPLoring graphs at UMB (PLUMB) that displays a drawn graph on a tablet PC and uses auditory cues to help a blind user navigate the graph. This work has applications to assist blind individuals in Computer Science education, navigation and map manipulation.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'graph, audio, accessibility, C# programming language', 'numpages': '2', 'pages': '182–183', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present our ongoing research in the communication of graphs and relational information to blind users. We have developed a system called exPLoring graphs at UMB (PLUMB) that displays a drawn graph on a tablet PC and uses auditory cues to help a blind user navigate the graph. This work has applications to assist blind individuals in Computer Science education, navigation and map manipulation.', 'doi': '10.1145/1090785.1090820', 'url': 'https://doi.org/10.1145/1090785.1090820', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'PLUMB: displaying graphs to the blind using an active auditory interface', 'author': 'Cohen, Robert F. and Yu, Rui and Meacham, Arthur and Skaff, Joelle', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090820'}"
Gestural text entry on multiple devices,10.1145/1090785.1090821,"We present various adaptations of the EdgeWrite unistroke text entry method that work on multiple computer input devices: styluses, touchpads, displacement and isometric joysticks, four keys or buttons, and trackballs. We argue that consistent, flexible, multi-device input is important to both accessibility and to ubiquitous computing. For accessibility, multi-device input means users can switch among devices, distributing strain and fatigue among different muscle groups. For ubiquity, it means users can ""learn once, write anywhere,"" even as new devices emerge. By considering the accessibility and ubiquity of input techniques, we can design for both motor-impaired users and ""situationally impaired"" able-bodied users who are on-the-go. We discuss the requirements for such input and the challenges of multi-device text entry, such as solving the segmentation problem. This paper accompanies a demonstration of EdgeWrite on multiple devices.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'unistroke, ubiquitous computing, trackball, text input, text entry, isometric joystick, accessibility, PDA, EdgeWrite', 'numpages': '2', 'pages': '184–185', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present various adaptations of the EdgeWrite unistroke text entry method that work on multiple computer input devices: styluses, touchpads, displacement and isometric joysticks, four keys or buttons, and trackballs. We argue that consistent, flexible, multi-device input is important to both accessibility and to ubiquitous computing. For accessibility, multi-device input means users can switch among devices, distributing strain and fatigue among different muscle groups. For ubiquity, it means users can ""learn once, write anywhere,"" even as new devices emerge. By considering the accessibility and ubiquity of input techniques, we can design for both motor-impaired users and ""situationally impaired"" able-bodied users who are on-the-go. We discuss the requirements for such input and the challenges of multi-device text entry, such as solving the segmentation problem. This paper accompanies a demonstration of EdgeWrite on multiple devices.', 'doi': '10.1145/1090785.1090821', 'url': 'https://doi.org/10.1145/1090785.1090821', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Gestural text entry on multiple devices', 'author': 'Wobbrock, Jacob O. and Myers, Brad A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090821'}"
Interactive virtual client for teaching occupational therapy evaluative processes,10.1145/1090785.1090822,"In this paper, we describe our current work in developing a computer-based educational tool for Occupational Therapy students learning client evaluation techniques. The software is dialog-based and allows the student to interact with a virtual client. Students carry out an evaluation, following the appropriate procedures and assessing both the client's physical and emotional state as they proceed. Students' actions are saved to a file for instructor and self evaluation of their performance. The software is being developed using the Source® game engine SDK developed by Valve™.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'virtual patient, occupational therapy assessment, interactive educational tool', 'numpages': '2', 'pages': '186–187', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this paper, we describe our current work in developing a computer-based educational tool for Occupational Therapy students learning client evaluation techniques. The software is dialog-based and allows the student to interact with a virtual client. Students carry out an evaluation, following the appropriate procedures and assessing both the client's physical and emotional state as they proceed. Students' actions are saved to a file for instructor and self evaluation of their performance. The software is being developed using the Source® game engine SDK developed by Valve™."", 'doi': '10.1145/1090785.1090822', 'url': 'https://doi.org/10.1145/1090785.1090822', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Interactive virtual client for teaching occupational therapy evaluative processes', 'author': 'Stansfield, Sharon and Butkiewicz, Tom and Suma, Evan and Kane, Marilyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090822'}"
Touchable online braille generator,10.1145/1090785.1090823,"Using the force feedback technology which has been used in video games for years, a prototype of an online Braille generator was developed for the visually impaired or blind user. Without any expensive devices, the prototype lets sightless persons use the information on the web by touching the output Braille displays on screen with a mouse. User studies will be conducted with blind people, and their data will provide valuable information about the optimal conditions for the online Braille display in the prototype, such as how strong the force should be and how big those Braille dots should be. The final product of this research will enable visually impaired people to enjoy all the library services and resources as well as the enormous amount of information on the web more freely.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'visually impaired, online braille, force feedback, blind', 'numpages': '2', 'pages': '188–189', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Using the force feedback technology which has been used in video games for years, a prototype of an online Braille generator was developed for the visually impaired or blind user. Without any expensive devices, the prototype lets sightless persons use the information on the web by touching the output Braille displays on screen with a mouse. User studies will be conducted with blind people, and their data will provide valuable information about the optimal conditions for the online Braille display in the prototype, such as how strong the force should be and how big those Braille dots should be. The final product of this research will enable visually impaired people to enjoy all the library services and resources as well as the enormous amount of information on the web more freely.', 'doi': '10.1145/1090785.1090823', 'url': 'https://doi.org/10.1145/1090785.1090823', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Touchable online braille generator', 'author': 'Jeong, Wooseob', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090823'}"
Solo: interactive task guidance,10.1145/1090785.1090824,"Solo is a cognitive assistive device which provides scheduling support and interactive task guidance. Solo includes user interfaces for the person with a disability and the caregiver, as well as a Cognition Manager which manages schedules and responds to unplanned events.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'traumatic brain injury, task guidance, cognitive disability', 'numpages': '2', 'pages': '190–191', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Solo is a cognitive assistive device which provides scheduling support and interactive task guidance. Solo includes user interfaces for the person with a disability and the caregiver, as well as a Cognition Manager which manages schedules and responds to unplanned events.', 'doi': '10.1145/1090785.1090824', 'url': 'https://doi.org/10.1145/1090785.1090824', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Solo: interactive task guidance', 'author': 'LoPresti, Edmund and Kirsch, Ned and Simpson, Richard and Schreckenghost, Debra', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090824'}"
An adaptive technologies course in a CS curriculum,10.1145/1090785.1090825,"This poster describes part 2 of the 2-year project ""Integrating Assistive Technology into an Undergraduate Computer Science Curriculum from an HCI Approach,"" funded by the National Science Foundation [3]. (Part I of this project is documented in [1, 2].) The intent of this phase of the project is to introduce the topic of computerized aids for the disabled (generally called assistive or adaptive technology (AT)) as an advanced elective course offered for senior Computer Science majors. This report will briefly describe some of the topics to be covered in this new course, how these topics fit within the CS curriculum, sample assignments, and the laboratory equipment used to support demonstrations and assignments. This course is more fully described in [4].","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'human-computer interaction, disabilities, assistive technology', 'numpages': '2', 'pages': '192–193', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This poster describes part 2 of the 2-year project ""Integrating Assistive Technology into an Undergraduate Computer Science Curriculum from an HCI Approach,"" funded by the National Science Foundation [3]. (Part I of this project is documented in [1, 2].) The intent of this phase of the project is to introduce the topic of computerized aids for the disabled (generally called assistive or adaptive technology (AT)) as an advanced elective course offered for senior Computer Science majors. This report will briefly describe some of the topics to be covered in this new course, how these topics fit within the CS curriculum, sample assignments, and the laboratory equipment used to support demonstrations and assignments. This course is more fully described in [4].', 'doi': '10.1145/1090785.1090825', 'url': 'https://doi.org/10.1145/1090785.1090825', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'An adaptive technologies course in a CS curriculum', 'author': 'Liffick, Blaise W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090825'}"
iSonic: interactive sonification for non-visual data exploration,10.1145/1090785.1090826,"iSonic is an interactive sonification tool for vision impaired users to explore geo-referenced statistical data, such as population or crime rates by geographical regions. Users use a keyboard or a smooth surface touchpad to interact with coordinated map and table views of the data. The integrated use of musical sounds and speech allows users to grasp the overall data trends and to explore the data to get more details. Scenarios of use are described.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'vision impairment, universal usability, sonification, information seeking, auditory user interfaces', 'numpages': '2', 'pages': '194–195', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'iSonic is an interactive sonification tool for vision impaired users to explore geo-referenced statistical data, such as population or crime rates by geographical regions. Users use a keyboard or a smooth surface touchpad to interact with coordinated map and table views of the data. The integrated use of musical sounds and speech allows users to grasp the overall data trends and to explore the data to get more details. Scenarios of use are described.', 'doi': '10.1145/1090785.1090826', 'url': 'https://doi.org/10.1145/1090785.1090826', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'iSonic: interactive sonification for non-visual data exploration', 'author': 'Zhao, Haixia and Plaisant, Catherine and Shneiderman, Ben', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090826'}"
A system for creating personalized synthetic voices,10.1145/1090785.1090827,"We will be demonstrating the ModelTalker Voice Creation System, which allows users to create a personalized synthetic voice with an unrestricted vocabulary. The system includes a tool for recording a speech inventory and a program that converts the recorded inventory into a synthetic voice for the ModelTalker TTS engine. The entire system can be downloaded for use on a home PC or in a clinical setting, and the resulting synthetic voices can be used with any SAPI compliant system.We will demonstrate the recording process, and convert the recordings to a mini-database with a limited vocabulary for participants to hear.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': ""synthetic voices, speech synthesis, augmentative and alternative communication (AAC), amyotrophic lateral sclerosis (ALS), Lou Gehrig's disease"", 'numpages': '2', 'pages': '196–197', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We will be demonstrating the ModelTalker Voice Creation System, which allows users to create a personalized synthetic voice with an unrestricted vocabulary. The system includes a tool for recording a speech inventory and a program that converts the recorded inventory into a synthetic voice for the ModelTalker TTS engine. The entire system can be downloaded for use on a home PC or in a clinical setting, and the resulting synthetic voices can be used with any SAPI compliant system.We will demonstrate the recording process, and convert the recordings to a mini-database with a limited vocabulary for participants to hear.', 'doi': '10.1145/1090785.1090827', 'url': 'https://doi.org/10.1145/1090785.1090827', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'A system for creating personalized synthetic voices', 'author': 'Yarrington, Debra and Pennington, Chris and Gray, John and Bunnell, H. Timothy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090827'}"
How to operate a PC without using the hands,10.1145/1090785.1090828,"A demo of a biosignal interface, which allows to operate a Windows® PC without using the hands, shall be given. The system -- called HaMCoS (for Hands-free Mouse Control System) -- enables its user to simulate clicks and movements of the computer mouse by issuing intentional contractions of a single muscle of choice only. Therefore, by employing HaMCoS, even a person with very severe physical disabilities can operate a PC, provided everything exclusively relies on mouse input. The framework built around the system's Main Module is optimized in this respect, since it offers a comfortable keyboard-free user interface (e.g. comprising large, easily clickable buttons).","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'muscle control, human-computer interaction, hands-free operation, electromechanical coupling, biosignal interface', 'numpages': '2', 'pages': '198–199', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""A demo of a biosignal interface, which allows to operate a Windows® PC without using the hands, shall be given. The system -- called HaMCoS (for Hands-free Mouse Control System) -- enables its user to simulate clicks and movements of the computer mouse by issuing intentional contractions of a single muscle of choice only. Therefore, by employing HaMCoS, even a person with very severe physical disabilities can operate a PC, provided everything exclusively relies on mouse input. The framework built around the system's Main Module is optimized in this respect, since it offers a comfortable keyboard-free user interface (e.g. comprising large, easily clickable buttons)."", 'doi': '10.1145/1090785.1090828', 'url': 'https://doi.org/10.1145/1090785.1090828', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'How to operate a PC without using the hands', 'author': 'Felzer, Torsten and Nordmann, Rainer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090828'}"
visiBabble demo,10.1145/1090785.1090829,The visiBabble system responds with animations to an infant's syllable-like productions and records the acoustic-phonetic analysis. The system reinforces production of syllabic utterances associated with later language and cognitive development. This demo will show off new animated responses and recent improvements in acoustic-phonetic feature detection.,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'real-time analysis, pre-speech vocalizations, feedback', 'numpages': '2', 'pages': '200–201', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The visiBabble system responds with animations to an infant's syllable-like productions and records the acoustic-phonetic analysis. The system reinforces production of syllabic utterances associated with later language and cognitive development. This demo will show off new animated responses and recent improvements in acoustic-phonetic feature detection."", 'doi': '10.1145/1090785.1090829', 'url': 'https://doi.org/10.1145/1090785.1090829', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'visiBabble demo', 'author': 'Fell, Harriet and MacAuslan, Joel and Gong, Jun and Ostrow, Josh', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090829'}"
DHTML accessibility: solving the JavaScript accessibility problem,10.1145/1090785.1090830,"This project demonstrates fully keyboard accessible components on a web page working with a screen reader. By adding the appropriate semantic data to web components and having user agents translate this to the platform accessibility application programming interfaces, the user interface of a web site can be made fully accessible to keyboard only and vision impaired users. In addition, the web component interface will operate in the same manner as client application components.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'accessibility, JavaScript, HTML, DHTML', 'numpages': '2', 'pages': '202–203', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This project demonstrates fully keyboard accessible components on a web page working with a screen reader. By adding the appropriate semantic data to web components and having user agents translate this to the platform accessibility application programming interfaces, the user interface of a web site can be made fully accessible to keyboard only and vision impaired users. In addition, the web component interface will operate in the same manner as client application components.', 'doi': '10.1145/1090785.1090830', 'url': 'https://doi.org/10.1145/1090785.1090830', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'DHTML accessibility: solving the JavaScript accessibility problem', 'author': 'Gibson, Becky and Schwerdtfeger, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090830'}"
MathPlayer: web-based math accessibility,10.1145/1090785.1090831,MathPlayer is a plug-in to Microsoft's Internet Explorer (IE) that renders MathML[11] visually. It also contains a number of features that make mathematical expressions accessible to people with print-disabilities. MathPlayer integrates with many screen readers including JAWS and Window-Eyes. MathPlayer also works with a number of TextHELP!'s learning disabilities products.,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'visual impairments, print disabilities, math accessibility, assistive technology, MathML', 'numpages': '2', 'pages': '204–205', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""MathPlayer is a plug-in to Microsoft's Internet Explorer (IE) that renders MathML[11] visually. It also contains a number of features that make mathematical expressions accessible to people with print-disabilities. MathPlayer integrates with many screen readers including JAWS and Window-Eyes. MathPlayer also works with a number of TextHELP!'s learning disabilities products."", 'doi': '10.1145/1090785.1090831', 'url': 'https://doi.org/10.1145/1090785.1090831', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'MathPlayer: web-based math accessibility', 'author': 'Soiffer, Neil', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090831'}"
Multimodal user input patterns in a non-visual context,10.1145/1090785.1090832,"How will users choose between speech and hand inputs to perform tasks when they are given equivalent choices between both modalities in a non-visual interface? This exploratory study investigates this question. The study was conducted using AudioBrowser, a non-visual information access for the visually impaired. Findings include: (1) Users chose between input modalities based on the type of operations undertaken. Navigation operations primarily used hand input on the touchpad, while non-navigation instructions primarily used speech input. (2) Surprisingly, multimodal error correction was not prevalent. Repeating a failed operation until it succeeded and trying other methods in the same input modality were dominant error-correction strategies. (3) The modality learned first was not necessarily the primary modality used later, but a training order effect existed. These empirical results provide implications for designing non-visual multimodal input dialogues.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'non-visual multimodal interaction, interfaces for the visually impaired, dialogue design, accessibility', 'numpages': '2', 'pages': '206–207', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'How will users choose between speech and hand inputs to perform tasks when they are given equivalent choices between both modalities in a non-visual interface? This exploratory study investigates this question. The study was conducted using AudioBrowser, a non-visual information access for the visually impaired. Findings include: (1) Users chose between input modalities based on the type of operations undertaken. Navigation operations primarily used hand input on the touchpad, while non-navigation instructions primarily used speech input. (2) Surprisingly, multimodal error correction was not prevalent. Repeating a failed operation until it succeeded and trying other methods in the same input modality were dominant error-correction strategies. (3) The modality learned first was not necessarily the primary modality used later, but a training order effect existed. These empirical results provide implications for designing non-visual multimodal input dialogues.', 'doi': '10.1145/1090785.1090832', 'url': 'https://doi.org/10.1145/1090785.1090832', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Multimodal user input patterns in a non-visual context', 'author': 'Chen, Xiaoyu and Tremaine, Marilyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090832'}"
"Emerging issues, solutions \&amp; challenges from the top 20 issues affecting web application accessibility",10.1145/1090785.1090833,"We will describe emerging accessible design issues, based on a second in-depth analysis of hundreds of accessibility issues documented in real projects, and a comparison of those results to a prior study of 1000+ accessibility issues. This poster will demonstrate recent trends in the top 20 UI design situations that are likely to pose problems for users with disabilities; highlight several creative design solutions; and identify several challenges that lack adequate solutions.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'web application, accessible design, accessibility', 'numpages': '2', 'pages': '208–209', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We will describe emerging accessible design issues, based on a second in-depth analysis of hundreds of accessibility issues documented in real projects, and a comparison of those results to a prior study of 1000+ accessibility issues. This poster will demonstrate recent trends in the top 20 UI design situations that are likely to pose problems for users with disabilities; highlight several creative design solutions; and identify several challenges that lack adequate solutions.', 'doi': '10.1145/1090785.1090833', 'url': 'https://doi.org/10.1145/1090785.1090833', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Emerging issues, solutions \\&amp; challenges from the top 20 issues affecting web application accessibility', 'author': 'Hoffman, David and Battle, Lisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090833'}"
Verification of computer display pre-compensation for visual aberrations in an artificial eye,10.1145/1090785.1090834,"The possibility of pre-compensating images in a computer display according to the visual aberrations previously assessed in an optical system (e.g., the computer user's eye) has been confirmed for a simple ""artificial eye"". This device has been constructed from optical components, which include a plano-convex lens, an adjustable aperture, and a Charged-Couple Device (CCD) array that mimics the retina of a real eye. While the CCD array allows for the inspection of the image as it would form on the retina of a real eye, its specular reflection does not allow the resulting ""artificial eye"" to be measured appropriately in a wavefront analyzer (a necessary pre-requisite for the image precompensation process). Therefore, an alternative, interchangeable CCD array covered with gray paint (i.e., disabled) was also created to provide the diffuse reflectivity that is presumed in the operation of the wavefront analyzer. Experiments with this system show that the visual aberrations in a properly characterized optical system can, in fact, be precompensated by the methods proposed by Alonso et al., [1]. These same experiments, however, reveal the need to adjust the precompensation method according to the effective pupil diameter in the system during viewing.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'wavefront aberration, visual aberration, point spread function, low vision, eye model, deconvolution, compensation', 'numpages': '2', 'pages': '210–211', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The possibility of pre-compensating images in a computer display according to the visual aberrations previously assessed in an optical system (e.g., the computer user\'s eye) has been confirmed for a simple ""artificial eye"". This device has been constructed from optical components, which include a plano-convex lens, an adjustable aperture, and a Charged-Couple Device (CCD) array that mimics the retina of a real eye. While the CCD array allows for the inspection of the image as it would form on the retina of a real eye, its specular reflection does not allow the resulting ""artificial eye"" to be measured appropriately in a wavefront analyzer (a necessary pre-requisite for the image precompensation process). Therefore, an alternative, interchangeable CCD array covered with gray paint (i.e., disabled) was also created to provide the diffuse reflectivity that is presumed in the operation of the wavefront analyzer. Experiments with this system show that the visual aberrations in a properly characterized optical system can, in fact, be precompensated by the methods proposed by Alonso et al., [1]. These same experiments, however, reveal the need to adjust the precompensation method according to the effective pupil diameter in the system during viewing.', 'doi': '10.1145/1090785.1090834', 'url': 'https://doi.org/10.1145/1090785.1090834', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Verification of computer display pre-compensation for visual aberrations in an artificial eye', 'author': 'Alonso, Miguel and Barreto, Armando and Jacko, Julie A. and Adjouadi, Malek', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090834'}"
A parametric approach to sign language synthesis,10.1145/1090785.1090835,In this paper we discuss the progress made toward accurate synthesis of signs in American Sign Language (ASL) using a finite number of descriptive parameters. A sign editor produces elements of a sign inventory that can be used with a commercially available human avatar to allow the generation of signed sentences from written or spoken text.,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'sign language synthesis, animation, ASL', 'numpages': '2', 'pages': '212–213', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper we discuss the progress made toward accurate synthesis of signs in American Sign Language (ASL) using a finite number of descriptive parameters. A sign editor produces elements of a sign inventory that can be used with a commercially available human avatar to allow the generation of signed sentences from written or spoken text.', 'doi': '10.1145/1090785.1090835', 'url': 'https://doi.org/10.1145/1090785.1090835', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'A parametric approach to sign language synthesis', 'author': 'Irving, Amanda and Foulds, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090835'}"
Graphical arithmetic for learners with dyscalculia,10.1145/1090785.1090836,"We propose a model for arithmetic, based on graphical represent-ations, to complement the symbolic language of mathematics. The focus is conceptual understanding of arithmetic. We argue that the graphical model supports understanding concepts known to be difficult for learners with dyscalculia, such as number-sense and decimal system. The proposed graphical representation share properties of the decimal system, but is closer to the semantic representation of numbers vital to the number-sense. The model is evaluated with school-children, but needs to be further tested by learners with dyscalculia.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'math disability, graphical model, dyscalculia, arithmetic', 'numpages': '2', 'pages': '214–215', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We propose a model for arithmetic, based on graphical represent-ations, to complement the symbolic language of mathematics. The focus is conceptual understanding of arithmetic. We argue that the graphical model supports understanding concepts known to be difficult for learners with dyscalculia, such as number-sense and decimal system. The proposed graphical representation share properties of the decimal system, but is closer to the semantic representation of numbers vital to the number-sense. The model is evaluated with school-children, but needs to be further tested by learners with dyscalculia.', 'doi': '10.1145/1090785.1090836', 'url': 'https://doi.org/10.1145/1090785.1090836', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Graphical arithmetic for learners with dyscalculia', 'author': 'Pareto, Lena', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090836'}"
iCARE interaction assistant: a wearable face recognition system for individuals with visual impairments,10.1145/1090785.1090837,"This presentation demonstrates a working prototype of the iCare Interaction Assistant, a wearable assistive device based on research aimed at facilitating the social interactions of people who are blind or visually impaired. Using a tiny unobtrusive camera mounted inside the nose bridge of a pair of eyeglasses, this prototype is able to learn and recognize faces at a distances up to 10 feet, thus allowing the user to initiate conversations with persons in their vicinity, without waiting for others to approach them. Ongoing work is aimed at facilitating the subsequent verbal interaction by recognizing and interpreting non-verbal communication, including eye contact, facial expressions, emotions, and gestures.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'wearable computing, social interaction aide, face recognition, assistive device for visually impaired', 'numpages': '2', 'pages': '216–217', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This presentation demonstrates a working prototype of the iCare Interaction Assistant, a wearable assistive device based on research aimed at facilitating the social interactions of people who are blind or visually impaired. Using a tiny unobtrusive camera mounted inside the nose bridge of a pair of eyeglasses, this prototype is able to learn and recognize faces at a distances up to 10 feet, thus allowing the user to initiate conversations with persons in their vicinity, without waiting for others to approach them. Ongoing work is aimed at facilitating the subsequent verbal interaction by recognizing and interpreting non-verbal communication, including eye contact, facial expressions, emotions, and gestures.', 'doi': '10.1145/1090785.1090837', 'url': 'https://doi.org/10.1145/1090785.1090837', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'iCARE interaction assistant: a wearable face recognition system for individuals with visual impairments', 'author': 'Krishna, Sreekar and Little, Greg and Black, John and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090837'}"
User modeling for individuals with disabilities: a pilot study of word prediction,10.1145/1090785.1090838,"We are developing user models that predict how a word prediction system affects performance on a text entry task for individuals with disabilities. In this paper we describe the instrumentation, test-bed software and analytic methods that we are using to collect pilot data.","{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'word prediction, user modeling, assistive technology', 'numpages': '2', 'pages': '218–219', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We are developing user models that predict how a word prediction system affects performance on a text entry task for individuals with disabilities. In this paper we describe the instrumentation, test-bed software and analytic methods that we are using to collect pilot data.', 'doi': '10.1145/1090785.1090838', 'url': 'https://doi.org/10.1145/1090785.1090838', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'User modeling for individuals with disabilities: a pilot study of word prediction', 'author': 'Agarwal, Abhishek and Simpson, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090838'}"
BlackBoardNV: a system for enabling non-visual access to the blackboard course management system,10.1145/1090785.1090839,Abstract not available,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'keywords': 'web-content analysis, web-based assistive course management, web page partitioning, audio/keyboard input, audio output', 'numpages': '2', 'pages': '220–221', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1090785.1090839', 'url': 'https://doi.org/10.1145/1090785.1090839', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'BlackBoardNV: a system for enabling non-visual access to the blackboard course management system', 'author': 'Enagandula, Vineet and Juthani, Niraj and Ramakrishnan, I. V. and Rawal, Devashish and Vidyasagar, Ritwick', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1090839'}"
Storytelling with a virtual peer as an intervention for children with autism,10.1145/1090785.1133180,Abstract not available,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'pages': '1–es', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1090785.1133180', 'url': 'https://doi.org/10.1145/1090785.1133180', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Storytelling with a virtual peer as an intervention for children with autism', 'author': 'Tarturo, Andrea', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1133180'}"
Awards,10.1145/1090785.1133181,Abstract not available,"{'series': ""Assets '05"", 'location': 'Baltimore, MD, USA', 'pages': '2–es', 'booktitle': 'Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1090785.1133181', 'url': 'https://doi.org/10.1145/1090785.1133181', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595931597', 'year': '2005', 'title': 'Awards', 'author': 'Pontelli, Enrico', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1090785.1133181'}"