Title,DOI,Abstract,BibTeX
Low vision: the role of visual acuity in the efficiency of cursor movement,10.1145/354324.354327,"Graphical user interfaces are one of the more prevalent  interface types which exist today. The popularity of this  interface type has caused problems for users with poor vision.  Because usage strategies of low vision users differ from blind  users,  existing  research  focusing  on  blind  users  is  not   sufficient in describing the techniques employed by low  vision users.The research presented here characterizes the interaction  strategies of a particular set of low vision users, those with  Age-related  Macular  Degeneration,  using  an  analysis  of   cursor movement. The low vision users have been grouped  according  to  the  severity  of  their  vision  loss  and  then   compared to fully sighted individuals, with respect to cursor  movement efficiency.Results revealed that as the size of the icons on the computer  screen increased, so did the performance of the fully sighted  participants as well as the participants with AMD.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'search strategy, low vision, icon size, graphical user interface, cursor movement, age-related macular degeneration, GUI', 'numpages': '8', 'pages': '1–8', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Graphical user interfaces are one of the more prevalent  interface types which exist today. The popularity of this  interface type has caused problems for users with poor vision.  Because usage strategies of low vision users differ from blind  users,  existing  research  focusing  on  blind  users  is  not   sufficient in describing the techniques employed by low  vision users.The research presented here characterizes the interaction  strategies of a particular set of low vision users, those with  Age-related  Macular  Degeneration,  using  an  analysis  of   cursor movement. The low vision users have been grouped  according  to  the  severity  of  their  vision  loss  and  then   compared to fully sighted individuals, with respect to cursor  movement efficiency.Results revealed that as the size of the icons on the computer  screen increased, so did the performance of the fully sighted  participants as well as the participants with AMD.', 'doi': '10.1145/354324.354327', 'url': 'https://doi.org/10.1145/354324.354327', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Low vision: the role of visual acuity in the efficiency of cursor movement', 'author': 'Jacko, Julie A. and Barreto, Armando B. and Marmet, Gottlieb J. and Chu, Josey Y. M. and Bautsch, Holly S. and Scott, Ingrid U. and Rosa, Robert H.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354327'}"
A framework of assistive pointers for low vision users,10.1145/354324.354329,"Manipulating a mouse pointer is often difficult for the low  vision computer user.  Working with such a small, mobile  screen object is very visually demanding.  Although several  techniques have been used to address this problem, the design  space of assistive pointers has not been fully explored by the  current  state  of  the  art.  This  paper  proposes  a  four   dimensional framework to fully articulate the design space of  assistive pointers for low vision users. The dimensions of the  framework describe the key attributes of assistance offered to  users by any pointing solution: the perceptual channel that  carries the assistance, the stage of targeting supported by the  assistance, the relationship between the assistance and the  interface, and the degree of availability associated with the  assistance.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'visual impairment, partial vision, mouse pointer, low vision, graphical interface, adaptive technology', 'numpages': '8', 'pages': '9–16', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Manipulating a mouse pointer is often difficult for the low  vision computer user.  Working with such a small, mobile  screen object is very visually demanding.  Although several  techniques have been used to address this problem, the design  space of assistive pointers has not been fully explored by the  current  state  of  the  art.  This  paper  proposes  a  four   dimensional framework to fully articulate the design space of  assistive pointers for low vision users. The dimensions of the  framework describe the key attributes of assistance offered to  users by any pointing solution: the perceptual channel that  carries the assistance, the stage of targeting supported by the  assistance, the relationship between the assistance and the  interface, and the degree of availability associated with the  assistance.', 'doi': '10.1145/354324.354329', 'url': 'https://doi.org/10.1145/354324.354329', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A framework of assistive pointers for low vision users', 'author': 'Fraser, Julie and Gutwin, Carl', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354329'}"
Constructing sonified haptic line graphs for the blind student: first steps,10.1145/354324.354330,"Line graphs stand as an established information visualisation  and analysis technique taught at various levels of difficulty  according to standard Mathematics curricula. It has been  argued that blind individuals cannot use line graphs as a  visualisation  and  analytic  tool  because  they  currently   primarily exist in the visual medium. The research described  in this paper aims at making line graphs accessible to blind  students through auditory and haptic media. We describe (1)  our  design  space  for  representing  line  graphs,  (2)  the   technology we use to develop our prototypes and (3) the  insights from our preliminary work.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'visual impairment, spatial sound, line graphs, haptic display, force feedback', 'numpages': '9', 'pages': '17–25', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Line graphs stand as an established information visualisation  and analysis technique taught at various levels of difficulty  according to standard Mathematics curricula. It has been  argued that blind individuals cannot use line graphs as a  visualisation  and  analytic  tool  because  they  currently   primarily exist in the visual medium. The research described  in this paper aims at making line graphs accessible to blind  students through auditory and haptic media. We describe (1)  our  design  space  for  representing  line  graphs,  (2)  the   technology we use to develop our prototypes and (3) the  insights from our preliminary work.', 'doi': '10.1145/354324.354330', 'url': 'https://doi.org/10.1145/354324.354330', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Constructing sonified haptic line graphs for the blind student: first steps', 'author': 'Ramloll, Rameshsharma and Yu, Wai and Brewster, Stephen and Riedel, Beate and Burton, Mike and Dimigen, Gisela', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354330'}"
Tactile imaging using watershed-based image segmentation,10.1145/354324.354332,"A new image segmentation method is proposed for the automatic conversion of images from visual to tactile form. The proposed method utilizes a watershed-based algorithm for obtaining the initial segmentation. A new joint region merging criterion is developed to reduce the number of initial regions in a more appropriate way.  The joint criterion combines, in a weighted fashion, criteria based on region homogeneity and edge integrity, which have each been applied marginally with some relative success. However, each criteria has shown some significant drawbacks when applied independently. The new criterion takes joint advantage of these two methods, giving a final segmentation that is more visually appropriate. Experimental results are presented showing the advantages of the new merging criterion.  Also, the proposed method is compared with multiresolution (MR) edge detection techniques for tactile imaging applications. Additional results are included showing the advantages of the segmentation procedure over MR edge detection techniques.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'tactile imaging, image segmentation, blind and non-visual interfaces', 'numpages': '8', 'pages': '26–33', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'A new image segmentation method is proposed for the automatic conversion of images from visual to tactile form. The proposed method utilizes a watershed-based algorithm for obtaining the initial segmentation. A new joint region merging criterion is developed to reduce the number of initial regions in a more appropriate way.  The joint criterion combines, in a weighted fashion, criteria based on region homogeneity and edge integrity, which have each been applied marginally with some relative success. However, each criteria has shown some significant drawbacks when applied independently. The new criterion takes joint advantage of these two methods, giving a final segmentation that is more visually appropriate. Experimental results are presented showing the advantages of the new merging criterion.  Also, the proposed method is compared with multiresolution (MR) edge detection techniques for tactile imaging applications. Additional results are included showing the advantages of the segmentation procedure over MR edge detection techniques.', 'doi': '10.1145/354324.354332', 'url': 'https://doi.org/10.1145/354324.354332', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Tactile imaging using watershed-based image segmentation', 'author': 'Hernandez, Sergio E. and Barner, Kenneth E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354332'}"
A study of blind drawing practice: creating graphical information without the visual channel,10.1145/354324.354334,"Existing drawing tools for blind users give inadequate  contextual feedback on the state of the drawing, leaving  blind users unable to comprehend and successfully produce  graphical  information.  We  have  investigated  a  tactile   method  of  drawing  used  by  blind  users  that  mimics   drawing with a pencil and a paper. Our study revealed a set  of properties that must be incorporated into drawing tools  for blind users, including giving feedback for relocating  important points, determining angles, and communicating  the overall structure of the drawing. We describe a grid- based model that provides these properties in a primitive- based 2D graphics environment, and we introduce its use in  drawing and other graphical interactions.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'non-visual drawing tools, grid, feedback, contextual inquiry, GUIs for blind users', 'numpages': '8', 'pages': '34–41', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Existing drawing tools for blind users give inadequate  contextual feedback on the state of the drawing, leaving  blind users unable to comprehend and successfully produce  graphical  information.  We  have  investigated  a  tactile   method  of  drawing  used  by  blind  users  that  mimics   drawing with a pencil and a paper. Our study revealed a set  of properties that must be incorporated into drawing tools  for blind users, including giving feedback for relocating  important points, determining angles, and communicating  the overall structure of the drawing. We describe a grid- based model that provides these properties in a primitive- based 2D graphics environment, and we introduce its use in  drawing and other graphical interactions.', 'doi': '10.1145/354324.354334', 'url': 'https://doi.org/10.1145/354324.354334', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A study of blind drawing practice: creating graphical information without the visual channel', 'author': 'Kamel, Hesham M. and Landay, James A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354334'}"
New technology enables many-fold reduction in the cost of refreshable Braille displays,10.1145/354324.354335,"By  analysis  of  the  primary  cost  factors  for  existing   refreshable Braille displays, a team at NIST has pioneered a  new  technology  that  can  reduce  the  cost  of  the   electromechanical  portions  of  a  Braille  display  by  an   extremely large factor, and the overall cost of a Braille  display by as much as a factor of ten. A massive cost  reduction in displays creates a new model for the purchase  and use of Braille displays by individuals, by employers, and  by educators. Readability and user control issues are are  addressed. It is hoped that this technology will open a  significant  new  market  for  low  cost,  high  performance   refreshable Braille displays.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'wheel, refreshable Braille, passive pin retention', 'numpages': '8', 'pages': '42–49', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'By  analysis  of  the  primary  cost  factors  for  existing   refreshable Braille displays, a team at NIST has pioneered a  new  technology  that  can  reduce  the  cost  of  the   electromechanical  portions  of  a  Braille  display  by  an   extremely large factor, and the overall cost of a Braille  display by as much as a factor of ten. A massive cost  reduction in displays creates a new model for the purchase  and use of Braille displays by individuals, by employers, and  by educators. Readability and user control issues are are  addressed. It is hoped that this technology will open a  significant  new  market  for  low  cost,  high  performance   refreshable Braille displays.', 'doi': '10.1145/354324.354335', 'url': 'https://doi.org/10.1145/354324.354335', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'New technology enables many-fold reduction in the cost of refreshable Braille displays', 'author': 'Roberts, John and Slattery, Oliver and Kardos, David and Swope, Brett', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354335'}"
A storytelling robot for pediatric rehabilitation,10.1145/354324.354338,"We are developing a prototype storytelling robot for use  with  children  in  rehabilitation.  Children  can  remotely   control a large furry robot by using a variety of body  sensors adapted to their disability or rehabilitation goal. In  doing so, they can teach the robot to act out series of  movements or ""emotions"" and then write stories - using a  storytelling software - including those movements in the  story.  The  story  can  then  be  ""played""  by  the  remote   controlled robot, which acts out the story. We believe that  this robot can motivate the children and help them reach  their  therapy  goals  through  therapeutic  play,  either  by   exercising muscles or joints (e.g. for physically challenges  children) or by reflecting on the stories (e.g. for children  with  developmental  disabilities).  We  use  an  innovative   design methodology involving children as design partners.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'user interface, therapeutic play, robot, rehabilitation, design process, children', 'numpages': '6', 'pages': '50–55', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'We are developing a prototype storytelling robot for use  with  children  in  rehabilitation.  Children  can  remotely   control a large furry robot by using a variety of body  sensors adapted to their disability or rehabilitation goal. In  doing so, they can teach the robot to act out series of  movements or ""emotions"" and then write stories - using a  storytelling software - including those movements in the  story.  The  story  can  then  be  ""played""  by  the  remote   controlled robot, which acts out the story. We believe that  this robot can motivate the children and help them reach  their  therapy  goals  through  therapeutic  play,  either  by   exercising muscles or joints (e.g. for physically challenges  children) or by reflecting on the stories (e.g. for children  with  developmental  disabilities).  We  use  an  innovative   design methodology involving children as design partners.', 'doi': '10.1145/354324.354338', 'url': 'https://doi.org/10.1145/354324.354338', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A storytelling robot for pediatric rehabilitation', 'author': 'Plaisant, Catherine and Druin, Allison and Lathan, Corinna and Dakhane, Kapil and Edwards, Kris and Vice, Jack Maxwell and Montemayor, Jaime', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354338'}"
A virtual reality-based exercise program for stroke rehabilitation,10.1145/354324.354340,"A PC based desktop Virtual Reality system was developed  for rehabilitating hand function in stroke patients. The  system uses two hand input devices, a CyberGlove and a  RMII force feedback glove, to allow the user to interact  with one of four rehabilitation exercises. Each of which is  designed  to  exercise  one  specific  parameter  of  hand   movement, namely range, speed, fractionation or strength.  The therapy program is semi-automated and personalized  to each user through the use of performance-based target  levels. These are adapted between sessions in order to  induce the user to improve. Feedback is provided to each  user throughout the exercise sessions. To further motivate  the user to continue the exercise program, screen displays  are designed as interactive games. The system is described  and sample data is presented from preliminary studies  performed on control subjects.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'virtual reality, stroke, rehabilitation, haptic glove, Rutgers Master II, CyberGlove', 'numpages': '8', 'pages': '56–63', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'A PC based desktop Virtual Reality system was developed  for rehabilitating hand function in stroke patients. The  system uses two hand input devices, a CyberGlove and a  RMII force feedback glove, to allow the user to interact  with one of four rehabilitation exercises. Each of which is  designed  to  exercise  one  specific  parameter  of  hand   movement, namely range, speed, fractionation or strength.  The therapy program is semi-automated and personalized  to each user through the use of performance-based target  levels. These are adapted between sessions in order to  induce the user to improve. Feedback is provided to each  user throughout the exercise sessions. To further motivate  the user to continue the exercise program, screen displays  are designed as interactive games. The system is described  and sample data is presented from preliminary studies  performed on control subjects.', 'doi': '10.1145/354324.354340', 'url': 'https://doi.org/10.1145/354324.354340', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A virtual reality-based exercise program for stroke rehabilitation', 'author': 'Jack, David and Boian, Rares and Merians, Alma and Adamovich, Sergei V. and Tremaine, Marilyn and Recce, Michael and Burdea, Grigore C. and Poizner, Howard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354340'}"
Fast web by using updated content extraction and a bookmark facility,10.1145/354324.354343,"This paper describes improved methods of web access for  the visually impaired. Some A few web access systems for  the visually impaired have already been developed and are  widely used. The improvements described in this paper are  in two areas. The first is a fastest mean of jumping from the  current sentence position into desired sentence position  within web pages. The second is a facility for searching for  sentences that have been updated since a previous viewing.  User testing was carried out, and the two facilities were  found to reduce not only the web page access time but also  the user?s mental workload.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'web access, visually impaired, updated-sentence, search facility, bookmark', 'numpages': '8', 'pages': '64–71', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This paper describes improved methods of web access for  the visually impaired. Some A few web access systems for  the visually impaired have already been developed and are  widely used. The improvements described in this paper are  in two areas. The first is a fastest mean of jumping from the  current sentence position into desired sentence position  within web pages. The second is a facility for searching for  sentences that have been updated since a previous viewing.  User testing was carried out, and the two facilities were  found to reduce not only the web page access time but also  the user?s mental workload.', 'doi': '10.1145/354324.354343', 'url': 'https://doi.org/10.1145/354324.354343', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Fast web by using updated content extraction and a bookmark facility', 'author': 'Ebina, Tsuyoshi and Igi, Seiji and Miyake, Teruhisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354343'}"
A comparison of voice controlled and mouse controlled web browsing,10.1145/354324.354345,"Voice controlled web browsers allow users to navigate by  speaking the text of a link or an associated number instead  of clicking with a mouse. One such browser is Conversa, by  Conversational Computing. This within subjects study with  18  subjects  compared  voice  browsing  with  traditional   mouse-based browsing. It attempted to identify which of  three common hypertext forms (linear slide show, grid/tiled  map,  and  hierarchical  menu)  are  well  suited  to  voice   navigation, and whether voice navigation is helped by  numbering links. The study shows that voice control adds  approximately 50\% to the performance time for certain  types of tasks. Subjective satisfaction measures indicate that  for voice browsing, textual links are preferable to numbered  links.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'web browsing, voice recognition, voice browsers, user interfaces, interaction, human-computer', 'numpages': '8', 'pages': '72–79', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Voice controlled web browsers allow users to navigate by  speaking the text of a link or an associated number instead  of clicking with a mouse. One such browser is Conversa, by  Conversational Computing. This within subjects study with  18  subjects  compared  voice  browsing  with  traditional   mouse-based browsing. It attempted to identify which of  three common hypertext forms (linear slide show, grid/tiled  map,  and  hierarchical  menu)  are  well  suited  to  voice   navigation, and whether voice navigation is helped by  numbering links. The study shows that voice control adds  approximately 50\\% to the performance time for certain  types of tasks. Subjective satisfaction measures indicate that  for voice browsing, textual links are preferable to numbered  links.', 'doi': '10.1145/354324.354345', 'url': 'https://doi.org/10.1145/354324.354345', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A comparison of voice controlled and mouse controlled web browsing', 'author': 'Christian, Kevin and Kules, Bill and Shneiderman, Ben and Youssef, Adel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354345'}"
Evaluating web resources for disability access,10.1145/354324.354346,"A majority of Web based information, facilities and services  is  unnecessarily  inaccessible  to  people  with  certain   disabilities,  largely  due  to  a  lack  of  awareness  of   accessibility issues on the part of developers. This paper  argues  that  currently  available  accessibility  evaluation   methods are unsatisfactory in the scope and presentation of  their results. Consequently, there is a need for a meta- method which utilises the strengths of current methods, but  which also bridges their weaknesses. The paper discusses a  comprehensive, yet usable methodology for evaluating web  sites for accessibility. Using this methodology, a semi- automatic accessibility evaluation tool is proposed, which  will guide evaluators through the auditing process and  produce a set of tailored recommendations for making the  subject site accessible.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'web resources, usability, evaluation, disability, accessibility', 'numpages': '5', 'pages': '80–84', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'A majority of Web based information, facilities and services  is  unnecessarily  inaccessible  to  people  with  certain   disabilities,  largely  due  to  a  lack  of  awareness  of   accessibility issues on the part of developers. This paper  argues  that  currently  available  accessibility  evaluation   methods are unsatisfactory in the scope and presentation of  their results. Consequently, there is a need for a meta- method which utilises the strengths of current methods, but  which also bridges their weaknesses. The paper discusses a  comprehensive, yet usable methodology for evaluating web  sites for accessibility. Using this methodology, a semi- automatic accessibility evaluation tool is proposed, which  will guide evaluators through the auditing process and  produce a set of tailored recommendations for making the  subject site accessible.', 'doi': '10.1145/354324.354346', 'url': 'https://doi.org/10.1145/354324.354346', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Evaluating web resources for disability access', 'author': 'Rowan, Murray and Gregor, Peter and Sloan, David and Booth, Paul', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354346'}"
An empirical investigation of ways in which some of the problems encountered by some dyslexics may be alleviated using computer techniques,10.1145/354324.354347,"This  research  describes  the  development  of  a  highly   configurable  word  processing  environment  to  alleviate   some of the difficulties encountered by dyslexics when  producing and reading text. It also describes a pragmatic,  empirical methodology, closely involving dyslexic users,  which has proved highly effective.All dyslexic subjects tested were able to use the software to  identify  and  store  a  configuration  of  background  and   foreground colour, text typeface and font, and spacing  between characters, words and lines which they found  easier to read than the default settings. Successful tests were  also  carried  out  to  investigate  the  use  of  different   appearances  (font,  colour  etc.)  to  alleviate  character   recognition and reversal problems.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'word processing, user-centered design, dyslexia, configuration', 'numpages': '7', 'pages': '85–91', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This  research  describes  the  development  of  a  highly   configurable  word  processing  environment  to  alleviate   some of the difficulties encountered by dyslexics when  producing and reading text. It also describes a pragmatic,  empirical methodology, closely involving dyslexic users,  which has proved highly effective.All dyslexic subjects tested were able to use the software to  identify  and  store  a  configuration  of  background  and   foreground colour, text typeface and font, and spacing  between characters, words and lines which they found  easier to read than the default settings. Successful tests were  also  carried  out  to  investigate  the  use  of  different   appearances  (font,  colour  etc.)  to  alleviate  character   recognition and reversal problems.', 'doi': '10.1145/354324.354347', 'url': 'https://doi.org/10.1145/354324.354347', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'An empirical investigation of ways in which some of the problems encountered by some dyslexics may be alleviated using computer techniques', 'author': 'Gregor, Peter and Newell, Alan F.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354347'}"
An intelligent tutoring system for deaf learners of written English,10.1145/354324.354348,"This paper describes progress toward a prototype implementation of a tool which aims to improve literacy in deaf high school and college students who are native (or near native) signers of American Sign Language (ASL). We envision a system that will take a piece of text written by a deaf student, analyze that text for grammatical errors, and engage that student in a tutorial dialogue, enabling the student to generate appropriate corrections to the text. A strong focus of this work is to develop a system which adapts this process to the knowledge level and learning strengths of the user and which has the flexibility to engage in multi-modal, multi-lingual tutorial instruction utilizing both English and the native language of the user.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'user modeling, second language acquisition, intelligent tutoring systems, English literacy, American Sign Language', 'numpages': '9', 'pages': '92–100', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This paper describes progress toward a prototype implementation of a tool which aims to improve literacy in deaf high school and college students who are native (or near native) signers of American Sign Language (ASL). We envision a system that will take a piece of text written by a deaf student, analyze that text for grammatical errors, and engage that student in a tutorial dialogue, enabling the student to generate appropriate corrections to the text. A strong focus of this work is to develop a system which adapts this process to the knowledge level and learning strengths of the user and which has the flexibility to engage in multi-modal, multi-lingual tutorial instruction utilizing both English and the native language of the user.', 'doi': '10.1145/354324.354348', 'url': 'https://doi.org/10.1145/354324.354348', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'An intelligent tutoring system for deaf learners of written English', 'author': 'Michaud, Lisa N. and McCoy, Kathleen F. and Pennington, Christopher A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354348'}"
The development of language processing support for the ViSiCAST project,10.1145/354324.354349,"ViSiCAST is a major new project funded by the European Union, aiming to provide improved access to services and facilities for deaf citizens through sign language presented by a virtual human, or avatar. We give here an outline of the project, and describe early work in the area of linguistics and language processing. This work covers two distinct but related areas: first, the development of an XML-compliant notation for deaf sign language gestures, which can be used to drive the signing avatar; and, second, the development of a framework supporting the translation of natural language text into this gesture-orientated notation.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'virtual signing, sign language, language processing', 'numpages': '8', 'pages': '101–108', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'ViSiCAST is a major new project funded by the European Union, aiming to provide improved access to services and facilities for deaf citizens through sign language presented by a virtual human, or avatar. We give here an outline of the project, and describe early work in the area of linguistics and language processing. This work covers two distinct but related areas: first, the development of an XML-compliant notation for deaf sign language gestures, which can be used to drive the signing avatar; and, second, the development of a framework supporting the translation of natural language text into this gesture-orientated notation.', 'doi': '10.1145/354324.354349', 'url': 'https://doi.org/10.1145/354324.354349', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'The development of language processing support for the ViSiCAST project', 'author': 'Elliott, R. and Glauert, J. R. W. and Kennaway, J. R. and Marshall, I.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354349'}"
The LF-ASD brain computer interface: on-line identification of imagined finger flexions in subjects with spinal cord injuries,10.1145/354324.354350,"Our research has focused on developing a brain-controlled  switch   that   is   suitable   for   asynchronous   control    applications.  We  have  developed  a  switch,  the  Low   Frequency Asynchronous Switch Design (LF-ASD) that  users  can  activate  by  imagining  movement.  On-line   implementations  of  the  LF-ASD  has  shown  promising   results  in  respond  to  actual  index  finger  flexions  and   imagined finger flexions within able-bodied subjects. This  work reports the results of our first test with subjects with  high-level spinal-cord injuries. In this study, two subjects  with high-level spinal-cord injuries were able to control the  LF-ASD with imagined voluntary movements with hit (true  positive) rates from 45-48\% and false positive rates below  1\%.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'switch, spinal-cord injury, machine, interface, human, computer, brain, EEG, BCI', 'numpages': '5', 'pages': '109–113', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Our research has focused on developing a brain-controlled  switch   that   is   suitable   for   asynchronous   control    applications.  We  have  developed  a  switch,  the  Low   Frequency Asynchronous Switch Design (LF-ASD) that  users  can  activate  by  imagining  movement.  On-line   implementations  of  the  LF-ASD  has  shown  promising   results  in  respond  to  actual  index  finger  flexions  and   imagined finger flexions within able-bodied subjects. This  work reports the results of our first test with subjects with  high-level spinal-cord injuries. In this study, two subjects  with high-level spinal-cord injuries were able to control the  LF-ASD with imagined voluntary movements with hit (true  positive) rates from 45-48\\% and false positive rates below  1\\%.', 'doi': '10.1145/354324.354350', 'url': 'https://doi.org/10.1145/354324.354350', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'The LF-ASD brain computer interface: on-line identification of imagined finger flexions in subjects with spinal cord injuries', 'author': 'Mason, Steven G. and Bozorgzadeh, Ziba and Birch, Gary E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354350'}"
Human factors issues in the neural signals direct brain-computer interfaces,10.1145/354324.354351,Controlling a computer directly by brain signals has been  made  possible  by  the  development  of  a  neurotrophic   electrode that is implanted in the human motor cortex. The  success of this technology can be enhanced by researching  and developing new human-computer interface paradigms for  neural signal control. This paper summarizes progress to date  on the software aspects of the Neural Signals brain-computer  interface  project  and  presents  a  vision  and  strategy  for   upcoming research.,"{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'neural signals, brain-computer interfaces, accessible software', 'numpages': '7', 'pages': '114–120', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Controlling a computer directly by brain signals has been  made  possible  by  the  development  of  a  neurotrophic   electrode that is implanted in the human motor cortex. The  success of this technology can be enhanced by researching  and developing new human-computer interface paradigms for  neural signal control. This paper summarizes progress to date  on the software aspects of the Neural Signals brain-computer  interface  project  and  presents  a  vision  and  strategy  for   upcoming research.', 'doi': '10.1145/354324.354351', 'url': 'https://doi.org/10.1145/354324.354351', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Human factors issues in the neural signals direct brain-computer interfaces', 'author': 'Moore, Melody M. and Kennedy, Philip R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354351'}"
Neck range of motion and use of computer head controls,10.1145/354324.354352,"Computer head controls provide an alternative means of computer access for people with disabilities. However, a person?s ability to use head controls may be reduced if his or her disability involves neck movement limitations. In this study, 15 subjects without disabilities and 10 subjects with disabilities received neck range of motion evaluations and performed computer exercises using head controls. Regression analysis was used to determine the relationship between neck range of motion and performance on  computer exercises. Reduced neck range of motion was found to be correlated with reduced functional range for moving the cursor across the screen, and reduced accuracy and speed in icon selection. Fitts' Law-type models were fit to the data, indicating higher Fitts' law slopes for subjects with disabilities compared to subjects without disabilities. Results also indicate that vertical cursor movements are faster than horizontal or diagonal movements.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'head movement, head controls, disability', 'numpages': '8', 'pages': '121–128', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': ""Computer head controls provide an alternative means of computer access for people with disabilities. However, a person?s ability to use head controls may be reduced if his or her disability involves neck movement limitations. In this study, 15 subjects without disabilities and 10 subjects with disabilities received neck range of motion evaluations and performed computer exercises using head controls. Regression analysis was used to determine the relationship between neck range of motion and performance on  computer exercises. Reduced neck range of motion was found to be correlated with reduced functional range for moving the cursor across the screen, and reduced accuracy and speed in icon selection. Fitts' Law-type models were fit to the data, indicating higher Fitts' law slopes for subjects with disabilities compared to subjects without disabilities. Results also indicate that vertical cursor movements are faster than horizontal or diagonal movements."", 'doi': '10.1145/354324.354352', 'url': 'https://doi.org/10.1145/354324.354352', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Neck range of motion and use of computer head controls', 'author': 'LoPresti, Edmund and Brienza, David M. and Angelo, Jennifer and Gilbertson, Lars and Sakai, Jonathan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354352'}"
Investigating the applicability of user models for motion-impaired users,10.1145/354324.354354,This paper considers the differences between users with  motion-impairments and able-bodied users when they interact  with computers and the implications for user models. Most  interface design and usability assessment practices are based  on explicit or implicit models of user behaviour. This paper  studies the applicability of an existing interface design user  model  to  motion-impaired  users  for  the  relatively   straightforward task of button activation. A discussion of the  empirical results is provided and the paper concludes that  there are significant differences between the behaviour of  motion-impaired users and the accepted modelling theory.,"{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'user models, universal access, motion-impaired users', 'numpages': '8', 'pages': '129–136', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This paper considers the differences between users with  motion-impairments and able-bodied users when they interact  with computers and the implications for user models. Most  interface design and usability assessment practices are based  on explicit or implicit models of user behaviour. This paper  studies the applicability of an existing interface design user  model  to  motion-impaired  users  for  the  relatively   straightforward task of button activation. A discussion of the  empirical results is provided and the paper concludes that  there are significant differences between the behaviour of  motion-impaired users and the accepted modelling theory.', 'doi': '10.1145/354324.354354', 'url': 'https://doi.org/10.1145/354324.354354', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Investigating the applicability of user models for motion-impaired users', 'author': 'Keates, Simeon and Clarkson, John and Robinson, Peter', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354354'}"
Evaluation of scanning user interfaces using real-time-data usage logs,10.1145/354324.354355,"This  research  concerns  the  use  of  Human  Computer   Interaction models to assist in the provision of the Electronic  Assistive  Technologies  (EAT)  for  people  with  severe   disabilities.  The  novel  feature  of  this  work  is  that  the   evaluation is conducted through the model-based analysis of  automatically generated usage logs. This analysis provides a  source of feedback to clinicians, which has previously been  unavailable from assistive technology users. The overall aim  of the research is to provide a set of tools to assist with the  prescription and configuration of assistive technologies.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'modelling, integrated systems, analysis, Electronic Assistive Technology', 'numpages': '5', 'pages': '137–141', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This  research  concerns  the  use  of  Human  Computer   Interaction models to assist in the provision of the Electronic  Assistive  Technologies  (EAT)  for  people  with  severe   disabilities.  The  novel  feature  of  this  work  is  that  the   evaluation is conducted through the model-based analysis of  automatically generated usage logs. This analysis provides a  source of feedback to clinicians, which has previously been  unavailable from assistive technology users. The overall aim  of the research is to provide a set of tools to assist with the  prescription and configuration of assistive technologies.', 'doi': '10.1145/354324.354355', 'url': 'https://doi.org/10.1145/354324.354355', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Evaluation of scanning user interfaces using real-time-data usage logs', 'author': ""O'Neill, Peter and Roast, Chris and Hawley, Mark"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354355'}"
A Java programming tool for students with visual disabilities,10.1145/354324.354356,"This paper reports on a tool for assisting students with visual  disabilities in learning how to program. The tool is meant to  be  used  by  computer  science  majors  learning  the  programming  language  Java.  As  part  of  the  developmental   process of building this tool, we have implemented a rapid  prototype to be used by people with disabilities in order to  define appropriate requirements for the full version of the  tool. This requires that the prototype is completely usable via  a keyboard and speech interface, and it is easily adaptable for  trying out different strategies. In this paper, we present the  motivation and philosophy of the full tool, called  JavaSpeak. We also present the details of a prototype implementation of  JavaSpeak.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'students with visual disabilities, programming tool, learning to program, Java', 'numpages': '7', 'pages': '142–148', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'This paper reports on a tool for assisting students with visual  disabilities in learning how to program. The tool is meant to  be  used  by  computer  science  majors  learning  the  programming  language  Java.  As  part  of  the  developmental   process of building this tool, we have implemented a rapid  prototype to be used by people with disabilities in order to  define appropriate requirements for the full version of the  tool. This requires that the prototype is completely usable via  a keyboard and speech interface, and it is easily adaptable for  trying out different strategies. In this paper, we present the  motivation and philosophy of the full tool, called  JavaSpeak. We also present the details of a prototype implementation of  JavaSpeak.', 'doi': '10.1145/354324.354356', 'url': 'https://doi.org/10.1145/354324.354356', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A Java programming tool for students with visual disabilities', 'author': 'Smith, Ann C. and Francioni, Joan M. and Matzek, Sam D.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354356'}"
"Programming by voice, VocalProgramming",10.1145/354324.354362,A system that enables a person to program without typing  is needed because of the high incidents of repetitive stress  injuries among people who program. This paper presents a  design  for  a  system  that  generates  environments  that   enables people to program by voice and a method of  determining if the system is successful. It also shows how  this generator can be used to support entering data and  writing XML documents.,"{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'voice recognition, computer programming, XML', 'numpages': '7', 'pages': '149–155', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'A system that enables a person to program without typing  is needed because of the high incidents of repetitive stress  injuries among people who program. This paper presents a  design  for  a  system  that  generates  environments  that   enables people to program by voice and a method of  determining if the system is successful. It also shows how  this generator can be used to support entering data and  writing XML documents.', 'doi': '10.1145/354324.354362', 'url': 'https://doi.org/10.1145/354324.354362', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Programming by voice, VocalProgramming', 'author': 'Arnold, Stephen C. and Mark, Leo and Goldthwaite, John', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354362'}"
A semantic transcoding system to adapt Web services for users with disabilities,10.1145/354324.354363,"Among the most critical issues of the internet today is how to make Web content accessible to all users, especially to users with disabilities. To meet the diverse needs and abilities of this population, the Web today calls for the development of new systems and methods to enable the same content to be adapted for display according to specific, often conflicting needs. One way to achieve this goal is through Web con- tent transcoding. This paper presents a system, called Aurora, that transcodes Web content based on semantic rather than syntactic constructs. The goal is to deliver Web-based services (such as auction, search engine, travel, etc.) to a diverse set of users according to their specific needs. Using a schema-driven framework, Aurora extracts and maps Web content into domain-specific XML data based on abstract user goals. In doing so, it separates the meaning Web content from its presentation. The system further enables an extensible set of interface adaptors to generate custom Web pages, on-the-fly, from this standardized XML data. Ultimately, it streamlines and customizes the Web interface to faciliate navigation. The mechanisms of this rule-based semantic transcoding system and its advantages and limitations as a strategy to make Web services more accessible are the subject of this paper.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'disabled users, adaptivity, adaptability, XML transcoding, Web intermediaries, Web accessiblity', 'numpages': '8', 'pages': '156–163', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'Among the most critical issues of the internet today is how to make Web content accessible to all users, especially to users with disabilities. To meet the diverse needs and abilities of this population, the Web today calls for the development of new systems and methods to enable the same content to be adapted for display according to specific, often conflicting needs. One way to achieve this goal is through Web con- tent transcoding. This paper presents a system, called Aurora, that transcodes Web content based on semantic rather than syntactic constructs. The goal is to deliver Web-based services (such as auction, search engine, travel, etc.) to a diverse set of users according to their specific needs. Using a schema-driven framework, Aurora extracts and maps Web content into domain-specific XML data based on abstract user goals. In doing so, it separates the meaning Web content from its presentation. The system further enables an extensible set of interface adaptors to generate custom Web pages, on-the-fly, from this standardized XML data. Ultimately, it streamlines and customizes the Web interface to faciliate navigation. The mechanisms of this rule-based semantic transcoding system and its advantages and limitations as a strategy to make Web services more accessible are the subject of this paper.', 'doi': '10.1145/354324.354363', 'url': 'https://doi.org/10.1145/354324.354363', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A semantic transcoding system to adapt Web services for users with disabilities', 'author': 'Huang, Anita W. and Sundaresan, Neel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354363'}"
Transcoding proxy for nonvisual web access,10.1145/354324.354371,"These days, the web has been coming to play various types of  roles, so each site has been designed in a complex way to integrate  as many roles as possible. Web authors tend to cram various  functions and many links into one page to improve usability for  sighted users. This authoring trend makes nonvisual Web  access  harder. To solve this problem, we decided to develop a system to  transcode already-existing Web pages to be accessible, which  works as an intermediary (proxy) between a Web server and a  user. Our transcoding proxy consists of 5 modules using 3 kinds  of annotations. The user interface of the system is characterized by  three transcoding modes: simplification, full-text and original  page.  In  this  paper,  we  will  describe  an  overview  of  our   transcoding proxy as well as the user interface of the system.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'transcoding, portal, differential, blind, annotations, Web accessibility', 'numpages': '8', 'pages': '164–171', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'These days, the web has been coming to play various types of  roles, so each site has been designed in a complex way to integrate  as many roles as possible. Web authors tend to cram various  functions and many links into one page to improve usability for  sighted users. This authoring trend makes nonvisual Web  access  harder. To solve this problem, we decided to develop a system to  transcode already-existing Web pages to be accessible, which  works as an intermediary (proxy) between a Web server and a  user. Our transcoding proxy consists of 5 modules using 3 kinds  of annotations. The user interface of the system is characterized by  three transcoding modes: simplification, full-text and original  page.  In  this  paper,  we  will  describe  an  overview  of  our   transcoding proxy as well as the user interface of the system.', 'doi': '10.1145/354324.354371', 'url': 'https://doi.org/10.1145/354324.354371', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Transcoding proxy for nonvisual web access', 'author': 'Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354371'}"
Annotation-based transcoding for nonvisual web access,10.1145/354324.354588,"These days, Web authors try to describe as much information as  possible in one page using various types of visual effects. This  information is visually fragmented into groupings. Blind users  read the Web contents in tag order, but visually fragmented  groupings are not  accessible using tag order reading. In addition,  the Web contents are designed to be visually appealing using a lot  of  images.  This  style  makes  nonvisual  Web   access  harder.   Therefore we decided to develop an annotation-based transcoding  system to convert already-existing Web pages to be accessible,  which works between a Web server and a user. It consists of two  components,  one  for  structural  annotations  and  one  for   commentary  annotations.  Structural  annotations  are  used  to   recognize visually fragmented groupings as well as to show the  importance and basic role of each group. Commentary annotations  are used to give users a useful description of each grouping. In this  paper, we will describe our transcoding method for nonvisual Web  access based on the annotations.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'transcoding system, structural annotation, nonvisual web access, commentary annotation, blind', 'numpages': '8', 'pages': '172–179', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'These days, Web authors try to describe as much information as  possible in one page using various types of visual effects. This  information is visually fragmented into groupings. Blind users  read the Web contents in tag order, but visually fragmented  groupings are not  accessible using tag order reading. In addition,  the Web contents are designed to be visually appealing using a lot  of  images.  This  style  makes  nonvisual  Web   access  harder.   Therefore we decided to develop an annotation-based transcoding  system to convert already-existing Web pages to be accessible,  which works between a Web server and a user. It consists of two  components,  one  for  structural  annotations  and  one  for   commentary  annotations.  Structural  annotations  are  used  to   recognize visually fragmented groupings as well as to show the  importance and basic role of each group. Commentary annotations  are used to give users a useful description of each grouping. In this  paper, we will describe our transcoding method for nonvisual Web  access based on the annotations.', 'doi': '10.1145/354324.354588', 'url': 'https://doi.org/10.1145/354324.354588', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Annotation-based transcoding for nonvisual web access', 'author': 'Asakawa, Chieko and Takagi, Hironobu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354588'}"
A domain specific language framework for non-visual browsing of complex HTML structures,10.1145/354324.354373,"We present a general framework for navigating complex structures - specifically, tables, frames, and forms?found in web-pages. Our framework is based on an (automatically or manually created) program written in a domain specific language that captures the semantic structure of the table/frame/form as well as specifies the strategy to be used for navigating it. We describe our general framework and the domain specific language we have designed.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'domain specific languages, Web browsers, HTML', 'numpages': '8', 'pages': '180–187', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'We present a general framework for navigating complex structures - specifically, tables, frames, and forms?found in web-pages. Our framework is based on an (automatically or manually created) program written in a domain specific language that captures the semantic structure of the table/frame/form as well as specifies the strategy to be used for navigating it. We describe our general framework and the domain specific language we have designed.', 'doi': '10.1145/354324.354373', 'url': 'https://doi.org/10.1145/354324.354373', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'A domain specific language framework for non-visual browsing of complex HTML structures', 'author': 'Pontelli, E. and Xiong, W. and Gupta, G. and Karshmer, A. I.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354373'}"
Constructive exploration of spatial information by blind users,10.1145/354324.354375,"When blind people wish to walk through an area not fully known to them, they have to prepare themselves even more thoroughly than sighted pedestrians. We propose a new approach to support this preparation with the help of an interactive computer method, called  constructive exploration. Using this method, the user is guided in physically constructing the spatial arrangement to be learned using building blocks. We describe two implementations of the concept, one with a graspable interface with object tracking and the other employing a force feedback device. We report on first tests of the implementations.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'orientation aids, force feedback devices, blind users, augmented reality', 'numpages': '5', 'pages': '188–192', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'When blind people wish to walk through an area not fully known to them, they have to prepare themselves even more thoroughly than sighted pedestrians. We propose a new approach to support this preparation with the help of an interactive computer method, called  constructive exploration. Using this method, the user is guided in physically constructing the spatial arrangement to be learned using building blocks. We describe two implementations of the concept, one with a graspable interface with object tracking and the other employing a force feedback device. We report on first tests of the implementations.', 'doi': '10.1145/354324.354375', 'url': 'https://doi.org/10.1145/354324.354375', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Constructive exploration of spatial information by blind users', 'author': 'Schneider, Jochen and Strothotte, Thomas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354375'}"
Wearable interfaces for orientation and wayfinding,10.1145/354324.354380,"People with severe visual impairment need a means of  remaining  oriented  to  their  environment  as  they  move   through  it.  Three  wearable  orientation  interfaces  were   developed  and  evaluated  toward  this  purpose:  a   stereophonic sonic guide (sonic ?carrot?), speech output,  and shoulder-tapping system. Street crossing was used as a  critical test setting in which to evaluate these interfaces.  The shoulder-tapping system was found most universally  usable.  Considering  the  great  variety  of  co-morbidities   within  this  population,  the  authors  concluded  that  a   combined tapping/speech interface would provide usability  and flexibility to the greatest number of people under the  widest range of environmental conditions.","{'series': ""Assets '00"", 'location': 'Arlington, Virginia, USA', 'keywords': 'wayfinding, street crossing, orientation aid, blindness', 'numpages': '8', 'pages': '193–200', 'booktitle': 'Proceedings of the Fourth International ACM Conference on Assistive Technologies', 'abstract': 'People with severe visual impairment need a means of  remaining  oriented  to  their  environment  as  they  move   through  it.  Three  wearable  orientation  interfaces  were   developed  and  evaluated  toward  this  purpose:  a   stereophonic sonic guide (sonic\u202f?carrot?), speech output,  and shoulder-tapping system. Street crossing was used as a  critical test setting in which to evaluate these interfaces.  The shoulder-tapping system was found most universally  usable.  Considering  the  great  variety  of  co-morbidities   within  this  population,  the  authors  concluded  that  a   combined tapping/speech interface would provide usability  and flexibility to the greatest number of people under the  widest range of environmental conditions.', 'doi': '10.1145/354324.354380', 'url': 'https://doi.org/10.1145/354324.354380', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581133138', 'year': '2000', 'title': 'Wearable interfaces for orientation and wayfinding', 'author': 'Ross, David A. and Blasch, Bruce B.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/354324.354380'}"
