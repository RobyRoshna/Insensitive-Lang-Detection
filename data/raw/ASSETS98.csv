Title,DOI,Abstract,BibTeX
"Smart rooms, desks, and clothes",10.1145/274497.274498,"We  are  working  to  develop  smart  networked  environments  thatcan  help  people  in  their  homes,  offices,  cars,  and  when  walking  about.  Our  research  is  aimed  at  giving  rooms,  desks,  and  clothes  the  perceptual  and  cognitive  intelligence  needed  to  become  active  helpers.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'adaptive environments, multimodal interfaces, perceptual environments, wearable computers', 'numpages': '2', 'pages': '1–2', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We  are  working  to  develop  smart  networked  environments  thatcan  help  people  in  their  homes,  offices,  cars,  and  when  walking  about.  Our  research  is  aimed  at  giving  rooms,  desks,  and  clothes  the  perceptual  and  cognitive  intelligence  needed  to  become  active  helpers.', 'doi': '10.1145/274497.274498', 'url': 'https://doi.org/10.1145/274497.274498', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Smart rooms, desks, and clothes', 'author': 'Pentland, Alexander', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274498'}"
Comparing effects of navigational interface modalities on speaker prosodics,10.1145/274497.274499,"Displayless  interface  technology  must  address  issues  similar  to  those  of  GUI  access  technology  for  users  with  visual  impairments.  Both  must  address  the  issue  of  providing  nonvisual  access  to  spatial  data.  This  research  examined  the  hypothesis  that  strictly  verbal  access  to  spatial  datsi  places  a  cognitive  burden  on  the  user,  which  in  turn  impacts  the  prosodies,  i.e.,  nonverbal  aspects,  of  the  user?s  speech.  The  hypothesis  was  tested  through  experiments  in  which  subjects  used  speech-based,  displayless  interface  followed  by  a  multimodal  interface  to  perform  a  series  of  navigational  tasks.  Their  speech  was  recorded  during  the  experiments  and  post-processed  for  prosodic  content.  Statistical  analysis  of  the  post-processed  data  showed  significant  differences  in  subjects?  prosodies  when  using  the  displayless  versus  the  multimodal  interface.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'GUI access, displayless interfaces prosodies', 'numpages': '8', 'pages': '3–10', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'Displayless  interface  technology  must  address  issues  similar  to  those  of  GUI  access  technology  for  users  with  visual  impairments.  Both  must  address  the  issue  of  providing  nonvisual  access  to  spatial  data.  This  research  examined  the  hypothesis  that  strictly  verbal  access  to  spatial  datsi  places  a  cognitive  burden  on  the  user,  which  in  turn  impacts  the  prosodies,  i.e.,  nonverbal  aspects,  of  the  user?s  speech.  The  hypothesis  was  tested  through  experiments  in  which  subjects  used  speech-based,  displayless  interface  followed  by  a  multimodal  interface  to  perform  a  series  of  navigational  tasks.  Their  speech  was  recorded  during  the  experiments  and  post-processed  for  prosodic  content.  Statistical  analysis  of  the  post-processed  data  showed  significant  differences  in  subjects?  prosodies  when  using  the  displayless  versus  the  multimodal  interface.', 'doi': '10.1145/274497.274499', 'url': 'https://doi.org/10.1145/274497.274499', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Comparing effects of navigational interface modalities on speaker prosodics', 'author': 'Baca, Julie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274499'}"
Computer-based cognitive prosthetics: assistive technology for the treatment of cognitive disabilities,10.1145/274497.274502,"Traumatic  brain  injury  and  stroke  leave  many  individuals  with  cognitive  disabilities  even  after  much  therapy.  For  over  a  decade,  our  multidisciplinary  group  has  been  conducting  a  research  and  clinical  program.  The  focus  of  our  efforts  has  been  restoration  of  individual?s  functioning  through  technology  enabling  them  to  perform  some  of  their  priority  everyday  activities.  Our  approach  has  been  three-fold:  1)  the  application  of  theory  and  methods  from  computer  science;  2)  the  design  of  one-of-a-kind  prosthetic  systems  to  bridge  deficits,  and  3)  therapy  integrated  tightly  with  prosthetic  technology.  Research  incorporated  the  single-subject  case  study  approach  -  widely  used  in  brain  injury  rehabilitation  -  with  studies  being  partial  replicates  for  grouping  data.  Results  have  been  significant  and  substantial,  with  an  increase  of  function  being  the  rule  rather  than  the  exception.  An  important  finding  is  that  our  evaluation  techniques  of  patient  abilities  tends  to  show  greater  abilities  than  show  in  clinical  testing  These  abilities  can  be  used  in  participatory  design  to  greatly  enhance  the  clinical  outcome.  Also,  the  impact  of  small  deficits  on  behavior  seems  to  be  significantly  greater  than  one  would  expect.  Resolving  or  bridging  small  deficits  can  have  considerable  behavioral  impact.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'cognitive disabilities, cognitive prosthetics, health care applications, learning disabilities, personal productivity tools, usability testing, user interfaces, user studies', 'numpages': '8', 'pages': '11–18', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'Traumatic  brain  injury  and  stroke  leave  many  individuals  with  cognitive  disabilities  even  after  much  therapy.  For  over  a  decade,  our  multidisciplinary  group  has  been  conducting  a  research  and  clinical  program.  The  focus  of  our  efforts  has  been  restoration  of  individual?s  functioning  through  technology  enabling  them  to  perform  some  of  their  priority  everyday  activities.  Our  approach  has  been  three-fold:  1)  the  application  of  theory  and  methods  from  computer  science;  2)  the  design  of  one-of-a-kind  prosthetic  systems  to  bridge  deficits,  and  3)  therapy  integrated  tightly  with  prosthetic  technology.  Research  incorporated  the  single-subject  case  study  approach  -  widely  used  in  brain  injury  rehabilitation  -  with  studies  being  partial  replicates  for  grouping  data.  Results  have  been  significant  and  substantial,  with  an  increase  of  function  being  the  rule  rather  than  the  exception.  An  important  finding  is  that  our  evaluation  techniques  of  patient  abilities  tends  to  show  greater  abilities  than  show  in  clinical  testing  These  abilities  can  be  used  in  participatory  design  to  greatly  enhance  the  clinical  outcome.  Also,  the  impact  of  small  deficits  on  behavior  seems  to  be  significantly  greater  than  one  would  expect.  Resolving  or  bridging  small  deficits  can  have  considerable  behavioral  impact.', 'doi': '10.1145/274497.274502', 'url': 'https://doi.org/10.1145/274497.274502', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Computer-based cognitive prosthetics: assistive technology for the treatment of cognitive disabilities', 'author': 'Cole, Elliot and Dehdashti, Parto', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274502'}"
Toward the use of speech and natural language technology in intervention for a language-disordered population,10.1145/274497.274503,"We  describe  the  design  of  Simone  Says  an  interactive  soft-  ware  environment  for  language  remediation  that  brings  to-  gether  research  in  speech  recognition,  natural  language  pro-  cessing  and  computer-aided  instruction.  The  underlying  technology  for  the  implementation  and  the  system?s  even-  tual  evaluation  are  also  discussed.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'numpages': '8', 'pages': '19–26', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We  describe  the  design  of  Simone  Says  an  interactive  soft-  ware  environment  for  language  remediation  that  brings  to-  gether  research  in  speech  recognition,  natural  language  pro-  cessing  and  computer-aided  instruction.  The  underlying  technology  for  the  implementation  and  the  system?s  even-  tual  evaluation  are  also  discussed.', 'doi': '10.1145/274497.274503', 'url': 'https://doi.org/10.1145/274497.274503', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Toward the use of speech and natural language technology in intervention for a language-disordered population', 'author': 'Lehman, Jill Fain', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274503'}"
Lessons from developing audio HTML interface,10.1145/274497.274504,"In this paper, we discuss the choice of specific sounds to use in an audio HTML interface, based on our previous research into developing principles for sound choice, called the AHA framework. AHA can be used along with the consideration of issues related to the target audience such as user tasks, goals, and interests to choose specific sounds for an interface. We describe two scenarios of potential users and interfaces that would seem to be appropriate for them.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'HTML, WWW, audio interfaces, blind, human-computer interaction', 'numpages': '8', 'pages': '27–34', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'In this paper, we discuss the choice of specific sounds to use in an audio HTML interface, based on our previous research into developing principles for sound choice, called the AHA framework. AHA can be used along with the consideration of issues related to the target audience such as user tasks, goals, and interests to choose specific sounds for an interface. We describe two scenarios of potential users and interfaces that would seem to be appropriate for them.', 'doi': '10.1145/274497.274504', 'url': 'https://doi.org/10.1145/274497.274504', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Lessons from developing audio HTML interface', 'author': 'James, Frankie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274504'}"
The use of gestures in multimodal input,10.1145/274497.274505,"For users with motion impairments, the standard keyboard and mouse arrangement for computer access often presents problems. Other approaches have to be adopted to overcome this.In this paper, we will describe the development of a prototype multimodal input system based on two gestural input channels. Results from extensive user trials of this system are presented. These trials showed that the physical and cognitive loads on the user can quickly become excessive and detrimental to the interaction. Designers of multimodal input systems need to be aware of this and perform regular user trials to minimize the problem.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'gesture recognition, multimodal input, user trials', 'numpages': '8', 'pages': '35–42', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'For users with motion impairments, the standard keyboard and mouse arrangement for computer access often presents problems. Other approaches have to be adopted to overcome this.In this paper, we will describe the development of a prototype multimodal input system based on two gestural input channels. Results from extensive user trials of this system are presented. These trials showed that the physical and cognitive loads on the user can quickly become excessive and detrimental to the interaction. Designers of multimodal input systems need to be aware of this and perform regular user trials to minimize the problem.', 'doi': '10.1145/274497.274505', 'url': 'https://doi.org/10.1145/274497.274505', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'The use of gestures in multimodal input', 'author': 'Keates, Simeon and Robinson, Peter', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274505'}"
VRML-based representations of ASL fingerspelling on the World Wide Web,10.1145/274497.274506,"Virtual  Reality  Modeling  Language  (VRML)  is  an  effective  tool  to  document  sign  language  on  the  World-Wide  Web.  In  this  paper,  we  present  techniques  to  enlarge  the  vocabulary  of  encoded  ASL  signs  in  VRML  2.0  for  educational  purposes.  In  order  to  prove  the  concept  of  gesture  making,  a  Web  site  is  presented  that  demonstrates  application  of  the  hand  model  to  fingerspell  the  ASL  manual  alphabet  and  numbers.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'American Sign Language, Virtual Reality Modeling Language, World Wide Web, hand gestures', 'numpages': '3', 'pages': '43–45', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'Virtual  Reality  Modeling  Language  (VRML)  is  an  effective  tool  to  document  sign  language  on  the  World-Wide  Web.  In  this  paper,  we  present  techniques  to  enlarge  the  vocabulary  of  encoded  ASL  signs  in  VRML  2.0  for  educational  purposes.  In  order  to  prove  the  concept  of  gesture  making,  a  Web  site  is  presented  that  demonstrates  application  of  the  hand  model  to  fingerspell  the  ASL  manual  alphabet  and  numbers.', 'doi': '10.1145/274497.274506', 'url': 'https://doi.org/10.1145/274497.274506', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'VRML-based representations of ASL fingerspelling on the World Wide Web', 'author': 'Su, S. Augustine and Furuta, Richard K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274506'}"
Programming for usability in nonvisual user interfaces,10.1145/274497.274507,Standard  software  engineering  methods  are  not  directly  applicable  to  nonvisual  user  inter-  faces  due  to  the  mismatch  of  user  interfaces  of  developers  and  users.  We  have  developed  tools  to  visualize  the  nonvisual  presentation  and  the  nonvisual  interaction.  This  requires  to  apply  software  interfaces  as  used  by  screen  readers  to  collect  data  about  widgets.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'evaluation, nonvisual user interfaces, software engineering', 'numpages': '3', 'pages': '46–48', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'Standard  software  engineering  methods  are  not  directly  applicable  to  nonvisual  user  inter-  faces  due  to  the  mismatch  of  user  interfaces  of  developers  and  users.  We  have  developed  tools  to  visualize  the  nonvisual  presentation  and  the  nonvisual  interaction.  This  requires  to  apply  software  interfaces  as  used  by  screen  readers  to  collect  data  about  widgets.', 'doi': '10.1145/274497.274507', 'url': 'https://doi.org/10.1145/274497.274507', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Programming for usability in nonvisual user interfaces', 'author': 'Weber, Gerhard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274507'}"
Expanded interactions: broadening human-centered computing,10.1145/274497.274508,"n this paper, we describe the preliminary results of an NSF sponsored invitational workshop entitled Expanded Interaction: Broadening Human-Centered Computing. The workshop brought together members of academia, industry and government, as well as individuals with disabilities to examine the commonalities and expansion of human-computer interaction and universal design. The underlying theme was to encourage a scientific understand of the diversity of human performance.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'disabilities, human-centered computing, intermedia, multimodal, telecommunications, universal access', 'numpages': '2', 'pages': '49–50', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'n this paper, we describe the preliminary results of an NSF sponsored invitational workshop entitled Expanded Interaction: Broadening Human-Centered Computing. The workshop brought together members of academia, industry and government, as well as individuals with disabilities to examine the commonalities and expansion of human-computer interaction and universal design. The underlying theme was to encourage a scientific understand of the diversity of human performance.', 'doi': '10.1145/274497.274508', 'url': 'https://doi.org/10.1145/274497.274508', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Expanded interactions: broadening human-centered computing', 'author': 'Foulds, Richard A. and Joyce, Arthur W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274508'}"
Conversational gestures for direct manipulation on the audio desktop,10.1145/274497.274509,We describe the speech-enabling approach to building auditory interfaces that treat speech as a first-class modality. The process of designing effective auditory interfaces is decomposed into identifying the atomic actions that make up the user interaction and the conversational gestures that enable these actions. The auditory interface is then synthesized by mapping these conversational gestures to appropriate primitives in the auditory environment.We illustrate this process with a concrete example by developing an auditory interface to the visually intensive task of playing tetris. Playing Tetris is a fun activity that has many of the same demands as day-to-day activities on the electronic desktop. Speech-enabling Tetris thus not only provides a fun way to exercise ones geometric reasoning abilities - it provides useful lessons in speech-enabling commonplace computing tasks.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'numpages': '8', 'pages': '51–58', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We describe the speech-enabling approach to building auditory interfaces that treat speech as a first-class modality. The process of designing effective auditory interfaces is decomposed into identifying the atomic actions that make up the user interaction and the conversational gestures that enable these actions. The auditory interface is then synthesized by mapping these conversational gestures to appropriate primitives in the auditory environment.We illustrate this process with a concrete example by developing an auditory interface to the visually intensive task of playing tetris. Playing Tetris is a fun activity that has many of the same demands as day-to-day activities on the electronic desktop. Speech-enabling Tetris thus not only provides a fun way to exercise ones geometric reasoning abilities - it provides useful lessons in speech-enabling commonplace computing tasks.', 'doi': '10.1145/274497.274509', 'url': 'https://doi.org/10.1145/274497.274509', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Conversational gestures for direct manipulation on the audio desktop', 'author': 'Raman, T. V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274509'}"
Automatic babble recognition for early detection of speech related disorders,10.1145/274497.274510,"We  have  developed  a  program,  the  Early  Vocalization  Analyzer  (EVA),  that  automatically  analyxes  digitized  recordings  of  infant  vocalizations.  The  purpose  of  such  a  system  is  to  automatically  and  reliably  screen  infants  who  may  be  at  risk  for  later  communication  problems.  Applying  the  landmark  detection  theory  of  Stevens  et  al.,  for  the  recognition  of  features  in  adult  speech,  EVA  detects  syllables  in  vocalixations  produced  by  typically  developing  six  to  thirteen  month  old  infants.  We  discuss  the  differences  between  adult-specific  code  and  code  written  to  analyxe  infant  vocalixations  and  present  the  results  of  validity-testing.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'acoustic analysis, early intervention, infants, pre-speech vocalization', 'numpages': '8', 'pages': '59–66', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We  have  developed  a  program,  the  Early  Vocalization  Analyzer  (EVA),  that  automatically  analyxes  digitized  recordings  of  infant  vocalizations.  The  purpose  of  such  a  system  is  to  automatically  and  reliably  screen  infants  who  may  be  at  risk  for  later  communication  problems.  Applying  the  landmark  detection  theory  of  Stevens  et  al.,  for  the  recognition  of  features  in  adult  speech,  EVA  detects  syllables  in  vocalixations  produced  by  typically  developing  six  to  thirteen  month  old  infants.  We  discuss  the  differences  between  adult-specific  code  and  code  written  to  analyxe  infant  vocalixations  and  present  the  results  of  validity-testing.', 'doi': '10.1145/274497.274510', 'url': 'https://doi.org/10.1145/274497.274510', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Automatic babble recognition for early detection of speech related disorders', 'author': 'Fell, Harriet J. and MacAuslan, Joel and Chenausky, Karen and Ferrier, Linda J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274510'}"
A tool for creating eye-aware applications that adapt to changes in user behaviors,10.1145/274497.274511,"A development tool is described that can be used to create eye-aware software applications that adapt in real-time to changes in a user's natural eye-movement behaviors and intentions. The research involved in developing this tool focuses on identifying patterns of eye-movement that describe three behaviors: Knowledgeable Movement, Searching, and Prolonged Searching. In the process of doing the research, two important features of eye-movement patterns were discovered-Revisits and Significant Fixations. Revisits and Significant Fixations complement the recognition of saccades, fixations, and blinks, and make easier the recognition of high-level patterns in users' natural eye-movements.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'eye interpretation engine, eye-aware, eyetracking, fixation duration, fixations, human-computer interaction, user intent, user-centered approach, visual search', 'numpages': '8', 'pages': '67–74', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': ""A development tool is described that can be used to create eye-aware software applications that adapt in real-time to changes in a user's natural eye-movement behaviors and intentions. The research involved in developing this tool focuses on identifying patterns of eye-movement that describe three behaviors: Knowledgeable Movement, Searching, and Prolonged Searching. In the process of doing the research, two important features of eye-movement patterns were discovered-Revisits and Significant Fixations. Revisits and Significant Fixations complement the recognition of saccades, fixations, and blinks, and make easier the recognition of high-level patterns in users' natural eye-movements."", 'doi': '10.1145/274497.274511', 'url': 'https://doi.org/10.1145/274497.274511', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'A tool for creating eye-aware applications that adapt to changes in user behaviors', 'author': 'Edwards, Greg', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274511'}"
Designing interfaces for an overlooked user group: considering the visual profiles of partially sighted users,10.1145/274497.274512,"In this position paper we argue the importance of research focusing on the issues involved in designing computer systems for partially sighted computer users. Currently, there is a lack of data that explores how combinations of impaired visual processes affect preferences for, and performance with, graphical user interfaces. This lack of fundamental information about how an individual's visual profile determines the strategies and behaviors exhibited while using computers limits our ability to design effective user interfaces for partially sighted computer users. The objective of this position paper is to motivate research that addresses this deficiency in our knowledge base so that researchers can design enabling technologies in a systematic fashion for this unique user group as has been done for fully sighted users and blind users.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'enabling technologies, human-computer interaction, partial vision, visually impaired', 'numpages': '3', 'pages': '75–77', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': ""In this position paper we argue the importance of research focusing on the issues involved in designing computer systems for partially sighted computer users. Currently, there is a lack of data that explores how combinations of impaired visual processes affect preferences for, and performance with, graphical user interfaces. This lack of fundamental information about how an individual's visual profile determines the strategies and behaviors exhibited while using computers limits our ability to design effective user interfaces for partially sighted computer users. The objective of this position paper is to motivate research that addresses this deficiency in our knowledge base so that researchers can design enabling technologies in a systematic fashion for this unique user group as has been done for fully sighted users and blind users."", 'doi': '10.1145/274497.274512', 'url': 'https://doi.org/10.1145/274497.274512', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Designing interfaces for an overlooked user group: considering the visual profiles of partially sighted users', 'author': 'Jacko, Julie A. and Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274512'}"
Modeling and generating sign language as animated line drawings,10.1145/274497.274513,"This paper introduces an application for creating words and sentences of sign language as animated gesture sequences. A gesture is composed of the left and right hand sign, a body movement and a facial expression.We propose a technique for generating gestures as line drawings. Using line drawings allows us to run the application with simple 3D models without loss of essential information while achieving images which can be transferred very quickly over a network. Furthermore, the images resemble those used in printed teaching materials for sign language.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'numpages': '7', 'pages': '78–84', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This paper introduces an application for creating words and sentences of sign language as animated gesture sequences. A gesture is composed of the left and right hand sign, a body movement and a facial expression.We propose a technique for generating gestures as line drawings. Using line drawings allows us to run the application with simple 3D models without loss of essential information while achieving images which can be transferred very quickly over a network. Furthermore, the images resemble those used in printed teaching materials for sign language.', 'doi': '10.1145/274497.274513', 'url': 'https://doi.org/10.1145/274497.274513', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Modeling and generating sign language as animated line drawings', 'author': 'Godenschweger, Frank and Strothotte, Thomas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274513'}"
TGuide: a guidance system for tactile image exploration,10.1145/274497.274514,We present a guidance system for blind people exploring tactile graphics. The system is composed of a new device using 8 vibrating elements to output directional information and a guidance software controlling the device. The evaluation of the system is also described.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'blind people, evaluation, graphics, guidance, tactile output device', 'numpages': '7', 'pages': '85–91', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We present a guidance system for blind people exploring tactile graphics. The system is composed of a new device using 8 vibrating elements to output directional information and a guidance software controlling the device. The evaluation of the system is also described.', 'doi': '10.1145/274497.274514', 'url': 'https://doi.org/10.1145/274497.274514', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'TGuide: a guidance system for tactile image exploration', 'author': 'Kurze, Martin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274514'}"
Haptic virtual reality for blind computer users,10.1145/274497.274515,"This  paper  describes  a  series  of  studies  involving  a  haptic  device  which  can  display  virtual  textures  and  3-D  objects.  The  device  has  potential  for  simulating  real  world  objects  and  assisting  in  the  navigation  of  virtual  environments.  Three  experiments  investigated:  (a)  whether  previous  results  from  experiments  using  real  textures  could  be  replicated  using  virtual  textures;  (b)  whether  participants  perceived  virtual  objects  to  have  the  intended  size  and  angle;  and  (c)  whether  simulated  real  objects  could  be  recognised.  In  all  the  experiments  differences  in  perception  by  blind  and  sighted  people  were  also  explored.  The  results  have  implications  for  the  future  design  of  VEs  in  that  it  cannot  be  assumed  that  virtual  textures  and  objects  will  feel  to  the  user  as  the  designer  intends.  However,  they  do  show  that  a  haptic  interface  has  considerable  potential  for  blind  computer  users.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'World Wide Web, blind users, haptic device, perception of virtual textures and objects, virtual environments', 'numpages': '8', 'pages': '92–99', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This  paper  describes  a  series  of  studies  involving  a  haptic  device  which  can  display  virtual  textures  and  3-D  objects.  The  device  has  potential  for  simulating  real  world  objects  and  assisting  in  the  navigation  of  virtual  environments.  Three  experiments  investigated:  (a)  whether  previous  results  from  experiments  using  real  textures  could  be  replicated  using  virtual  textures;  (b)  whether  participants  perceived  virtual  objects  to  have  the  intended  size  and  angle;  and  (c)  whether  simulated  real  objects  could  be  recognised.  In  all  the  experiments  differences  in  perception  by  blind  and  sighted  people  were  also  explored.  The  results  have  implications  for  the  future  design  of  VEs  in  that  it  cannot  be  assumed  that  virtual  textures  and  objects  will  feel  to  the  user  as  the  designer  intends.  However,  they  do  show  that  a  haptic  interface  has  considerable  potential  for  blind  computer  users.', 'doi': '10.1145/274497.274515', 'url': 'https://doi.org/10.1145/274497.274515', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Haptic virtual reality for blind computer users', 'author': 'Colwell, Chetz and Petrie, Helen and Kornbrot, Diana and Hardwick, Andrew and Furner, Stephen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274515'}"
Auditory navigation in hyperspace: design and evaluation of a non-visual hypermedia system for blind users,10.1145/274497.274516,"This  paper  presents  the  design  and  evaluation  of  a  hypermedia  system  for  blind  users,  making  use  of  a  non-visual  interface,  non-speech  sounds,  three  input  devices,  and  a  37-node  hypermedia  module.  The  important  components  of  an  effective  auditory  interface  are  discussed,  together  with  the  design  of  the  auditory  interface  to  hypermedia  material.  The  evaluation  is  described,  which  was  conducted  over  several  weeks,  and  used  a  range  of  complementary  objective  and  subjective  measures  to  assess  usability,  performance  and  user  preferences.  The  findings  from  evaluations  with  9  visually  impaired  student  participants  are  presented.  The  results  from  this  research  can  be  applied  to  the  design  and  evaluation  of  other  non-visual  hypermedia  systems,  such  as  auditory  WWW  browsers  and  digital  talking  books.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'auditory navigation of hypermedia, blind and visually impaired users, evaluation methodology, non-speech sounds, non-visual interface design', 'numpages': '8', 'pages': '100–107', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This  paper  presents  the  design  and  evaluation  of  a  hypermedia  system  for  blind  users,  making  use  of  a  non-visual  interface,  non-speech  sounds,  three  input  devices,  and  a  37-node  hypermedia  module.  The  important  components  of  an  effective  auditory  interface  are  discussed,  together  with  the  design  of  the  auditory  interface  to  hypermedia  material.  The  evaluation  is  described,  which  was  conducted  over  several  weeks,  and  used  a  range  of  complementary  objective  and  subjective  measures  to  assess  usability,  performance  and  user  preferences.  The  findings  from  evaluations  with  9  visually  impaired  student  participants  are  presented.  The  results  from  this  research  can  be  applied  to  the  design  and  evaluation  of  other  non-visual  hypermedia  systems,  such  as  auditory  WWW  browsers  and  digital  talking  books.', 'doi': '10.1145/274497.274516', 'url': 'https://doi.org/10.1145/274497.274516', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Auditory navigation in hyperspace: design and evaluation of a non-visual hypermedia system for blind users', 'author': ""Morley, Sarah and Petrie, Helen and O'Neill, Anne-Marie and McNally, Peter"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274516'}"
SUITEKeys: a speech understanding interface for the motor-control challenged,10.1145/274497.274517,"This paper presents SUITEKeys, a continuous speech understanding interface for motor-control challenged computer users. This interface provides access to all available functionality of a computer by modeling interaction at the physical keyboard and mouse level. The paper briefly discusses the advantages and disadvantages of using speech at the user interface; it outlines the user- centered approach employed in developing the system; it introduces the formal model of the user interface in terms of its conceptual, semantic, syntactic, lexical and acoustic levels; it describes the SUITEKeys system architecture which consists of symbolic, statistical, and connectionist components; it presents a pilot study for assessing the effectiveness of speech as an alternate input modality for motor-control challenged users; and closes with directions for future research.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'accessibility, input devices, intelligent user interfaces, keyboard, motor-disabilities, mouse, natural language, selectable modalities, speech recognition', 'numpages': '8', 'pages': '108–115', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This paper presents SUITEKeys, a continuous speech understanding interface for motor-control challenged computer users. This interface provides access to all available functionality of a computer by modeling interaction at the physical keyboard and mouse level. The paper briefly discusses the advantages and disadvantages of using speech at the user interface; it outlines the user- centered approach employed in developing the system; it introduces the formal model of the user interface in terms of its conceptual, semantic, syntactic, lexical and acoustic levels; it describes the SUITEKeys system architecture which consists of symbolic, statistical, and connectionist components; it presents a pilot study for assessing the effectiveness of speech as an alternate input modality for motor-control challenged users; and closes with directions for future research.', 'doi': '10.1145/274497.274517', 'url': 'https://doi.org/10.1145/274497.274517', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'SUITEKeys: a speech understanding interface for the motor-control challenged', 'author': 'Manaris, Bill and Harkreader, Alan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274517'}"
Adaptation of a cash dispenser to the needs of blind and visually impaired people,10.1145/274497.274518,"An existing cash dispenser was implemented with speech output to give access to blind and visually impaired people. Additionally, the screen graphics and the function access were modified. The hardware was not changed. Blind and visually impaired subjects performed a usability-test, and experts in the field of human-computer-interaction evaluated the dispenser system?s usability heuristically. The results showed that the modifications help blind and visually impaired people to access such machines, but adaptations of the hardware are necessary to maintain usability. The two evaluation methods did not produce consistent results.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'ATM, application design, automatic teller machine, blind and visually impaired users, cash dispenser, heuristic evaluation, usability-test', 'numpages': '8', 'pages': '116–123', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'An existing cash dispenser was implemented with speech output to give access to blind and visually impaired people. Additionally, the screen graphics and the function access were modified. The hardware was not changed. Blind and visually impaired subjects performed a usability-test, and experts in the field of human-computer-interaction evaluated the dispenser system?s usability heuristically. The results showed that the modifications help blind and visually impaired people to access such machines, but adaptations of the hardware are necessary to maintain usability. The two evaluation methods did not produce consistent results.', 'doi': '10.1145/274497.274518', 'url': 'https://doi.org/10.1145/274497.274518', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Adaptation of a cash dispenser to the needs of blind and visually impaired people', 'author': 'Manzke, Jens M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274518'}"
Some thoughts on assistive technology for the blind,10.1145/274497.274519,"As  a  youngster,  the  principal  assistive  technology  I  had  was  Braille.  Braille  was,  and  still  remains,  the  most  important  assistive  technology  for  a  blind  person.  It  is  the  basis  of  literacy.  A  blind  person  must  have  much  more  information  about  computers  than  his  sighted  colleague  to  do  the  same  job.  Not  only  must  he  know  how  to  run  the  application  programs  that  he  uses  daily,  but  he  must  also  know  how  to  operated  all  the  assistive  equipment  he  uses  to  run  those  applications.  His  colleagues  can  help  him  with  the  application  programs,  but  they  know  nothing  about  the  assistive  devices  he  must  use.  And  such  devices  am  proliferating  in  number  and  in  complexity  all  the  time.Not  every  assistive  device  needs  to  be  high  tech  Some  skills  of  daily  living  unrelated  to  a  computer  can  be  very  effective.  Imagination,  resourcefulness,  and  memory  skills  can  be  regatded  as  assistive  techniques  even  if  they  do  not  quality  as  technology.  There  is  also  the  problem  of  putting  useful  devices  into  the  hands  of  those  who  can  benefit  from  them.  Money  is  one  obstacle;  adequate  training  is  another.  Of  course,  all  of  the  above  themes  will  be  elaborated  when  developing  the  text  of  the  full  presentation.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'numpages': '2', 'pages': '124–125', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'As  a  youngster,  the  principal  assistive  technology  I  had  was  Braille.  Braille  was,  and  still  remains,  the  most  important  assistive  technology  for  a  blind  person.  It  is  the  basis  of  literacy.  A  blind  person  must  have  much  more  information  about  computers  than  his  sighted  colleague  to  do  the  same  job.  Not  only  must  he  know  how  to  run  the  application  programs  that  he  uses  daily,  but  he  must  also  know  how  to  operated  all  the  assistive  equipment  he  uses  to  run  those  applications.  His  colleagues  can  help  him  with  the  application  programs,  but  they  know  nothing  about  the  assistive  devices  he  must  use.  And  such  devices  am  proliferating  in  number  and  in  complexity  all  the  time.Not  every  assistive  device  needs  to  be  high  tech  Some  skills  of  daily  living  unrelated  to  a  computer  can  be  very  effective.  Imagination,  resourcefulness,  and  memory  skills  can  be  regatded  as  assistive  techniques  even  if  they  do  not  quality  as  technology.  There  is  also  the  problem  of  putting  useful  devices  into  the  hands  of  those  who  can  benefit  from  them.  Money  is  one  obstacle;  adequate  training  is  another.  Of  course,  all  of  the  above  themes  will  be  elaborated  when  developing  the  text  of  the  full  presentation.', 'doi': '10.1145/274497.274519', 'url': 'https://doi.org/10.1145/274497.274519', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Some thoughts on assistive technology for the blind', 'author': 'Nemeth, Abraham', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274519'}"
An interactive method for accessing tables in HTML,10.1145/274497.274521,"Although visually impaired people can access digital information by using computers, GUIs make it difficult for them to do so. One of the main obstacles preventing them from taking advantage of the almost unlimited information resources on the Web is the use of visual representations such as tables, image maps, and classified structures. This paper proposes a method for converting these visual representations into non-visual representations in HMTL. After describing a system that we developed to evaluate our method, we will discuss an interactive method for accessing tables in HTML files.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'HTML, WWW, blind, conversion, table, visually disabled', 'numpages': '3', 'pages': '126–128', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'Although visually impaired people can access digital information by using computers, GUIs make it difficult for them to do so. One of the main obstacles preventing them from taking advantage of the almost unlimited information resources on the Web is the use of visual representations such as tables, image maps, and classified structures. This paper proposes a method for converting these visual representations into non-visual representations in HMTL. After describing a system that we developed to evaluate our method, we will discuss an interactive method for accessing tables in HTML files.', 'doi': '10.1145/274497.274521', 'url': 'https://doi.org/10.1145/274497.274521', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'An interactive method for accessing tables in HTML', 'author': 'Oogane, Toshiya and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274521'}"
Alliance for technology access (briefing): making assistive technology accessible to the community,10.1145/274497.274522,The Alliance for Technology Access is a network of 40+ community-based consumer-driven centers whose mission is to redefine human potential by making assistive technology a part of the daily lives of people with disabilities.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'choice, disability access, individual preferences', 'pages': '129', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'The Alliance for Technology Access is a network of 40+ community-based consumer-driven centers whose mission is to redefine human potential by making assistive technology a part of the daily lives of people with disabilities.', 'doi': '10.1145/274497.274522', 'url': 'https://doi.org/10.1145/274497.274522', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Alliance for technology access (briefing): making assistive technology accessible to the community', 'author': 'Glicksman, Mary Ann', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274522'}"
Dual level intraframe coding for increased video telecommunication bandwidth,10.1145/274497.274523,"While  digital  video  transmission  and  video  conferencing  methods  have  improved  significantly  over  the  last  few  years,  the  transmission  of  sign  language  for  individuals  who  are  deaf  via  this  medium  still  remains  a  problem.  Desktop  video  teleconferencing  systems  accommodate  the  bandwidth  limitations  of  both  analog  and  digital  (ISDN)  telephone  channels  by  reducing  the  frame  rate  while  preserving  voice  quality  and  only  minimally  degrading  image  quality.  Sign  language  transmission  requires  fidelity  to  movement  (consistent  and  high  frame  rate),  and  requires  reasonable  image  quality  only  in  the  areas  around  the  hands  and  face.  This  paper  presents  a  dual-level  compression  approach  which  uses  a  newly  developed  technique  to  identify  the  hands  and  face  from  the  remainder  of  each  video  frame.  This  allows  for  a  very  lossy,  high  compression  of  most  of  each  frame,  while  retaining  the  visual  quality  necessary  to  identify  hand  shapes  and  read  facial  expressions.  By  taking  advantage  of  this compression,  additional  bandwidth  is  recaptured  to  allow  an  acceptable  frame  rate  that  maintains  the  fidelity  of  human  movement  necessary  to  represent  sign  language.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'disability access, gesture, hearing impairments, sign language', 'numpages': '6', 'pages': '130–135', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'While  digital  video  transmission  and  video  conferencing  methods  have  improved  significantly  over  the  last  few  years,  the  transmission  of  sign  language  for  individuals  who  are  deaf  via  this  medium  still  remains  a  problem.  Desktop  video  teleconferencing  systems  accommodate  the  bandwidth  limitations  of  both  analog  and  digital  (ISDN)  telephone  channels  by  reducing  the  frame  rate  while  preserving  voice  quality  and  only  minimally  degrading  image  quality.  Sign  language  transmission  requires  fidelity  to  movement  (consistent  and  high  frame  rate),  and  requires  reasonable  image  quality  only  in  the  areas  around  the  hands  and  face.  This  paper  presents  a  dual-level  compression  approach  which  uses  a  newly  developed  technique  to  identify  the  hands  and  face  from  the  remainder  of  each  video  frame.  This  allows  for  a  very  lossy,  high  compression  of  most  of  each  frame,  while  retaining  the  visual  quality  necessary  to  identify  hand  shapes  and  read  facial  expressions.  By  taking  advantage  of  this compression,  additional  bandwidth  is  recaptured  to  allow  an  acceptable  frame  rate  that  maintains  the  fidelity  of  human  movement  necessary  to  represent  sign  language.', 'doi': '10.1145/274497.274523', 'url': 'https://doi.org/10.1145/274497.274523', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Dual level intraframe coding for increased video telecommunication bandwidth', 'author': 'Saxe, David M. and Foulds, Richard A. and Joyce, Arthur W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274523'}"
Reading and writing mathematics: the MAVIS project,10.1145/274497.274524,"One of the greatest challenges to the visually impaired student in science and mathematics disciplines is the reading and writing of complex mathematical equations or have convenient access to information based tools such as the world wide web. In research currently underway at New Mexico State University, tools are being built using logic programming to facilitate access to complex information in a variety of formats. On top of the logic based tools, new interfaces are being designed to permit more convenient access to information by our visually impaired students.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'LaTeX, Nemeth code, education, mathematics', 'numpages': '8', 'pages': '136–143', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'One of the greatest challenges to the visually impaired student in science and mathematics disciplines is the reading and writing of complex mathematical equations or have convenient access to information based tools such as the world wide web. In research currently underway at New Mexico State University, tools are being built using logic programming to facilitate access to complex information in a variety of formats. On top of the logic based tools, new interfaces are being designed to permit more convenient access to information by our visually impaired students.', 'doi': '10.1145/274497.274524', 'url': 'https://doi.org/10.1145/274497.274524', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Reading and writing mathematics: the MAVIS project', 'author': 'Karshmer, A. I. and Gupta, G. and Geiiger, S. and Weaver, C.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274524'}"
Making VRML accessible for people with disabilities,10.1145/274497.274525,This paper describes a set of techniques for improving access to Virtual Reality Modeling Language (VRML) environments for people with disabilities. These range from simple textual additions to the VRML file to scripts which aid in the creation of more accessible worlds. We also propose an initial set of guidelines authors can use to improve VRML accessibility.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'VRML, accessibility, audio feedback, data access, navigational aids, speech input, user interfaces, virtual environments', 'numpages': '5', 'pages': '144–148', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This paper describes a set of techniques for improving access to Virtual Reality Modeling Language (VRML) environments for people with disabilities. These range from simple textual additions to the VRML file to scripts which aid in the creation of more accessible worlds. We also propose an initial set of guidelines authors can use to improve VRML accessibility.', 'doi': '10.1145/274497.274525', 'url': 'https://doi.org/10.1145/274497.274525', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Making VRML accessible for people with disabilities', 'author': 'Ressler, Sandy and Wang, Qiming', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274525'}"
User interface of a Home Page Reader,10.1145/274497.274526,"We first discuss the difficulties that blind people face in trying to lie in society, because of the lack of accessible information resources, and then consider the potential of the Web as a new information resource for the blind. After describing how blind people in Japan currently access the Web, we give an overview of our system for nonvisual Web access. Our system has five special characteristics. One is the use of a numeric keypad for surfing the Net, with a key assignment designed for intuitive operation. The second is a fast- forward key for quick reading. The next two are that hyperlinks are read in a female voice and HTML tags are converted into voice data. The fifth is that the system can be synchronized with Netscape Navigator. After evaluating the system and offering some conclusions, we discuss our plans for future work.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'GUI, WWW, blind, home page reader, numeric keypad, visually disabled', 'numpages': '8', 'pages': '149–156', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We first discuss the difficulties that blind people face in trying to lie in society, because of the lack of accessible information resources, and then consider the potential of the Web as a new information resource for the blind. After describing how blind people in Japan currently access the Web, we give an overview of our system for nonvisual Web access. Our system has five special characteristics. One is the use of a numeric keypad for surfing the Net, with a key assignment designed for intuitive operation. The second is a fast- forward key for quick reading. The next two are that hyperlinks are read in a female voice and HTML tags are converted into voice data. The fifth is that the system can be synchronized with Netscape Navigator. After evaluating the system and offering some conclusions, we discuss our plans for future work.', 'doi': '10.1145/274497.274526', 'url': 'https://doi.org/10.1145/274497.274526', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'User interface of a Home Page Reader', 'author': 'Asakawa, Chieko and Itoh, Takashi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274526'}"
Digital talking books on a PC: a usability evaluation of the prototype DAISY playback software,10.1145/274497.274527,"his  paper  describes  the  design  and  evaluation  of  the  first  system  to  play  digital  talking  books  on  a  PC:  the  DAISY  Playback  Software.  The  features  of  the  software  for  navigating  through  structured  digital  audio  are  described.  A  detailed  usability  evaluation  of  this  prototype  software  was  designed  and  conducted  to  assess  its  current  usability,  in  which  13  blind/partially  sighted  participants  completed  a  series  of  realistic  tasks  and  answered  detailed  usability  questions  on  the  system.  Recommendations  for  improvements  are  presented  which  might  inform  designers  of  similar  systems,  such  as  other  digital  talking  book  systems  or  WWW  browsers.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'auditory navigation, blind and visually impaired readers, digital talking books, evaluation methodology, structured information access', 'numpages': '8', 'pages': '157–164', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'his  paper  describes  the  design  and  evaluation  of  the  first  system  to  play  digital  talking  books  on  a  PC:  the  DAISY  Playback  Software.  The  features  of  the  software  for  navigating  through  structured  digital  audio  are  described.  A  detailed  usability  evaluation  of  this  prototype  software  was  designed  and  conducted  to  assess  its  current  usability,  in  which  13  blind/partially  sighted  participants  completed  a  series  of  realistic  tasks  and  answered  detailed  usability  questions  on  the  system.  Recommendations  for  improvements  are  presented  which  might  inform  designers  of  similar  systems,  such  as  other  digital  talking  book  systems  or  WWW  browsers.', 'doi': '10.1145/274497.274527', 'url': 'https://doi.org/10.1145/274497.274527', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Digital talking books on a PC: a usability evaluation of the prototype DAISY playback software', 'author': 'Morley, Sarah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274527'}"
A phoneme probability display for individuals with hearing disabilities,10.1145/274497.274528,We are building an aid for individuals with hearing impairments which converts continuous speech into an animated visual display. A speech analysis system continuously estimates phoneme probabilities from the input acoustic stream. Phoneme symbols are displayed graphically with brightness in proportion to estimated phoneme probabilities. We use an automated layout algorithm to design the display to group acoustically confusable phonemes together in the graphical display.,"{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'numpages': '4', 'pages': '165–168', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'We are building an aid for individuals with hearing impairments which converts continuous speech into an animated visual display. A speech analysis system continuously estimates phoneme probabilities from the input acoustic stream. Phoneme symbols are displayed graphically with brightness in proportion to estimated phoneme probabilities. We use an automated layout algorithm to design the display to group acoustically confusable phonemes together in the graphical display.', 'doi': '10.1145/274497.274528', 'url': 'https://doi.org/10.1145/274497.274528', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'A phoneme probability display for individuals with hearing disabilities', 'author': 'Roy, Deb and Pentland, Alex', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274528'}"
Augmenting home and office environments,10.1145/274497.274529,"In this panel, we describe different techniques and applications of augmenting home and office environments. One application of augmented environments is to provide additional information associated with the environment via visual and / or auditory cues. Other applications assist users hi controlling aspects of their environment. Commercial opportunities in home automation allow people to more easily operate complex systems for temperature control, security, and maintenance. There are numerous research issues in designing augmented environments such as how multimodal input and output can be used effectively. Many of these systems need to assume some knowledge of the user?s intent and context. How to capture and interpret information about users in these environments is an open question. We will describe these issues during this panel as well as discuss with the ASSETS community how these efforts can be applied to the realm of assistive technology.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'audio, augmented reality, home automation, multimodal, see-through displays, ubiquitous computing', 'numpages': '4', 'pages': '169–172', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'In this panel, we describe different techniques and applications of augmenting home and office environments. One application of augmented environments is to provide additional information associated with the environment via visual and / or auditory cues. Other applications assist users hi controlling aspects of their environment. Commercial opportunities in home automation allow people to more easily operate complex systems for temperature control, security, and maintenance. There are numerous research issues in designing augmented environments such as how multimodal input and output can be used effectively. Many of these systems need to assume some knowledge of the user?s intent and context. How to capture and interpret information about users in these environments is an open question. We will describe these issues during this panel as well as discuss with the ASSETS community how these efforts can be applied to the realm of assistive technology.', 'doi': '10.1145/274497.274529', 'url': 'https://doi.org/10.1145/274497.274529', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'Augmenting home and office environments', 'author': 'Mynatt, Elizabeth and Blattner, Douglas and Blattner, Meera M. and MacIntyre, Blair and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274529'}"
A model of keyboard configuration requirements,10.1145/274497.274530,"This  paper  presents  a  user  model:  a  computer  program  which  examines  the  behaviour  of  a  real  computer  user.  The  model  encompasses  four  aspects  of  keyboard  use  which  can  present  difficulties  for  people  with  motor  disabilities.  Where  relevant  keyboard  configuratibn  options  exist,  the  model  chooses  appropriate  settings  for  these  options.  The  model  bases  its  recommendations  on  observation  of  users  typing  free  English  text.  It  is  intended  to  form  part  of  a  dynamic  configuration  support  tool.  Empirical  evaluation  showed  the  model  to  be  very  accurate  in  identification  of  a  given  user?s  difficulties.  Where  recommended  configuration  options  were  tried  by  the  participants,  high  levels  of  error  reduction  and  user  satisfaction  were  found.","{'series': ""Assets '98"", 'location': 'Marina del Rey, California, USA', 'keywords': 'Bounce Keys, Repeat Keys, Sticky Keys, empirical studies, keyboard configuration, keyboards, motor disabilities, user modelling', 'numpages': '9', 'pages': '173–181', 'booktitle': 'Proceedings of the Third International ACM Conference on Assistive Technologies', 'abstract': 'This  paper  presents  a  user  model:  a  computer  program  which  examines  the  behaviour  of  a  real  computer  user.  The  model  encompasses  four  aspects  of  keyboard  use  which  can  present  difficulties  for  people  with  motor  disabilities.  Where  relevant  keyboard  configuratibn  options  exist,  the  model  chooses  appropriate  settings  for  these  options.  The  model  bases  its  recommendations  on  observation  of  users  typing  free  English  text.  It  is  intended  to  form  part  of  a  dynamic  configuration  support  tool.  Empirical  evaluation  showed  the  model  to  be  very  accurate  in  identification  of  a  given  user?s  difficulties.  Where  recommended  configuration  options  were  tried  by  the  participants,  high  levels  of  error  reduction  and  user  satisfaction  were  found.', 'doi': '10.1145/274497.274530', 'url': 'https://doi.org/10.1145/274497.274530', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1581130201', 'year': '1998', 'title': 'A model of keyboard configuration requirements', 'author': 'Trewin, Shari and Pain, Helen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/274497.274530'}"
