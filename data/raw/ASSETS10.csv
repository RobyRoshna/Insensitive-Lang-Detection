Title,DOI,Abstract,BibTeX
Session details: Keynote address,10.1145/3252136,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252136', 'url': 'https://doi.org/10.1145/3252136', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Keynote address', 'author': 'Hanson, Vicki L.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252136'}"
The future of assistive technologies: a time of promise and apprehension,10.1145/1878803.1878805,"Continual advances in the capabilities of both assistive and mainstream technologies offers great potential for meeting the needs people with disabilities. However, there are significant potential obstacles to actually realizing the benefits of these advances for people with disabilities.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technologies, human-machine interfaces', 'numpages': '2', 'pages': '1–2', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Continual advances in the capabilities of both assistive and mainstream technologies offers great potential for meeting the needs people with disabilities. However, there are significant potential obstacles to actually realizing the benefits of these advances for people with disabilities.', 'doi': '10.1145/1878803.1878805', 'url': 'https://doi.org/10.1145/1878803.1878805', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'The future of assistive technologies: a time of promise and apprehension', 'author': 'Cook, Albert M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878805'}"
Session details: Considering accessibility,10.1145/3252137,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252137', 'url': 'https://doi.org/10.1145/3252137', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Considering accessibility', 'author': 'Lewis, Clayton', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252137'}"
Disability studies as a source of critical inquiry for the field of assistive technology,10.1145/1878803.1878807,"Disability studies and assistive technology are two related fields that have long shared common goals - understanding the experience of disability and identifying and addressing relevant issues. Despite these common goals, there are some important differences in what professionals in these fields consider problems, perhaps related to the lack of connection between the fields. To help bridge this gap, we review some of the key literature in disability studies. We present case studies of two research projects in assistive technology and discuss how the field of disability studies influenced that work, led us to identify new or different problems relevant to the field of assistive technology, and helped us to think in new ways about the research process and its impact on the experiences of individuals who live with disability. We also discuss how the field of disability studies has influenced our teaching and highlight some of the key publications and publication venues from which our community may want to draw more deeply in the future.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, disability studies', 'numpages': '8', 'pages': '3–10', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Disability studies and assistive technology are two related fields that have long shared common goals - understanding the experience of disability and identifying and addressing relevant issues. Despite these common goals, there are some important differences in what professionals in these fields consider problems, perhaps related to the lack of connection between the fields. To help bridge this gap, we review some of the key literature in disability studies. We present case studies of two research projects in assistive technology and discuss how the field of disability studies influenced that work, led us to identify new or different problems relevant to the field of assistive technology, and helped us to think in new ways about the research process and its impact on the experiences of individuals who live with disability. We also discuss how the field of disability studies has influenced our teaching and highlight some of the key publications and publication venues from which our community may want to draw more deeply in the future.', 'doi': '10.1145/1878803.1878807', 'url': 'https://doi.org/10.1145/1878803.1878807', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Disability studies as a source of critical inquiry for the field of assistive technology', 'author': 'Mankoff, Jennifer and Hayes, Gillian R. and Kasnitz, Devva', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878807'}"
"A general education course on universal access, disability, technology and society",10.1145/1878803.1878808,"This paper reports on a General Education course called ""Universal Access: Disability, Technology and Society"" that enables students from all majors to learn more about disability and the issues that surround it, as well as how Assistive Technology facilitates effective participation of those with disabilities in society. Guest lectures, meant to give the students different perspectives on disability, are integral part of the course. Guest lecturers include experts in disability studies, professionals working with people with disabilities, and persons with disability. To gain practical knowledge, the students carry out group projects or volunteering activities that involves people with disabilities. Since its first introduction in 2006, the course had always filled to capacity. A survey with 75 students conducted in Winter 2010 revealed that students felt that their knowledge about universal access and disabilities had improved significantly, and that they had become aware of accessibility in everyday life.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'disability awareness, general education, undergraduate education, universal access', 'numpages': '8', 'pages': '11–18', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper reports on a General Education course called ""Universal Access: Disability, Technology and Society"" that enables students from all majors to learn more about disability and the issues that surround it, as well as how Assistive Technology facilitates effective participation of those with disabilities in society. Guest lectures, meant to give the students different perspectives on disability, are integral part of the course. Guest lecturers include experts in disability studies, professionals working with people with disabilities, and persons with disability. To gain practical knowledge, the students carry out group projects or volunteering activities that involves people with disabilities. Since its first introduction in 2006, the course had always filled to capacity. A survey with 75 students conducted in Winter 2010 revealed that students felt that their knowledge about universal access and disabilities had improved significantly, and that they had become aware of accessibility in everyday life.', 'doi': '10.1145/1878803.1878808', 'url': 'https://doi.org/10.1145/1878803.1878808', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A general education course on universal access, disability, technology and society', 'author': 'Kurniawan, Sri H. and Arteaga, Sonia and Manduchi, Roberto', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878808'}"
Towards accessible touch interfaces,10.1145/1878803.1878809,"Touch screen mobile devices bear the promise of endless leisure, communication, and productivity opportunities to motor-impaired people. Indeed, users with residual capacities in their upper extremities could benefit immensely from a device with no demands regarding strength. However, the precision required to effectively select a target without physical cues creates problems to people with limited motor abilities. Our goal is to thoroughly study mobile touch screen interfaces, their characteristics and parameterizations, thus providing the tools for informed interface design for motor-impaired users. We present an evaluation performed with 15 tetraplegic people that allowed us to understand the factors limiting user performance within a comprehensive set of interaction techniques (Tapping, Crossing, Exiting and Directional Gesturing) and parameterizations (Position, Size and Direction). Our results show that for each technique, accuracy and precision vary across different areas of the screen and directions, in a way that is directly dependent on target size. Overall, Tapping was both the preferred technique and among the most effective. This proves that it is possible to design inclusive unified interfaces for motor-impaired and able-bodied users once the correct parameterization or adaptability is assured.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'evaluation, interaction techniques, mobile device, tetraplegic, touch screen', 'numpages': '8', 'pages': '19–26', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Touch screen mobile devices bear the promise of endless leisure, communication, and productivity opportunities to motor-impaired people. Indeed, users with residual capacities in their upper extremities could benefit immensely from a device with no demands regarding strength. However, the precision required to effectively select a target without physical cues creates problems to people with limited motor abilities. Our goal is to thoroughly study mobile touch screen interfaces, their characteristics and parameterizations, thus providing the tools for informed interface design for motor-impaired users. We present an evaluation performed with 15 tetraplegic people that allowed us to understand the factors limiting user performance within a comprehensive set of interaction techniques (Tapping, Crossing, Exiting and Directional Gesturing) and parameterizations (Position, Size and Direction). Our results show that for each technique, accuracy and precision vary across different areas of the screen and directions, in a way that is directly dependent on target size. Overall, Tapping was both the preferred technique and among the most effective. This proves that it is possible to design inclusive unified interfaces for motor-impaired and able-bodied users once the correct parameterization or adaptability is assured.', 'doi': '10.1145/1878803.1878809', 'url': 'https://doi.org/10.1145/1878803.1878809', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Towards accessible touch interfaces', 'author': 'Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim and Gon\\c{c}alves, Daniel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878809'}"
Session details: Evaluating accessibility,10.1145/3252138,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252138', 'url': 'https://doi.org/10.1145/3252138', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Evaluating accessibility', 'author': 'Sanchez, Jaime', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252138'}"
Towards a tool for keystroke level modeling of skilled screen reading,10.1145/1878803.1878811,"Designers often have no access to individuals who use screen reading software, and may have little understanding of how their design choices impact these users. We explore here whether cog-nitive models of auditory interaction could provide insight into screen reader usability. By comparing human data with a tool-generated model of a practiced task performed using a screen reader, we identify several requirements for such models and tools. Most important is the need to represent parallel execution of hearing with thinking and acting. Rules for placement of cogni-tive operators that were developed for visual user interfaces may not be applicable in the auditory domain. Other mismatches be-tween the data and the model were attributed to the extremely fast listening rate and differences between the typing patterns of screen reader usage and the model's assumptions. This work in-forms the development of more accurate models of auditory inter-action. Tools incorporating such models could help designers create user interfaces that are well tuned for screen reader users, without the need for modeling expertise.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, keyboard navigation, klm, screen reader, usability', 'numpages': '8', 'pages': '27–34', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Designers often have no access to individuals who use screen reading software, and may have little understanding of how their design choices impact these users. We explore here whether cog-nitive models of auditory interaction could provide insight into screen reader usability. By comparing human data with a tool-generated model of a practiced task performed using a screen reader, we identify several requirements for such models and tools. Most important is the need to represent parallel execution of hearing with thinking and acting. Rules for placement of cogni-tive operators that were developed for visual user interfaces may not be applicable in the auditory domain. Other mismatches be-tween the data and the model were attributed to the extremely fast listening rate and differences between the typing patterns of screen reader usage and the model's assumptions. This work in-forms the development of more accurate models of auditory inter-action. Tools incorporating such models could help designers create user interfaces that are well tuned for screen reader users, without the need for modeling expertise."", 'doi': '10.1145/1878803.1878811', 'url': 'https://doi.org/10.1145/1878803.1878811', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Towards a tool for keystroke level modeling of skilled screen reading', 'author': 'Trewin, Shari and John, Bonnie E. and Richards, John and Swart, Cal and Brezin, Jonathan and Bellamy, Rachel and Thomas, John', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878811'}"
Accessibility by demonstration: enabling end users to guide developers to web accessibility solutions,10.1145/1878803.1878812,"Few web developers have been explicitly trained to create accessible web pages, and are unlikely to recognize subtle accessibility and usability concerns that disabled people face. Evaluating web pages with assistive technology can reveal problems, but this software takes time to install and its complexity can be overwhelming. To address these problems, we introduce a new approach for accessibility evaluation called Accessibility by Demonstration (ABD). ABD lets assistive technology users retroactively record accessibility problems at the time they experience them as human-readable macros and easily send those recordings and the software necessary to replay them to others. This paper describes an implementation of ABD as an extension to the WebAnywhere screen reader, and presents an evaluation with 15 web developers not experienced with accessibility showing that interacting with these recordings helped them understand and fix some subtle accessibility problems better than existing tools.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blind users, evaluation, web accessibility, web usability', 'numpages': '8', 'pages': '35–42', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Few web developers have been explicitly trained to create accessible web pages, and are unlikely to recognize subtle accessibility and usability concerns that disabled people face. Evaluating web pages with assistive technology can reveal problems, but this software takes time to install and its complexity can be overwhelming. To address these problems, we introduce a new approach for accessibility evaluation called Accessibility by Demonstration (ABD). ABD lets assistive technology users retroactively record accessibility problems at the time they experience them as human-readable macros and easily send those recordings and the software necessary to replay them to others. This paper describes an implementation of ABD as an extension to the WebAnywhere screen reader, and presents an evaluation with 15 web developers not experienced with accessibility showing that interacting with these recordings helped them understand and fix some subtle accessibility problems better than existing tools.', 'doi': '10.1145/1878803.1878812', 'url': 'https://doi.org/10.1145/1878803.1878812', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Accessibility by demonstration: enabling end users to guide developers to web accessibility solutions', 'author': 'Bigham, Jeffrey P. and Brudvik, Jeremy T. and Zhang, Bernie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878812'}"
Testability and validity of WCAG 2.0: the expertise effect,10.1145/1878803.1878813,"Web Content Accessibility Guidelines 2.0 (WCAG 2.0) require that success criteria be tested by human inspection. Further, testability of WCAG 2.0 criteria is achieved if 80\% of knowledgeable inspectors agree that the criteria has been met or not. In this paper we investigate the very core WCAG 2.0, being their ability to determine web content accessibility conformance. We conducted an empirical study to ascertain the testability of WCAG 2.0 success criteria when experts and non-experts evaluated four relatively complex web pages; and the differences between the two. Further, we discuss the validity of the evaluations generated by these inspectors and look at the differences in validity due to expertise.In summary, our study, comprising 22 experts and 27 non-experts, shows that approximately 50\% of success criteria fail to meet the 80\% agreement threshold; experts produce 20\% false positives and miss 32\% of the true problems. We also compared the performance of experts against that of non-experts and found that agreement for the non-experts dropped by 6\%, false positives reach 42\% and false negatives 49\%. This suggests that in many cases WCAG 2.0 conformance cannot be tested by human inspection to a level where it is believed that at least 80\% of knowledgeable human evaluators would agree on the conclusion. Why experts fail to meet the 80\% threshold and what can be done to help achieve this level are the subjects of further investigation.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'evaluation, expertise, guideline, web accessibility', 'numpages': '8', 'pages': '43–50', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Web Content Accessibility Guidelines 2.0 (WCAG 2.0) require that success criteria be tested by human inspection. Further, testability of WCAG 2.0 criteria is achieved if 80\\% of knowledgeable inspectors agree that the criteria has been met or not. In this paper we investigate the very core WCAG 2.0, being their ability to determine web content accessibility conformance. We conducted an empirical study to ascertain the testability of WCAG 2.0 success criteria when experts and non-experts evaluated four relatively complex web pages; and the differences between the two. Further, we discuss the validity of the evaluations generated by these inspectors and look at the differences in validity due to expertise.In summary, our study, comprising 22 experts and 27 non-experts, shows that approximately 50\\% of success criteria fail to meet the 80\\% agreement threshold; experts produce 20\\% false positives and miss 32\\% of the true problems. We also compared the performance of experts against that of non-experts and found that agreement for the non-experts dropped by 6\\%, false positives reach 42\\% and false negatives 49\\%. This suggests that in many cases WCAG 2.0 conformance cannot be tested by human inspection to a level where it is believed that at least 80\\% of knowledgeable human evaluators would agree on the conclusion. Why experts fail to meet the 80\\% threshold and what can be done to help achieve this level are the subjects of further investigation.', 'doi': '10.1145/1878803.1878813', 'url': 'https://doi.org/10.1145/1878803.1878813', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Testability and validity of WCAG 2.0: the expertise effect', 'author': 'Brajnik, Giorgio and Yesilada, Yeliz and Harper, Simon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878813'}"
Session details: Accessibility research in the wild,10.1145/3252139,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252139', 'url': 'https://doi.org/10.1145/3252139', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Accessibility research in the wild', 'author': 'Feng, Jinjung', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252139'}"
Field evaluation of a collaborative memory aid for persons with amnesia and their family members,10.1145/1878803.1878815,"The loss of memory can have a profound and disabling effect on individuals. People who acquire memory impairments are often unable to live independent lives because they cannot remember what they need to do. In many cases, they rely on family members who live with them to accomplish everyday activities, such as coordinating a doctor's appointment. To design technology for persons with amnesia and their families, we involved end users in the participatory design of a collaborative memory aid called Family-Link. We evaluated Family-Link by comparing it to a commercially available calendar application. We found that participants shared significantly more events when using Family-Link. Qualitative evidence also suggests that Family-Link increased participants' awareness of family members' schedules, enabled caregivers to track the person with amnesia leading to a greater a sense of security and reduced stress, and reduced the amount of caregiver coordination effort. The paper concludes with design implications.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'amnesia, collaboration, design, family, memory aid, user study', 'numpages': '8', 'pages': '51–58', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The loss of memory can have a profound and disabling effect on individuals. People who acquire memory impairments are often unable to live independent lives because they cannot remember what they need to do. In many cases, they rely on family members who live with them to accomplish everyday activities, such as coordinating a doctor's appointment. To design technology for persons with amnesia and their families, we involved end users in the participatory design of a collaborative memory aid called Family-Link. We evaluated Family-Link by comparing it to a commercially available calendar application. We found that participants shared significantly more events when using Family-Link. Qualitative evidence also suggests that Family-Link increased participants' awareness of family members' schedules, enabled caregivers to track the person with amnesia leading to a greater a sense of security and reduced stress, and reduced the amount of caregiver coordination effort. The paper concludes with design implications."", 'doi': '10.1145/1878803.1878815', 'url': 'https://doi.org/10.1145/1878803.1878815', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Field evaluation of a collaborative memory aid for persons with amnesia and their family members', 'author': 'Wu, Mike and Baecker, Ronald M. and Richards, Brian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878815'}"
In-situ study of blind individuals listening to audio-visual contents,10.1145/1878803.1878816,"Videodescription (VD) or audio description is added to the sound track of audio-visual contents to make media such as film and television accessible to individuals with visual impairment. VD translates the relevant visual information into auditory information. In our previous users' testing, we found that the need of VD could be quite different depending on the visual disabilities of the participants. In order to better identify those differences, we conducted a study with ten legally blind individuals (with and without residual vision) to observe the type, quantity and frequency of the information needed by them. We learned that the degree of residual vision and the complexity of the content have a significant impact of the required level of VD. This suggests that a tool to render VD should offer a basic level of information, allow enough flexibility to provide more VD if needed, and answer on the fly demands for specific information. These specifications were implanted into an accessible video player.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, audio description, blind and visual impairment., multimedia', 'numpages': '8', 'pages': '59–66', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Videodescription (VD) or audio description is added to the sound track of audio-visual contents to make media such as film and television accessible to individuals with visual impairment. VD translates the relevant visual information into auditory information. In our previous users' testing, we found that the need of VD could be quite different depending on the visual disabilities of the participants. In order to better identify those differences, we conducted a study with ten legally blind individuals (with and without residual vision) to observe the type, quantity and frequency of the information needed by them. We learned that the degree of residual vision and the complexity of the content have a significant impact of the required level of VD. This suggests that a tool to render VD should offer a basic level of information, allow enough flexibility to provide more VD if needed, and answer on the fly demands for specific information. These specifications were implanted into an accessible video player."", 'doi': '10.1145/1878803.1878816', 'url': 'https://doi.org/10.1145/1878803.1878816', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'In-situ study of blind individuals listening to audio-visual contents', 'author': 'Chapdelaine, Claude', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878816'}"
Understanding the challenges and opportunities for richer descriptions of stereotypical behaviors of children with asd: a concept exploration and validation,10.1145/1878803.1878817,"Individuals with Autism Spectrum Disorder (ASD) often engage in stereotypical behaviors. In some individuals these behaviors occur with very high frequency and can be disruptive and at times self-injurious. We propose a system that can tacitly collect contextual data related to the individual's physiological state and their external environment, and map it to occurrences of stereotypies. A user study was conducted with children with ASD, parents, and caregivers to explore and validate this concept. A prototype of the system, developed through participatory design, was used in the study as a probe to elicit the information needs of these stakeholders, and provide a better understanding of the nuances involved in supporting those needs. Here we present the findings of this study, and four design recommendations; promoting ecological integration, addressing privacy concerns, supporting inference, and enabling customization.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'autism spectrum disorder, stereotypical repetitive behavior', 'numpages': '8', 'pages': '67–74', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Individuals with Autism Spectrum Disorder (ASD) often engage in stereotypical behaviors. In some individuals these behaviors occur with very high frequency and can be disruptive and at times self-injurious. We propose a system that can tacitly collect contextual data related to the individual's physiological state and their external environment, and map it to occurrences of stereotypies. A user study was conducted with children with ASD, parents, and caregivers to explore and validate this concept. A prototype of the system, developed through participatory design, was used in the study as a probe to elicit the information needs of these stakeholders, and provide a better understanding of the nuances involved in supporting those needs. Here we present the findings of this study, and four design recommendations; promoting ecological integration, addressing privacy concerns, supporting inference, and enabling customization."", 'doi': '10.1145/1878803.1878817', 'url': 'https://doi.org/10.1145/1878803.1878817', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Understanding the challenges and opportunities for richer descriptions of stereotypical behaviors of children with asd: a concept exploration and validation', 'author': 'Nazneen, Fnu and Boujarwah, Fatima A. and Sadler, Shone and Mogus, Amha and Abowd, Gregory D. and Arriaga, Rosa I.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878817'}"
Session details: Non-visual access,10.1145/3252140,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252140', 'url': 'https://doi.org/10.1145/3252140', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Non-visual access', 'author': 'Brajnik, Giorgio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252140'}"
Designing auditory cues to enhance spoken mathematics for visually impaired users,10.1145/1878803.1878819,"Visual mathematic notation provides a succinct and unambiguous description of the structure of mathematical formulae in a manner that is difficult to replicate through the linear channels of synthesized speech and Braille. It is proposed that the use of auditory cues can enhance accessibility to mathematical material and reduce common ambiguities encountered through spoken mathematics. However, the use of additional complex hierarchies of non-speech sounds to represent the structure and scope of equations may be cognitively demanding to process. This can detract from the users' understanding of the mathematical content. In this paper, a new system is presented, which uses a mixture of non-speech auditory cues, modified speech (spearcons) and binaural spatialization to disambiguate the structure of mathematical formulae. A design study, involving an online survey with 56 users, was undertaken to evaluate an existing set of auditory cues and to brainstorm alternative ideas and solutions from users before implementing modified designs and conducting a separate controlled evaluation. It is proposed that by involving a wide number of users in the creative design process, intuitive auditory cues will be implemented with the potential to enhance spoken mathematics for visually impaired users.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, design methods for user interfaces, mathematics, non-speech sound, spearcons, visually impaired users', 'numpages': '8', 'pages': '75–82', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Visual mathematic notation provides a succinct and unambiguous description of the structure of mathematical formulae in a manner that is difficult to replicate through the linear channels of synthesized speech and Braille. It is proposed that the use of auditory cues can enhance accessibility to mathematical material and reduce common ambiguities encountered through spoken mathematics. However, the use of additional complex hierarchies of non-speech sounds to represent the structure and scope of equations may be cognitively demanding to process. This can detract from the users' understanding of the mathematical content. In this paper, a new system is presented, which uses a mixture of non-speech auditory cues, modified speech (spearcons) and binaural spatialization to disambiguate the structure of mathematical formulae. A design study, involving an online survey with 56 users, was undertaken to evaluate an existing set of auditory cues and to brainstorm alternative ideas and solutions from users before implementing modified designs and conducting a separate controlled evaluation. It is proposed that by involving a wide number of users in the creative design process, intuitive auditory cues will be implemented with the potential to enhance spoken mathematics for visually impaired users."", 'doi': '10.1145/1878803.1878819', 'url': 'https://doi.org/10.1145/1878803.1878819', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Designing auditory cues to enhance spoken mathematics for visually impaired users', 'author': ""Murphy, Emma and Bates, Enda and Fitzpatrick, D\\'{o}nal"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878819'}"
Evaluating a tool for improving accessibility to charts and graphs,10.1145/1878803.1878820,"We discuss factors in the design and evaluation of natural language-driven assistive technologies that generate descriptions of, and allow interaction with, graphical representations of numerical data. In particular, we provide data in favor of 1) screen-reading technologies as a usable, useful, and cost-effective means of interacting with graphs. The data also show that by carrying out evaluation of Assistive Technologies on populations other than the target communities, certain subtleties of navigation and interaction may be lost or distorted.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility (blind and visually-impaired), natural language generation and interaction, statistical graphs and diagrams', 'numpages': '8', 'pages': '83–90', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We discuss factors in the design and evaluation of natural language-driven assistive technologies that generate descriptions of, and allow interaction with, graphical representations of numerical data. In particular, we provide data in favor of 1) screen-reading technologies as a usable, useful, and cost-effective means of interacting with graphs. The data also show that by carrying out evaluation of Assistive Technologies on populations other than the target communities, certain subtleties of navigation and interaction may be lost or distorted.', 'doi': '10.1145/1878803.1878820', 'url': 'https://doi.org/10.1145/1878803.1878820', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Evaluating a tool for improving accessibility to charts and graphs', 'author': 'Ferres, Leo and Lindgaard, Gitte and Sumegi, Livia', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878820'}"
A tactile windowing system for blind users,10.1145/1878803.1878821,"Today's window systems present the information in a graphical and thereby a spatial manner making the text-only access of a standard Braille device insufficient to enable blind users an equivalent exploration of the data. In this paper we present the planar Braille Window System (BWS) designed for a tactile display consisting of a pin-matrix of 120 columns and 60 rows. The system is composed of six separate regions enabling the user to receive different types of information simultaneously. The content of the main region containing Braille windows can be shown in various manners (text-or graphics-based) through four different views. The interaction within our Braille Window System is implemented not only by keyboard shortcuts but also by the use of multitouch gestures. Therefore the user is able to interact directly on the touch-sensitive display. A study conducted with eight blind users has confirmed the concept of Braille windows, regions and views. Especially the gestural input for exploring details of the content offers new possibilities in interacting within a GUI.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blind user, braille, gesture interaction, planar tactile display, screen reader, tactile graphics', 'numpages': '8', 'pages': '91–98', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Today's window systems present the information in a graphical and thereby a spatial manner making the text-only access of a standard Braille device insufficient to enable blind users an equivalent exploration of the data. In this paper we present the planar Braille Window System (BWS) designed for a tactile display consisting of a pin-matrix of 120 columns and 60 rows. The system is composed of six separate regions enabling the user to receive different types of information simultaneously. The content of the main region containing Braille windows can be shown in various manners (text-or graphics-based) through four different views. The interaction within our Braille Window System is implemented not only by keyboard shortcuts but also by the use of multitouch gestures. Therefore the user is able to interact directly on the touch-sensitive display. A study conducted with eight blind users has confirmed the concept of Braille windows, regions and views. Especially the gestural input for exploring details of the content offers new possibilities in interacting within a GUI."", 'doi': '10.1145/1878803.1878821', 'url': 'https://doi.org/10.1145/1878803.1878821', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A tactile windowing system for blind users', 'author': 'Prescher, Denise and Weber, Gerhard and Spindler, Martin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878821'}"
Session details: Sign language,10.1145/3252141,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252141', 'url': 'https://doi.org/10.1145/3252141', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Sign language', 'author': 'Fell, Harriet', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252141'}"
Modeling and synthesizing spatially inflected verbs for American sign language animations,10.1145/1878803.1878823,"Animations of American Sign Language (ASL) have accessibility benefits for many signers with lower levels of written language literacy. This paper introduces a novel method for modeling and synthesizing ASL animations based on movement data collected from native signers. This technique allows for the synthesis of animations of signs (in particular, inflecting verbs, which are frequent in ASL) whose performance is affected by the arrangement of locations in 3D space that represent entities under discussion. Mathematical models of hand movement are trained on examples of signs produced by a human animator. Animations of ASL synthesized from the model were judged to be of similar quality to animations produced by a human animator, and these animations led to higher comprehension scores (than baseline approaches limited to selecting signs from a finite dictionary) in an evaluation study conducted with 18 native signers. This novel technique is applicable to ASL or other sign languages. It can significantly increase the repertoire of generation systems and can partially automate the work of humans using scripting systems.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'American sign language, accessibility technology for people who are deaf, animation, natural language generation', 'numpages': '8', 'pages': '99–106', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Animations of American Sign Language (ASL) have accessibility benefits for many signers with lower levels of written language literacy. This paper introduces a novel method for modeling and synthesizing ASL animations based on movement data collected from native signers. This technique allows for the synthesis of animations of signs (in particular, inflecting verbs, which are frequent in ASL) whose performance is affected by the arrangement of locations in 3D space that represent entities under discussion. Mathematical models of hand movement are trained on examples of signs produced by a human animator. Animations of ASL synthesized from the model were judged to be of similar quality to animations produced by a human animator, and these animations led to higher comprehension scores (than baseline approaches limited to selecting signs from a finite dictionary) in an evaluation study conducted with 18 native signers. This novel technique is applicable to ASL or other sign languages. It can significantly increase the repertoire of generation systems and can partially automate the work of humans using scripting systems.', 'doi': '10.1145/1878803.1878823', 'url': 'https://doi.org/10.1145/1878803.1878823', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Modeling and synthesizing spatially inflected verbs for American sign language animations', 'author': 'Huenerfauth, Matt and Lu, Pengfei', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878823'}"
An evaluation of video intelligibility for novice american sign language learners on a mobile device,10.1145/1878803.1878824,"Language immersion from birth is crucial to a child's language development. However, language immersion can be particularly challenging for hearing parents of deaf children to provide as they may have to overcome many difficulties while learning sign language. We intend to create a mobile device-based system to help hearing parents learn sign language. The first step is to understand what level of detail (i.e., resolution) is necessary for novice signers to learn from video of signs. In this paper we present the results of a study designed to evaluate the ability of novices learning sign language to ascertain the details of a particular sign based on video presented on a mobile device. Four conditions were presented. Three conditions involve manipulation of video resolution (low, medium, and high). The fourth condition employs insets showing the sign handshapes along with the high resolution video. Subjects were tested on their ability to emulate the given sign over 80 signs commonly used between parents and their young children. Although participants noticed a reduction in quality in the low resolution condition, there was no significant effect of condition on ability to generate the sign. Sign difficulty had a significant correlation with ability to correctly reproduce the sign. Although the inset handshape condition did not improve the participants' ability to emulate the signs correctly, participant feedback provided insight into situations where insets would be more useful, as well as further suggestions to improve video intelligibility. Participants were able to reproduce even the most complex signs tested with relatively high accuracy.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'american sign language, computer assisted language learning, mobile devices', 'numpages': '8', 'pages': '107–114', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Language immersion from birth is crucial to a child's language development. However, language immersion can be particularly challenging for hearing parents of deaf children to provide as they may have to overcome many difficulties while learning sign language. We intend to create a mobile device-based system to help hearing parents learn sign language. The first step is to understand what level of detail (i.e., resolution) is necessary for novice signers to learn from video of signs. In this paper we present the results of a study designed to evaluate the ability of novices learning sign language to ascertain the details of a particular sign based on video presented on a mobile device. Four conditions were presented. Three conditions involve manipulation of video resolution (low, medium, and high). The fourth condition employs insets showing the sign handshapes along with the high resolution video. Subjects were tested on their ability to emulate the given sign over 80 signs commonly used between parents and their young children. Although participants noticed a reduction in quality in the low resolution condition, there was no significant effect of condition on ability to generate the sign. Sign difficulty had a significant correlation with ability to correctly reproduce the sign. Although the inset handshape condition did not improve the participants' ability to emulate the signs correctly, participant feedback provided insight into situations where insets would be more useful, as well as further suggestions to improve video intelligibility. Participants were able to reproduce even the most complex signs tested with relatively high accuracy."", 'doi': '10.1145/1878803.1878824', 'url': 'https://doi.org/10.1145/1878803.1878824', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'An evaluation of video intelligibility for novice american sign language learners on a mobile device', 'author': 'Weaver, Kimberly A. and Starner, Thad and Hamilton, Harley', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878824'}"
A web-based user survey for evaluating power saving strategies for deaf users of mobileASL,10.1145/1878803.1878825,"MobileASL is a video compression project for two-way, real-time video communication on cell phones, allowing Deaf people to communicate in the language most accessible to them, American Sign Language. Unfortunately, running MobileASL quickly depletes a full battery charge in a few hours. Previous work on MobileASL investigated a method called variable frame rate (VFR) to increase the battery duration. We expand on this previous work by creating two new power saving algorithms, variable spatial resolution (VSR), and the application of both VFR and VSR. These algorithms extend the battery life by altering the temporal and/or spatial resolutions of video transmitted on MobileASL. We found that implementing only VFR extended the battery life from 284 minutes to 307 minutes; implementing only VSR extended the battery life to 306 minutes, and implementing both VFR and VSR extended the battery life to 315 minutes. We evaluated all three algorithms by creating a linguistically accessible online survey to investigate Deaf people's perceptions of video quality when these algorithms were applied. In our survey results, we found that VFR produces perceived video choppiness and VSR produces perceived video blurriness; however, a surprising finding was that when both VFR and VSR are used together, they largely ameliorate the choppiness and blurriness perceived, i.e., they each improve the use of the other. This is a useful finding because using VFR and VSR together saves the most battery life.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'american sign language, battery power consumption, deaf community, deaf culture, encoding algorithms, mobile phones, video compression, web-based user survey', 'numpages': '8', 'pages': '115–122', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""MobileASL is a video compression project for two-way, real-time video communication on cell phones, allowing Deaf people to communicate in the language most accessible to them, American Sign Language. Unfortunately, running MobileASL quickly depletes a full battery charge in a few hours. Previous work on MobileASL investigated a method called variable frame rate (VFR) to increase the battery duration. We expand on this previous work by creating two new power saving algorithms, variable spatial resolution (VSR), and the application of both VFR and VSR. These algorithms extend the battery life by altering the temporal and/or spatial resolutions of video transmitted on MobileASL. We found that implementing only VFR extended the battery life from 284 minutes to 307 minutes; implementing only VSR extended the battery life to 306 minutes, and implementing both VFR and VSR extended the battery life to 315 minutes. We evaluated all three algorithms by creating a linguistically accessible online survey to investigate Deaf people's perceptions of video quality when these algorithms were applied. In our survey results, we found that VFR produces perceived video choppiness and VSR produces perceived video blurriness; however, a surprising finding was that when both VFR and VSR are used together, they largely ameliorate the choppiness and blurriness perceived, i.e., they each improve the use of the other. This is a useful finding because using VFR and VSR together saves the most battery life."", 'doi': '10.1145/1878803.1878825', 'url': 'https://doi.org/10.1145/1878803.1878825', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A web-based user survey for evaluating power saving strategies for deaf users of mobileASL', 'author': 'Tran, Jessica J. and Johnson, Tressa W. and Kim, Joy and Rodriguez, Rafael and Yin, Sheri and Riskin, Eve A. and Ladner, Richard E. and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878825'}"
Session details: Accessible education,10.1145/3252142,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252142', 'url': 'https://doi.org/10.1145/3252142', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Accessible education', 'author': 'Felzer, Torsten', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252142'}"
Multiple view perspectives: improving inclusiveness and video compression in mainstream classroom recordings,10.1145/1878803.1878827,"Multiple View Perspectives (MVP) enables deaf and hard of hearing students to view and record multiple video views of a classroom presentation using a stand-alone solution. We show that deaf and hard of hearing students prefer multiple, focused videos over a single, high-quality video and that a compacted layout of only the most important views is preferred. We also show that this approach empowers deaf and hard of hearing students by virtue of its low cost, flexibility, and ease of use in the classroom.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessible technology, deaf and hard of hearing users', 'numpages': '8', 'pages': '123–130', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Multiple View Perspectives (MVP) enables deaf and hard of hearing students to view and record multiple video views of a classroom presentation using a stand-alone solution. We show that deaf and hard of hearing students prefer multiple, focused videos over a single, high-quality video and that a compacted layout of only the most important views is preferred. We also show that this approach empowers deaf and hard of hearing students by virtue of its low cost, flexibility, and ease of use in the classroom.', 'doi': '10.1145/1878803.1878827', 'url': 'https://doi.org/10.1145/1878803.1878827', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Multiple view perspectives: improving inclusiveness and video compression in mainstream classroom recordings', 'author': 'Kushalnagar, Raja S. and Cavender, Anna C. and P\\^{a}ris, Jehan-Fran\\c{c}ois', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878827'}"
Note-taker 2.0: the next step toward enabling students who are legally blind to take notes in class,10.1145/1878803.1878828,"In-class note-taking is a vital learning activity in secondary and post-secondary classrooms. The process of note-taking helps students stay focused on the instruction, forces them to cognitively process what is being presented, and better retain what has been taught, even if they never refer to their notes after the class. However, note-taking is difficult for students with low vision, or who are legally blind for two reasons. First, they are less able to see what is being presented at the front of them room, and second, they must repeatedly switch between the far-sight task of viewing the front of the room, and the near-sight task of taking notes. This paper describes ongoing research aimed at developing a portable assistive device (called the Note-Taker) that a student can take to class, to assist in the process of taking notes. It describes the principles that have guided the development of the proof-of-concept Note-Taker prototype and the Note-Taker 2.0 prototype. Initial testing of those prototypes has been encouraging, but some significant problems remain to be solved. Proposed solutions are currently being implemented, and appear to be effective. If ongoing usability testing confirms their effectiveness, they will be implemented on the planned Note-Taker 3.0 prototype.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'lecture notes, legal blindness, low vision, note-taker, note-taking', 'numpages': '8', 'pages': '131–138', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In-class note-taking is a vital learning activity in secondary and post-secondary classrooms. The process of note-taking helps students stay focused on the instruction, forces them to cognitively process what is being presented, and better retain what has been taught, even if they never refer to their notes after the class. However, note-taking is difficult for students with low vision, or who are legally blind for two reasons. First, they are less able to see what is being presented at the front of them room, and second, they must repeatedly switch between the far-sight task of viewing the front of the room, and the near-sight task of taking notes. This paper describes ongoing research aimed at developing a portable assistive device (called the Note-Taker) that a student can take to class, to assist in the process of taking notes. It describes the principles that have guided the development of the proof-of-concept Note-Taker prototype and the Note-Taker 2.0 prototype. Initial testing of those prototypes has been encouraging, but some significant problems remain to be solved. Proposed solutions are currently being implemented, and appear to be effective. If ongoing usability testing confirms their effectiveness, they will be implemented on the planned Note-Taker 3.0 prototype.', 'doi': '10.1145/1878803.1878828', 'url': 'https://doi.org/10.1145/1878803.1878828', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Note-taker 2.0: the next step toward enabling students who are legally blind to take notes in class', 'author': 'Hayden, David S. and Zhou, Liqing and Astrauskas, Michael J. and Black, John A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878828'}"
Using accessible math textbooks with students who have learning disabilities,10.1145/1878803.1878829,Math is a subject that most students in K-12 participate in every school day. This includes students with learning disabilities as they are equally accountable to meeting general math curriculum requirements. Project SMART provided digital versions of math textbooks modified to include MathML for use by eighth grade students with various learning disabilities. A goal of Project SMART was to determine whether these accessible digital textbooks improved student test performance as compared to control groups using the same texts in print format with a traditional oral accommodation. The study also examined the extent to which using accessible math impacted student perceptions about math abilities. Students and most teachers found the accessible digital textbooks preferable to the print versions. This was generally reflected in higher test scores as well as consistently positive responses from qualitative measures obtained from ongoing student and teacher surveys.,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, daisy, learning disabilities, math disabilities, mathml, print disabilities, visual impairments', 'numpages': '8', 'pages': '139–146', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Math is a subject that most students in K-12 participate in every school day. This includes students with learning disabilities as they are equally accountable to meeting general math curriculum requirements. Project SMART provided digital versions of math textbooks modified to include MathML for use by eighth grade students with various learning disabilities. A goal of Project SMART was to determine whether these accessible digital textbooks improved student test performance as compared to control groups using the same texts in print format with a traditional oral accommodation. The study also examined the extent to which using accessible math impacted student perceptions about math abilities. Students and most teachers found the accessible digital textbooks preferable to the print versions. This was generally reflected in higher test scores as well as consistently positive responses from qualitative measures obtained from ongoing student and teacher surveys.', 'doi': '10.1145/1878803.1878829', 'url': 'https://doi.org/10.1145/1878803.1878829', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Using accessible math textbooks with students who have learning disabilities', 'author': 'Lewis, Preston and Noble, Steve and Soiffer, Neil', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878829'}"
Relating computer tasks to existing knowledge to improve accessibility for older adults,10.1145/1878803.1878830,"Routine computer tasks are often difficult for older adult computer users to learn and remember. People tend to learn new tasks by relating new concepts to existing knowledge. However, even for 'basic' computer tasks there is little, if any, existing knowledge on which older adults can base their learning. This paper investigates a custom file management interface that was designed to aid discovery and learnability by providing interface objects that are familiar to the user. A study was conducted which examined the differences between older and younger computer users when undertaking routine file management tasks using the standard Windows desktop as compared with the custom interface. Results showed that older adult computer users requested help more than ten times as often as younger users when using a standard windows/mouse configuration, made more mistakes and also required significantly more confirmations than younger users. The custom interface showed improvements over standard Windows/mouse, with fewer confirmations and less help being required. Hence, there is potential for an interface that closely mimics the real world to improve computer accessibility for older adults, aiding self-discovery and learnability.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'human computer interaction, older adults', 'numpages': '8', 'pages': '147–154', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Routine computer tasks are often difficult for older adult computer users to learn and remember. People tend to learn new tasks by relating new concepts to existing knowledge. However, even for 'basic' computer tasks there is little, if any, existing knowledge on which older adults can base their learning. This paper investigates a custom file management interface that was designed to aid discovery and learnability by providing interface objects that are familiar to the user. A study was conducted which examined the differences between older and younger computer users when undertaking routine file management tasks using the standard Windows desktop as compared with the custom interface. Results showed that older adult computer users requested help more than ten times as often as younger users when using a standard windows/mouse configuration, made more mistakes and also required significantly more confirmations than younger users. The custom interface showed improvements over standard Windows/mouse, with fewer confirmations and less help being required. Hence, there is potential for an interface that closely mimics the real world to improve computer accessibility for older adults, aiding self-discovery and learnability."", 'doi': '10.1145/1878803.1878830', 'url': 'https://doi.org/10.1145/1878803.1878830', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Relating computer tasks to existing knowledge to improve accessibility for older adults', 'author': 'Hollinworth, Nic and Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878830'}"
Session details: Communication,10.1145/3252143,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252143', 'url': 'https://doi.org/10.1145/3252143', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Communication', 'author': 'Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252143'}"
Click on bake to get cookies: guiding word-finding with semantic associations,10.1145/1878803.1878832,"It is challenging to navigate a dictionary consisting of thousands of entries in order to select appropriate words for building communication. This is particularly true for people with lexical access disorders like those present in aphasia. We make vocabulary navigation and word-finding easier by building a vocabulary network where links between words reflect human judgments of semantic relatedness. We report the results from a user study with people with aphasia that evaluated how our system (called ViVA) performs compared to a widely used vocabulary access system in which words are organized hierarchically into common categories and subcategories. The results indicate that word retrieval is significantly better with ViVA, but finding the first word to start a communication is still problematic and requires further investigation.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'adaptive user interfaces, aphasia, assistive communication, semantic networks, visual vocabularies', 'numpages': '8', 'pages': '155–162', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'It is challenging to navigate a dictionary consisting of thousands of entries in order to select appropriate words for building communication. This is particularly true for people with lexical access disorders like those present in aphasia. We make vocabulary navigation and word-finding easier by building a vocabulary network where links between words reflect human judgments of semantic relatedness. We report the results from a user study with people with aphasia that evaluated how our system (called ViVA) performs compared to a widely used vocabulary access system in which words are organized hierarchically into common categories and subcategories. The results indicate that word retrieval is significantly better with ViVA, but finding the first word to start a communication is still problematic and requires further investigation.', 'doi': '10.1145/1878803.1878832', 'url': 'https://doi.org/10.1145/1878803.1878832', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Click on bake to get cookies: guiding word-finding with semantic associations', 'author': 'Nikolova, Sonya and Tremaine, Marilyn and Cook, Perry R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878832'}"
Are synthesized video descriptions acceptable?,10.1145/1878803.1878833,"We conducted a series of experiments to assess the feasibility of synthesized narrations to describe online videos. To reduce the cultural bias, we included adult blind or low-vision participants from Japan and the U.S. in the main study. Our research also includes a follow-up study we conducted in Japan to assess the effectiveness of synthesized video descriptions in realistic situations. The results showed that synthesized video descriptions were generally accepted in both countries. We also found that appropriate technology support allowed a novice describer to make effective video descriptions. Based on these results, we discuss the implications for developing a technology platform for describing online videos.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'audio description, online videos, speech synthesis, text-to-speech (tts), video description, web accessibility', 'numpages': '8', 'pages': '163–170', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We conducted a series of experiments to assess the feasibility of synthesized narrations to describe online videos. To reduce the cultural bias, we included adult blind or low-vision participants from Japan and the U.S. in the main study. Our research also includes a follow-up study we conducted in Japan to assess the effectiveness of synthesized video descriptions in realistic situations. The results showed that synthesized video descriptions were generally accepted in both countries. We also found that appropriate technology support allowed a novice describer to make effective video descriptions. Based on these results, we discuss the implications for developing a technology platform for describing online videos.', 'doi': '10.1145/1878803.1878833', 'url': 'https://doi.org/10.1145/1878803.1878833', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Are synthesized video descriptions acceptable?', 'author': ""Kobayashi, Masatomo and O'Connell, Trisha and Gould, Bryan and Takagi, Hironobu and Asakawa, Chieko"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878833'}"
Broadening accessibility through special interests: a new approach for software customization,10.1145/1878803.1878834,"Individuals diagnosed with autism spectrum disorder (ASD) often fixate on narrow, restricted interests. These interests can be highly motivating, but they can also create attentional myopia, preventing individuals from pursuing a broad range of activities. Interestingly, researchers have found that preferred interests can be used to help individuals with ASD branch out and participate in educational, therapeutic, or social situations they might otherwise shun. When interventions are modified, such that an individual's interest is properly represented, task adherence and performance can increase. While this strategy has seen success in the research literature, it is difficult to implement on a large scale and therefore has not been widely adopted. This paper describes a software approach designed to solve this problem. The approach facilitates customization, allowing users to easily embed images of almost any special interest into computer-based interventions. Specifically, we describe an algorithm that will: (1) retrieve any image from the Google image database; (2) strip it of its background; and (3) embed it seamlessly into Flash-based computer programs. To evaluate our algorithm, we employed it in a naturalistic setting with eleven individuals (nine diagnosed with ASD and two diagnosed with other developmental disorders). We also tested its ability to retrieve and process examples of preferred interests previously reported in the ASD literature. The results indicate that our method was an easy and efficient way for users to customize our software programs. While we believe this model is uniquely suited for individuals with ASD, we also foresee this approach being useful for anyone that might like a quick and simple way to personalize software programs.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'autism, preferred interests, software and technology design', 'numpages': '8', 'pages': '171–178', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Individuals diagnosed with autism spectrum disorder (ASD) often fixate on narrow, restricted interests. These interests can be highly motivating, but they can also create attentional myopia, preventing individuals from pursuing a broad range of activities. Interestingly, researchers have found that preferred interests can be used to help individuals with ASD branch out and participate in educational, therapeutic, or social situations they might otherwise shun. When interventions are modified, such that an individual's interest is properly represented, task adherence and performance can increase. While this strategy has seen success in the research literature, it is difficult to implement on a large scale and therefore has not been widely adopted. This paper describes a software approach designed to solve this problem. The approach facilitates customization, allowing users to easily embed images of almost any special interest into computer-based interventions. Specifically, we describe an algorithm that will: (1) retrieve any image from the Google image database; (2) strip it of its background; and (3) embed it seamlessly into Flash-based computer programs. To evaluate our algorithm, we employed it in a naturalistic setting with eleven individuals (nine diagnosed with ASD and two diagnosed with other developmental disorders). We also tested its ability to retrieve and process examples of preferred interests previously reported in the ASD literature. The results indicate that our method was an easy and efficient way for users to customize our software programs. While we believe this model is uniquely suited for individuals with ASD, we also foresee this approach being useful for anyone that might like a quick and simple way to personalize software programs."", 'doi': '10.1145/1878803.1878834', 'url': 'https://doi.org/10.1145/1878803.1878834', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Broadening accessibility through special interests: a new approach for software customization', 'author': 'Morris, Robert R. and Kirschbaum, Connor R. and Picard, Rosalind W.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878834'}"
Session details: Mobility,10.1145/3252144,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252144', 'url': 'https://doi.org/10.1145/3252144', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Mobility', 'author': 'Kurniawan, Sri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252144'}"
Vi-bowling: a tactile spatial exergame for individuals with visual impairments,10.1145/1878803.1878836,"Lack of sight forms a significant barrier to participate in physical activity. Consequently, individuals with visual impairments are at greater risk for developing serious health problems, such as obesity. Exergames are video games that provide physical exercise. For individuals with visual impairments, exergames have the potential to reduce health disparities as they may be safer to play and can be played without the help of others. This paper presents VI Bowling, a tactile/audio exergame that can be played using an inexpensive motion-sensing controller. VI Bowling explores tactile dowsing: a novel technique for performing spatial sensorimotor challenges, which can be used for motor learning. VI Bowling was evaluated with six blind adults. All players enjoyed VI Bowling and the challenge tactile dowsing provided. Players could throw their ball with an average error of 9.76 degrees using tactile dowsing. Participants achieved an average active energy expenditure of 4.61 kJ/Min while playing VI Bowling, which is comparable to walking.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'exergames, haptics, health, visual impairments', 'numpages': '8', 'pages': '179–186', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Lack of sight forms a significant barrier to participate in physical activity. Consequently, individuals with visual impairments are at greater risk for developing serious health problems, such as obesity. Exergames are video games that provide physical exercise. For individuals with visual impairments, exergames have the potential to reduce health disparities as they may be safer to play and can be played without the help of others. This paper presents VI Bowling, a tactile/audio exergame that can be played using an inexpensive motion-sensing controller. VI Bowling explores tactile dowsing: a novel technique for performing spatial sensorimotor challenges, which can be used for motor learning. VI Bowling was evaluated with six blind adults. All players enjoyed VI Bowling and the challenge tactile dowsing provided. Players could throw their ball with an average error of 9.76 degrees using tactile dowsing. Participants achieved an average active energy expenditure of 4.61 kJ/Min while playing VI Bowling, which is comparable to walking.', 'doi': '10.1145/1878803.1878836', 'url': 'https://doi.org/10.1145/1878803.1878836', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Vi-bowling: a tactile spatial exergame for individuals with visual impairments', 'author': 'Morelli, Tony and Foley, John and Folmer, Eelke', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878836'}"
Leveraging proprioception to make mobile phones more accessible to users with visual impairments,10.1145/1878803.1878837,"Accessing the advanced functions of a mobile phone is not a trivial task for users with visual impairments. They rely on screen readers and voice commands to discover and execute functions. In mobile situations, however, screen readers are not ideal because users may depend on their hearing for safety, and voice commands are difficult for a system to recognize in noisy environments. In this paper, we extend Virtual Shelves--an interaction technique that leverages proprioception to access application shortcuts--for visually impaired users. We measured the directional accuracy of visually impaired participants and found that they were less accurate than people with vision. We then built a functional prototype that uses an accelerometer and a gyroscope to sense its position and orientation. Finally, we evaluated the interaction and prototype by allowing participants to customize the placement of seven shortcuts within 15 regions. Participants were able to access shortcuts in their personal layout with 88.3\% accuracy in an average of 1.74 seconds.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, mobile devices, proprioception, visual impairments', 'numpages': '8', 'pages': '187–194', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Accessing the advanced functions of a mobile phone is not a trivial task for users with visual impairments. They rely on screen readers and voice commands to discover and execute functions. In mobile situations, however, screen readers are not ideal because users may depend on their hearing for safety, and voice commands are difficult for a system to recognize in noisy environments. In this paper, we extend Virtual Shelves--an interaction technique that leverages proprioception to access application shortcuts--for visually impaired users. We measured the directional accuracy of visually impaired participants and found that they were less accurate than people with vision. We then built a functional prototype that uses an accelerometer and a gyroscope to sense its position and orientation. Finally, we evaluated the interaction and prototype by allowing participants to customize the placement of seven shortcuts within 15 regions. Participants were able to access shortcuts in their personal layout with 88.3\\% accuracy in an average of 1.74 seconds.', 'doi': '10.1145/1878803.1878837', 'url': 'https://doi.org/10.1145/1878803.1878837', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Leveraging proprioception to make mobile phones more accessible to users with visual impairments', 'author': 'Li, Frank Chun Yat and Dearman, David and Truong, Khai N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878837'}"
Autonomous navigation through the city for the blind,10.1145/1878803.1878838,"Autonomous navigation in the city has become a necessity for people with visual disabilities, due to the fact that they now enjoy a higher degree of social insertion. As such, several technological solutions seek to assist with this autonomy. In this work, we present a study on the effect of the use of an easy-to-access, audio-based GPS software program on navigation through open spaces, and in particular on the stimulation of orientation and mobility skills in blind people. Results show that the use of the audio-based GPS software allowed blind users to be able to get to various destinations without the need for prior information on the environment, favoring the navigation of blind people in unfamiliar contexts, stimulating the use of different orientation and mobility skills, and finally providing help to users that habitually navigate spaces in the city only in the company of other people.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, mobile technology, orientation and mobility, people who are blind', 'numpages': '8', 'pages': '195–202', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Autonomous navigation in the city has become a necessity for people with visual disabilities, due to the fact that they now enjoy a higher degree of social insertion. As such, several technological solutions seek to assist with this autonomy. In this work, we present a study on the effect of the use of an easy-to-access, audio-based GPS software program on navigation through open spaces, and in particular on the stimulation of orientation and mobility skills in blind people. Results show that the use of the audio-based GPS software allowed blind users to be able to get to various destinations without the need for prior information on the environment, favoring the navigation of blind people in unfamiliar contexts, stimulating the use of different orientation and mobility skills, and finally providing help to users that habitually navigate spaces in the city only in the company of other people.', 'doi': '10.1145/1878803.1878838', 'url': 'https://doi.org/10.1145/1878803.1878838', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Autonomous navigation through the city for the blind', 'author': ""S\\'{a}nchez, Jaime and de la Torre, Natalia"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878838'}"
Session details: Approaches to therapy,10.1145/3252145,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252145', 'url': 'https://doi.org/10.1145/3252145', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Approaches to therapy', 'author': 'Tremaine, Marilyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252145'}"
Introducing multimodal paper-digital interfaces for speech-language therapy,10.1145/1878803.1878840,"After a stroke or brain injury, it may be more difficult to understand language and communicate with others. Speech-language therapy may help an individual regain language and cope with changes in their communication abilities. Our research examines the process of speech-language therapy with an emphasis on the practices of therapists working with adults with aphasia and apraxia of speech. This paper presents findings from field work undertaken to inform the design of a mixed paper-digital interface prototype using multimodal digital pens. We describe and analyze therapists' initial reactions to the system and present two case studies of use by older adults undergoing speech-language therapy. We discuss the utility of multimodal paper-digital interfaces to assist therapy and describe our vision of a system to help therapists independently create custom interactive paper materials for their clients.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'communication, multimodal interaction, older adults, pen-based computing, speech-language therapy', 'numpages': '8', 'pages': '203–210', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""After a stroke or brain injury, it may be more difficult to understand language and communicate with others. Speech-language therapy may help an individual regain language and cope with changes in their communication abilities. Our research examines the process of speech-language therapy with an emphasis on the practices of therapists working with adults with aphasia and apraxia of speech. This paper presents findings from field work undertaken to inform the design of a mixed paper-digital interface prototype using multimodal digital pens. We describe and analyze therapists' initial reactions to the system and present two case studies of use by older adults undergoing speech-language therapy. We discuss the utility of multimodal paper-digital interfaces to assist therapy and describe our vision of a system to help therapists independently create custom interactive paper materials for their clients."", 'doi': '10.1145/1878803.1878840', 'url': 'https://doi.org/10.1145/1878803.1878840', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Introducing multimodal paper-digital interfaces for speech-language therapy', 'author': 'Piper, Anne Marie and Weibel, Nadir and Hollan, James D.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878840'}"
A tool to promote prolonged engagement in art therapy: design and development from arts therapist requirements,10.1145/1878803.1878841,"This paper describes the development of a tool that assists arts therapists working with older adults with dementia. Participation in creative activities is becoming accepted as a method for improving quality of life. This paper presents the design of a novel tool to increase the capacity of creative arts therapists to engage cognitively impaired older adults in creative activities. The tool is a creative arts touch-screen interface that presents a user with activities such as painting, drawing, or collage. It was developed with a user-centered design methodology in collaboration with a group of creative arts therapists. The tool is customizable by therapists, allowing them to design and build personalized therapeutic/goal-oriented creative activities for each client. In this paper, we evaluate the acceptability of the tool by arts therapists (our primary user group). We perform this evaluation qualitatively with a set of one-on-one interviews with arts therapists who work specifically with persons with dementia. We show how their responses during interviews support the idea of a customizable assistance tool. We evaluate the tool in simulation by showing a number of examples, and by demonstrating customizable components.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'art therapy, computer vision, dementia, markov decision process, user modeling', 'numpages': '8', 'pages': '211–218', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes the development of a tool that assists arts therapists working with older adults with dementia. Participation in creative activities is becoming accepted as a method for improving quality of life. This paper presents the design of a novel tool to increase the capacity of creative arts therapists to engage cognitively impaired older adults in creative activities. The tool is a creative arts touch-screen interface that presents a user with activities such as painting, drawing, or collage. It was developed with a user-centered design methodology in collaboration with a group of creative arts therapists. The tool is customizable by therapists, allowing them to design and build personalized therapeutic/goal-oriented creative activities for each client. In this paper, we evaluate the acceptability of the tool by arts therapists (our primary user group). We perform this evaluation qualitatively with a set of one-on-one interviews with arts therapists who work specifically with persons with dementia. We show how their responses during interviews support the idea of a customizable assistance tool. We evaluate the tool in simulation by showing a number of examples, and by demonstrating customizable components.', 'doi': '10.1145/1878803.1878841', 'url': 'https://doi.org/10.1145/1878803.1878841', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A tool to promote prolonged engagement in art therapy: design and development from arts therapist requirements', 'author': 'Hoey, Jesse and Zutis, Krists and Leuty, Valerie and Mihailidis, Alex', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878841'}"
Stroke therapy through motion-based games: a case study,10.1145/1878803.1878842,"In the United States alone, more than five million people are living with long term motor impairments caused by a stroke. Video game-based therapies show promise in helping people recover lost range of motion and motor control. While researchers have demonstrated the potential utility of game-based rehabilitation through controlled studies, relatively little work has explored longer-term home-based use of therapeutic games. We conducted a six-week home study with a 62 year old woman who was seventeen years post-stroke. She played therapeutic games for approximately one hour a day, five days a week. Over the six weeks, she recovered significant motor abilities, which is unexpected given the time since her stroke. Through observations and interviews, we present lessons learned about the barriers and opportunities that arise from long-term home-based use of therapeutic games.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'case study, stroke rehabilitation, video games', 'numpages': '8', 'pages': '219–226', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In the United States alone, more than five million people are living with long term motor impairments caused by a stroke. Video game-based therapies show promise in helping people recover lost range of motion and motor control. While researchers have demonstrated the potential utility of game-based rehabilitation through controlled studies, relatively little work has explored longer-term home-based use of therapeutic games. We conducted a six-week home study with a 62 year old woman who was seventeen years post-stroke. She played therapeutic games for approximately one hour a day, five days a week. Over the six weeks, she recovered significant motor abilities, which is unexpected given the time since her stroke. Through observations and interviews, we present lessons learned about the barriers and opportunities that arise from long-term home-based use of therapeutic games.', 'doi': '10.1145/1878803.1878842', 'url': 'https://doi.org/10.1145/1878803.1878842', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Stroke therapy through motion-based games: a case study', 'author': 'Alankus, Gazihan and Proffitt, Rachel and Kelleher, Caitlin and Engsberg, Jack', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878842'}"
Session details: Posters and Demonstrations,10.1145/3252146,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252146', 'url': 'https://doi.org/10.1145/3252146', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: Posters and Demonstrations', 'author': 'Yesilada, Yeliz', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252146'}"
"A low-cost, variable-amplitude haptic distributed display for persons who are blind and visually impaired",10.1145/1878803.1878844,"Previously in our lab, we developed a low-cost mouse-like device that has high position accuracy, very good temporal and spatial collocation between kinesthetic and tactile information, a fairly large temporal bandwidth and a short time delay. However, it can still be limiting when generating texture-like patterns. We have therefore extended the function of the device to be able to vary the amplitude as well, while maintaining its low cost (under $500). Various virtual textures have been developed which can be used to create salient graphics that can be perceived through this device. Preliminary investigations suggest that having multiple amplitude levels increases the number of distinguishable textures as well as the amount of information that can be displayed.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blind, haptics, tactile graphics, virtual texture, visually impaired', 'numpages': '2', 'pages': '227–228', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Previously in our lab, we developed a low-cost mouse-like device that has high position accuracy, very good temporal and spatial collocation between kinesthetic and tactile information, a fairly large temporal bandwidth and a short time delay. However, it can still be limiting when generating texture-like patterns. We have therefore extended the function of the device to be able to vary the amplitude as well, while maintaining its low cost (under $500). Various virtual textures have been developed which can be used to create salient graphics that can be perceived through this device. Preliminary investigations suggest that having multiple amplitude levels increases the number of distinguishable textures as well as the amount of information that can be displayed.', 'doi': '10.1145/1878803.1878844', 'url': 'https://doi.org/10.1145/1878803.1878844', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A low-cost, variable-amplitude haptic distributed display for persons who are blind and visually impaired', 'author': 'Headley, Patrick C. and Pawluk, Dianne T. V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878844'}"
"A multimodal, computer-based drawing system for persons who are blind and visually impaired",10.1145/1878803.1878845,"Many individuals who are blind or visually impaired are interested in drawing tactile pictures, and some have already done so with static raised-line drawing kits. However, static raised-line drawing kits are problematic as they are non-erasable. Various computer systems, with or without accompanying device interfaces, have been designed to allow these individuals the ability to both perceive and construct their own drawings on a computer, but each with various drawbacks. A focus group was conducted to gain input from blind and visually impaired computer users on a new design. Based on these results, a new multimodal device design concept has been generated which will improve upon previous solutions and give graphic editing and viewing to blind and visually impaired individuals at a low cost.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'drawing system, haptics, tactile graphics, visually impaired', 'numpages': '2', 'pages': '229–230', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many individuals who are blind or visually impaired are interested in drawing tactile pictures, and some have already done so with static raised-line drawing kits. However, static raised-line drawing kits are problematic as they are non-erasable. Various computer systems, with or without accompanying device interfaces, have been designed to allow these individuals the ability to both perceive and construct their own drawings on a computer, but each with various drawbacks. A focus group was conducted to gain input from blind and visually impaired computer users on a new design. Based on these results, a new multimodal device design concept has been generated which will improve upon previous solutions and give graphic editing and viewing to blind and visually impaired individuals at a low cost.', 'doi': '10.1145/1878803.1878845', 'url': 'https://doi.org/10.1145/1878803.1878845', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A multimodal, computer-based drawing system for persons who are blind and visually impaired', 'author': 'Headley, Patrick C. and Pawluk, Dianne T. V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878845'}"
Adaptive mappings for mouse-replacement interfaces,10.1145/1878803.1878846,Users of mouse-replacement interfaces may have difficulty conforming to the motion requirements of their interface system. We have observed users with severe motor disabilities who controlled the mouse pointer with a head tracking interface. Our analysis shows that some users may be able to move in some directions easier than other directions. We propose several mouse pointer mappings that adapt to the user's movement abilities. These mappings will take into account the user's motions in two-or three-dimensions to move the mouse pointer in the intended direction.,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'camera mouse, human-computer interaction, mouse replacement interfaces', 'numpages': '2', 'pages': '231–232', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Users of mouse-replacement interfaces may have difficulty conforming to the motion requirements of their interface system. We have observed users with severe motor disabilities who controlled the mouse pointer with a head tracking interface. Our analysis shows that some users may be able to move in some directions easier than other directions. We propose several mouse pointer mappings that adapt to the user's movement abilities. These mappings will take into account the user's motions in two-or three-dimensions to move the mouse pointer in the intended direction."", 'doi': '10.1145/1878803.1878846', 'url': 'https://doi.org/10.1145/1878803.1878846', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Adaptive mappings for mouse-replacement interfaces', 'author': 'Magee, John J. and Epstein, Samuel and Missimer, Eric S. and Betke, Margrit', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878846'}"
Anti-blur feedback for visually impaired users of smartphone cameras,10.1145/1878803.1878847,"A wide range of smartphone applications are emerging that employ image processing and computer vision algorithms to interpret the contents of images acquired by the phone's built-in camera, including applications that read product barcodes and recognize a variety of documents and other objects. However, almost all of these applications are designed for normally sighted users; a major barrier for visually impaired users (who might benefit greatly from such applications) is the difficulty of taking good-quality images. To overcome this barrier, this paper focuses on reducing the incidence of motion blur, caused by camera shake and other movements, which is a common cause of poor-quality, unusable images. We propose a simple technique for detecting camera shake, using the smartphone's built-in accelerometer (i.e. tilt sensor) to alert the user in real-time to any shake, providing feedback that enables him/her to hold the camera more steadily. A preliminary experiment with a blind iPhone user demonstrates the feasibility of the approach.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blindness, cell phone, low vision, smartphone', 'numpages': '2', 'pages': '233–234', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""A wide range of smartphone applications are emerging that employ image processing and computer vision algorithms to interpret the contents of images acquired by the phone's built-in camera, including applications that read product barcodes and recognize a variety of documents and other objects. However, almost all of these applications are designed for normally sighted users; a major barrier for visually impaired users (who might benefit greatly from such applications) is the difficulty of taking good-quality images. To overcome this barrier, this paper focuses on reducing the incidence of motion blur, caused by camera shake and other movements, which is a common cause of poor-quality, unusable images. We propose a simple technique for detecting camera shake, using the smartphone's built-in accelerometer (i.e. tilt sensor) to alert the user in real-time to any shake, providing feedback that enables him/her to hold the camera more steadily. A preliminary experiment with a blind iPhone user demonstrates the feasibility of the approach."", 'doi': '10.1145/1878803.1878847', 'url': 'https://doi.org/10.1145/1878803.1878847', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Anti-blur feedback for visually impaired users of smartphone cameras', 'author': 'Sanketi, Pannag R. and Coughlan, James M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878847'}"
Assistive web browsing with touch interfaces,10.1145/1878803.1878848,"This demonstration will propose a touch-based directional navigation technique, on touch interface (e.g., iPhone, Macbook) for people with visual disabilities especially blind individuals. Such interfaces coupled with TTS (text-to-speech) systems open up intriguing possibilities for browsing and skimming web content with ease and speed. Apple's seminal VoiceOver system for iOS is an exemplar of bringing touch-based web navigation to blind people. There are two major shortcomings: ""fat finger"" and ""finger-fatigue"" problems, which have been addressed in this paper with two proposed approaches. A preliminary user evaluation of the system incorporating these ideas suggests that they can be effective in practice.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'granularity, navigation, touch interface, web accessibility', 'numpages': '2', 'pages': '235–236', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This demonstration will propose a touch-based directional navigation technique, on touch interface (e.g., iPhone, Macbook) for people with visual disabilities especially blind individuals. Such interfaces coupled with TTS (text-to-speech) systems open up intriguing possibilities for browsing and skimming web content with ease and speed. Apple\'s seminal VoiceOver system for iOS is an exemplar of bringing touch-based web navigation to blind people. There are two major shortcomings: ""fat finger"" and ""finger-fatigue"" problems, which have been addressed in this paper with two proposed approaches. A preliminary user evaluation of the system incorporating these ideas suggests that they can be effective in practice.', 'doi': '10.1145/1878803.1878848', 'url': 'https://doi.org/10.1145/1878803.1878848', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Assistive web browsing with touch interfaces', 'author': 'Ahmed, Faisal and Islam, Muhammad Asiful and Borodin, Yevgen and Ramakrishnan, I. V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878848'}"
Audio and haptic based virtual environments for orientation and mobility in people who are blind,10.1145/1878803.1878849,"This study presents the development of a videogame with two audio and haptic interfaces that allow for the stimulation of orientation and mobility skills in people who are blind through the use of virtual environments. Our idea was to test the hypothesis regarding the use of audio and haptic interfaces together, allowing for the creation of a better mental representation of a virtual environment, compared to that which results from the use of each kind of interface separately. The videogame's icon usability has been evaluated, as well as a posterior cognitive analysis of the skills acquired through its use. The preliminary usability results show that the people correctly describe the textures and shapes used in the software.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'haptic and audio interfaces, icon usability, mobility, orientation', 'numpages': '2', 'pages': '237–238', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This study presents the development of a videogame with two audio and haptic interfaces that allow for the stimulation of orientation and mobility skills in people who are blind through the use of virtual environments. Our idea was to test the hypothesis regarding the use of audio and haptic interfaces together, allowing for the creation of a better mental representation of a virtual environment, compared to that which results from the use of each kind of interface separately. The videogame's icon usability has been evaluated, as well as a posterior cognitive analysis of the skills acquired through its use. The preliminary usability results show that the people correctly describe the textures and shapes used in the software."", 'doi': '10.1145/1878803.1878849', 'url': 'https://doi.org/10.1145/1878803.1878849', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Audio and haptic based virtual environments for orientation and mobility in people who are blind', 'author': ""S\\'{a}nchez, Jaime and Tadres, Angelo"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878849'}"
"Automatic, intuitive zooming for people who are blind or visually impaired.",10.1145/1878803.1878850,"In this paper we present a novel technique of automatic, ""intuitive"" zooming of graphical information for individuals who are blind or visually impaired. The idea is to automatically choose for the user only zoom levels with significantly different content than the last and which preserve the cognitive grouping of information (such as whole objects or whole object parts) thereby making ""intuitive"" sense. The algorithm uses wavelet analysis to localize the details of a graphic. It then uses methods looking at the clustering of details to decide on the levels of zoom. An initial pilot study is presented that uses this zooming method with three individuals who are visually impaired and four who are sighted. Results show that all participants liked intuitive zooming over areas of details and being prevented from zooming when no details were present. Almost all participants required zooming to perform the identification task, which had an 86\% correct rate.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'haptic device, haptic mouse, information visualization, raised line drawing, tactile graphic, zoomable interface', 'numpages': '2', 'pages': '239–240', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper we present a novel technique of automatic, ""intuitive"" zooming of graphical information for individuals who are blind or visually impaired. The idea is to automatically choose for the user only zoom levels with significantly different content than the last and which preserve the cognitive grouping of information (such as whole objects or whole object parts) thereby making ""intuitive"" sense. The algorithm uses wavelet analysis to localize the details of a graphic. It then uses methods looking at the clustering of details to decide on the levels of zoom. An initial pilot study is presented that uses this zooming method with three individuals who are visually impaired and four who are sighted. Results show that all participants liked intuitive zooming over areas of details and being prevented from zooming when no details were present. Almost all participants required zooming to perform the identification task, which had an 86\\% correct rate.', 'doi': '10.1145/1878803.1878850', 'url': 'https://doi.org/10.1145/1878803.1878850', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Automatic, intuitive zooming for people who are blind or visually impaired.', 'author': 'Rastogi, Ravi and Pawluk, Dianne T.V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878850'}"
Blind guidance using mobile computer vision: a usability study,10.1145/1878803.1878851,"We present a study focusing on the usability of a wayfinding and localization system for persons with visual impairment. This system uses special color markers, placed at key locations in the environment, that can be detected by a regular camera phone. Three blind participants tested the system in various indoor locations and under different system settings. Quantitative performance results are reported.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'guidance, mobility, orientation, recognition, wayfinding', 'numpages': '2', 'pages': '241–242', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present a study focusing on the usability of a wayfinding and localization system for persons with visual impairment. This system uses special color markers, placed at key locations in the environment, that can be detected by a regular camera phone. Three blind participants tested the system in various indoor locations and under different system settings. Quantitative performance results are reported.', 'doi': '10.1145/1878803.1878851', 'url': 'https://doi.org/10.1145/1878803.1878851', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Blind guidance using mobile computer vision: a usability study', 'author': 'Manduchi, Roberto and Kurniawan, Sri and Bagherinia, Homayoun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878851'}"
Cerebral palsy and online social networks,10.1145/1878803.1878852,"This study qualitatively explores the experiences and challenges faced when people with cerebral palsy use online social networks. Fourteen interviews were carried out consisting of participants with different types of cerebral palsy. The study identified the reasons for use and non-use and also discovered key themes together with challenges that affected their experiences. For example abrupt and frequently changing online social networks were reported to slow down or prevent use. In spite of this, the study recognized the technology is a vital way for these people to communicate and would continue to play a crucial role within their lives.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'cerebral palsy, online social network use, online social networks', 'numpages': '2', 'pages': '243–244', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study qualitatively explores the experiences and challenges faced when people with cerebral palsy use online social networks. Fourteen interviews were carried out consisting of participants with different types of cerebral palsy. The study identified the reasons for use and non-use and also discovered key themes together with challenges that affected their experiences. For example abrupt and frequently changing online social networks were reported to slow down or prevent use. In spite of this, the study recognized the technology is a vital way for these people to communicate and would continue to play a crucial role within their lives.', 'doi': '10.1145/1878803.1878852', 'url': 'https://doi.org/10.1145/1878803.1878852', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Cerebral palsy and online social networks', 'author': 'Lewis, Makayla', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878852'}"
Color-audio encoding interface for visual substitution: see color matlab-based demo,10.1145/1878803.1878853,"Providing the blind with substitute visual perception is a relentless challenge confronting researchers of diverse areas. The See ColOr (Seeing Color with an Orchestra) system translates aimed-at regions of a color scene into 2D-spatialized sound signals represented by musical instruments. Associating sounds with colors is achieved thanks to an efficient quantization of the regions' HSL representation (Hue, Saturation, Luminosity). See ColOr can be used both for exploring static images and as a mobility aid. In this report, we introduce its general framework for color-audio encoding of images to provide visually impaired individuals with a low-cost application for color perception substitution, using the sense of hearing instead of sight. The experimental tests using a demo implementation have shown the feasibility and usefulness of this approach.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'color, hsl, instruments, matlab, sonification, visual substitution', 'numpages': '2', 'pages': '245–246', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Providing the blind with substitute visual perception is a relentless challenge confronting researchers of diverse areas. The See ColOr (Seeing Color with an Orchestra) system translates aimed-at regions of a color scene into 2D-spatialized sound signals represented by musical instruments. Associating sounds with colors is achieved thanks to an efficient quantization of the regions' HSL representation (Hue, Saturation, Luminosity). See ColOr can be used both for exploring static images and as a mobility aid. In this report, we introduce its general framework for color-audio encoding of images to provide visually impaired individuals with a low-cost application for color perception substitution, using the sense of hearing instead of sight. The experimental tests using a demo implementation have shown the feasibility and usefulness of this approach."", 'doi': '10.1145/1878803.1878853', 'url': 'https://doi.org/10.1145/1878803.1878853', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Color-audio encoding interface for visual substitution: see color matlab-based demo', 'author': 'Gomez, Juan Diego and Bologna, Guido and Pun, Thierry', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878853'}"
Comparison of methods presenting contour information to individuals who are blind or visually impaired,10.1145/1878803.1878854,"Graphs and charts are frequently used in school, work and everyday living. However, traditional techniques of providing this information to individuals who are visually impaired are cumbersome and slow. Refreshable tactile displays have been developed and used to display line graphs, bar graphs and pie charts. In this paper, we investigate the use of a haptic matrix-like display that can produce multiple amplitude levels and multiple frequencies for displaying contour plots. Experiments were performed to compare performance and usability for the two different methods. According to preliminary results, the use of amplitude variation provides the user with a more accurate awareness of contour level differences than frequency variation.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'braille, contour plots, haptic mouse, tactile graphics, visually impaired', 'numpages': '2', 'pages': '247–248', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Graphs and charts are frequently used in school, work and everyday living. However, traditional techniques of providing this information to individuals who are visually impaired are cumbersome and slow. Refreshable tactile displays have been developed and used to display line graphs, bar graphs and pie charts. In this paper, we investigate the use of a haptic matrix-like display that can produce multiple amplitude levels and multiple frequencies for displaying contour plots. Experiments were performed to compare performance and usability for the two different methods. According to preliminary results, the use of amplitude variation provides the user with a more accurate awareness of contour level differences than frequency variation.', 'doi': '10.1145/1878803.1878854', 'url': 'https://doi.org/10.1145/1878803.1878854', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Comparison of methods presenting contour information to individuals who are blind or visually impaired', 'author': ""D'Souza, Steve and Pawluk, Dianne T. V."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878854'}"
Customizable keyboard,10.1145/1878803.1878855,Customizable Keyboard is an on-screen keyboard designed to be flexible and expandable. Instead of giving the user a keyboard layout Customizable Keyboard allows the user to create a layout that is accommodating to the user's needs. Customizable Keyboard also allows the user to select from a variety of ways to interact with the keyboard including but not limited to using the mouse pointer to select keys and different types of scan based systems. Customizable Keyboard provides more functionality than a typical onscreen keyboard including the ability to control infrared devices such as TVs and send Twitter® Tweets.,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, onscreen keyboard', 'numpages': '2', 'pages': '249–250', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Customizable Keyboard is an on-screen keyboard designed to be flexible and expandable. Instead of giving the user a keyboard layout Customizable Keyboard allows the user to create a layout that is accommodating to the user's needs. Customizable Keyboard also allows the user to select from a variety of ways to interact with the keyboard including but not limited to using the mouse pointer to select keys and different types of scan based systems. Customizable Keyboard provides more functionality than a typical onscreen keyboard including the ability to control infrared devices such as TVs and send Twitter® Tweets."", 'doi': '10.1145/1878803.1878855', 'url': 'https://doi.org/10.1145/1878803.1878855', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Customizable keyboard', 'author': 'Missimer, Eric S. and Epstein, Samuel and Magee, John J. and Betke, Margrit', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878855'}"
Designing effective sound-based aquarium exhibit interpretation for visitors with vision impairments,10.1145/1878803.1878856,"Sound-based exhibit interpretation at aquariums has the potential to more effectively mediate visitor-exhibit interaction and support participation for visitors with vision impairments. However, existing interpretation strategies do not adequately convey dynamic animal information to visitors with vision impairments. In an effort to improve access, we are developing research-based guidelines for sound-based exhibit interpretation including audio tours, interpretive staff presentations, and a real-time information delivery system. This poster reports on proposed and completed user-centered design activities.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, aquarium, exhibit, sound, vision impairment', 'numpages': '2', 'pages': '251–252', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sound-based exhibit interpretation at aquariums has the potential to more effectively mediate visitor-exhibit interaction and support participation for visitors with vision impairments. However, existing interpretation strategies do not adequately convey dynamic animal information to visitors with vision impairments. In an effort to improve access, we are developing research-based guidelines for sound-based exhibit interpretation including audio tours, interpretive staff presentations, and a real-time information delivery system. This poster reports on proposed and completed user-centered design activities.', 'doi': '10.1145/1878803.1878856', 'url': 'https://doi.org/10.1145/1878803.1878856', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Designing effective sound-based aquarium exhibit interpretation for visitors with vision impairments', 'author': 'Bruce, Carrie M. and Walker, Bruce N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878856'}"
Detecting objects and obstacles for visually impaired individuals using visual saliency,10.1145/1878803.1878857,"In this demo, we present the detection module of the See ColOr (Seeing Colors with an Orchestra) mobility aid for visually impaired persons. This module points out areas that present either particular interest or potential threat. In order to detect object and obstacles, we propose a bottom-up approach based on visual saliency: objects that would attract the visual attention of a non-disabled individual are pointed out by the system as areas of interest for the user. The device uses a stereoscopic camera, a laptop, and standard headphones. Given the type of scene and/or scenario, specific feature maps are computed in order to indicate areas of interest in real-time. This demonstration shows that the module indicates objects and obstacles as accurately as a system using all available feature maps.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'color, mobility aid, stereo, video processing, visual impairment, visual saliency', 'numpages': '2', 'pages': '253–254', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this demo, we present the detection module of the See ColOr (Seeing Colors with an Orchestra) mobility aid for visually impaired persons. This module points out areas that present either particular interest or potential threat. In order to detect object and obstacles, we propose a bottom-up approach based on visual saliency: objects that would attract the visual attention of a non-disabled individual are pointed out by the system as areas of interest for the user. The device uses a stereoscopic camera, a laptop, and standard headphones. Given the type of scene and/or scenario, specific feature maps are computed in order to indicate areas of interest in real-time. This demonstration shows that the module indicates objects and obstacles as accurately as a system using all available feature maps.', 'doi': '10.1145/1878803.1878857', 'url': 'https://doi.org/10.1145/1878803.1878857', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Detecting objects and obstacles for visually impaired individuals using visual saliency', 'author': 'Deville, Beno\\^{\\i}t and Bologna, Guido and Pun, Thierry', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878857'}"
Development of tactile map production device and tactile map with multilingual vocal guidance function,10.1145/1878803.1878858,"A tactile map is an assistive tool for visually impaired persons to obtain special information. As new barrier-free laws were recently enacted in Japan, many Braille signs and tactile guide maps have been installed in various facilities. Several production methods are available for tactile guide maps. Screen prints have become increasingly popular in Japan because they offer several advantages, including the fact that they can be printed together with visual characters. However, users have one major complaint: screen printing does not create lines and dots on tactile maps, thus necessitating improvement in screen printing performance. In this study, we developed a new tactile map production device as an alternative to screen printing devices. Also, a tactile map created by our method included a vocal guidance function based on users' needs. We found that the finished-print performance and convenience of tactile maps improved considerably. This study will be useful in providing a new style for future tactile maps.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'tactile map, tactile sense, vocal guidance functions', 'numpages': '2', 'pages': '255–256', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""A tactile map is an assistive tool for visually impaired persons to obtain special information. As new barrier-free laws were recently enacted in Japan, many Braille signs and tactile guide maps have been installed in various facilities. Several production methods are available for tactile guide maps. Screen prints have become increasingly popular in Japan because they offer several advantages, including the fact that they can be printed together with visual characters. However, users have one major complaint: screen printing does not create lines and dots on tactile maps, thus necessitating improvement in screen printing performance. In this study, we developed a new tactile map production device as an alternative to screen printing devices. Also, a tactile map created by our method included a vocal guidance function based on users' needs. We found that the finished-print performance and convenience of tactile maps improved considerably. This study will be useful in providing a new style for future tactile maps."", 'doi': '10.1145/1878803.1878858', 'url': 'https://doi.org/10.1145/1878803.1878858', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Development of tactile map production device and tactile map with multilingual vocal guidance function', 'author': 'Doi, Kouki and Toyoda, Wataru and Fujimoto, Hiroshi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878858'}"
EPG: speech access to program guides for people with disabilities,10.1145/1878803.1878859,"Over the last 10 years, in-home entertainment options have expanded dramatically. However, interfaces to listing data are still very limited. For people with visual disabilities, or those with limited hand mobility, it can be difficult or impossible to use the ""guide"" provided by many cable and satellite television companies. In this demo, we present the assistive technology features of AT&amp;T's Electronic Program Guide (EPG) prototype. These features include: speech input for listing search, speech commands for browsing search results, and text to speech for browsing search results. In addition, EPG uses commodity hardware and software to reduce barriers to entry.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, speech recognition, television, text to speech', 'numpages': '2', 'pages': '257–258', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Over the last 10 years, in-home entertainment options have expanded dramatically. However, interfaces to listing data are still very limited. For people with visual disabilities, or those with limited hand mobility, it can be difficult or impossible to use the ""guide"" provided by many cable and satellite television companies. In this demo, we present the assistive technology features of AT&amp;T\'s Electronic Program Guide (EPG) prototype. These features include: speech input for listing search, speech commands for browsing search results, and text to speech for browsing search results. In addition, EPG uses commodity hardware and software to reduce barriers to entry.', 'doi': '10.1145/1878803.1878859', 'url': 'https://doi.org/10.1145/1878803.1878859', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'EPG: speech access to program guides for people with disabilities', 'author': 'Johnston, Michael and Stent, Amanda J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878859'}"
Evaluating text descriptions of mathematical graphs,10.1145/1878803.1878860,"One approach to making graphs more accessible has been the incorporation of natural language descriptions of graphs into multimodal assistive technologies. MathTrax is software targeted at middle and high school students that employs a Math Description Engine (MDE) [1] to produce a textual description of graphs, as well as a visual and auditory representation of the graphs. Our study compared descriptions generated by the MDE to those generated by teachers of high school math, in order to better understand how to optimize the structure and content of mathematical graph descriptions. Feedback from these experts is compiled into suggestions for description templates to improve graphs descriptions, as well as design recommendations for future applications.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'graph description, graphs, math description engine, math education, technology review', 'numpages': '2', 'pages': '259–260', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'One approach to making graphs more accessible has been the incorporation of natural language descriptions of graphs into multimodal assistive technologies. MathTrax is software targeted at middle and high school students that employs a Math Description Engine (MDE) [1] to produce a textual description of graphs, as well as a visual and auditory representation of the graphs. Our study compared descriptions generated by the MDE to those generated by teachers of high school math, in order to better understand how to optimize the structure and content of mathematical graph descriptions. Feedback from these experts is compiled into suggestions for description templates to improve graphs descriptions, as well as design recommendations for future applications.', 'doi': '10.1145/1878803.1878860', 'url': 'https://doi.org/10.1145/1878803.1878860', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Evaluating text descriptions of mathematical graphs', 'author': 'Moskovitch, Yarden and Walker, Bruce N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878860'}"
Gesture recognition for fingerspelling applications: an approach based on sign language cheremes,10.1145/1878803.1878861,"This paper presents an approach for carrying out gesture recognition for the Brazilian Sign Language Manual Alphabet. The gestural patterns are treated as a combination of three primitives, or cheremes - hand configuration, hand orientation and hand movement. The recognizer is built in a modular architecture composed by inductive reasoning modules, which use the artificial neural network Fuzzy Learning Vector Quantization; and rule-based modules. This architecture has been tested and results are presented here. Some strengths of such approach are: robustness of recognition, portability to similar contexts, extensibility of the dataset to be recognize and reduction of the vocabulary recognition problem to the recognition of its primitives.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'cheremes, fingerspelling applications, gesture recognition, sign language', 'numpages': '2', 'pages': '261–262', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents an approach for carrying out gesture recognition for the Brazilian Sign Language Manual Alphabet. The gestural patterns are treated as a combination of three primitives, or cheremes - hand configuration, hand orientation and hand movement. The recognizer is built in a modular architecture composed by inductive reasoning modules, which use the artificial neural network Fuzzy Learning Vector Quantization; and rule-based modules. This architecture has been tested and results are presented here. Some strengths of such approach are: robustness of recognition, portability to similar contexts, extensibility of the dataset to be recognize and reduction of the vocabulary recognition problem to the recognition of its primitives.', 'doi': '10.1145/1878803.1878861', 'url': 'https://doi.org/10.1145/1878803.1878861', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Gesture recognition for fingerspelling applications: an approach based on sign language cheremes', 'author': 'Madeo, Renata C. B. and Peres, Sarajane M. and Dias, Daniel B. and Boscarioli, Clodis', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878861'}"
I like to log: a questionnaire study towards accessible lifelogging for older users,10.1145/1878803.1878862,"Lifelogging is the capture and storage of everyday experiences and the act of reviewing lifelog data can significantly support episodic memory, which is particularly vulnerable to the effects of ageing. To design an accessible lifelogging application for older users we firstly need to explore what lifelogging features the application should include. We carried out a questionnaire study to investigate what lifelogging items people from different age groups are currently collecting. Also of interest to us was what items the participants would like to collect and the differences in lifelogging choices between age groups. The results from this questionnaire will contribute to the design of a lifelogging application which focuses on older users' preferences, motivations and abilities.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'lifelogging, older adults, questionnaire', 'numpages': '2', 'pages': '263–264', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Lifelogging is the capture and storage of everyday experiences and the act of reviewing lifelog data can significantly support episodic memory, which is particularly vulnerable to the effects of ageing. To design an accessible lifelogging application for older users we firstly need to explore what lifelogging features the application should include. We carried out a questionnaire study to investigate what lifelogging items people from different age groups are currently collecting. Also of interest to us was what items the participants would like to collect and the differences in lifelogging choices between age groups. The results from this questionnaire will contribute to the design of a lifelogging application which focuses on older users' preferences, motivations and abilities."", 'doi': '10.1145/1878803.1878862', 'url': 'https://doi.org/10.1145/1878803.1878862', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'I like to log: a questionnaire study towards accessible lifelogging for older users', 'author': ""Caprani, Niamh and Gurrin, Cathal and O'Connor, Noel E."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878862'}"
Image categorization for improving accessibility to information graphics,10.1145/1878803.1878863,"Information graphics are important visual information in digital media. This paper investigates the accessibility issues associate with the information graphics for visually impaired people. The goal is to provide them with comprehensive numerical information contained in the figures. Towards the goal, we address the practical problems of automatic figure categorization, information extraction and multi-modal presentation scheme. In particular, the system identifies the image class using image processing and machine learning algorithms. With the knowledge of the image class, specific domain features and information are extracted, and then different modalities of presentation are employed based on the need. This paper first proposes the system framework and then focuses on the automated categorization algorithm.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'classification, information graphics, visual impairment', 'numpages': '2', 'pages': '265–266', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Information graphics are important visual information in digital media. This paper investigates the accessibility issues associate with the information graphics for visually impaired people. The goal is to provide them with comprehensive numerical information contained in the figures. Towards the goal, we address the practical problems of automatic figure categorization, information extraction and multi-modal presentation scheme. In particular, the system identifies the image class using image processing and machine learning algorithms. With the knowledge of the image class, specific domain features and information are extracted, and then different modalities of presentation are employed based on the need. This paper first proposes the system framework and then focuses on the automated categorization algorithm.', 'doi': '10.1145/1878803.1878863', 'url': 'https://doi.org/10.1145/1878803.1878863', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Image categorization for improving accessibility to information graphics', 'author': 'Gao, Jinglun and Carrillo, Rafael E. and Barner, Kenneth E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878863'}"
Interactive SIGHT demo: textual summaries of simple bar charts,10.1145/1878803.1878864,"Interactive SIGHT is a system that is intended to provide people with visual impairments access to the kind of information graphics found in popular media (i.e., electronic newspapers or magazines). The majority of such graphics are intended to convey a message; the graphic designer chose the graphic and its design in order to make a point. Interactive SIGHT, which is implemented as a browser extension that works on simple bar charts, provides a brief high-level summary of the graphic through natural language text that is conveyed to the user as speech. The user may request further information about the graphic through a follow-up question facility which allows many follow-up responses to be generated. The demo will illustrate the system's methodology on several bar charts that have been preloaded along with some accompanying text.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, information graphics, visual impairments', 'numpages': '2', 'pages': '267–268', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Interactive SIGHT is a system that is intended to provide people with visual impairments access to the kind of information graphics found in popular media (i.e., electronic newspapers or magazines). The majority of such graphics are intended to convey a message; the graphic designer chose the graphic and its design in order to make a point. Interactive SIGHT, which is implemented as a browser extension that works on simple bar charts, provides a brief high-level summary of the graphic through natural language text that is conveyed to the user as speech. The user may request further information about the graphic through a follow-up question facility which allows many follow-up responses to be generated. The demo will illustrate the system's methodology on several bar charts that have been preloaded along with some accompanying text."", 'doi': '10.1145/1878803.1878864', 'url': 'https://doi.org/10.1145/1878803.1878864', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Interactive SIGHT demo: textual summaries of simple bar charts', 'author': 'Demir, Seniz and Oliver, David and Schwartz, Edward and Elzer, Stephanie and Carberry, Sandra and McCoy, Kathleen F.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878864'}"
Iwalk: a lightweight navigation system for low-vision users,10.1145/1878803.1878865,"Smart phones typically support a range of GPS-enabled navigation services. However, most navigation services on smart phones are of limited use to people with visual disabilities. In this paper, we present iWalk, a speech-enabled local search and navigation prototype for people with low vision. iWalk runs on smart phones. It supports speech input, and provides real-time turn-by-turn walking directions in speech and text, using distances and time-to-turn information in addition to street names so that users are not forced to read street signs. In between turns iWalk uses non-speech cues to indicate to the user that s/he is 'on-track'.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, navigation, speech recognition, text to speech', 'numpages': '2', 'pages': '269–270', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Smart phones typically support a range of GPS-enabled navigation services. However, most navigation services on smart phones are of limited use to people with visual disabilities. In this paper, we present iWalk, a speech-enabled local search and navigation prototype for people with low vision. iWalk runs on smart phones. It supports speech input, and provides real-time turn-by-turn walking directions in speech and text, using distances and time-to-turn information in addition to street names so that users are not forced to read street signs. In between turns iWalk uses non-speech cues to indicate to the user that s/he is 'on-track'."", 'doi': '10.1145/1878803.1878865', 'url': 'https://doi.org/10.1145/1878803.1878865', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Iwalk: a lightweight navigation system for low-vision users', 'author': 'Stent, Amanda J. and Azenkot, Shiri and Stern, Ben', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878865'}"
JBrick: accessible lego mindstorm programming tool for users who are visually impaired,10.1145/1878803.1878866,"Despite advances in assistive technology, relatively few visually impaired students participate in computer science courses. Significant factors in this underrepresentation include lack of precollege preparation, access to resources, and the highly visual nature of computing. This poster describes the development of a prototype to provide an accessible programming environment for Lego Mindstorm NXT. With the popularity of robotics in both pre-college and introductory programming classes, such an environment has the potential to better accommodate students who are visually impaired. JBrick's motivation in addition to its design will be presented.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'programming, robotics, visual impairment', 'numpages': '2', 'pages': '271–272', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Despite advances in assistive technology, relatively few visually impaired students participate in computer science courses. Significant factors in this underrepresentation include lack of precollege preparation, access to resources, and the highly visual nature of computing. This poster describes the development of a prototype to provide an accessible programming environment for Lego Mindstorm NXT. With the popularity of robotics in both pre-college and introductory programming classes, such an environment has the potential to better accommodate students who are visually impaired. JBrick's motivation in addition to its design will be presented."", 'doi': '10.1145/1878803.1878866', 'url': 'https://doi.org/10.1145/1878803.1878866', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'JBrick: accessible lego mindstorm programming tool for users who are visually impaired', 'author': 'Ludi, Stephanie and Abadi, Mohammed and Fujiki, Yuji and Sankaran, Priya and Herzberg, Spencer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878866'}"
Naming practice for people with aphasia in a mobile web application: early user experience,10.1145/1878803.1878867,"Bangaten is a new version of Banga [2,3], a smart phone application that supports word finding practice, a form of therapy for people with aphasia. Early user experience shows that Bangaten offers useful cross-platform operation, on both Android and iPhone devices, including remote management of a client's device. Bangaten demonstrates the growing usefulness of emerging HTML5 technology for implementing assistive technology applications, while also illustrating some remaining limitations.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'aphasia, html5, mobile platform, therapy, web applications, word finding', 'numpages': '2', 'pages': '273–274', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Bangaten is a new version of Banga [2,3], a smart phone application that supports word finding practice, a form of therapy for people with aphasia. Early user experience shows that Bangaten offers useful cross-platform operation, on both Android and iPhone devices, including remote management of a client's device. Bangaten demonstrates the growing usefulness of emerging HTML5 technology for implementing assistive technology applications, while also illustrating some remaining limitations."", 'doi': '10.1145/1878803.1878867', 'url': 'https://doi.org/10.1145/1878803.1878867', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Naming practice for people with aphasia in a mobile web application: early user experience', 'author': 'Hagood, Khalyle and Moore, Terrance and Pierre, Tiffany and Messamer, Paula and Ramsberger, Gail and Lewis, Clayton', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878867'}"
Performance-based functional assessment: integrating multiple perspectives,10.1145/1878803.1878868,"The lack of quantifiable, reliable and repeatable methods for assessing functional capabilities of users with physical limitations creates challenges for accessibility researchers and practitioners. Current practice includes descriptors such as medical diagnoses, third-party observations, and self-assessment to characterize physical capabilities of information technology users. These solutions are inadequate due to similarities in functional capabilities between diagnoses, differences in capabilities within a diagnosis, and the potential for bias when characterizing functional capabilities. The current research examines performance-based functional assessment as an alternative to existing assessment techniques. Initial study results based on a single focus model (task efficiency) were reported earlier [1, 2]. This paper builds on that work, highlighting the benefits of integrating multiple perspectives such that both efficiency and anomalies are considered. A decision tree was produced combining results from several performance-based functional assessment models providing improved predictive capabilities.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'HCI, accessibility, functional assessment, physical capabilities', 'numpages': '2', 'pages': '275–276', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The lack of quantifiable, reliable and repeatable methods for assessing functional capabilities of users with physical limitations creates challenges for accessibility researchers and practitioners. Current practice includes descriptors such as medical diagnoses, third-party observations, and self-assessment to characterize physical capabilities of information technology users. These solutions are inadequate due to similarities in functional capabilities between diagnoses, differences in capabilities within a diagnosis, and the potential for bias when characterizing functional capabilities. The current research examines performance-based functional assessment as an alternative to existing assessment techniques. Initial study results based on a single focus model (task efficiency) were reported earlier [1, 2]. This paper builds on that work, highlighting the benefits of integrating multiple perspectives such that both efficiency and anomalies are considered. A decision tree was produced combining results from several performance-based functional assessment models providing improved predictive capabilities.', 'doi': '10.1145/1878803.1878868', 'url': 'https://doi.org/10.1145/1878803.1878868', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Performance-based functional assessment: integrating multiple perspectives', 'author': 'Price, Kathleen J. and Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878868'}"
Reading difficulty in adults with intellectual disabilities: analysis with a hierarchical latent trait model,10.1145/1878803.1878869,"In prior work, adults with intellectual disabilities answered comprehension questions after reading texts. We apply a latent trait model to this data to infer the intrinsic difficulty of texts for the participant group. We then analyze the correlation between grade levels predicted by an automatic readability assessment tool and the inferred text difficulty.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, intellectual disabilities, text comprehension, text readability assessment', 'numpages': '2', 'pages': '277–278', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In prior work, adults with intellectual disabilities answered comprehension questions after reading texts. We apply a latent trait model to this data to infer the intrinsic difficulty of texts for the participant group. We then analyze the correlation between grade levels predicted by an automatic readability assessment tool and the inferred text difficulty.', 'doi': '10.1145/1878803.1878869', 'url': 'https://doi.org/10.1145/1878803.1878869', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Reading difficulty in adults with intellectual disabilities: analysis with a hierarchical latent trait model', 'author': 'Jansche, Martin and Feng, Lijun and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878869'}"
Sasayaki: an augmented voice-based web browsing experience,10.1145/1878803.1878870,"While the usability of voice-based Web navigation has been steadily improving, it is still not as easy for users with visual impairments as it is for sighted users. One reason is that sequential voice representation can only convey a limited amount of information at a time. Another challenge comes from the fact that current voice browsers omit various visual cues such as text styles and page structures, and lack meaningful feedback about the current focus. To address these issues, we created Sasayaki, an intelligent voice-based user agent that augments the primary voice output of a voice browser with a secondary voice that whispers contextually relevant information as appropriate or in response to user requests. A prototype has been implemented as a plug-in for a voice browser. The results from a pilot study show that our Sasayaki agent is able to improve users' information search task time and their overall confidence level. We believe that our intelligent voice-based agent has great potential to enrich the Web browsing experiences of users with visual impairments.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'sasayaki, voice agent, voice browser, web accessibility', 'numpages': '2', 'pages': '279–280', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""While the usability of voice-based Web navigation has been steadily improving, it is still not as easy for users with visual impairments as it is for sighted users. One reason is that sequential voice representation can only convey a limited amount of information at a time. Another challenge comes from the fact that current voice browsers omit various visual cues such as text styles and page structures, and lack meaningful feedback about the current focus. To address these issues, we created Sasayaki, an intelligent voice-based user agent that augments the primary voice output of a voice browser with a secondary voice that whispers contextually relevant information as appropriate or in response to user requests. A prototype has been implemented as a plug-in for a voice browser. The results from a pilot study show that our Sasayaki agent is able to improve users' information search task time and their overall confidence level. We believe that our intelligent voice-based agent has great potential to enrich the Web browsing experiences of users with visual impairments."", 'doi': '10.1145/1878803.1878870', 'url': 'https://doi.org/10.1145/1878803.1878870', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Sasayaki: an augmented voice-based web browsing experience', 'author': 'Zhu, Shaojian and Sato, Daisuke and Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878870'}"
A customized mouse for people with physical disabilities,10.1145/1878803.1878871,"In a rapidly growing information-oriented society, people with disabilities are faced with serious inconveniences in accessing products due to the increasingly complicated use of technology-oriented but poorly designed devices. To solve these problems, we designed a customized computer input device (mouse) to be used by physically impaired people. The users performed better with the customized computer mouse than with the traditional computer mouse.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, customized mouse, handheld device, physically impaired, user needs', 'numpages': '2', 'pages': '281–282', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In a rapidly growing information-oriented society, people with disabilities are faced with serious inconveniences in accessing products due to the increasingly complicated use of technology-oriented but poorly designed devices. To solve these problems, we designed a customized computer input device (mouse) to be used by physically impaired people. The users performed better with the customized computer mouse than with the traditional computer mouse.', 'doi': '10.1145/1878803.1878871', 'url': 'https://doi.org/10.1145/1878803.1878871', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A customized mouse for people with physical disabilities', 'author': 'Jang, Minsun and Choi, Jiho and Lee, Seongil', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878871'}"
The augenda: structuring the lives of autistic teenagers,10.1145/1878803.1878872,In this paper we present an application that assists autistic teenagers in organizing their lives and enhances the communication between autistic teenagers and their caregivers. This application was designed in a participatory manner where autistics teenagers and caregivers participated in all phases of the application development. The early results show that the application has a potential to improve the lives of autistic teenagers by not only bringing structure in their lives but also by improving the communication channel between teenagers and their caregivers.,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'agendas, autism, children, design, user interface', 'numpages': '2', 'pages': '283–284', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper we present an application that assists autistic teenagers in organizing their lives and enhances the communication between autistic teenagers and their caregivers. This application was designed in a participatory manner where autistics teenagers and caregivers participated in all phases of the application development. The early results show that the application has a potential to improve the lives of autistic teenagers by not only bringing structure in their lives but also by improving the communication channel between teenagers and their caregivers.', 'doi': '10.1145/1878803.1878872', 'url': 'https://doi.org/10.1145/1878803.1878872', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'The augenda: structuring the lives of autistic teenagers', 'author': 'Hong, Alain P.C.I. and van Heugten, Sjoerd and Kooken, Tom and Vinke, Nikkie and Vromans, Myrtille and Shahid, Suleman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878872'}"
The design and development of an interactive aural rehabilitation therapy program,10.1145/1878803.1878873,"In this paper, we describe our current work in developing a computer-based aural rehabilitation tool for profoundly deaf children that have recently acquired Cochlear Implants. The software is an interactive program aimed at young Arabic-speaking children, called Rannan. Evaluations of Rannan involved comparing different input modalities and evaluating the effectiveness of sound discrimination activities. Findings show that touch-based interaction facilitated faster response and improved accuracy over cursor-based input modalities. Moreover, usability evaluations suggest that Rannan can be an effective bridge between clinical-based therapy and home-based aural rehabilitation.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'aural rehabilitation, cochlear implants, input modalities', 'numpages': '2', 'pages': '285–286', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we describe our current work in developing a computer-based aural rehabilitation tool for profoundly deaf children that have recently acquired Cochlear Implants. The software is an interactive program aimed at young Arabic-speaking children, called Rannan. Evaluations of Rannan involved comparing different input modalities and evaluating the effectiveness of sound discrimination activities. Findings show that touch-based interaction facilitated faster response and improved accuracy over cursor-based input modalities. Moreover, usability evaluations suggest that Rannan can be an effective bridge between clinical-based therapy and home-based aural rehabilitation.', 'doi': '10.1145/1878803.1878873', 'url': 'https://doi.org/10.1145/1878803.1878873', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'The design and development of an interactive aural rehabilitation therapy program', 'author': 'Al-Ghamdi, Najwa Musfer and Al-Ohali, Yousef', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878873'}"
The evaluation of visually impaired people's ability of defining the object location on touch-screen,10.1145/1878803.1878874,"Touch-screen has been used not only on home appliances but also on so many kinds of machines in public facilities at the present time. However the fact is that most of visually impaired people have a problem with the difficult usability of a touch-screen. We come up with an idea of Presentation Methods of Sound Information, which is thought to enable visually impaired people to define the object location on the touch-screen. We also make a proposal of the Concentration game content that is possible in improving the Sound localization's ability and evaluating the visually impaired people's characteristics of touch-screen's operation method. In this paper, we introduce the results of the experiment that we conducted with 5 visually impaired people. These are evaluated through the way of the finger moving on the touch-screen panel while using this content, and the ability of defining the object location.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blind, recognition, sound-localization, touch-screen, visually impaired', 'numpages': '2', 'pages': '287–288', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Touch-screen has been used not only on home appliances but also on so many kinds of machines in public facilities at the present time. However the fact is that most of visually impaired people have a problem with the difficult usability of a touch-screen. We come up with an idea of Presentation Methods of Sound Information, which is thought to enable visually impaired people to define the object location on the touch-screen. We also make a proposal of the Concentration game content that is possible in improving the Sound localization's ability and evaluating the visually impaired people's characteristics of touch-screen's operation method. In this paper, we introduce the results of the experiment that we conducted with 5 visually impaired people. These are evaluated through the way of the finger moving on the touch-screen panel while using this content, and the ability of defining the object location."", 'doi': '10.1145/1878803.1878874', 'url': 'https://doi.org/10.1145/1878803.1878874', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': ""The evaluation of visually impaired people's ability of defining the object location on touch-screen"", 'author': 'Usui, Keijiro and Takano, Masamitsu and Fukushima, Yusuke and Yairi, Ikuko Eguchi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878874'}"
Toward tactile authentication for blind users,10.1145/1878803.1878875,"This paper describes the design of an accessible authentication mechanism. The Tactile Authentication System has been adapted to enable individuals who are blind to access electronic data using their sense of touch. To enter the system, users must identify a set of pre-selected pin-based icons from a wider range presented via a tactile mouse. As information is presented underneath the user's fingertips, 'tactile passwords' are shielded from observers, thereby enhancing security from third-party attacks. Results from a pilot study showed that five participants were able to authenticate entry to the non-visual interface over the course of a two week period. However, findings have revealed that the time needed to perform this process should be reduced to improve the quality of the user experience.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'authentication, multimodal interfaces, tactile feedback', 'numpages': '2', 'pages': '289–290', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper describes the design of an accessible authentication mechanism. The Tactile Authentication System has been adapted to enable individuals who are blind to access electronic data using their sense of touch. To enter the system, users must identify a set of pre-selected pin-based icons from a wider range presented via a tactile mouse. As information is presented underneath the user's fingertips, 'tactile passwords' are shielded from observers, thereby enhancing security from third-party attacks. Results from a pilot study showed that five participants were able to authenticate entry to the non-visual interface over the course of a two week period. However, findings have revealed that the time needed to perform this process should be reduced to improve the quality of the user experience."", 'doi': '10.1145/1878803.1878875', 'url': 'https://doi.org/10.1145/1878803.1878875', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Toward tactile authentication for blind users', 'author': 'Kuber, Ravi and Sharma, Shiva', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878875'}"
Usability and use of SLS: caption,10.1145/1878803.1878876,"SLS:Caption provides captioning functionality for deaf and hearing users to provide captions to video content (including sign language content). Users are able to enter and modify text as well as adjust its font, colour, location and background opacity. An initial user study with hearing users showed that SLS:Caption was easy to learn and use. However, users seem reluctant to produce captions for their own video material; this was likely due to the task complexity and time required to create captions regardless of the usability of the captioning tool.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'captioning, captioning tools, sign language online', 'numpages': '2', 'pages': '291–292', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'SLS:Caption provides captioning functionality for deaf and hearing users to provide captions to video content (including sign language content). Users are able to enter and modify text as well as adjust its font, colour, location and background opacity. An initial user study with hearing users showed that SLS:Caption was easy to learn and use. However, users seem reluctant to produce captions for their own video material; this was likely due to the task complexity and time required to create captions regardless of the usability of the captioning tool.', 'doi': '10.1145/1878803.1878876', 'url': 'https://doi.org/10.1145/1878803.1878876', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Usability and use of SLS: caption', 'author': 'Fels, Deborah I. and Gerdzhev, Martin and Ho, Janice and Hibbard, Ellen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878876'}"
Using the phone with a single input signal only: evaluation of 3dscan's telephone module,10.1145/1878803.1878877,"3dScan is a scanning-based software system allowing its user to interact with the immediate environment by intentionally contracting a single muscle of choice as input signals. The system is targeted at persons with severe physical impairments with the objective to improve its users' quality of life by empowering them to independently perform certain activities of daily life (ADL), e.g., to open the door by activating a suitable switch or to control the TV remote. The required input signals can, for example, be produced by merely raising the eyebrow ('frowning') and thus demand only a minimum of physical effort. A recent design change in 3dScan's data acquisition component made it possible to add telephony functionality to the list of supported ADL's. The proposed poster describes the 3dScan's telephone module which now is already in a revised and mature state. The usability of the newest version of the module was tested in two evaluations, where the second one involved participants belonging to the target population, and the results are presented in the poster","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'activities of daily life, environment control, human-computer interaction, intentional muscle contractions, scanning, voice-over-ip', 'numpages': '2', 'pages': '293–294', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""3dScan is a scanning-based software system allowing its user to interact with the immediate environment by intentionally contracting a single muscle of choice as input signals. The system is targeted at persons with severe physical impairments with the objective to improve its users' quality of life by empowering them to independently perform certain activities of daily life (ADL), e.g., to open the door by activating a suitable switch or to control the TV remote. The required input signals can, for example, be produced by merely raising the eyebrow ('frowning') and thus demand only a minimum of physical effort. A recent design change in 3dScan's data acquisition component made it possible to add telephony functionality to the list of supported ADL's. The proposed poster describes the 3dScan's telephone module which now is already in a revised and mature state. The usability of the newest version of the module was tested in two evaluations, where the second one involved participants belonging to the target population, and the results are presented in the poster"", 'doi': '10.1145/1878803.1878877', 'url': 'https://doi.org/10.1145/1878803.1878877', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': ""Using the phone with a single input signal only: evaluation of 3dscan's telephone module"", 'author': 'Felzer, Torsten and Rinderknecht, Stephan and Vateva, Tsvetoslava', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878877'}"
V-braille: haptic braille perception using a touch-screen and vibration on mobile phones,10.1145/1878803.1878878,"V-Braille is a novel way to haptically represent Braille characters on a standard mobile phone using the touch-screen and vibration. V-Braille may be suitable for deaf-blind people who rely primarily on their tactile sense. A preliminary study with deaf-blind Braille users found that, with minimal training, V-Braille can be used to read individual characters and sentences.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, blind, deaf-blind, haptic perception, mobile phone, touchscreen, vibration', 'numpages': '2', 'pages': '295–296', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'V-Braille is a novel way to haptically represent Braille characters on a standard mobile phone using the touch-screen and vibration. V-Braille may be suitable for deaf-blind people who rely primarily on their tactile sense. A preliminary study with deaf-blind Braille users found that, with minimal training, V-Braille can be used to read individual characters and sentences.', 'doi': '10.1145/1878803.1878878', 'url': 'https://doi.org/10.1145/1878803.1878878', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'V-braille: haptic braille perception using a touch-screen and vibration on mobile phones', 'author': 'Jayant, Chandrika and Acuario, Christine and Johnson, William and Hollier, Janet and Ladner, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878878'}"
Vocsyl: visualizing syllable production for children with ASD and speech delays,10.1145/1878803.1878879,"Communication disorders occur across the lifespan and encompass a wide range of conditions that interfere with individuals' abilities to hear (e.g., hearing loss), speak (e.g., voice disorders; motor speech disorders), and/or use language (e.g., specific language impairment; aphasia) to meet their communication needs. Such disorders often compromise the social, recreational, emotional, educational, and vocational aspects of an individual's life. This research examines the development and implementation of new software that facilitates multi-syllabic speech production in children with autism and speech delays. The VocSyl software package utilizes a suite of audio visualizations that represent a myriad of audio features in abstract representations. The goal of these visualizations is to provide children with language impairments a new persistent modality in which to experience and practice speech-language skills.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'autism, speech delays, syllables, visualization', 'numpages': '2', 'pages': '297–298', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Communication disorders occur across the lifespan and encompass a wide range of conditions that interfere with individuals' abilities to hear (e.g., hearing loss), speak (e.g., voice disorders; motor speech disorders), and/or use language (e.g., specific language impairment; aphasia) to meet their communication needs. Such disorders often compromise the social, recreational, emotional, educational, and vocational aspects of an individual's life. This research examines the development and implementation of new software that facilitates multi-syllabic speech production in children with autism and speech delays. The VocSyl software package utilizes a suite of audio visualizations that represent a myriad of audio features in abstract representations. The goal of these visualizations is to provide children with language impairments a new persistent modality in which to experience and practice speech-language skills."", 'doi': '10.1145/1878803.1878879', 'url': 'https://doi.org/10.1145/1878803.1878879', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Vocsyl: visualizing syllable production for children with ASD and speech delays', 'author': 'Hailpern, Joshua and Karahalios, Karrie and DeThorne, Laura and Halle, Jim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878879'}"
Walking in another's shoes: aphasia emulation software,10.1145/1878803.1878880,"The impact of living in a world that does not understand your impairment can be frustrating and a daunting task. Consider how an individual would feel if their family, friends, or doctors did not understand or were not even empathetic to daily struggles brought on by an acquired language disorder such as Aphasia. This work seeks to shed new light on aphasia by creating an instant message client which emulates the effects of aphasia. The goal of this new system is to raise awareness, teach, and increase empathy for caregivers, family members, and doctors/therapists who work with this population on a daily basis.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'aphasia, empathy, emulation', 'numpages': '2', 'pages': '299–300', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The impact of living in a world that does not understand your impairment can be frustrating and a daunting task. Consider how an individual would feel if their family, friends, or doctors did not understand or were not even empathetic to daily struggles brought on by an acquired language disorder such as Aphasia. This work seeks to shed new light on aphasia by creating an instant message client which emulates the effects of aphasia. The goal of this new system is to raise awareness, teach, and increase empathy for caregivers, family members, and doctors/therapists who work with this population on a daily basis.', 'doi': '10.1145/1878803.1878880', 'url': 'https://doi.org/10.1145/1878803.1878880', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': ""Walking in another's shoes: aphasia emulation software"", 'author': 'Hailpern, Joshua and Danilevsky, Marina and Karahalios, Karrie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878880'}"
What can the 'ash cloud' tell us about older adults' technology adoption,10.1145/1878803.1878881,"Older adults are often encouraged to try new technology by a specific motivator or 'trigger'. Recently, a surprising 'trigger' has emerged - the 'ash cloud' which caused large scale disruption for air travel across Europe earlier in 2010. Understanding why this unexpected event managed to motivate interest into technology where other efforts have failed may provide further insight for research looking at the digitally disinterested.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'digital economy, inclusion, older adults, technology acceptance', 'numpages': '2', 'pages': '301–302', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Older adults are often encouraged to try new technology by a specific motivator or 'trigger'. Recently, a surprising 'trigger' has emerged - the 'ash cloud' which caused large scale disruption for air travel across Europe earlier in 2010. Understanding why this unexpected event managed to motivate interest into technology where other efforts have failed may provide further insight for research looking at the digitally disinterested."", 'doi': '10.1145/1878803.1878881', 'url': 'https://doi.org/10.1145/1878803.1878881', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': ""What can the 'ash cloud' tell us about older adults' technology adoption"", 'author': 'Gibson, Lorna and Forbes, Paula and Hanson, Vicki', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878881'}"
Session details: ACM student research competition,10.1145/3252147,Abstract not available,"{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252147', 'url': 'https://doi.org/10.1145/3252147', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Session details: ACM student research competition', 'author': 'Bigham, Jeffrey P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252147'}"
A system of clothes matching for visually impaired persons,10.1145/1878803.1878883,"Choosing clothes is a challenge task for blind people. In this paper, we propose a proof of concept system to match a pair of image from different clothes for both pattern and color. Our system consists of 1) a camera and a computer to perform color detection, pattern and color matching process; 2) supporting speech commands to flexibly control and configure; and 3) audio feedbacks to provide matching results of both color and pattern. The system can deal with clothes in uniform color without any pattern, as well as clothes with multiple colors and complex patterns. Furthermore, our method is robust to variations of illumination, clothes rotation, and clothes wrinkles. The proposed method is evaluated on two challenge databases of clothes. Experimental results demonstrate the robustness and effectiveness on clothes matching.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'blind, clothes matching, color blind, color matching, computer vision, pattern matching', 'numpages': '2', 'pages': '303–304', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Choosing clothes is a challenge task for blind people. In this paper, we propose a proof of concept system to match a pair of image from different clothes for both pattern and color. Our system consists of 1) a camera and a computer to perform color detection, pattern and color matching process; 2) supporting speech commands to flexibly control and configure; and 3) audio feedbacks to provide matching results of both color and pattern. The system can deal with clothes in uniform color without any pattern, as well as clothes with multiple colors and complex patterns. Furthermore, our method is robust to variations of illumination, clothes rotation, and clothes wrinkles. The proposed method is evaluated on two challenge databases of clothes. Experimental results demonstrate the robustness and effectiveness on clothes matching.', 'doi': '10.1145/1878803.1878883', 'url': 'https://doi.org/10.1145/1878803.1878883', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'A system of clothes matching for visually impaired persons', 'author': 'Yuan, Shuai', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878883'}"
Accessible indoor navigation,10.1145/1878803.1878884,"This research focuses on designing an indoor navigation application for disabled users. Outdoor navigation systems make use of GPS satellites to locate users; this same technique, however, is not reliable enough for indoor way-finding. Indoor Positioning Systems (IPS) exist but rely on complex and expensive networks. Described here is a new approach towards such indoor navigation, reporting on research related to the interactions and user experiences involved in locating a user within a building. Interactions are customized to suit the needs of individual users when way-finding helping to ensure that the tool is both usable and accessible by users of varying abilities.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, adaptive systems, indoor navigation, way-finding', 'numpages': '2', 'pages': '305–306', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This research focuses on designing an indoor navigation application for disabled users. Outdoor navigation systems make use of GPS satellites to locate users; this same technique, however, is not reliable enough for indoor way-finding. Indoor Positioning Systems (IPS) exist but rely on complex and expensive networks. Described here is a new approach towards such indoor navigation, reporting on research related to the interactions and user experiences involved in locating a user within a building. Interactions are customized to suit the needs of individual users when way-finding helping to ensure that the tool is both usable and accessible by users of varying abilities.', 'doi': '10.1145/1878803.1878884', 'url': 'https://doi.org/10.1145/1878803.1878884', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Accessible indoor navigation', 'author': 'Montague, Kyle', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878884'}"
Audiowiz: nearly real-time audio transcriptions,10.1145/1878803.1878885,"Existing automated transcription solutions filter out environmental noises and focus only on transcribing the spoken word. This leaves deaf and hard of hearing users with no way of learning about events that provide no spoken information such as the sounds produced by a faulty appliance or the barked alert of a dutiful guard dog. In this paper we present AudioWiz, a mobile application that provides highly detailed audio transcriptions of both the spoken word and the accompanying environmental sounds. This approach is made possible by harnessing humans to provide audio transcriptions instead of more traditional automated means. Web-workers are recruited automatically in nearly real-time as dictated by demand.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'assistive technology, audio transcription, sound visualization', 'numpages': '2', 'pages': '307–308', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Existing automated transcription solutions filter out environmental noises and focus only on transcribing the spoken word. This leaves deaf and hard of hearing users with no way of learning about events that provide no spoken information such as the sounds produced by a faulty appliance or the barked alert of a dutiful guard dog. In this paper we present AudioWiz, a mobile application that provides highly detailed audio transcriptions of both the spoken word and the accompanying environmental sounds. This approach is made possible by harnessing humans to provide audio transcriptions instead of more traditional automated means. Web-workers are recruited automatically in nearly real-time as dictated by demand.', 'doi': '10.1145/1878803.1878885', 'url': 'https://doi.org/10.1145/1878803.1878885', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Audiowiz: nearly real-time audio transcriptions', 'author': 'White, Samuel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878885'}"
"Does a sonar system make a blind maze navigation computer game more ""fun""?",10.1145/1878803.1878886,"As part of the Blind Programming Project at Southern Illinois University Edwardsville, we are investigating ways to make programming more fun for school aged blind children. We are beginning this search by creating and empirically analyzing a number of different auditory computer games. These games are being analyzed to see if we can make them customizable (programmable), using blind programming environments, and to see what kind of strategies work best when designing video games in general for blind users.In this work, we explored the creation of a zombie-killing maze navigation game for the blind. Specifically, we were curious whether a sonar based system would be more fun for users when trying to navigate the maze as compared to a navigation system that literally told the user which way to travel. We hypothesized that the sonar system would be more fun, as it provided a playful challenge. Unlike most auditory games for the blind, which typically use screen readers, we made high quality voice recordings of the entire user interface for our game. Overall, results did not show that the sonar based game was more fun, however our game was rated so highly by users, that the navigation system itself appears less important than careful user design and innovative and fun auditory feedback.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, auditory games', 'numpages': '2', 'pages': '309–310', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'As part of the Blind Programming Project at Southern Illinois University Edwardsville, we are investigating ways to make programming more fun for school aged blind children. We are beginning this search by creating and empirically analyzing a number of different auditory computer games. These games are being analyzed to see if we can make them customizable (programmable), using blind programming environments, and to see what kind of strategies work best when designing video games in general for blind users.In this work, we explored the creation of a zombie-killing maze navigation game for the blind. Specifically, we were curious whether a sonar based system would be more fun for users when trying to navigate the maze as compared to a navigation system that literally told the user which way to travel. We hypothesized that the sonar system would be more fun, as it provided a playful challenge. Unlike most auditory games for the blind, which typically use screen readers, we made high quality voice recordings of the entire user interface for our game. Overall, results did not show that the sonar based game was more fun, however our game was rated so highly by users, that the navigation system itself appears less important than careful user design and innovative and fun auditory feedback.', 'doi': '10.1145/1878803.1878886', 'url': 'https://doi.org/10.1145/1878803.1878886', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Does a sonar system make a blind maze navigation computer game more ""fun""?', 'author': 'Wilkerson, Matt and Koenig, Amanda and Daniel, James', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878886'}"
FlashDOM: interacting with flash content from the document object model,10.1145/1878803.1878887,"Assistive technologies are often only adapted to emerging web technologies after they are common enough to generate demand for relevant assistive technology. This paper proposes a general approach to speed up and simplify the process of making assistive technologies compatible with innovation on the web by providing hooks to the browser's standard Document Object Model that expose the capabilities of a new technology.In this paper, we will illustrate the utility of this model by applying it to Adobe Flash content, which, despite years of attempts to produce more accessible content, remains woefully inaccessible.We show how this approach enables screen readers that would normally not have permission to read Flash content to access this content, and how it can enable interactivity with Flash content in a modern browser.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, assistive technology, document object model, flash, screen reader', 'numpages': '2', 'pages': '311–312', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Assistive technologies are often only adapted to emerging web technologies after they are common enough to generate demand for relevant assistive technology. This paper proposes a general approach to speed up and simplify the process of making assistive technologies compatible with innovation on the web by providing hooks to the browser's standard Document Object Model that expose the capabilities of a new technology.In this paper, we will illustrate the utility of this model by applying it to Adobe Flash content, which, despite years of attempts to produce more accessible content, remains woefully inaccessible.We show how this approach enables screen readers that would normally not have permission to read Flash content to access this content, and how it can enable interactivity with Flash content in a modern browser."", 'doi': '10.1145/1878803.1878887', 'url': 'https://doi.org/10.1145/1878803.1878887', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'FlashDOM: interacting with flash content from the document object model', 'author': 'Murray, Kyle I.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878887'}"
Head-guided wheelchair control system,10.1145/1878803.1878888,"Many individuals using a wheelchair do not have the use of their hands, thereby impeding their ability to control a motorized wheelchair. Available systems that accomplish wheelchair control utilize potentially inhibitive peripheral devices. The purpose of this project was to design a system that allows individuals to control a motorized wheelchair with simple head movements. This system consists of a self-designed program, headset, and a control module that interfaces with a motorized wheelchair joystick.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accelerometer, control, headset, joystick, module, servomotor, wheelchair', 'numpages': '2', 'pages': '313–314', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many individuals using a wheelchair do not have the use of their hands, thereby impeding their ability to control a motorized wheelchair. Available systems that accomplish wheelchair control utilize potentially inhibitive peripheral devices. The purpose of this project was to design a system that allows individuals to control a motorized wheelchair with simple head movements. This system consists of a self-designed program, headset, and a control module that interfaces with a motorized wheelchair joystick.', 'doi': '10.1145/1878803.1878888', 'url': 'https://doi.org/10.1145/1878803.1878888', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Head-guided wheelchair control system', 'author': 'Hinkel, John B.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878888'}"
Helping older adults locate 'lost' cursors using FieldMouse,10.1145/1878803.1878889,"This paper describes how a standard optical mouse was augmented by the addition of a touch sensor inside the body of the mouse. When the mouse is released and subsequently touched it generates a Windows message which can then be used to execute an action. Three techniques were developed using the augmented mouse (nicknamed 'FieldMouse') to help older adult computer users find the mouse cursor when it has become 'lost': placing the mouse cursor at the center of the screen; wiggling the mouse cursor from side to side; displaying a flashing red ring around the mouse cursor. The techniques were compared in a pilot study to see which one was the most effective, and this would then be used in a later study to compare techniques of finding the mouse cursor. Following the pilot, the technique of centering the mouse cursor was chosen for the later study since it was the quickest to find the mouse cursor, without needing to search the entire screen.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'computer mouse, losing mouse cursor, touch sensor', 'numpages': '2', 'pages': '315–316', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper describes how a standard optical mouse was augmented by the addition of a touch sensor inside the body of the mouse. When the mouse is released and subsequently touched it generates a Windows message which can then be used to execute an action. Three techniques were developed using the augmented mouse (nicknamed 'FieldMouse') to help older adult computer users find the mouse cursor when it has become 'lost': placing the mouse cursor at the center of the screen; wiggling the mouse cursor from side to side; displaying a flashing red ring around the mouse cursor. The techniques were compared in a pilot study to see which one was the most effective, and this would then be used in a later study to compare techniques of finding the mouse cursor. Following the pilot, the technique of centering the mouse cursor was chosen for the later study since it was the quickest to find the mouse cursor, without needing to search the entire screen."", 'doi': '10.1145/1878803.1878889', 'url': 'https://doi.org/10.1145/1878803.1878889', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': ""Helping older adults locate 'lost' cursors using FieldMouse"", 'author': 'Hollinworth, Nic', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878889'}"
Improving public transit usability for blind and deaf-blind people by connecting a braille display to a smartphone,10.1145/1878803.1878890,"We conducted interviews with blind and deaf-blind people to understand how they use the public transit system. In this paper, we discuss key challenges our participants faced and present a tool we developed to alleviate these challenges. We built this tool on MoBraille, a novel framework that enables a Braille display to benefit from many features in an Android phone without knowledge of proprietary, device-specific protocols. We conducted participatory design with a deaf-blind person and describe the lessons learned about designing an interface for a deaf-blind person.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, blind, deaf-blind, public transit usability', 'numpages': '2', 'pages': '317–318', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We conducted interviews with blind and deaf-blind people to understand how they use the public transit system. In this paper, we discuss key challenges our participants faced and present a tool we developed to alleviate these challenges. We built this tool on MoBraille, a novel framework that enables a Braille display to benefit from many features in an Android phone without knowledge of proprietary, device-specific protocols. We conducted participatory design with a deaf-blind person and describe the lessons learned about designing an interface for a deaf-blind person.', 'doi': '10.1145/1878803.1878890', 'url': 'https://doi.org/10.1145/1878803.1878890', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Improving public transit usability for blind and deaf-blind people by connecting a braille display to a smartphone', 'author': 'Azenkot, Shiri and Fortuna, Emily', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878890'}"
Investigating meaning in uses of assistive devices: implications of social and professional contexts,10.1145/1878803.1878891,"People with disabilities use assistive devices both to bridge accessibility gaps in everyday tasks, and to augment inaccessible technologies, such as desktop computers. This interview study investigates how people with disabilities are affected when using assistive devices in professional and social situations. Participants were asked about different contexts of use, and how people around them reacted to their devices. Key findings were that individuals experienced issues of self consciousness and empowerment when using assistive devices and that specific aspects of assistive device design, such as size and perceived sleekness, contributed to these feelings.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessibility, assistive device, assistive technology', 'numpages': '2', 'pages': '319–320', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with disabilities use assistive devices both to bridge accessibility gaps in everyday tasks, and to augment inaccessible technologies, such as desktop computers. This interview study investigates how people with disabilities are affected when using assistive devices in professional and social situations. Participants were asked about different contexts of use, and how people around them reacted to their devices. Key findings were that individuals experienced issues of self consciousness and empowerment when using assistive devices and that specific aspects of assistive device design, such as size and perceived sleekness, contributed to these feelings.', 'doi': '10.1145/1878803.1878891', 'url': 'https://doi.org/10.1145/1878803.1878891', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Investigating meaning in uses of assistive devices: implications of social and professional contexts', 'author': 'Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878891'}"
Joystick text entry with word prediction for people with motor impairments,10.1145/1878803.1878892,"Joysticks are used by people with motor impairments as an assistive device which acts as a replacement for the keyboard and mouse. Most existing entry methods that use the joystick take the form of on-screen or selection keyboards which require multiple movements of a joystick to enter a single character, making text input slow. We try to reduce the number of required joystick movements by adding word completion and next word prediction. Evaluations show text entry with word prediction is 30\% faster compared with entry on a regular selection keyboard and reduces the amount of movements by 50\%, even for first-time users with less than 15 minutes of practice.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'joystick, selection keyboard, text entry, text input, word prediction', 'numpages': '2', 'pages': '321–322', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Joysticks are used by people with motor impairments as an assistive device which acts as a replacement for the keyboard and mouse. Most existing entry methods that use the joystick take the form of on-screen or selection keyboards which require multiple movements of a joystick to enter a single character, making text input slow. We try to reduce the number of required joystick movements by adding word completion and next word prediction. Evaluations show text entry with word prediction is 30\\% faster compared with entry on a regular selection keyboard and reduces the amount of movements by 50\\%, even for first-time users with less than 15 minutes of practice.', 'doi': '10.1145/1878803.1878892', 'url': 'https://doi.org/10.1145/1878803.1878892', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Joystick text entry with word prediction for people with motor impairments', 'author': 'Song, Young Chol', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878892'}"
LocalEyes: accessible GPS and points of interest,10.1145/1878803.1878893,"Most current GPS devices are inaccessible for blind and low-vision users and the few that are tend to be expensive and highly specialized [2]. LocalEyes uses less expensive, multi-purpose smart phone technology and freely available data sources to provide an accessible GPS application that will increase a user's independence and ability to explore new places alone.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'accessible, assistive, gps, maps, points of interest', 'numpages': '2', 'pages': '323–324', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Most current GPS devices are inaccessible for blind and low-vision users and the few that are tend to be expensive and highly specialized [2]. LocalEyes uses less expensive, multi-purpose smart phone technology and freely available data sources to provide an accessible GPS application that will increase a user's independence and ability to explore new places alone."", 'doi': '10.1145/1878803.1878893', 'url': 'https://doi.org/10.1145/1878803.1878893', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'LocalEyes: accessible GPS and points of interest', 'author': 'Behmer, Jason and Knox, Stillman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878893'}"
Text locating in scene images for reading and navigation aids for visually impaired persons,10.1145/1878803.1878894,"Many reading assistants and navigation systems have been designed specifically for people who are blind or visually impaired, but text locating in scene image with complex background has not yet been successfully addressed. In this paper, we propose a novel method to locate scene text by combining color uniformity and high edge density together. We perform structural analysis of text strings which contain several characters in alignment. First, we calculate the edge image and then repaint the corresponding edge pixels in the original image by using a non-dominant color. Second, color reduction is performed by color histogram and K-means algorithms to segment the repainted image into color layers. Third, we perform edge detection and label the boundaries of both text characters and unexpected noises in each color layer. Each centroid is assigned a degree which is the number of overlap in the same position among color layers. Fourth, text line fitting among centroids with high degree is performed to cascade the character boundaries which belong to the same text string. The detected text string is presented by a rectangle region covering all character boundaries in its text line. Experimental results demonstrate that our algorithm is able to locate text strings with arbitrary orientations. The performance of our algorithm is comparable with the state-of-art algorithms.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'boundary centroid, color-based segmentation, navigation, reading assistant, text line fitting, text locating, visual impairment', 'numpages': '2', 'pages': '325–326', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many reading assistants and navigation systems have been designed specifically for people who are blind or visually impaired, but text locating in scene image with complex background has not yet been successfully addressed. In this paper, we propose a novel method to locate scene text by combining color uniformity and high edge density together. We perform structural analysis of text strings which contain several characters in alignment. First, we calculate the edge image and then repaint the corresponding edge pixels in the original image by using a non-dominant color. Second, color reduction is performed by color histogram and K-means algorithms to segment the repainted image into color layers. Third, we perform edge detection and label the boundaries of both text characters and unexpected noises in each color layer. Each centroid is assigned a degree which is the number of overlap in the same position among color layers. Fourth, text line fitting among centroids with high degree is performed to cascade the character boundaries which belong to the same text string. The detected text string is presented by a rectangle region covering all character boundaries in its text line. Experimental results demonstrate that our algorithm is able to locate text strings with arbitrary orientations. The performance of our algorithm is comparable with the state-of-art algorithms.', 'doi': '10.1145/1878803.1878894', 'url': 'https://doi.org/10.1145/1878803.1878894', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Text locating in scene images for reading and navigation aids for visually impaired persons', 'author': 'Yi, Chucai', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878894'}"
Utterance-based systems: organization and design of AAC interfaces,10.1145/1878803.1878895,"Augmented and Alternative Communication (AAC) interfaces present many unique design challenges due to the wide variation of physical ability among AAC users. The development of technological aids for AAC users to bridge the communication gap, increase both rate and comprehensiveness of communication [1]. Here we focus on the design of an utterance-based system developed for literate, high-functioning adults interacting in public situations. This research involves the design and development of a coherent and intuitive AAC interface for an utterance-based system built upon theoretical evidence and observation of commercial-grade AAC interface software.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'aac, communication, interface design', 'numpages': '2', 'pages': '327–328', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Augmented and Alternative Communication (AAC) interfaces present many unique design challenges due to the wide variation of physical ability among AAC users. The development of technological aids for AAC users to bridge the communication gap, increase both rate and comprehensiveness of communication [1]. Here we focus on the design of an utterance-based system developed for literate, high-functioning adults interacting in public situations. This research involves the design and development of a coherent and intuitive AAC interface for an utterance-based system built upon theoretical evidence and observation of commercial-grade AAC interface software.', 'doi': '10.1145/1878803.1878895', 'url': 'https://doi.org/10.1145/1878803.1878895', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'Utterance-based systems: organization and design of AAC interfaces', 'author': 'Walsh, Timothy J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878895'}"
ZigAlert: a zigbee alert for toileting training children with developmental delay in a public school setting,10.1145/1878803.1878896,"Zigbee is used as assistive technology for children with developmental delays to achieve the goal of going to the toilet independently. In special education under the guidance of a teacher, we use a Zigbee sensor network to assist a 9-year-old child with toilet training.","{'series': ""ASSETS '10"", 'location': 'Orlando, Florida, USA', 'keywords': 'severe intellectual disabilities, toilet training, wetness alarm, wireless sensor network, zigbee', 'numpages': '2', 'pages': '329–330', 'booktitle': 'Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Zigbee is used as assistive technology for children with developmental delays to achieve the goal of going to the toilet independently. In special education under the guidance of a teacher, we use a Zigbee sensor network to assist a 9-year-old child with toilet training.', 'doi': '10.1145/1878803.1878896', 'url': 'https://doi.org/10.1145/1878803.1878896', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605588810', 'year': '2010', 'title': 'ZigAlert: a zigbee alert for toileting training children with developmental delay in a public school setting', 'author': 'Chen, Yi-Chien', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1878803.1878896'}"