Title,DOI,Abstract,BibTeX
Session details: Motor input assistance,10.1145/3245625,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245625', 'url': 'https://doi.org/10.1145/3245625', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Motor input assistance', 'author': 'Yesilada, Y.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245625'}"
From letters to words: efficient stroke-based word completion for trackball text entry,10.1145/1168987.1168990,"We present a major extension to our previous work on Trackball EdgeWrite--a unistroke text entry method for trackballs--by taking it from a character-level technique to a word-level one. Our design is called stroke-based word completion, and it enables efficient word selection as part of the stroke-making process. Unlike most word completion designs, which require users to select words from a list, our technique allows users to select words by performing a fluid crossing gesture. Our theoretical model shows this word-level design to be 45.0\% faster than our prior model for character-only strokes. A study with a subject with spinal cord injury comparing Trackball EdgeWrite to the onscreen keyboard WiViK, both using word prediction and completion, shows that Trackball EdgeWrite is competitive with WiViK in speed (12.09 vs. 11.82 WPM) and accuracy (3.95\% vs. 2.21\% total errors), but less visually tedious and ultimately preferred. The results also show that word-level Trackball EdgeWrite is 46.5\% faster and 36.7\% more accurate than our subject's prior peak performance with character-level Trackball EdgeWrite, and 75.2\% faster and 40.2\% more accurate than his prior peak performance with his preferred on-screen keyboard. An additional evaluation of the same subject over a two-month field deployment shows a 43.9\% reduction in unistrokes due to strokebased word completion in Trackball EdgeWrite.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': ""EdgeWrite, Fitts' law, Hick-Hyman law, WiViK, Zipf's law, gestures, goal crossing, steering law, text input, trackballs, unistrokes, word prediction and completion, word-level text entry"", 'numpages': '8', 'pages': '2–9', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We present a major extension to our previous work on Trackball EdgeWrite--a unistroke text entry method for trackballs--by taking it from a character-level technique to a word-level one. Our design is called stroke-based word completion, and it enables efficient word selection as part of the stroke-making process. Unlike most word completion designs, which require users to select words from a list, our technique allows users to select words by performing a fluid crossing gesture. Our theoretical model shows this word-level design to be 45.0\\% faster than our prior model for character-only strokes. A study with a subject with spinal cord injury comparing Trackball EdgeWrite to the onscreen keyboard WiViK, both using word prediction and completion, shows that Trackball EdgeWrite is competitive with WiViK in speed (12.09 vs. 11.82 WPM) and accuracy (3.95\\% vs. 2.21\\% total errors), but less visually tedious and ultimately preferred. The results also show that word-level Trackball EdgeWrite is 46.5\\% faster and 36.7\\% more accurate than our subject's prior peak performance with character-level Trackball EdgeWrite, and 75.2\\% faster and 40.2\\% more accurate than his prior peak performance with his preferred on-screen keyboard. An additional evaluation of the same subject over a two-month field deployment shows a 43.9\\% reduction in unistrokes due to strokebased word completion in Trackball EdgeWrite."", 'doi': '10.1145/1168987.1168990', 'url': 'https://doi.org/10.1145/1168987.1168990', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'From letters to words: efficient stroke-based word completion for trackball text entry', 'author': 'Wobbrock, Jacob O. and Myers, Brad A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168990'}"
Alternative text entry using different input methods,10.1145/1168987.1168991,"This paper deals with PC-based alternative (i.e., keyboardfree) text entry and the issues related to emulating keystrokes with only a limited number of input signals. The previously introduced HaMCoS tool tries to enable someone who cannot use the hands to enter text almost as fast as someone exclusively using a manual mouse. To achieve this rather ambitious goal, HaMCoS provides two different (but combinable) solutions. On the one hand, word completion is offered as a shortcut technique. On the other hand, in addition to a mere on-screen keyboard, a completely new application has been implemented where selecting characters is somehow similar to entering Morse code (but with four 'bits' instead of dots and dashes only). In order to show the effect of these measures, the times needed to copy a moderately long text in various circumstances are reported.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'BCI, bio-signals, hands-free operation, human-computer interaction, keyboard-free text entry, morse code, muscle control, single-switch, word completion', 'numpages': '8', 'pages': '10–17', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper deals with PC-based alternative (i.e., keyboardfree) text entry and the issues related to emulating keystrokes with only a limited number of input signals. The previously introduced HaMCoS tool tries to enable someone who cannot use the hands to enter text almost as fast as someone exclusively using a manual mouse. To achieve this rather ambitious goal, HaMCoS provides two different (but combinable) solutions. On the one hand, word completion is offered as a shortcut technique. On the other hand, in addition to a mere on-screen keyboard, a completely new application has been implemented where selecting characters is somehow similar to entering Morse code (but with four 'bits' instead of dots and dashes only). In order to show the effect of these measures, the times needed to copy a moderately long text in various circumstances are reported."", 'doi': '10.1145/1168987.1168991', 'url': 'https://doi.org/10.1145/1168987.1168991', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Alternative text entry using different input methods', 'author': 'Felzer, Torsten and Nordmann, Rainer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168991'}"
Indirect text entry using one or two keys,10.1145/1168987.1168992,"This paper introduces a new descriptive model for indirect text composition facilities that is based on the notion of a containment hierarchy. This paper also demonstrates a novel, computer-aided technique for the design of indirect text selection interfaces -- one in which Huffman coding is used for the derivation of the containment hierarchy. This approach guarantees the derivation of optimal containment hierarchies, insofar as mean encoding length. This paper describes an empirical study of two two-key indirect text entry variants and compares them to one another and to the predictive model. The intended application of these techniques is the design of improved indirect text entry facilities for the users of AAC systems.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'augmentative and alternative communication (AAC), indirect text entry, information theory, interface evaluation, interventions for communication disorders, scanning, speech generating devices (SGD), voice output communication aids (VOCA)', 'numpages': '8', 'pages': '18–25', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper introduces a new descriptive model for indirect text composition facilities that is based on the notion of a containment hierarchy. This paper also demonstrates a novel, computer-aided technique for the design of indirect text selection interfaces -- one in which Huffman coding is used for the derivation of the containment hierarchy. This approach guarantees the derivation of optimal containment hierarchies, insofar as mean encoding length. This paper describes an empirical study of two two-key indirect text entry variants and compares them to one another and to the predictive model. The intended application of these techniques is the design of improved indirect text entry facilities for the users of AAC systems.', 'doi': '10.1145/1168987.1168992', 'url': 'https://doi.org/10.1145/1168987.1168992', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Indirect text entry using one or two keys', 'author': 'Baljko, Melanie and Tam, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168992'}"
Developing steady clicks: a method of cursor assistance for people with motor impairments,10.1145/1168987.1168993,"Slipping while clicking and accidental clicks are a source of errors for mouse users with motor impairments. The Steady Clicks assistance feature suppresses these errors by freezing the cursor during mouse clicks, preventing overlapping button presses and suppressing clicks made while the mouse is moving at a high velocity. Evaluation with eleven target users found that Steady Clicks enabled participants to select targets using significantly fewer attempts. Overall task performance times were significantly improved for the five participants with the highest slip rates. Blocking of overlapping and high velocity clicks also shows promise as an error filter. Nine participants preferred Steady Clicks to the unassisted condition. If used in conjunction with existing techniques for cursor positioning, all of the major sources of clicking errors observed in empirical studies would be addressed, enabling faster and more effective mouse use for those who currently struggle with the standard mouse.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'clicking, clicking errors, disability, mouse, pointing and selection tasks, target acquisition, user input', 'numpages': '8', 'pages': '26–33', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Slipping while clicking and accidental clicks are a source of errors for mouse users with motor impairments. The Steady Clicks assistance feature suppresses these errors by freezing the cursor during mouse clicks, preventing overlapping button presses and suppressing clicks made while the mouse is moving at a high velocity. Evaluation with eleven target users found that Steady Clicks enabled participants to select targets using significantly fewer attempts. Overall task performance times were significantly improved for the five participants with the highest slip rates. Blocking of overlapping and high velocity clicks also shows promise as an error filter. Nine participants preferred Steady Clicks to the unassisted condition. If used in conjunction with existing techniques for cursor positioning, all of the major sources of clicking errors observed in empirical studies would be addressed, enabling faster and more effective mouse use for those who currently struggle with the standard mouse.', 'doi': '10.1145/1168987.1168993', 'url': 'https://doi.org/10.1145/1168987.1168993', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Developing steady clicks: a method of cursor assistance for people with motor impairments', 'author': 'Trewin, Shari and Keates, Simeon and Moffatt, Karyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168993'}"
Session details: Vision,10.1145/3245626,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245626', 'url': 'https://doi.org/10.1145/3245626', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Vision', 'author': 'Pontelli, E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245626'}"
A multi-domain approach for enhancing text display for users with visual aberrations,10.1145/1168987.1168995,"In this paper, we describe a multi-domain approach for enhancing text displayed on a computer screen for users with visual aberrations. This research is based on a priori knowledge of the user's visual aberration, as measured by a wavefront analyzer. With this information it is possible to generate text that, when displayed to this user, will counteract his/her visual aberration. The method described in this paper advances the development of techniques for providing such compensation by integrating spatial information in the image as a means to eliminate some of the shortcomings inherent in using display devices such as monitors or LCD panels.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'deconvolution, pre-compensation visual aberration, spatial processing, wavefront aberration function, wavefront analysis', 'numpages': '6', 'pages': '34–39', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this paper, we describe a multi-domain approach for enhancing text displayed on a computer screen for users with visual aberrations. This research is based on a priori knowledge of the user's visual aberration, as measured by a wavefront analyzer. With this information it is possible to generate text that, when displayed to this user, will counteract his/her visual aberration. The method described in this paper advances the development of techniques for providing such compensation by integrating spatial information in the image as a means to eliminate some of the shortcomings inherent in using display devices such as monitors or LCD panels."", 'doi': '10.1145/1168987.1168995', 'url': 'https://doi.org/10.1145/1168987.1168995', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A multi-domain approach for enhancing text display for users with visual aberrations', 'author': 'Alonso, Miguel and Barreto, Armando and Jacko, Julie A. and Adjouadi, Malek', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168995'}"
Accommodating color blind computer users,10.1145/1168987.1168996,"Important visual information often disappears when color documents are viewed by color blind people. The algorithm introduced here maps colors using the World Wide Web Consortium evaluation criteria so that detail is preserved for color blind viewers, especially dichromats. The algorithm has four parts: 1) select a representative set of colors from the source document; 2) compute target color distances using color and brightness differences; 3) solve an optimization step that preserves the target distances for a particular class of color blind viewer; and 4) interpolate the mapped colors across the remaining colors in the document. We demonstrate the efficacy of our method using simulations and critique our method in the context of earlier work.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, assistive technology, color vision deficiency', 'numpages': '8', 'pages': '40–47', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Important visual information often disappears when color documents are viewed by color blind people. The algorithm introduced here maps colors using the World Wide Web Consortium evaluation criteria so that detail is preserved for color blind viewers, especially dichromats. The algorithm has four parts: 1) select a representative set of colors from the source document; 2) compute target color distances using color and brightness differences; 3) solve an optimization step that preserves the target distances for a particular class of color blind viewer; and 4) interpolate the mapped colors across the remaining colors in the document. We demonstrate the efficacy of our method using simulations and critique our method in the context of earlier work.', 'doi': '10.1145/1168987.1168996', 'url': 'https://doi.org/10.1145/1168987.1168996', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Accommodating color blind computer users', 'author': 'Jefferson, Luke and Harvey, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168996'}"
Lambda: a multimodal approach to making mathematics accessible to blind students,10.1145/1168987.1168997,"The study of mathematics is all but precluded to most blind students because of the reliance on visual notations. The Lambda System is an attempt to overcome this barrier to access through the development of a linear mathematical notation which can be manipulated by a multimodal mathematical editor. This provides access through braille, synthetic speech and a visual display. Initial results from a longitudinal study with prospective users are encouraging.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'MathML, blind students, braille, mathematics education, synthetic speech', 'numpages': '7', 'pages': '48–54', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The study of mathematics is all but precluded to most blind students because of the reliance on visual notations. The Lambda System is an attempt to overcome this barrier to access through the development of a linear mathematical notation which can be manipulated by a multimodal mathematical editor. This provides access through braille, synthetic speech and a visual display. Initial results from a longitudinal study with prospective users are encouraging.', 'doi': '10.1145/1168987.1168997', 'url': 'https://doi.org/10.1145/1168987.1168997', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Lambda: a multimodal approach to making mathematics accessible to blind students', 'author': 'Edwards, Alistair D N and McCartney, Heather and Fogarolo, Flavio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168997'}"
Measuring website usability for visually impaired people-a modified GOMS analysis,10.1145/1168987.1168998,"Web designers regularly wonder which version of a design would suit best their target groups' needs. This becomes even more complicated if the design is to comply with accessibility rules. This paper describes an interaction model of blind users' interaction strategies. This model is based on GOMS (Goals, Operators, Methods, Selection rules) and can be used to measure aspects of website usability for blind users. The model evolved from findings of user observations and field studies. It can be applied to specific layouts in order to find the 'best' alternative. 'Classic' GOMS models lack functions which are necessary for the presented GOMS model. Thus, new structures to extend the classic GOMS notation are proposed. Finally, an example GOMS analysis is run on a modified version of the ASSETS '06 web page.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'GOMS, accessibility, blind users, braille, evaluation, screen reader, speech, usability, visually impaired users', 'numpages': '8', 'pages': '55–62', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Web designers regularly wonder which version of a design would suit best their target groups' needs. This becomes even more complicated if the design is to comply with accessibility rules. This paper describes an interaction model of blind users' interaction strategies. This model is based on GOMS (Goals, Operators, Methods, Selection rules) and can be used to measure aspects of website usability for blind users. The model evolved from findings of user observations and field studies. It can be applied to specific layouts in order to find the 'best' alternative. 'Classic' GOMS models lack functions which are necessary for the presented GOMS model. Thus, new structures to extend the classic GOMS notation are proposed. Finally, an example GOMS analysis is run on a modified version of the ASSETS '06 web page."", 'doi': '10.1145/1168987.1168998', 'url': 'https://doi.org/10.1145/1168987.1168998', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Measuring website usability for visually impaired people-a modified GOMS analysis', 'author': 'Tonn-Eichst\\""{a}dt, Henrik', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1168998'}"
Session details: Design challenges,10.1145/3245627,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245627', 'url': 'https://doi.org/10.1145/3245627', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Design challenges', 'author': 'Fell, H.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245627'}"
Dynamically adapting GUIs to diverse input devices,10.1145/1168987.1169000,"Many of today's desktop applications are designed for use with a pointing device and keyboard. Someone with a disability, or in a unique environment, may not be able to use one or both of these devices. We have developed an approach for automatically modifying desktop applications to accommodate a variety of input alternatives as well as a demonstration implementation, the Input Adapter Tool (IAT). Our work is differentiated from past work by our focus on input adaptation (such as adapting a paint program to work without a pointing device) rather than output adaptation (such as adapting web pages to work on a cellphone). We present an analysis showing how different common interactive elements and navigation techniques can be adapted to specific input modalities. We also describe IAT, which supports a subset of these adaptations, and illustrate how it adapts different inputs to two applications, a paint program and a form entry program.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, interaction techniques, toolkits', 'numpages': '8', 'pages': '63–70', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Many of today's desktop applications are designed for use with a pointing device and keyboard. Someone with a disability, or in a unique environment, may not be able to use one or both of these devices. We have developed an approach for automatically modifying desktop applications to accommodate a variety of input alternatives as well as a demonstration implementation, the Input Adapter Tool (IAT). Our work is differentiated from past work by our focus on input adaptation (such as adapting a paint program to work without a pointing device) rather than output adaptation (such as adapting web pages to work on a cellphone). We present an analysis showing how different common interactive elements and navigation techniques can be adapted to specific input modalities. We also describe IAT, which supports a subset of these adaptations, and illustrate how it adapts different inputs to two applications, a paint program and a form entry program."", 'doi': '10.1145/1168987.1169000', 'url': 'https://doi.org/10.1145/1168987.1169000', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Dynamically adapting GUIs to diverse input devices', 'author': 'Carter, Scott and Hurst, Amy and Mankoff, Jennifer and Li, Jack', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169000'}"
MobileASL: intelligibility of sign language video as constrained by mobile phone technology,10.1145/1168987.1169001,"For Deaf people, access to the mobile telephone network in the United States is currently limited to text messaging, forcing communication in English as opposed to American Sign Language (ASL), the preferred language. Because ASL is a visual language, mobile video phones have the potential to give Deaf people access to real-time mobile communication in their preferred language. However, even today's best video compression techniques can not yield intelligible ASL at limited cell phone network bandwidths. Motivated by this constraint, we conducted one focus group and one user study with members of the Deaf Community to determine the intelligibility effects of video compression techniques that exploit the visual nature of sign language. Inspired by eyetracking results that show high resolution foveal vision is maintained around the face, we studied region-of-interest encodings (where the face is encoded at higher quality) as well as reduced frame rates (where fewer, better quality, frames are displayed every second). At all bit rates studied here, participants preferred moderate quality increases in the face region, sacrificing quality in other regions. They also preferred slightly lower frame rates because they yield better quality frames for a fixed bit rate. These results show promise for realtime access to the current cell phone network through signlanguage-specific encoding techniques.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'american sign language (ASL), deaf community, mobile telephone use, video compression', 'numpages': '8', 'pages': '71–78', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""For Deaf people, access to the mobile telephone network in the United States is currently limited to text messaging, forcing communication in English as opposed to American Sign Language (ASL), the preferred language. Because ASL is a visual language, mobile video phones have the potential to give Deaf people access to real-time mobile communication in their preferred language. However, even today's best video compression techniques can not yield intelligible ASL at limited cell phone network bandwidths. Motivated by this constraint, we conducted one focus group and one user study with members of the Deaf Community to determine the intelligibility effects of video compression techniques that exploit the visual nature of sign language. Inspired by eyetracking results that show high resolution foveal vision is maintained around the face, we studied region-of-interest encodings (where the face is encoded at higher quality) as well as reduced frame rates (where fewer, better quality, frames are displayed every second). At all bit rates studied here, participants preferred moderate quality increases in the face region, sacrificing quality in other regions. They also preferred slightly lower frame rates because they yield better quality frames for a fixed bit rate. These results show promise for realtime access to the current cell phone network through signlanguage-specific encoding techniques."", 'doi': '10.1145/1168987.1169001', 'url': 'https://doi.org/10.1145/1168987.1169001', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'MobileASL: intelligibility of sign language video as constrained by mobile phone technology', 'author': 'Cavender, Anna and Ladner, Richard E. and Riskin, Eve A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169001'}"
American sign language recognition in game development for deaf children,10.1145/1168987.1169002,"CopyCat is an American Sign Language (ASL) game, which uses gesture recognition technology to help young deaf children practice ASL skills. We describe a brief history of the game, an overview of recent user studies, and the results of recent work on the problem of continuous, user-independent sign language recognition in classroom settings. Our database of signing samples was collected from user studies of deaf children playing aWizard of Oz version of the game at the Atlanta Area School for the Deaf (AASD). Our data set is characterized by disfluencies inherent in continuous signing, varied user characteristics including clothing and skin tones, and illumination changes in the classroom. The dataset consisted of 541 phrase samples and 1,959 individual sign samples of five children signing game phrases from a 22 word vocabulary. Our recognition approach uses color histogram adaptation for robust hand segmentation and tracking. The children wear small colored gloves with wireless accelerometers mounted on the back of their wrists. The hand shape information is combined with accelerometer data and used to train hidden Markov models for recognition. We evaluated our approach by using leave-one-out validation; this technique iterates through each child, training on data from four children and testing on the remaining child's data. We achieved average word accuracies per child ranging from 91.75\% to 73.73\% for the user-independent models.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'ASL, game, recognition, sign language', 'numpages': '8', 'pages': '79–86', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""CopyCat is an American Sign Language (ASL) game, which uses gesture recognition technology to help young deaf children practice ASL skills. We describe a brief history of the game, an overview of recent user studies, and the results of recent work on the problem of continuous, user-independent sign language recognition in classroom settings. Our database of signing samples was collected from user studies of deaf children playing aWizard of Oz version of the game at the Atlanta Area School for the Deaf (AASD). Our data set is characterized by disfluencies inherent in continuous signing, varied user characteristics including clothing and skin tones, and illumination changes in the classroom. The dataset consisted of 541 phrase samples and 1,959 individual sign samples of five children signing game phrases from a 22 word vocabulary. Our recognition approach uses color histogram adaptation for robust hand segmentation and tracking. The children wear small colored gloves with wireless accelerometers mounted on the back of their wrists. The hand shape information is combined with accelerometer data and used to train hidden Markov models for recognition. We evaluated our approach by using leave-one-out validation; this technique iterates through each child, training on data from four children and testing on the remaining child's data. We achieved average word accuracies per child ranging from 91.75\\% to 73.73\\% for the user-independent models."", 'doi': '10.1145/1168987.1169002', 'url': 'https://doi.org/10.1145/1168987.1169002', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'American sign language recognition in game development for deaf children', 'author': 'Brashear, Helene and Henderson, Valerie and Park, Kwang-Hyun and Hamilton, Harley and Lee, Seungyon and Starner, Thad', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169002'}"
"Are ""universal design resources"" designed for designers?",10.1145/1168987.1169003,"Universal design (UD) is an approach to design that incorporates things which can be used by all people to the greatest extent possible. UD in information and communication technologies (ICTs) is of growing importance because standard ICTs have great potential to be usable by all people, including people with disabilities (PWDs). Currently, PWDs who need ICTs often have less access because the products have not been universally designed. We hypothesize that one of the reasons for the slow adoption of UD is that universal design resources (UDRs) are not adequate for facilitating designers' tasks. We investigated the usability of UDRs from designers' perspectives. A heuristic evaluation on eight selected UDRs was conducted, and the opinions of contributors to the content of these resources were collected through a web-based survey study. The results of the heuristic evaluation show that most of the investigated UDRs do not provide a clear central idea and fail to support the cognitive processes of designers. The results of the survey also confirmed that the content of these resources do not systematically address the needs of designers as end-users during the development process.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology, design resources, heuristic evaluation, universal design', 'numpages': '8', 'pages': '87–94', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Universal design (UD) is an approach to design that incorporates things which can be used by all people to the greatest extent possible. UD in information and communication technologies (ICTs) is of growing importance because standard ICTs have great potential to be usable by all people, including people with disabilities (PWDs). Currently, PWDs who need ICTs often have less access because the products have not been universally designed. We hypothesize that one of the reasons for the slow adoption of UD is that universal design resources (UDRs) are not adequate for facilitating designers' tasks. We investigated the usability of UDRs from designers' perspectives. A heuristic evaluation on eight selected UDRs was conducted, and the opinions of contributors to the content of these resources were collected through a web-based survey study. The results of the heuristic evaluation show that most of the investigated UDRs do not provide a clear central idea and fail to support the cognitive processes of designers. The results of the survey also confirmed that the content of these resources do not systematically address the needs of designers as end-users during the development process."", 'doi': '10.1145/1168987.1169003', 'url': 'https://doi.org/10.1145/1168987.1169003', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Are ""universal design resources"" designed for designers?', 'author': 'Choi, Young Sang and Yi, Ji Soo and Law, Chris M. and Jacko, Julie A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169003'}"
Session details: Navigational assistance,10.1145/3245628,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245628', 'url': 'https://doi.org/10.1145/3245628', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Navigational assistance', 'author': 'Soiffer, N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245628'}"
Indoor wayfinding: developing a functional interface for individuals with cognitive impairments,10.1145/1168987.1169005,"Assistive technology for wayfinding will significantly improve the quality of life for many individuals with cognitive impairments. The user interface of such a system is as crucial as the underlying implementation and localization technology. We built a system using the Wizard-of-Oz technique that let us experiment with many guidance strategies and interface modalities. Through user studies, we evaluated various configurations of the user interface for accuracy of route completion, time to completion, and user preferences. We used a counter-balanced design that included different modalities (images, audio, and text) and different routes. We found that although users were able to use all types of modalities to find their way indoors, they varied significantly in their preferred modalities. We also found that timing of directions requires careful attention, as does providing users with confirmation messages at appropriate times. Our findings suggest that the ability to adapt indoor wayfinding devices for specific users' preferences and needs will be particularly important.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'cognitive disability, ubiquitous computing, user interface, wizard-of-oz', 'numpages': '8', 'pages': '95–102', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Assistive technology for wayfinding will significantly improve the quality of life for many individuals with cognitive impairments. The user interface of such a system is as crucial as the underlying implementation and localization technology. We built a system using the Wizard-of-Oz technique that let us experiment with many guidance strategies and interface modalities. Through user studies, we evaluated various configurations of the user interface for accuracy of route completion, time to completion, and user preferences. We used a counter-balanced design that included different modalities (images, audio, and text) and different routes. We found that although users were able to use all types of modalities to find their way indoors, they varied significantly in their preferred modalities. We also found that timing of directions requires careful attention, as does providing users with confirmation messages at appropriate times. Our findings suggest that the ability to adapt indoor wayfinding devices for specific users' preferences and needs will be particularly important."", 'doi': '10.1145/1168987.1169005', 'url': 'https://doi.org/10.1145/1168987.1169005', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Indoor wayfinding: developing a functional interface for individuals with cognitive impairments', 'author': 'Liu, Alan L. and Hile, Harlan and Kautz, Henry and Borriello, Gaetano and Brown, Pat A. and Harniss, Mark and Johnson, Kurt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169005'}"
Where's my stuff? design and evaluation of a mobile system for locating lost items for the visually impaired,10.1145/1168987.1169006,"Finding lost items is a common problem for the visually impaired and is something that computing technology can help alleviate. In this paper, we present the design and evaluation of a mobile solution, called FETCH, for allowing the visually impaired to track and locate objects they lose frequently but for which they do not have a specific strategy for tracking. FETCH uses devices the user already owns, such as their cell phone or laptop, to locate objects around their house. Results from a focus group with visually impaired users informed the design of the system. We then studied the usability of a laptop solution in a laboratory study and studied the usability and usefulness of the system through a one-month deployment and diary study. These studies demonstrate that FETCH is usable and useful, but there is still room for improvement.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology, item location, mobile technology, ubiquitous computing, visually impaired', 'numpages': '8', 'pages': '103–110', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Finding lost items is a common problem for the visually impaired and is something that computing technology can help alleviate. In this paper, we present the design and evaluation of a mobile solution, called FETCH, for allowing the visually impaired to track and locate objects they lose frequently but for which they do not have a specific strategy for tracking. FETCH uses devices the user already owns, such as their cell phone or laptop, to locate objects around their house. Results from a focus group with visually impaired users informed the design of the system. We then studied the usability of a laptop solution in a laboratory study and studied the usability and usefulness of the system through a one-month deployment and diary study. These studies demonstrate that FETCH is usable and useful, but there is still room for improvement.', 'doi': '10.1145/1168987.1169006', 'url': 'https://doi.org/10.1145/1168987.1169006', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': ""Where's my stuff? design and evaluation of a mobile system for locating lost items for the visually impaired"", 'author': 'Kientz, Julie A. and Patel, Shwetak N. and Tyebkhan, Arwa Z. and Gane, Brian and Wiley, Jennifer and Abowd, Gregory D.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169006'}"
Interactive tracking of movable objects for the blind on the basis of environment models and perception-oriented object recognition methods,10.1145/1168987.1169007,"In previous work we have presented a prototype of an assistant system for the blind that can be used for self-localization and interactive object identification of static objects stored within 3D environment models. In this paper we present a new method for interactive tracking of various types of movable objects. The state of fixed movable objects, like doors, can be recognized by comparing the distance between sensor data and a 3D model. For the identification and model-based tracking of free movable objects, like chairs, we have developed an algorithm that is similar to human perception, based on shape and color comparisons to trained objects. Further, using a common face detection algorithm, our assistant system informs the user of the presence of people, and enables the localization of a real person based on interactive tracking of virtual models of humans.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'blind users, impaired vision, indoor navigation, mobile computing', 'numpages': '8', 'pages': '111–118', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In previous work we have presented a prototype of an assistant system for the blind that can be used for self-localization and interactive object identification of static objects stored within 3D environment models. In this paper we present a new method for interactive tracking of various types of movable objects. The state of fixed movable objects, like doors, can be recognized by comparing the distance between sensor data and a 3D model. For the identification and model-based tracking of free movable objects, like chairs, we have developed an algorithm that is similar to human perception, based on shape and color comparisons to trained objects. Further, using a common face detection algorithm, our assistant system informs the user of the presence of people, and enables the localization of a real person based on interactive tracking of virtual models of humans.', 'doi': '10.1145/1168987.1169007', 'url': 'https://doi.org/10.1145/1168987.1169007', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Interactive tracking of movable objects for the blind on the basis of environment models and perception-oriented object recognition methods', 'author': 'Hub, Andreas and Hartter, Tim and Ertl, Thomas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169007'}"
Using an audio interface to assist users Who are visually impaired with steering tasks,10.1145/1168987.1169008,"In this paper we describe the latest results in our on-going study of techniques to present relational graphs to users with visual impairments. Our work tests the effectiveness of the PLUMB software package, which uses audio feedback and the pen-based Tablet PC interface to relay graphs and diagrams to users with visual impairments. Our study included human trials with ten participants without usable vision, in which we evaluated the users' ability to perform steering tasks under varying conditions.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, audio, graph, sonification', 'numpages': '6', 'pages': '119–124', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this paper we describe the latest results in our on-going study of techniques to present relational graphs to users with visual impairments. Our work tests the effectiveness of the PLUMB software package, which uses audio feedback and the pen-based Tablet PC interface to relay graphs and diagrams to users with visual impairments. Our study included human trials with ten participants without usable vision, in which we evaluated the users' ability to perform steering tasks under varying conditions."", 'doi': '10.1145/1168987.1169008', 'url': 'https://doi.org/10.1145/1168987.1169008', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Using an audio interface to assist users Who are visually impaired with steering tasks', 'author': 'Cohen, Robert F. and Haven, Valerie and Lanzoni, Jessica A. and Meacham, Arthur and Skaff, Joelle and Wissell, Michael', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169008'}"
Session details: Cognition and emotion,10.1145/3245629,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245629', 'url': 'https://doi.org/10.1145/3245629', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Cognition and emotion', 'author': 'Edwards, A. D. N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245629'}"
Networked reminiscence therapy for individuals with dementia by using photo and video sharing,10.1145/1168987.1169010,"Reminiscence therapy, which is effective for increasing the selfesteem of and for reducing behavioral disturbances in individuals with dementia, is usually conducted in a group led by experienced staff. However, due to the shortage of care attendants, only a limited number of patients at home can receive the benefits of this therapy. To provide this therapy for patients anytime or anywhere, we have developed a networked reminiscence therapy system that combines IP videophones with a photo- and video-sharing mechanism based on Web technology. First, we prepared the experimental setup in a hospital and examined whether dementia patients could communicate with therapists by videophone. Then we conducted a field trial of networked reminiscence therapy with a more realistic situation where remote volunteers communicated with dementia sufferers in the care home by IP videophones connected by broadband network. In this paper, we describe our developed system. Then, we present experimental results showing that dementia sufferers could communicate with therapists by videophone and that networked reminiscence sessions were generally as successful for individuals with dementia as face-to-face reminiscence sessions.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'IP videophone, dementia, internet, photo sharing, reminiscence therapy, web browser', 'numpages': '8', 'pages': '125–132', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Reminiscence therapy, which is effective for increasing the selfesteem of and for reducing behavioral disturbances in individuals with dementia, is usually conducted in a group led by experienced staff. However, due to the shortage of care attendants, only a limited number of patients at home can receive the benefits of this therapy. To provide this therapy for patients anytime or anywhere, we have developed a networked reminiscence therapy system that combines IP videophones with a photo- and video-sharing mechanism based on Web technology. First, we prepared the experimental setup in a hospital and examined whether dementia patients could communicate with therapists by videophone. Then we conducted a field trial of networked reminiscence therapy with a more realistic situation where remote volunteers communicated with dementia sufferers in the care home by IP videophones connected by broadband network. In this paper, we describe our developed system. Then, we present experimental results showing that dementia sufferers could communicate with therapists by videophone and that networked reminiscence sessions were generally as successful for individuals with dementia as face-to-face reminiscence sessions.', 'doi': '10.1145/1168987.1169010', 'url': 'https://doi.org/10.1145/1168987.1169010', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Networked reminiscence therapy for individuals with dementia by using photo and video sharing', 'author': 'Kuwahara, Noriaki and Abe, Shinji and Yasuda, Kiyoshi and Kuwabara, Kazuhiro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169010'}"
Attention analysis in interactive software for children with autism,10.1145/1168987.1169011,"This work is a part of an ongoing project that focuses on potential applications of an interactive system that helps children with autism. Autism is classified as a neurodevelopmental disorder that manifests itself in markedly abnormal social interaction, communication ability, patterns of interests, and patterns of behavior [1]. Children with autism are socially impaired and usually do not attend to the people around them. An interesting point which characterized children with autism is that they are unable to choose which event is more or less important. As a consequence they are often saturated because of too many stimuli and thus they adopt an extremely repetitive, unusual, self-injurious, or aggressive behaviour. Recently, a new trend of using human computer interface (HCI) technology and computer science in the treatment of autism has emerged [2, 3]. The platform we developed helps children with autism to focus their attention on a specific task. In this article, we only present the attention analysis system which is a part of a more general system that used a multi-agent architecture [4]. Each task proposed on our system fit to each child, is reproducible and evolutive following a specific scenario defined by the expert. This scenario takes into account age, ability, and degree of autism of each child. In order to focus a child's attention onto the relevant object, our system displays or plays specific stimulus; once again the specific stimulus is defined for each child. Symbol or sound represents an emotional and satisfaction value for the child. The major problem is to define the correct moment when the system has to (dis)play this signal. We tackle this problem by defining a robust measure of attention. This measure is defined by analyzing the gaze direction and the face orientation, and incorporating the child's specific profile. Following expert directives, our system helps children to categorize elementary perception (strong, smooth, quick, slow, big, small...). Our objective is that children re-use these classifications in others situations.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'attention analysis, behavior study, children with autism', 'numpages': '8', 'pages': '133–140', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This work is a part of an ongoing project that focuses on potential applications of an interactive system that helps children with autism. Autism is classified as a neurodevelopmental disorder that manifests itself in markedly abnormal social interaction, communication ability, patterns of interests, and patterns of behavior [1]. Children with autism are socially impaired and usually do not attend to the people around them. An interesting point which characterized children with autism is that they are unable to choose which event is more or less important. As a consequence they are often saturated because of too many stimuli and thus they adopt an extremely repetitive, unusual, self-injurious, or aggressive behaviour. Recently, a new trend of using human computer interface (HCI) technology and computer science in the treatment of autism has emerged [2, 3]. The platform we developed helps children with autism to focus their attention on a specific task. In this article, we only present the attention analysis system which is a part of a more general system that used a multi-agent architecture [4]. Each task proposed on our system fit to each child, is reproducible and evolutive following a specific scenario defined by the expert. This scenario takes into account age, ability, and degree of autism of each child. In order to focus a child's attention onto the relevant object, our system displays or plays specific stimulus; once again the specific stimulus is defined for each child. Symbol or sound represents an emotional and satisfaction value for the child. The major problem is to define the correct moment when the system has to (dis)play this signal. We tackle this problem by defining a robust measure of attention. This measure is defined by analyzing the gaze direction and the face orientation, and incorporating the child's specific profile. Following expert directives, our system helps children to categorize elementary perception (strong, smooth, quick, slow, big, small...). Our objective is that children re-use these classifications in others situations."", 'doi': '10.1145/1168987.1169011', 'url': 'https://doi.org/10.1145/1168987.1169011', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Attention analysis in interactive software for children with autism', 'author': 'Mohamed, A. Ould and Courboulay, V. and Sehaba, K. and Menard, M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169011'}"
Understanding emotion through multimedia: comparison between hearing-impaired people and people with hearing abilities,10.1145/1168987.1169012,"We conducted an experiment to determine the abilities of hearing-impaired and normal-hearing people to recognize intended emotions conveyed in four types of stimuli: a drum performance, a drum performance accompanied by a drawing expressing the same intended emotion, and a drum performance accompanied by one of two types of motion pictures. The recognition rate was the highest for a drum performance accompanied by a drawing even though participants in both groups found it difficult to identify the intended emotion because they felt the two stimuli sometimes conveyed different emotions. Visual stimuli were especially effective for performances whose intended emotions were not clear by themselves. The difference in ability to recognize intended emotions between the hearing-impaired and normal-hearing participants was insignificant. The results of this and a series of experiments will enable us to better understand the similarities and differences between how people with different hearing abilities encode and decode emotions in and from sound and visual media. We should then be able to develop a system that will enable hearing-impaired and normal-hearing people to play music together.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'drum performance, emotion, hearing-impairment, recognition', 'numpages': '8', 'pages': '141–148', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We conducted an experiment to determine the abilities of hearing-impaired and normal-hearing people to recognize intended emotions conveyed in four types of stimuli: a drum performance, a drum performance accompanied by a drawing expressing the same intended emotion, and a drum performance accompanied by one of two types of motion pictures. The recognition rate was the highest for a drum performance accompanied by a drawing even though participants in both groups found it difficult to identify the intended emotion because they felt the two stimuli sometimes conveyed different emotions. Visual stimuli were especially effective for performances whose intended emotions were not clear by themselves. The difference in ability to recognize intended emotions between the hearing-impaired and normal-hearing participants was insignificant. The results of this and a series of experiments will enable us to better understand the similarities and differences between how people with different hearing abilities encode and decode emotions in and from sound and visual media. We should then be able to develop a system that will enable hearing-impaired and normal-hearing people to play music together.', 'doi': '10.1145/1168987.1169012', 'url': 'https://doi.org/10.1145/1168987.1169012', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Understanding emotion through multimedia: comparison between hearing-impaired people and people with hearing abilities', 'author': 'Hiraga, Rumi and Kato, Nobuko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169012'}"
Determining the impact of computer frustration on the mood of blind users browsing the web,10.1145/1168987.1169013,"While previous studies have investigated the impact of frustration on computer users' mood as well as the causes of frustration, no research has ever been conducted to examine the relationship between computer frustrations and mood change for users with visual impairment. In this paper, we report on a study that examined the frustrating experiences and mood change of 100 participants, all with visual impairments, when they were browsing the web. The result shows that frustration does cause the participants' mood to deteriorate. However, the amount of time lost due to frustrating situations does not have a significant impact on users' mood, which is very different from the previous research on users without visual impairment. The impact on work seems to have the greatest impact on user mood.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology, emotion, error, frustration, screen reader, time diary, visual impairment, web usability', 'numpages': '8', 'pages': '149–156', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""While previous studies have investigated the impact of frustration on computer users' mood as well as the causes of frustration, no research has ever been conducted to examine the relationship between computer frustrations and mood change for users with visual impairment. In this paper, we report on a study that examined the frustrating experiences and mood change of 100 participants, all with visual impairments, when they were browsing the web. The result shows that frustration does cause the participants' mood to deteriorate. However, the amount of time lost due to frustrating situations does not have a significant impact on users' mood, which is very different from the previous research on users without visual impairment. The impact on work seems to have the greatest impact on user mood."", 'doi': '10.1145/1168987.1169013', 'url': 'https://doi.org/10.1145/1168987.1169013', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Determining the impact of computer frustration on the mood of blind users browsing the web', 'author': 'Lazar, Jonathan and Feng, Jinjuan and Allen, Aaron', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169013'}"
Session details: Mode transformations for vision,10.1145/3245630,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245630', 'url': 'https://doi.org/10.1145/3245630', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Mode transformations for vision', 'author': 'Sears, A. S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245630'}"
Transforming flash to XML for accessibility evaluations,10.1145/1168987.1169015,"Rich Internet content, such as Flash and DHTML, has been spreading all over the net, since it can provide rich and dynamic Web experiences for the sighted majority. It is obvious that this content is inaccessible for visually impaired people because of its visual richness. For Flash, many efforts have been made to address the issue, such as accessibility guidelines and best practices documents However, the amount of accessible content has not been increasing in spite of these efforts. One of the severe issues is the lack of tools to create accessible content. Current Web accessibility technologies are built on top of XMLbased technology infrastructures. In contrast, there is no foundation for investigating inside of Flash content, since it is distributed in a binary format. This characteristic has prevented vendors from developing Flash accessibility technologies. In order to address this issue, this paper proposes a method to transform existing Flash content into XML structures. It combines two approaches for accessing the internal structures. One approach is to obtain MSAA output through the Flash Player and the other is to acquire information by injecting ActionScript bridge code into the content. In this paper, we will first give an overview of the accessibility framework for Flash content, and then present our XML transformation and checking method. A prototype of the checker has been implemented, and some preliminary results of accessibility evaluations are discussed.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, accessibility checker, blind, flash, visually impaired', 'numpages': '8', 'pages': '157–164', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Rich Internet content, such as Flash and DHTML, has been spreading all over the net, since it can provide rich and dynamic Web experiences for the sighted majority. It is obvious that this content is inaccessible for visually impaired people because of its visual richness. For Flash, many efforts have been made to address the issue, such as accessibility guidelines and best practices documents However, the amount of accessible content has not been increasing in spite of these efforts. One of the severe issues is the lack of tools to create accessible content. Current Web accessibility technologies are built on top of XMLbased technology infrastructures. In contrast, there is no foundation for investigating inside of Flash content, since it is distributed in a binary format. This characteristic has prevented vendors from developing Flash accessibility technologies. In order to address this issue, this paper proposes a method to transform existing Flash content into XML structures. It combines two approaches for accessing the internal structures. One approach is to obtain MSAA output through the Flash Player and the other is to acquire information by injecting ActionScript bridge code into the content. In this paper, we will first give an overview of the accessibility framework for Flash content, and then present our XML transformation and checking method. A prototype of the checker has been implemented, and some preliminary results of accessibility evaluations are discussed.', 'doi': '10.1145/1168987.1169015', 'url': 'https://doi.org/10.1145/1168987.1169015', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Transforming flash to XML for accessibility evaluations', 'author': 'Saito, Shin and Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169015'}"
Analyzing visual layout for a non-visual presentation-document interface,10.1145/1168987.1169016,"Presentation documents play important roles in many fields, such as business and education. The principal purpose of presentation documents is to convey information visually, so recognizing the visual layout is essential for understanding those documents. However it is inherently difficult for the blind people to recognize a visual layout, because there are numerous types of charts in presentation documents. As the first step to solve such problems, this study focuses on diagrams in which objects or groups of objects are bound by arrows. Such diagrams usually show relationships among the objects. If such relationships could be recognized by screen readers, it would make them accessible. However, the presentation authoring applications do not have functions for embedding these relationships among objects. Therefore this paper proposes a visual analysis method for diagram structure in presentation documents to automatically create metadata. It generates metadata which describes the relationships of objects, and the source-destination relationships of arrows. Then a novel interface utilizing the metadata was prototyped to present the visual structure of presentation documents in a tree view. This allows blind users to understand presentation documents easily, because it represents the visual structure that current screen readers cannot expose. In addition, they are familiar with the tree view interface, so they can use it without training. Finally, an evaluation shows that our method for automatically creating the metadata can be applied to various types of diagrams in presentation documents.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'alternative interface, diagram, metadata, visual analysis', 'numpages': '8', 'pages': '165–172', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Presentation documents play important roles in many fields, such as business and education. The principal purpose of presentation documents is to convey information visually, so recognizing the visual layout is essential for understanding those documents. However it is inherently difficult for the blind people to recognize a visual layout, because there are numerous types of charts in presentation documents. As the first step to solve such problems, this study focuses on diagrams in which objects or groups of objects are bound by arrows. Such diagrams usually show relationships among the objects. If such relationships could be recognized by screen readers, it would make them accessible. However, the presentation authoring applications do not have functions for embedding these relationships among objects. Therefore this paper proposes a visual analysis method for diagram structure in presentation documents to automatically create metadata. It generates metadata which describes the relationships of objects, and the source-destination relationships of arrows. Then a novel interface utilizing the metadata was prototyped to present the visual structure of presentation documents in a tree view. This allows blind users to understand presentation documents easily, because it represents the visual structure that current screen readers cannot expose. In addition, they are familiar with the tree view interface, so they can use it without training. Finally, an evaluation shows that our method for automatically creating the metadata can be applied to various types of diagrams in presentation documents.', 'doi': '10.1145/1168987.1169016', 'url': 'https://doi.org/10.1145/1168987.1169016', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Analyzing visual layout for a non-visual presentation-document interface', 'author': 'Ishihara, Tatsuya and Takagi, Hironobu and Itoh, Takashi and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169016'}"
Learning and perceiving colors haptically,10.1145/1168987.1169017,"Color is an integral part of spatial perception and there is a need to develop systems that render color information accessible to blind individuals. A novel system that allows learning, presentation and analysis of color information, designed in consultations with focus groups of individuals who are blind is proposed. Our system is based on a methodology that renders colors as textures through a haptic device. The aim of the proposed approach is to enable color perception and provide a basis for assessing color similarity. Initial testing of the system shows that both blind individuals and sighted individuals can recognize colors through our approach and further assess similarity between colors through the system. A space was obtained through multidimensional scaling performed on similarity scores between pairs of colors as presented through our system. This space obtained high congruency with the chromaticity diagram and the hue saturation color wheel which shows the validity of our system to allow color visualization. A realtime system based on the proposed mapping is designed to allow realtime color perception.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'color perception, haptic user interfaces', 'numpages': '8', 'pages': '173–180', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Color is an integral part of spatial perception and there is a need to develop systems that render color information accessible to blind individuals. A novel system that allows learning, presentation and analysis of color information, designed in consultations with focus groups of individuals who are blind is proposed. Our system is based on a methodology that renders colors as textures through a haptic device. The aim of the proposed approach is to enable color perception and provide a basis for assessing color similarity. Initial testing of the system shows that both blind individuals and sighted individuals can recognize colors through our approach and further assess similarity between colors through the system. A space was obtained through multidimensional scaling performed on similarity scores between pairs of colors as presented through our system. This space obtained high congruency with the chromaticity diagram and the hue saturation color wheel which shows the validity of our system to allow color visualization. A realtime system based on the proposed mapping is designed to allow realtime color perception.', 'doi': '10.1145/1168987.1169017', 'url': 'https://doi.org/10.1145/1168987.1169017', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Learning and perceiving colors haptically', 'author': 'Kahol, Kanav and French, Jamieson and Bratton, Laura and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169017'}"
WebInSight: making web images accessible,10.1145/1168987.1169018,"Images without alternative text are a barrier to equal web access for blind users. To illustrate the problem, we conducted a series of studies that conclusively show that a large fraction of significant images have no alternative text. To ameliorate this problem, we introduce WebInSight, a system that automatically creates and inserts alternative text into web pages on-the-fly. To formulate alternative text for images, we present three labeling modules based on web context analysis, enhanced optical character recognition (OCR) and human labeling. The system caches alternative text in a local database and can add new labels seamlessly after a web page is downloaded, resulting in minimal impact to the browsing experience.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'optical character recognition, transformation proxy, web accessibility, web studies', 'numpages': '8', 'pages': '181–188', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Images without alternative text are a barrier to equal web access for blind users. To illustrate the problem, we conducted a series of studies that conclusively show that a large fraction of significant images have no alternative text. To ameliorate this problem, we introduce WebInSight, a system that automatically creates and inserts alternative text into web pages on-the-fly. To formulate alternative text for images, we present three labeling modules based on web context analysis, enhanced optical character recognition (OCR) and human labeling. The system caches alternative text in a local database and can add new labels seamlessly after a web page is downloaded, resulting in minimal impact to the browsing experience.', 'doi': '10.1145/1168987.1169018', 'url': 'https://doi.org/10.1145/1168987.1169018', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'WebInSight: making web images accessible', 'author': 'Bigham, Jeffrey P. and Kaminsky, Ryan S. and Ladner, Richard E. and Danielsson, Oscar M. and Hempton, Gordon L.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169018'}"
Session details: Alternative modes for motor input,10.1145/3245631,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245631', 'url': 'https://doi.org/10.1145/3245631', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Alternative modes for motor input', 'author': 'Trewin, S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245631'}"
Improvements in vision-based pointer control,10.1145/1168987.1169020,"Vision-based head trackers have been around for some years and are even beginning to be commercialized, but problems remain with respect to usability. Users without the ability to use traditional pointing devices - the intended audience of such systems - have no alternative if the automatic boot strapping process fails, there is room for improvement in face tracking, and the pointer movement dynamics do not support accurate and efficient pointing. This paper describes a novel head tracking pointer that addresses these problems.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessible user interfaces, human-computer interaction, vision-based user interfaces', 'numpages': '8', 'pages': '189–196', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Vision-based head trackers have been around for some years and are even beginning to be commercialized, but problems remain with respect to usability. Users without the ability to use traditional pointing devices - the intended audience of such systems - have no alternative if the automatic boot strapping process fails, there is room for improvement in face tracking, and the pointer movement dynamics do not support accurate and efficient pointing. This paper describes a novel head tracking pointer that addresses these problems.', 'doi': '10.1145/1168987.1169020', 'url': 'https://doi.org/10.1145/1168987.1169020', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Improvements in vision-based pointer control', 'author': 'Kjeldsen, Rick', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169020'}"
The vocal joystick: evaluation of voice-based cursor control techniques,10.1145/1168987.1169021,"Mouse control has become a crucial aspect of many modern day computer interactions. This poses a challenge for individuals with motor impairments or those whose use of hands are restricted due to situational constraints. We present a system called the Vocal Joystick which allows the user to continuously control the mouse cursor by varying vocal parameters such as vowel quality, loudness and pitch. A survey of existing cursor control methods is presented to highlight the key characteristics of the Vocal Joystick. Evaluations were conducted to characterize expert performance capability of the Vocal Joystick, and to compare novice user performance and preference for the Vocal Joystick and two other existing speech based cursor control methods. Our results show that Fitts' law is a good predictor of the speedaccuracy tradeoff for the Vocal Joystick, and suggests that the optimal performance of the Vocal Joystick may be comparable to that of a conventional hand-operated joystick. Novice user evaluations show that the Vocal Joystick can be used by people without extensive training, and that it presents a viable alternative to existing speech-based cursor control methods.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': ""Fitts' law, continuous input, cursor control, speech recognition, voice-based interface"", 'numpages': '8', 'pages': '197–204', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Mouse control has become a crucial aspect of many modern day computer interactions. This poses a challenge for individuals with motor impairments or those whose use of hands are restricted due to situational constraints. We present a system called the Vocal Joystick which allows the user to continuously control the mouse cursor by varying vocal parameters such as vowel quality, loudness and pitch. A survey of existing cursor control methods is presented to highlight the key characteristics of the Vocal Joystick. Evaluations were conducted to characterize expert performance capability of the Vocal Joystick, and to compare novice user performance and preference for the Vocal Joystick and two other existing speech based cursor control methods. Our results show that Fitts' law is a good predictor of the speedaccuracy tradeoff for the Vocal Joystick, and suggests that the optimal performance of the Vocal Joystick may be comparable to that of a conventional hand-operated joystick. Novice user evaluations show that the Vocal Joystick can be used by people without extensive training, and that it presents a viable alternative to existing speech-based cursor control methods."", 'doi': '10.1145/1168987.1169021', 'url': 'https://doi.org/10.1145/1168987.1169021', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'The vocal joystick: evaluation of voice-based cursor control techniques', 'author': 'Harada, Susumu and Landay, James A. and Malkin, Jonathan and Li, Xiao and Bilmes, Jeff A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169021'}"
A voice-activated syntax-directed editor for manually disabled programmers,10.1145/1168987.1169022,"This paper discusses a research project targeted at the design and implementation of an interface intended to allow manually disabled people to more easily perform the task of programming. It proposes a Speech User Interface (SUI) targeted for this task. Voice was selected as the means of input as an alternative to the keyboard and mouse. Traditional programming IDEs tend to be character and line oriented. It is argued that this orientation is not conducive to voice input, and so a syntaxdirected programming interface is proposed. To test the viability of this combination of voice with a syntax-directed approach, an editor named VASDE (Voice-Activated Syntax-Directed Editor) was implemented using ECLIPSE as the underlying platform for development. This paper describes the syntax-directed interface, VASDE, and some of the lessons learned from initial usability studies.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'IDE, programming by voice, speech user interface, syntax directed', 'numpages': '8', 'pages': '205–212', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper discusses a research project targeted at the design and implementation of an interface intended to allow manually disabled people to more easily perform the task of programming. It proposes a Speech User Interface (SUI) targeted for this task. Voice was selected as the means of input as an alternative to the keyboard and mouse. Traditional programming IDEs tend to be character and line oriented. It is argued that this orientation is not conducive to voice input, and so a syntaxdirected programming interface is proposed. To test the viability of this combination of voice with a syntax-directed approach, an editor named VASDE (Voice-Activated Syntax-Directed Editor) was implemented using ECLIPSE as the underlying platform for development. This paper describes the syntax-directed interface, VASDE, and some of the lessons learned from initial usability studies.', 'doi': '10.1145/1168987.1169022', 'url': 'https://doi.org/10.1145/1168987.1169022', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A voice-activated syntax-directed editor for manually disabled programmers', 'author': 'Hubbell, Thomas J. and Langan, David D. and Hain, Thomas F.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169022'}"
Non-speech input and speech recognition for real-time control of computer games,10.1145/1168987.1169023,"This paper reports a comparison of user performance (time and accuracy) when controlling a popular arcade game of Tetris using speech recognition or non-speech (humming) input techniques. The preliminary qualitative study with seven participants shows that users were able to control the game using both methods but required more training and feedback for the humming control. The revised interface, which implemented these requirements, was positively responded by users. The quantitative test with 12 other participants shows that humming excelled in both time and accuracy, especially over longer distances and advanced difficulty levels.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'acoustic input, game control, motor-impaired users, non-speech control, speech recognition, voice interaction', 'numpages': '8', 'pages': '213–220', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper reports a comparison of user performance (time and accuracy) when controlling a popular arcade game of Tetris using speech recognition or non-speech (humming) input techniques. The preliminary qualitative study with seven participants shows that users were able to control the game using both methods but required more training and feedback for the humming control. The revised interface, which implemented these requirements, was positively responded by users. The quantitative test with 12 other participants shows that humming excelled in both time and accuracy, especially over longer distances and advanced difficulty levels.', 'doi': '10.1145/1168987.1169023', 'url': 'https://doi.org/10.1145/1168987.1169023', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Non-speech input and speech recognition for real-time control of computer games', 'author': ""Sporka, Adam J. and Kurniawan, Sri H. and Mahmud, Murni and Slav\\'{\\i}k, Pavel"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169023'}"
Session details: Posters and demos,10.1145/3245632,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245632', 'url': 'https://doi.org/10.1145/3245632', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Posters and demos', 'author': 'Black, J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245632'}"
A general HCI framework of sonification applications,10.1145/1168987.1169025,This paper proposes a general HCI framework of sonification applications. It is used to explain and understand sonification applications and how it might be interpreted by the users. The framework emphasizes on two models namely Sonification Application Model (SA Model) and User Interpretation Construction Model (UIC Model).,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'human computer interaction (HCI), perception, sonification, usability, usability inspection, usability inspection material', 'numpages': '2', 'pages': '221–222', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper proposes a general HCI framework of sonification applications. It is used to explain and understand sonification applications and how it might be interpreted by the users. The framework emphasizes on two models namely Sonification Application Model (SA Model) and User Interpretation Construction Model (UIC Model).', 'doi': '10.1145/1168987.1169025', 'url': 'https://doi.org/10.1145/1168987.1169025', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A general HCI framework of sonification applications', 'author': 'Ibrahim, Ag Asri Ag and Hunt, Andy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169025'}"
A three-countries case study of older people's browsing,10.1145/1168987.1169026,"This paper presents quantitative data on browsing activities with 63 respondents aged 55 years old and over from three countries: UK, USA and Thailand. The questionnaire explored frequently browsed topics, browser's functions used, problems with standard browsers and features to add to a standard browser to make it more ageing-friendly. The study revealed country-related differences in various aspects of Internet uses, including the topics accessed and places of access. However, no country-related difference was observed on the input device used and the number of browsing windows opened.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'HCI, ageing, elderly, seniors, web browsers', 'numpages': '2', 'pages': '223–224', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper presents quantitative data on browsing activities with 63 respondents aged 55 years old and over from three countries: UK, USA and Thailand. The questionnaire explored frequently browsed topics, browser's functions used, problems with standard browsers and features to add to a standard browser to make it more ageing-friendly. The study revealed country-related differences in various aspects of Internet uses, including the topics accessed and places of access. However, no country-related difference was observed on the input device used and the number of browsing windows opened."", 'doi': '10.1145/1168987.1169026', 'url': 'https://doi.org/10.1145/1168987.1169026', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': ""A three-countries case study of older people's browsing"", 'author': 'Sa-nga-ngam, Prush and Kurniawan, Sri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169026'}"
Helping aphasic people process online information,10.1145/1168987.1169027,"In this paper, we describe the HAPPI (Helping Aphasic People Process Information) project which aims to develop web based systems to help Aphasic people gain access to web based information such as online news stories. It does this by simplifying the language and providing alternative means to help jog users' memories and hence improve their comprehension of the online material.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'aphasia, online text simplification', 'numpages': '2', 'pages': '225–226', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this paper, we describe the HAPPI (Helping Aphasic People Process Information) project which aims to develop web based systems to help Aphasic people gain access to web based information such as online news stories. It does this by simplifying the language and providing alternative means to help jog users' memories and hence improve their comprehension of the online material."", 'doi': '10.1145/1168987.1169027', 'url': 'https://doi.org/10.1145/1168987.1169027', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Helping aphasic people process online information', 'author': 'Devlin, Siobhan and Unthank, Gary', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169027'}"
Loudmouth: modifying text-to-speech synthesis in noise,10.1145/1168987.1169028,"Current speech synthesis technology is difficult to understand in everyday noise situations. Although there is a significant body of work on how humans modify their speech in noise, the results have yet to be implemented in a synthesizer. Algorithms capable of processing and incorporating these modifications may lead to improved speech intelligibility of assistive communication aids and more generally of spoken dialogue systems. We describe our efforts in building the Loudmouth synthesizer which emulates human modifications to speech in noise. A perceptual experiment indicated that Loudmouth achieved a statistically significant gain in intelligibility compared to a standard synthesizer in noise.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'augmentative and alternative communication (AAC), speech synthesis, text-to-speech synthesis (TTS)', 'numpages': '2', 'pages': '227–228', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Current speech synthesis technology is difficult to understand in everyday noise situations. Although there is a significant body of work on how humans modify their speech in noise, the results have yet to be implemented in a synthesizer. Algorithms capable of processing and incorporating these modifications may lead to improved speech intelligibility of assistive communication aids and more generally of spoken dialogue systems. We describe our efforts in building the Loudmouth synthesizer which emulates human modifications to speech in noise. A perceptual experiment indicated that Loudmouth achieved a statistically significant gain in intelligibility compared to a standard synthesizer in noise.', 'doi': '10.1145/1168987.1169028', 'url': 'https://doi.org/10.1145/1168987.1169028', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Loudmouth: modifying text-to-speech synthesis in noise', 'author': 'Patel, Rupal and Everett, Michael and Sadikov, Eldar', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169028'}"
Hardware-based text-to-braille translator,10.1145/1168987.1169029,"This paper describes the hardware implementation of a text to Braille Translator using Field-Programmable Gate Arrays (FPGAs). Different from most commercial software-based translators, the circuit presented is able to carry out text-to-Braille translation in hardware. The translator is based on the translating algorithm, proposed by Paul Blenkhorn [1]. The Very high speed Hardware Description Language (VHDL) was used to describe the chip in a hierarchical way. The test results indicate that the hardware-based translator achieves the same results as software-based commercial translators.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'FPGAs, VHDL, braille translation', 'numpages': '2', 'pages': '229–230', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes the hardware implementation of a text to Braille Translator using Field-Programmable Gate Arrays (FPGAs). Different from most commercial software-based translators, the circuit presented is able to carry out text-to-Braille translation in hardware. The translator is based on the translating algorithm, proposed by Paul Blenkhorn [1]. The Very high speed Hardware Description Language (VHDL) was used to describe the chip in a hierarchical way. The test results indicate that the hardware-based translator achieves the same results as software-based commercial translators.', 'doi': '10.1145/1168987.1169029', 'url': 'https://doi.org/10.1145/1168987.1169029', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Hardware-based text-to-braille translator', 'author': 'Zhang, Xuan and Ortega-Sanchez, Cesar and Murray, Iain', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169029'}"
A portable device for the translation of braille to text,10.1145/1168987.1169030,"This paper presents the development of a portable device for the translation of embossed Braille to text. The device optically scans a Braille page and outputs the equivalent text output in real time, thus acting as a written communications gateway between sighted and vision impaired persons.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'braille, optical braille recognition, portable machine translation', 'numpages': '2', 'pages': '231–232', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents the development of a portable device for the translation of embossed Braille to text. The device optically scans a Braille page and outputs the equivalent text output in real time, thus acting as a written communications gateway between sighted and vision impaired persons.', 'doi': '10.1145/1168987.1169030', 'url': 'https://doi.org/10.1145/1168987.1169030', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A portable device for the translation of braille to text', 'author': 'Murray, Iain and Pasquale, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169030'}"
South African sign language machine translation project,10.1145/1168987.1169031,"We describe the South African Sign Language Machine Translation project, and point out the role that the project is playing in the larger context of South African Sign Language and accessibility for the South African Deaf community.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'machine translation, sign language', 'numpages': '2', 'pages': '233–234', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We describe the South African Sign Language Machine Translation project, and point out the role that the project is playing in the larger context of South African Sign Language and accessibility for the South African Deaf community.', 'doi': '10.1145/1168987.1169031', 'url': 'https://doi.org/10.1145/1168987.1169031', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'South African sign language machine translation project', 'author': 'van Zijl, Lynette', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169031'}"
A cisco education tool accessible to the vision impaired,10.1145/1168987.1169032,"This paper describes iNetSim, a universally accessible network simulator, created to allow vision-impaired and sighted users to complete Cisco Certified Network Associate level two (CCNA 2) laboratory sessions. Previously, software used in the CCNA course was not accessible to those with impaired vision because it utilized images of network topology. These images were incompatible with screen reader software. In contrast, iNetSim is assessable by blind and vision impaired users, in addition to those with normal vision. It is based on Mac OS X Tiger, an operating system with an integrated screen reader called VoiceOver.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technologies, screen readers, universal access, user interfaces, vision-impaired', 'numpages': '2', 'pages': '235–236', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes iNetSim, a universally accessible network simulator, created to allow vision-impaired and sighted users to complete Cisco Certified Network Associate level two (CCNA 2) laboratory sessions. Previously, software used in the CCNA course was not accessible to those with impaired vision because it utilized images of network topology. These images were incompatible with screen reader software. In contrast, iNetSim is assessable by blind and vision impaired users, in addition to those with normal vision. It is based on Mac OS X Tiger, an operating system with an integrated screen reader called VoiceOver.', 'doi': '10.1145/1168987.1169032', 'url': 'https://doi.org/10.1145/1168987.1169032', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A cisco education tool accessible to the vision impaired', 'author': 'Hope, J. and von Konsky, B. R. and Murray, I. and Chew, L. C. and Farrugia, B.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169032'}"
Wireless headset communications for vision impaired persons in multi-User environments,10.1145/1168987.1169033,"Wireless headsets are a great asset to Vision Impaired Persons (VIP's) as they prove to be much easier to use and reliable than wired equivalents. Radio based wireless headsets are the most common and have many favorable characteristics, however for environments where there may be numerous users with wireless headsets, radio channels easily become congested compromising audio quality and reliable operation. The research undertaken in this project attempts to sidestep the radio channel congestion problem and also produce a wireless headset tailored to the requirements of VIP's.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'audio communication, headset, screen reading software, wireless', 'numpages': '2', 'pages': '237–238', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Wireless headsets are a great asset to Vision Impaired Persons (VIP's) as they prove to be much easier to use and reliable than wired equivalents. Radio based wireless headsets are the most common and have many favorable characteristics, however for environments where there may be numerous users with wireless headsets, radio channels easily become congested compromising audio quality and reliable operation. The research undertaken in this project attempts to sidestep the radio channel congestion problem and also produce a wireless headset tailored to the requirements of VIP's."", 'doi': '10.1145/1168987.1169033', 'url': 'https://doi.org/10.1145/1168987.1169033', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Wireless headset communications for vision impaired persons in multi-User environments', 'author': 'Murray, Iain and Pasquale, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169033'}"
Picture planner: a cognitively accessible personal activity scheduling application,10.1145/1168987.1169034,"This paper describes design elements and field test results for an icon-driven, cognitively accessible personal activity scheduling application for use by individuals with disabilities and their assistants. Results showed that users with significant cognitive disabilities can learn to use and benefit from accessible computerbased self-management applications.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, activities of daily living, cognitive disabilities, life skills software, personal management', 'numpages': '2', 'pages': '239–240', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes design elements and field test results for an icon-driven, cognitively accessible personal activity scheduling application for use by individuals with disabilities and their assistants. Results showed that users with significant cognitive disabilities can learn to use and benefit from accessible computerbased self-management applications.', 'doi': '10.1145/1168987.1169034', 'url': 'https://doi.org/10.1145/1168987.1169034', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Picture planner: a cognitively accessible personal activity scheduling application', 'author': 'Keating, Thomas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169034'}"
Designing a scripting language to help the blind program visually,10.1145/1168987.1169035,"The vast proliferation of GUI-based applications, including graphical interactive development environments (IDEs), has placed blind programmers at a severe disadvantage in a profession that had previously been relatively accessible. Visual Basic is one such programming language and IDE, in which most programmers ""point and click"" to design the forms on which their applications rely. It is the goal of this project to introduce a scripting language that eliminates this barrier by providing a scripting language that makes it possible to define Visual Basic GUI forms and their components verbally, while remaining easy to write.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'blind programmers, graphical user interfaces, visual basic, visual programming', 'numpages': '2', 'pages': '241–242', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The vast proliferation of GUI-based applications, including graphical interactive development environments (IDEs), has placed blind programmers at a severe disadvantage in a profession that had previously been relatively accessible. Visual Basic is one such programming language and IDE, in which most programmers ""point and click"" to design the forms on which their applications rely. It is the goal of this project to introduce a scripting language that eliminates this barrier by providing a scripting language that makes it possible to define Visual Basic GUI forms and their components verbally, while remaining easy to write.', 'doi': '10.1145/1168987.1169035', 'url': 'https://doi.org/10.1145/1168987.1169035', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Designing a scripting language to help the blind program visually', 'author': 'Franqueiro, Kenneth G. and Siegfried, Robert M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169035'}"
Automatically generating custom user interfaces for users with physical disabilities,10.1145/1168987.1169036,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'arnauld, automatic UI generation, optimization, physical disabilities, supple', 'numpages': '2', 'pages': '243–244', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1168987.1169036', 'url': 'https://doi.org/10.1145/1168987.1169036', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Automatically generating custom user interfaces for users with physical disabilities', 'author': 'Gajos, Krzysztof Z. and Long, Jing Jing and Weld, Daniel S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169036'}"
A rollator-mounted wayfinding system for the elderly: a smart world perspective,10.1145/1168987.1169037,"We will demonstrate the iWalker, a three-sensor rollatormounted wayfinding system for the elderly with cognitive and visual impairments. Unlike several previous and ongoing research efforts, iWalker emphasizes a smart world (SW) perspective. A SWis a physical space equipped with embedded sensors. One implication of the SW perspective is the simplification of the onboard computing machinery needed to make iWalker operational.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology for deaf, meeting accommodations, transparent video, user studies', 'numpages': '2', 'pages': '245–246', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We will demonstrate the iWalker, a three-sensor rollatormounted wayfinding system for the elderly with cognitive and visual impairments. Unlike several previous and ongoing research efforts, iWalker emphasizes a smart world (SW) perspective. A SWis a physical space equipped with embedded sensors. One implication of the SW perspective is the simplification of the onboard computing machinery needed to make iWalker operational.', 'doi': '10.1145/1168987.1169037', 'url': 'https://doi.org/10.1145/1168987.1169037', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A rollator-mounted wayfinding system for the elderly: a smart world perspective', 'author': 'Kutiyanawala, Aliasgar and Kulyukin, Vladimir and LoPresti, Edmund', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169037'}"
Facetop tablet: note-taking assistance for deaf persons,10.1145/1168987.1169038,"Meetings comprise a vital part of participation in social activities. For a deaf or hard of hearing person who does not understand spoken language, following meetings can become confusing if there are too many simultaneous sources of information. When the person focuses on one source of information, she misses information from another source; for example, while looking at a presenter's slides, the person misses information from the signing interpreter. The features of Facetop Tablet were iteratively designed according to feedback from members of the Deaf community. Through this feedback, we have refined and completed the implementation and it is ready for evaluation through user studies. We are ready to recruit participants whom we could reach through demonstrations.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology for deaf, meeting accommodations, transparent video', 'numpages': '2', 'pages': '247–248', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Meetings comprise a vital part of participation in social activities. For a deaf or hard of hearing person who does not understand spoken language, following meetings can become confusing if there are too many simultaneous sources of information. When the person focuses on one source of information, she misses information from another source; for example, while looking at a presenter's slides, the person misses information from the signing interpreter. The features of Facetop Tablet were iteratively designed according to feedback from members of the Deaf community. Through this feedback, we have refined and completed the implementation and it is ready for evaluation through user studies. We are ready to recruit participants whom we could reach through demonstrations."", 'doi': '10.1145/1168987.1169038', 'url': 'https://doi.org/10.1145/1168987.1169038', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Facetop tablet: note-taking assistance for deaf persons', 'author': 'Miller, Dorian and Culp, James and Stotts, David', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169038'}"
Evaluating a pen-based computer interface for novice older users,10.1145/1168987.1169039,"Nowadays, few efforts have been dedicated to the design of specialized graphical user interfaces (GUIs) for elderly people despite the fact that they have computer interaction problems with the WIMP standard (Windows, Icons, Menus, and Pointers). This research goes one step further, proposing and evaluating a penbased interaction technique based on to draw simple lines that improves the computer usability for novice older users.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility for elderly people, gesture input, graphical users interfaces, interaction techniques', 'numpages': '2', 'pages': '249–250', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Nowadays, few efforts have been dedicated to the design of specialized graphical user interfaces (GUIs) for elderly people despite the fact that they have computer interaction problems with the WIMP standard (Windows, Icons, Menus, and Pointers). This research goes one step further, proposing and evaluating a penbased interaction technique based on to draw simple lines that improves the computer usability for novice older users.', 'doi': '10.1145/1168987.1169039', 'url': 'https://doi.org/10.1145/1168987.1169039', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Evaluating a pen-based computer interface for novice older users', 'author': 'Torres, Dante Arias', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169039'}"
Using think aloud protocol with blind users: a case for inclusive usability evaluation methods,10.1145/1168987.1169040,"There is a need to assess the applicability of conventional Usability Evaluation Methods to users with disabilities, given the growing importance of involving these users in the usability evaluation process. We found that conventional Think Aloud Protocol cannot be used as is, and will require modification to be useful, when evaluating websites with blind users.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'blind web users, think aloud protocol, usability evaluation', 'numpages': '2', 'pages': '251–252', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'There is a need to assess the applicability of conventional Usability Evaluation Methods to users with disabilities, given the growing importance of involving these users in the usability evaluation process. We found that conventional Think Aloud Protocol cannot be used as is, and will require modification to be useful, when evaluating websites with blind users.', 'doi': '10.1145/1168987.1169040', 'url': 'https://doi.org/10.1145/1168987.1169040', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Using think aloud protocol with blind users: a case for inclusive usability evaluation methods', 'author': 'Chandrashekar, Sambhavi and Stockman, Tony and Fels, Deborah and Benedyk, Rachel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169040'}"
Accessibility evaluation based on machine learning technique,10.1145/1168987.1169041,"Presentation documents are used in several situations. However, there is no tool to sufficiently check the accessibility level of a presentation document. Traditional rule-based checking has limitations in checking semantic criteria. This paper describes a new approach to evaluate the accessibility of presentation documents using machine learning with a model built from features of a presentation's appearance. A prototype system was implemented, and an exploratory experiment was conducted.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, appearance features, machine learning, presentation documents', 'numpages': '2', 'pages': '253–254', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Presentation documents are used in several situations. However, there is no tool to sufficiently check the accessibility level of a presentation document. Traditional rule-based checking has limitations in checking semantic criteria. This paper describes a new approach to evaluate the accessibility of presentation documents using machine learning with a model built from features of a presentation's appearance. A prototype system was implemented, and an exploratory experiment was conducted."", 'doi': '10.1145/1168987.1169041', 'url': 'https://doi.org/10.1145/1168987.1169041', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Accessibility evaluation based on machine learning technique', 'author': 'Sato, Daisuke and Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169041'}"
Designing auditory displays to facilitate object localization in virtual haptic 3D environments,10.1145/1168987.1169042,Five different auditory displays were designed to aid blind users in finding objects in a virtual haptic 3d environment. Each auditory display was based on a different principle and incorporated different methods for representing spatial information. Results from an evaluation with seven visually impaired persons reveal to what extent these methods facilitate object localization in a virtual haptic 3d environment.,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'auditory display, haptics, object localization, visually impaired users', 'numpages': '2', 'pages': '255–256', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Five different auditory displays were designed to aid blind users in finding objects in a virtual haptic 3d environment. Each auditory display was based on a different principle and incorporated different methods for representing spatial information. Results from an evaluation with seven visually impaired persons reveal to what extent these methods facilitate object localization in a virtual haptic 3d environment.', 'doi': '10.1145/1168987.1169042', 'url': 'https://doi.org/10.1145/1168987.1169042', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Designing auditory displays to facilitate object localization in virtual haptic 3D environments', 'author': 'Crommentuijn, Koen and Winberg, Fredrik', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169042'}"
Lecture adaptation for students with visual disabilities using high-resolution photography,10.1145/1168987.1169043,Visual content in lectures can be enhanced for use by students with visual disabilities by using high-resolution digital still cameras. This paper presents a system which uses two high-resolution cameras; one to capture multiple sources of visual content and another to monitor the head pose of up to 20 audience members. This capture technique eliminates the need for multiple cameras or intrusive and distracting instrumentation but introduced some new problems which were solved with an algorithm used to distinguish between two possible sources of visual interest.,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'students with disabilities, time-lapse photography, visual disabilities', 'numpages': '2', 'pages': '257–258', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Visual content in lectures can be enhanced for use by students with visual disabilities by using high-resolution digital still cameras. This paper presents a system which uses two high-resolution cameras; one to capture multiple sources of visual content and another to monitor the head pose of up to 20 audience members. This capture technique eliminates the need for multiple cameras or intrusive and distracting instrumentation but introduced some new problems which were solved with an algorithm used to distinguish between two possible sources of visual interest.', 'doi': '10.1145/1168987.1169043', 'url': 'https://doi.org/10.1145/1168987.1169043', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Lecture adaptation for students with visual disabilities using high-resolution photography', 'author': 'Hughes, Gregory and Robinson, Peter Robinson', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169043'}"
SADIe: transcoding based on CSS,10.1145/1168987.1169044,"Visually impaired users are hindered in their efforts to access the World Wide Web (Web) because their information and presentation requirements are different from those of a sighted user. These requirements can become problems as the Web becomes ever more visually centric with regard to presentation and information order / layout, this can (and does) hinder users who need presentationagnostic access to information. Finding semantic information already encoded directly into pages can help to alleviate these problems and support users who wish to understand the meaning as opposed to the presentation and order of the information. Our solution, Structural-Semantics for Accessibility and Device Independence (SADIe) involves building ontologies of Cascading Sytle-Sheets (CSS) and using those ontologies to transform Web pages.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'document engineering, tools, transcoding, visual impairment, web', 'numpages': '2', 'pages': '259–260', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Visually impaired users are hindered in their efforts to access the World Wide Web (Web) because their information and presentation requirements are different from those of a sighted user. These requirements can become problems as the Web becomes ever more visually centric with regard to presentation and information order / layout, this can (and does) hinder users who need presentationagnostic access to information. Finding semantic information already encoded directly into pages can help to alleviate these problems and support users who wish to understand the meaning as opposed to the presentation and order of the information. Our solution, Structural-Semantics for Accessibility and Device Independence (SADIe) involves building ontologies of Cascading Sytle-Sheets (CSS) and using those ontologies to transform Web pages.', 'doi': '10.1145/1168987.1169044', 'url': 'https://doi.org/10.1145/1168987.1169044', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'SADIe: transcoding based on CSS', 'author': 'Harper, Simon and Bechhofer, Sean and Lunn, Darren', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169044'}"
Linux screen reader: extensible assistive technology,10.1145/1168987.1169045,"The Linux Screen Reader (LSR) project is an open source effort to develop an extensible assistive technology for the GNOME desktop environment. The goal of the project is to create a reusable development platform for building alternative and supplemental user interfaces in support of people with diverse disabilities. In this paper, we highlight some key features of LSR including cascading scripts that tailor the user experience to particular applications and tasks, support for novel methods of input and output (e.g. concurrent spatial audio) suited to the needs and preferences of the user, and the ease and flexibility of extension development.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'AT-SPI, GNOME, accessibility, assistive technology, linux, python, screen reader, scripting, spatial sound, usability', 'numpages': '2', 'pages': '261–262', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The Linux Screen Reader (LSR) project is an open source effort to develop an extensible assistive technology for the GNOME desktop environment. The goal of the project is to create a reusable development platform for building alternative and supplemental user interfaces in support of people with diverse disabilities. In this paper, we highlight some key features of LSR including cascading scripts that tailor the user experience to particular applications and tasks, support for novel methods of input and output (e.g. concurrent spatial audio) suited to the needs and preferences of the user, and the ease and flexibility of extension development.', 'doi': '10.1145/1168987.1169045', 'url': 'https://doi.org/10.1145/1168987.1169045', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Linux screen reader: extensible assistive technology', 'author': 'Parente, Peter and Clippingdale, Brett', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169045'}"
"PLUMB: an interface for users who are blind to display, create, and modify graphs",10.1145/1168987.1169046,"We demonstrate the most recent version of our system to communicate graphs and relational information to blind users. We have developed a system called exPLoring graphs at UMB (PLUMB) that displays a drawn graph on a tablet PC and uses auditory cues to help a blind user navigate the graph. This work has applications to assist blind individuals in Computer Science and other educational disciplines, navigation and map manipulation.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, audio, graph', 'numpages': '2', 'pages': '263–264', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We demonstrate the most recent version of our system to communicate graphs and relational information to blind users. We have developed a system called exPLoring graphs at UMB (PLUMB) that displays a drawn graph on a tablet PC and uses auditory cues to help a blind user navigate the graph. This work has applications to assist blind individuals in Computer Science and other educational disciplines, navigation and map manipulation.', 'doi': '10.1145/1168987.1169046', 'url': 'https://doi.org/10.1145/1168987.1169046', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'PLUMB: an interface for users who are blind to display, create, and modify graphs', 'author': 'Calder, Matt and Cohen, Robert F. and Lanzoni, Jessica and Xu, Yun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169046'}"
The personal portable profile project,10.1145/1168987.1169047,"This presentation will demonstrate the Personal Portable Profile (P3) system, capturing the characteristics of a user profile from one computer and copying them to a second computer. This is accomplished through an auto-run program stored on a UD-RW flash drive device. Such a system will be useful for those with disabilities by allowing them to easily set the interaction characteristics of any computer they encounter to their ""home"" settings.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'assistive technology, user profile', 'numpages': '2', 'pages': '265–266', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This presentation will demonstrate the Personal Portable Profile (P3) system, capturing the characteristics of a user profile from one computer and copying them to a second computer. This is accomplished through an auto-run program stored on a UD-RW flash drive device. Such a system will be useful for those with disabilities by allowing them to easily set the interaction characteristics of any computer they encounter to their ""home"" settings.', 'doi': '10.1145/1168987.1169047', 'url': 'https://doi.org/10.1145/1168987.1169047', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'The personal portable profile project', 'author': 'Liffick, Blaise W. and Zoppetti, Gary and Shearer, Shane', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169047'}"
A prototype of google interfaces modified for simplifying interaction for blind users,10.1145/1168987.1169048,"In this study we present a SW prototype developed within the framework of a research project aiming at improving the usability of search engines for blind users who interact via screen reader and voice synthesizer. Following the eight specific guidelines we proposed for simplifying interaction with search engines using assistive technology, we redesigned Google user interfaces (i.e. simple search and result pages) by using XSL Transformations, Google APIs and PERL technologies. A remote test with 12 totally blind users was carried out in order to evaluate the proposed prototype. Collected results highlight ways in which Google interfaces could be modified in order to improve usability for the blind. In our demo we will show how interaction with the modified Google UIs is simplified and how the time for reaching the most important elements (i.e. first query result, next result page, etc.) is shortened in comparison to interaction with the original Google UIs. The demo uses the JAWS screen reader for announcing the UI contents.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, blind, search engine, usability, user interface design', 'numpages': '2', 'pages': '267–268', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this study we present a SW prototype developed within the framework of a research project aiming at improving the usability of search engines for blind users who interact via screen reader and voice synthesizer. Following the eight specific guidelines we proposed for simplifying interaction with search engines using assistive technology, we redesigned Google user interfaces (i.e. simple search and result pages) by using XSL Transformations, Google APIs and PERL technologies. A remote test with 12 totally blind users was carried out in order to evaluate the proposed prototype. Collected results highlight ways in which Google interfaces could be modified in order to improve usability for the blind. In our demo we will show how interaction with the modified Google UIs is simplified and how the time for reaching the most important elements (i.e. first query result, next result page, etc.) is shortened in comparison to interaction with the original Google UIs. The demo uses the JAWS screen reader for announcing the UI contents.', 'doi': '10.1145/1168987.1169048', 'url': 'https://doi.org/10.1145/1168987.1169048', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A prototype of google interfaces modified for simplifying interaction for blind users', 'author': 'Andronico, Patrizia and Buzzi, Marina and Castillo, Carlos and Leporini, Barbara', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169048'}"
Functional web accessibility techniques and tools from the university of Illinois,10.1145/1168987.1169049,For web developers to create functionally accessible web resources they need more than general guidelines and tools that provide them with lists of manual accessibility checks. Web developers need specific web accessibility techniques and tools that help them verify they have correctly implemented the techniques. The techniques also need to support the wider concepts of the web of interoperability and device independence. The CITES/DRES Functional Web Accessibility Best Practices provide developers with specific techniques and requirements to implement Section 508 and W3C WCAG 1.0 requirements. The use of the Functional Web Accessibility Evaluation (FAE) Tool and the Mozilla/Firefox accessibility extension provide free and open source tools to allow developers to verify they have used the best practices.,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, best practices, dynamic HTML, evaluation, firefox, mozilla, scripting and techniques, tools, web', 'numpages': '2', 'pages': '269–270', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'For web developers to create functionally accessible web resources they need more than general guidelines and tools that provide them with lists of manual accessibility checks. Web developers need specific web accessibility techniques and tools that help them verify they have correctly implemented the techniques. The techniques also need to support the wider concepts of the web of interoperability and device independence. The CITES/DRES Functional Web Accessibility Best Practices provide developers with specific techniques and requirements to implement Section 508 and W3C WCAG 1.0 requirements. The use of the Functional Web Accessibility Evaluation (FAE) Tool and the Mozilla/Firefox accessibility extension provide free and open source tools to allow developers to verify they have used the best practices.', 'doi': '10.1145/1168987.1169049', 'url': 'https://doi.org/10.1145/1168987.1169049', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Functional web accessibility techniques and tools from the university of Illinois', 'author': 'Gunderson, Jon and Rangin, Hadi Bargi and Hoyt, Nicholas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169049'}"
Introduction to the talking points project,10.1145/1168987.1169050,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'RFID, location awareness, visual impairment', 'numpages': '2', 'pages': '271–272', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1168987.1169050', 'url': 'https://doi.org/10.1145/1168987.1169050', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Introduction to the talking points project', 'author': 'Gifford, Scott and Knox, Jim and James, Jonathan and Prakash, Atul', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169050'}"
Improving non-visual web access using context,10.1145/1168987.1169051,"To browse the Web, blind people have to use screen readers, which process pages sequentially, making browsing timeconsuming. We present a prototype system, CSurf, which provides all features of a regular screen reader, but when a user follows a link, CSurf captures the context of the link and uses it to identify relevant information on the next page. CSurf rearranges the content of the next page, so, that the relevant information is read out first. A series experiments have been conducted to evaluate the performance of CSurf.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'CSurf, assistive device, context, information rearrangement, non-visual, partitioning, screen-reader, user interface, voice browsing, web navigation', 'numpages': '2', 'pages': '273–274', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'To browse the Web, blind people have to use screen readers, which process pages sequentially, making browsing timeconsuming. We present a prototype system, CSurf, which provides all features of a regular screen reader, but when a user follows a link, CSurf captures the context of the link and uses it to identify relevant information on the next page. CSurf rearranges the content of the next page, so, that the relevant information is read out first. A series experiments have been conducted to evaluate the performance of CSurf.', 'doi': '10.1145/1168987.1169051', 'url': 'https://doi.org/10.1145/1168987.1169051', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Improving non-visual web access using context', 'author': 'Mahmud, Jalal and Borodin, Yevgen and Das, Dipanjan and Ramakrishnan, I. V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169051'}"
VoxBoox: a system for automatic generation of interactive talking books,10.1145/1168987.1169052,"The VoxBoox system makes digital books accessible to visually impaired individuals via audio and voice. It automatically translates a book published in HTML to VoiceXML, and then further enhances this VoiceXML rendering of the book to enable listener-controlled dynamic aural navigation. The VoxBoox system has the following salient features: (i) it leverages existing infrastructure since the book that is to be made accessible need only be published digitally using HTML on the visual Web, (ii) it is based on accepted Web standards of HTML and VoiceXML and thus books can be made accessible inexpensively, and (iii) it is user-centered in that the listener (the user) has complete control over (aural) navigation of the book. In this paper, we present details of the technologies that make the VoxBoox system possible, as well as the details of the system itself. A prototype of the VoxBoox system is operational.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'numpages': '2', 'pages': '275–276', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The VoxBoox system makes digital books accessible to visually impaired individuals via audio and voice. It automatically translates a book published in HTML to VoiceXML, and then further enhances this VoiceXML rendering of the book to enable listener-controlled dynamic aural navigation. The VoxBoox system has the following salient features: (i) it leverages existing infrastructure since the book that is to be made accessible need only be published digitally using HTML on the visual Web, (ii) it is based on accepted Web standards of HTML and VoiceXML and thus books can be made accessible inexpensively, and (iii) it is user-centered in that the listener (the user) has complete control over (aural) navigation of the book. In this paper, we present details of the technologies that make the VoxBoox system possible, as well as the details of the system itself. A prototype of the VoxBoox system is operational.', 'doi': '10.1145/1168987.1169052', 'url': 'https://doi.org/10.1145/1168987.1169052', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'VoxBoox: a system for automatic generation of interactive talking books', 'author': 'Jain, Aanchal and Gupta, Gopal', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169052'}"
Accessibility now! teaching accessible computing at the introductory level,10.1145/1168987.1169053,"As ASSETS attendees, we are clearly interested in promoting accessibility in computing. One way to do this is to teach courses on the topic. Most such courses are aimed at upper-level students. But why wait? It's possible to teach accessibility immediately at the introductory level, thereby affecting a greater number of students. I offer a description of a course in computer science that accomplishes this.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, computer users, pedagogy, service learning, visually impaired', 'numpages': '2', 'pages': '277–278', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""As ASSETS attendees, we are clearly interested in promoting accessibility in computing. One way to do this is to teach courses on the topic. Most such courses are aimed at upper-level students. But why wait? It's possible to teach accessibility immediately at the introductory level, thereby affecting a greater number of students. I offer a description of a course in computer science that accomplishes this."", 'doi': '10.1145/1168987.1169053', 'url': 'https://doi.org/10.1145/1168987.1169053', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Accessibility now! teaching accessible computing at the introductory level', 'author': 'Rosmaita, Brian J.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169053'}"
A demonstration of the iCARE portable reader,10.1145/1168987.1169054,"This demonstration will show the features and function of the portable iCARE Reader device, which allows people who are blind or visually impaired to read books (and other forms of printed text) in a more natural and convenient way than current tabletop flatbed scanner systems.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'OCR, assistive technologies, flatbed scanner, iCARE project, portable iCARE reader, table-top iCARE reader, wearable iCARE reader', 'numpages': '2', 'pages': '279–280', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This demonstration will show the features and function of the portable iCARE Reader device, which allows people who are blind or visually impaired to read books (and other forms of printed text) in a more natural and convenient way than current tabletop flatbed scanner systems.', 'doi': '10.1145/1168987.1169054', 'url': 'https://doi.org/10.1145/1168987.1169054', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A demonstration of the iCARE portable reader', 'author': 'Hedgpeth, Terri and Black, Jr., John A. and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169054'}"
The impact of user research on product design case study: accessibility ecosystem for windows vista,10.1145/1168987.1169055,"This paper describes the impact of user research on the accessibility features of the Windows Vista operating system. Conducting user research for a complex and widely-used product requires assessing a wide-range of users, experiences, and an ecosystem of PC hardware and software. Our user research for Windows XP gave us a greater understanding of the user's selfperception of their abilities. We also uncovered three pivotal usability issues: awareness, discoverability, and learnability. To address these issues for Windows Vista, we iteratively researched the product while focusing on universal design. The impact of this research resulted in design changes to the following major accessibility areas: an enhanced entry-point, a recommendation process that maps user needs to relevant accessibility components, and enhanced features of Windows Speech Recognition.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, aging, assistive technology, speech recognition', 'numpages': '2', 'pages': '281–282', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper describes the impact of user research on the accessibility features of the Windows Vista operating system. Conducting user research for a complex and widely-used product requires assessing a wide-range of users, experiences, and an ecosystem of PC hardware and software. Our user research for Windows XP gave us a greater understanding of the user's selfperception of their abilities. We also uncovered three pivotal usability issues: awareness, discoverability, and learnability. To address these issues for Windows Vista, we iteratively researched the product while focusing on universal design. The impact of this research resulted in design changes to the following major accessibility areas: an enhanced entry-point, a recommendation process that maps user needs to relevant accessibility components, and enhanced features of Windows Speech Recognition."", 'doi': '10.1145/1168987.1169055', 'url': 'https://doi.org/10.1145/1168987.1169055', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'The impact of user research on product design case study: accessibility ecosystem for windows vista', 'author': 'Perkins, Annuska and Cohene, Tira', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169055'}"
DuckCall: tackling the first hundred yards problem,10.1145/1168987.1169056,We describe a system that supports travel planning for a user with a cognitive impairment.,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'TV interface, cognitive impairments, reminders, social isolation, transportation access, trip planning', 'numpages': '2', 'pages': '283–284', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We describe a system that supports travel planning for a user with a cognitive impairment.', 'doi': '10.1145/1168987.1169056', 'url': 'https://doi.org/10.1145/1168987.1169056', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'DuckCall: tackling the first hundred yards problem', 'author': 'Fickas, Stephen and Pataky, Craig and Chen, Zebin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169056'}"
"An extensible, scalable browser-based architecture for synchronous and asynchronous communication and collaboration systems for deaf and hearing individuals",10.1145/1168987.1169057,"To facilitate face-to-face conversation between deaf and hearing team-members, we created a cross-platform, browser-based, persistent-content text-as-you-type system that aggregates each individual's utterances in revisable personal notes on a userconfigurable multi-person workspace. The system increases the fluidity of real time interaction, makes it easier to keep track of an individual's contributions over time, and supports new patterns of interaction. It has also become an interesting case of universal design: by rethinking web-based chat for deaf users, we have developed a platform with promise for the general population.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'CSCW, accessibility, assistive technology, chat, collaboration, deafness, web 2.0', 'numpages': '2', 'pages': '285–286', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""To facilitate face-to-face conversation between deaf and hearing team-members, we created a cross-platform, browser-based, persistent-content text-as-you-type system that aggregates each individual's utterances in revisable personal notes on a userconfigurable multi-person workspace. The system increases the fluidity of real time interaction, makes it easier to keep track of an individual's contributions over time, and supports new patterns of interaction. It has also become an interesting case of universal design: by rethinking web-based chat for deaf users, we have developed a platform with promise for the general population."", 'doi': '10.1145/1168987.1169057', 'url': 'https://doi.org/10.1145/1168987.1169057', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'An extensible, scalable browser-based architecture for synchronous and asynchronous communication and collaboration systems for deaf and hearing individuals', 'author': 'Schull, Jonathan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169057'}"
"""Beyond Perceivability"": critical requirements for universal design of information",10.1145/1168987.1169058,"This paper addresses the importance of cognitive accessibility and cognitive usability as critical requirements for universal design of information. Information should not be said to be accessed unless its content is cognitively internalized or understood by the user. Accessibility of information, therefore, should be evaluated not only for its perceivability but also for its understandability. We proposed a new cognitive walkthrough (CW) method whose CW questions were formulated based on an extended HCI model that distinguishes between perceiving and understanding. Applied to a Web design evaluation study, the extended CW was shown to be more effective in identifying accessibility and usability problems while remaining as efficient as the currently-practiced CW.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'HCI model, cognitive accessibility, cognitive usability, perceiving, understanding', 'numpages': '2', 'pages': '287–288', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper addresses the importance of cognitive accessibility and cognitive usability as critical requirements for universal design of information. Information should not be said to be accessed unless its content is cognitively internalized or understood by the user. Accessibility of information, therefore, should be evaluated not only for its perceivability but also for its understandability. We proposed a new cognitive walkthrough (CW) method whose CW questions were formulated based on an extended HCI model that distinguishes between perceiving and understanding. Applied to a Web design evaluation study, the extended CW was shown to be more effective in identifying accessibility and usability problems while remaining as efficient as the currently-practiced CW.', 'doi': '10.1145/1168987.1169058', 'url': 'https://doi.org/10.1145/1168987.1169058', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': '""Beyond Perceivability"": critical requirements for universal design of information', 'author': 'Kato, Takashi and Hori, Masahiro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169058'}"
Session details: Student research competition,10.1145/3245633,Abstract not available,"{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3245633', 'url': 'https://doi.org/10.1145/3245633', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Session details: Student research competition', 'author': 'Lewis, C.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3245633'}"
Task analysis for sonification applications usability evaluation,10.1145/1168987.1169060,"This paper proposes a tasks analysis of sonification applications for usability inspection. The analysis is based on a unified HCI Sonification Application Model. The tasks are based on three different perspectives on how the data being transformed into sound representation as well as from three different points of view including users, interaction and application. The input and output of the transformations are also included in this analysis as the final interfaces and sound representations of the applications.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'human computer interaction (HCI), sonification, task analysis, task descriptions, usability, usability inspection', 'numpages': '2', 'pages': '289–290', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper proposes a tasks analysis of sonification applications for usability inspection. The analysis is based on a unified HCI Sonification Application Model. The tasks are based on three different perspectives on how the data being transformed into sound representation as well as from three different points of view including users, interaction and application. The input and output of the transformations are also included in this analysis as the final interfaces and sound representations of the applications.', 'doi': '10.1145/1168987.1169060', 'url': 'https://doi.org/10.1145/1168987.1169060', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Task analysis for sonification applications usability evaluation', 'author': 'Ibrahim, Ag Asri Ag', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169060'}"
WISE: a wizard interface supporting enhanced usability,10.1145/1168987.1169061,"The current state of software which targets older adults' ability to use computers focuses on physical issues while largely ignoring the cognitive issues. As a larger percentage of Americans are considered ""old"" (60+), the lack of a system tailored to the needs of this age demographic has resulted in a part of the population that is disconnected from the rest of the world. This paper describes WISE, an alternative OS and application UI that specifically targets the cognitive deficits of older adults.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, age-related challenges, effective cognitive strategy prompting, gerontology, linear interaction, user-centered design', 'numpages': '2', 'pages': '291–292', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The current state of software which targets older adults\' ability to use computers focuses on physical issues while largely ignoring the cognitive issues. As a larger percentage of Americans are considered ""old"" (60+), the lack of a system tailored to the needs of this age demographic has resulted in a part of the population that is disconnected from the rest of the world. This paper describes WISE, an alternative OS and application UI that specifically targets the cognitive deficits of older adults.', 'doi': '10.1145/1168987.1169061', 'url': 'https://doi.org/10.1145/1168987.1169061', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'WISE: a wizard interface supporting enhanced usability', 'author': 'Hailpern, Joshua M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169061'}"
Designing assistive technology for blind users,10.1145/1168987.1169062,"This project reports on an observational and interview study of a non-sighted person to develop design insights for enhancing interactions between a blind person and everyday technological artifacts found in their home such as wristwatches, cell phones or software applications. Analyzing situations where work-arounds compensate for task failures reveals important insights for future artifact design for the blind such as the value of socialization, tactile and audio feedback, and facilitation of user independence.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'PRInCiPleS, assistive technology, design, human computer interaction, technology biographies', 'numpages': '2', 'pages': '293–294', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This project reports on an observational and interview study of a non-sighted person to develop design insights for enhancing interactions between a blind person and everyday technological artifacts found in their home such as wristwatches, cell phones or software applications. Analyzing situations where work-arounds compensate for task failures reveals important insights for future artifact design for the blind such as the value of socialization, tactile and audio feedback, and facilitation of user independence.', 'doi': '10.1145/1168987.1169062', 'url': 'https://doi.org/10.1145/1168987.1169062', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Designing assistive technology for blind users', 'author': 'Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169062'}"
A mixed method for evaluating input devices with older persons,10.1145/1168987.1169063,"This research is an exploratory study which introduces a mixed method in evaluating common input devices. The method includes both quantitative and qualitative approaches and considers both subjective and objective measures. The study incorporates psychometric tests to measure user ability, introduces real tasks in the evaluation, and interviews users to elicit their opinions regarding the important qualities of preferred devices. A mouse, a tablet-with-stylus and a touch screen have been evaluated in two tasks: browsing a website and playing a card game. This paper shows the mixed method has made possible a more nuanced understanding of the use of input devices by older persons.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'evaluation method, experimental design, input device', 'numpages': '2', 'pages': '295–296', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This research is an exploratory study which introduces a mixed method in evaluating common input devices. The method includes both quantitative and qualitative approaches and considers both subjective and objective measures. The study incorporates psychometric tests to measure user ability, introduces real tasks in the evaluation, and interviews users to elicit their opinions regarding the important qualities of preferred devices. A mouse, a tablet-with-stylus and a touch screen have been evaluated in two tasks: browsing a website and playing a card game. This paper shows the mixed method has made possible a more nuanced understanding of the use of input devices by older persons.', 'doi': '10.1145/1168987.1169063', 'url': 'https://doi.org/10.1145/1168987.1169063', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A mixed method for evaluating input devices with older persons', 'author': 'Mahmud, Murni', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169063'}"
Self-adapting user interfaces as assistive technology for handheld mobile devices,10.1145/1168987.1169064,"The accessibility of handheld mobile devices is a unique problem domain. They present with a small form factor, constraining display size, and making serious demands on user mobility. Existing assistive technology tackles these problems with bespoke solutions and text-to-speech augmentation, bulking out the device, and forcing visual metaphors upon blind users. Stepping away from such ""bolt-on"" accessibility, this research revisits the processes by which user interfaces are designed, constructing a model of user interface development that allows for dynamic adaptation of the interface to match individual user capability profiles. In doing so, it abstracts content meaning from presentation, mapping interaction metaphors to categorized user capabilities within individual design spaces (visual, sonic, and haptic) and interaction metaphors to relevant content meaning.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, capability model, design space, self-adaptation', 'numpages': '2', 'pages': '297–298', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The accessibility of handheld mobile devices is a unique problem domain. They present with a small form factor, constraining display size, and making serious demands on user mobility. Existing assistive technology tackles these problems with bespoke solutions and text-to-speech augmentation, bulking out the device, and forcing visual metaphors upon blind users. Stepping away from such ""bolt-on"" accessibility, this research revisits the processes by which user interfaces are designed, constructing a model of user interface development that allows for dynamic adaptation of the interface to match individual user capability profiles. In doing so, it abstracts content meaning from presentation, mapping interaction metaphors to categorized user capabilities within individual design spaces (visual, sonic, and haptic) and interaction metaphors to relevant content meaning.', 'doi': '10.1145/1168987.1169064', 'url': 'https://doi.org/10.1145/1168987.1169064', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Self-adapting user interfaces as assistive technology for handheld mobile devices', 'author': 'Dodd, Robert', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169064'}"
Usability and accessibility issues in the localization of assistive technology,10.1145/1168987.1169065,"People with disabilities are faced with several barriers to computer usage. Various companies provide assistive software that makes computer usage possible for the population with disabilities. While increased awareness of disability issues has resulted in the formulation of guidelines for developing accessible software, such guidelines do not guarantee that the end product will be optimal for a person with a disability [5]. During localization of software it is important to understand the needs and requirements and target culture of users, which is beyond mere translation of the interface language. This project was carried out to provide broad design guidelines which are driven by usability and accessibility issues that were uncovered during the evaluation of an assistive technology software package.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'accessibility, assistive technology, design guidelines, localization, usability', 'numpages': '2', 'pages': '299–300', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with disabilities are faced with several barriers to computer usage. Various companies provide assistive software that makes computer usage possible for the population with disabilities. While increased awareness of disability issues has resulted in the formulation of guidelines for developing accessible software, such guidelines do not guarantee that the end product will be optimal for a person with a disability [5]. During localization of software it is important to understand the needs and requirements and target culture of users, which is beyond mere translation of the interface language. This project was carried out to provide broad design guidelines which are driven by usability and accessibility issues that were uncovered during the evaluation of an assistive technology software package.', 'doi': '10.1145/1168987.1169065', 'url': 'https://doi.org/10.1145/1168987.1169065', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'Usability and accessibility issues in the localization of assistive technology', 'author': 'Jhangiani, Ira', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169065'}"
A flexible VXML interpreter for non-visual web access,10.1145/1168987.1169066,"VoiceXML (VXML) is a W3C's standard for specifying interactive dialogs. It finds multiple uses in variousWeb applications. VXML can also be used in non-visual Web browsing. There is no suitable, complete, open-source, flexible VXML interpreter to process VXML dialogs. My project is focusing on developing a VXML interpreter, VXMLSurf, that will be fully compliant with VXML 2.0 specifications and geared toward accessing Web content. VXMLSurf implements a number of extended features that provide blind users with more control over interactive browsing dialogs. VXMLSurf is a part of the HearSay project for developing a non-visual Web browser. The goal of the project is to make the Web more accessible for blind people.","{'series': ""Assets '06"", 'location': 'Portland, Oregon, USA', 'keywords': 'VXML, VXMLSurf, interpreter, non-visual, screen-reader, user interface, voice browsing, voiceXML, web navigation', 'numpages': '2', 'pages': '301–302', 'booktitle': 'Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""VoiceXML (VXML) is a W3C's standard for specifying interactive dialogs. It finds multiple uses in variousWeb applications. VXML can also be used in non-visual Web browsing. There is no suitable, complete, open-source, flexible VXML interpreter to process VXML dialogs. My project is focusing on developing a VXML interpreter, VXMLSurf, that will be fully compliant with VXML 2.0 specifications and geared toward accessing Web content. VXMLSurf implements a number of extended features that provide blind users with more control over interactive browsing dialogs. VXMLSurf is a part of the HearSay project for developing a non-visual Web browser. The goal of the project is to make the Web more accessible for blind people."", 'doi': '10.1145/1168987.1169066', 'url': 'https://doi.org/10.1145/1168987.1169066', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '1595932909', 'year': '2006', 'title': 'A flexible VXML interpreter for non-visual web access', 'author': 'Borodin, Yevgen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1168987.1169066'}"