Title,DOI,Abstract,BibTeX
Session details: Keynote address,10.1145/3252455,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252455', 'url': 'https://doi.org/10.1145/3252455', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Keynote address', 'author': 'Trewin, Shari', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252455'}"
Using information technology to assist people with disabilities,10.1145/1639642.1639644,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'remote monitoring, human-machine interfaces, assistive technology', 'numpages': '2', 'pages': '1–2', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/1639642.1639644', 'url': 'https://doi.org/10.1145/1639642.1639644', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Using information technology to assist people with disabilities', 'author': 'Cooper, Rory', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639644'}"
Session details: Cognitive accessibility,10.1145/3252456,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252456', 'url': 'https://doi.org/10.1145/3252456', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Cognitive accessibility', 'author': 'Lewis, Clayton', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252456'}"
Comparing evaluation techniques for text readability software for adults with intellectual disabilities,10.1145/1639642.1639646,"In this paper, we compare alternative techniques for evaluating a software system for simplifying the readability of texts for adults with mild intellectual disabilities (ID). We introduce our research on the development of software to automatically simplify news articles, display them, and read them aloud for adults with ID. Using a Wizard-of-Oz prototype, we conducted experiments with a group of adults with ID to test alternative formats of questions to measure comprehension of the information in the news articles. We have found that some forms of questions work well at measuring the difficulty level of a text: multiple-choice questions with three answer choices, each illustrated with clip-art or a photo. Some types of questions do a poor job: yes/no questions and Likert-scale questions in which participants report their perception of the text's difficulty level. Our findings inform the design of future evaluation studies of computational linguistic software for adults with ID; this study may also be of interest to researchers conducting usability studies or other surveys with adults with ID.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'assistive technology, intellectual disabilities, natural language processing, text comprehension, text readability assessment', 'numpages': '8', 'pages': '3–10', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this paper, we compare alternative techniques for evaluating a software system for simplifying the readability of texts for adults with mild intellectual disabilities (ID). We introduce our research on the development of software to automatically simplify news articles, display them, and read them aloud for adults with ID. Using a Wizard-of-Oz prototype, we conducted experiments with a group of adults with ID to test alternative formats of questions to measure comprehension of the information in the news articles. We have found that some forms of questions work well at measuring the difficulty level of a text: multiple-choice questions with three answer choices, each illustrated with clip-art or a photo. Some types of questions do a poor job: yes/no questions and Likert-scale questions in which participants report their perception of the text's difficulty level. Our findings inform the design of future evaluation studies of computational linguistic software for adults with ID; this study may also be of interest to researchers conducting usability studies or other surveys with adults with ID."", 'doi': '10.1145/1639642.1639646', 'url': 'https://doi.org/10.1145/1639642.1639646', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Comparing evaluation techniques for text readability software for adults with intellectual disabilities', 'author': ""Huenerfauth, Matt and Feng, Lijun and Elhadad, No\\'{e}mie"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639646'}"
Designing judicious interactions for cognitive assistance: the acts of assistance approach,10.1145/1639642.1639647,"The completion of complex activities of daily living (ADL) like meal preparation is a key concept for achieving autonomous living. Due to cognitive impairments, some people need to be supported when performing ADL. In this paper, we present a technological approach to guide people with cognitive impairments to complete complex activities. The assistance is provided in the form of pervasive human-machine interactions (HMI), that encourage the person to complete some actions to settle the difficulty identified by the system. These HMI are called ""acts of assistance"". This approach was implemented in Archipel, a cognitive orthosis developed at the DOMUS Laboratory, University of Sherbrooke (Canada). An evaluation of the prototype was conducted around meal preparation activities, involving 12 people with intellectual disabilities. This study demonstrates that our approach is promising.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'activity monitoring, assistance generation, cognitive assistance, pervasive HMI, speech-acts theory', 'numpages': '8', 'pages': '11–18', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The completion of complex activities of daily living (ADL) like meal preparation is a key concept for achieving autonomous living. Due to cognitive impairments, some people need to be supported when performing ADL. In this paper, we present a technological approach to guide people with cognitive impairments to complete complex activities. The assistance is provided in the form of pervasive human-machine interactions (HMI), that encourage the person to complete some actions to settle the difficulty identified by the system. These HMI are called ""acts of assistance"". This approach was implemented in Archipel, a cognitive orthosis developed at the DOMUS Laboratory, University of Sherbrooke (Canada). An evaluation of the prototype was conducted around meal preparation activities, involving 12 people with intellectual disabilities. This study demonstrates that our approach is promising.', 'doi': '10.1145/1639642.1639647', 'url': 'https://doi.org/10.1145/1639642.1639647', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Designing judicious interactions for cognitive assistance: the acts of assistance approach', 'author': ""Bauchet, J\\'{e}r\\'{e}my and Pigot, H\\'{e}l\\`{e}ne and Giroux, Sylvain and Lussier-Desrochers, Dany and Lachapelle, Yves and Mokhtari, Mounir"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639647'}"
Context-aware prompting to transition autonomously through vocational tasks for individuals with cognitive impairments,10.1145/1639642.1639648,"A challenge to individuals with cognitive impairments in workplaces is how to remain engaged, recall task routines, and transition autonomously across tasks in a way relying on limited cognitive capacity. A novel task prompting system is presented with an aim to increase workplace and life independence for people with traumatic brain injury, cerebral palsy, intellectual disability, schizophrenia, and Down syndromes. This paper describes an approach to providing distributed cognition support of work engagement for persons with cognitive disabilities. The unique strength of the system is the ability to provide unique-to-the-user prompts that are triggered by context. As this population is very sensitive to issues of abstraction (e.g. icons) and presents the designer with the need to tailor prompts to a 'universe-of-one' the use of picture or verbal cues specific to each user and context is implemented. The key to the approach is to spread the context awareness across the system, with the context being flagged by beacon sources and the appropriate response being evoked by displaying the appropriate task prompting cues indexed by the intersection of specific end-user and context ID embedded in the beacons. By separating the context trigger from the pictorial or verbal response, responses can be updated independently of the rest of the installed system, and a single beacon source can trigger multiple responses in the PDA depending on the end-user and their specific tasks. A prototype is built and tested in field experiments involving eight individuals with cognitive impairments. The experimental results show the task load of the human-device interface is low or very low and the capabilities of helping with task engagement are high and reliable.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'cognitively impaired, social services, task prompting, ubiquitous computing', 'numpages': '8', 'pages': '19–26', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""A challenge to individuals with cognitive impairments in workplaces is how to remain engaged, recall task routines, and transition autonomously across tasks in a way relying on limited cognitive capacity. A novel task prompting system is presented with an aim to increase workplace and life independence for people with traumatic brain injury, cerebral palsy, intellectual disability, schizophrenia, and Down syndromes. This paper describes an approach to providing distributed cognition support of work engagement for persons with cognitive disabilities. The unique strength of the system is the ability to provide unique-to-the-user prompts that are triggered by context. As this population is very sensitive to issues of abstraction (e.g. icons) and presents the designer with the need to tailor prompts to a 'universe-of-one' the use of picture or verbal cues specific to each user and context is implemented. The key to the approach is to spread the context awareness across the system, with the context being flagged by beacon sources and the appropriate response being evoked by displaying the appropriate task prompting cues indexed by the intersection of specific end-user and context ID embedded in the beacons. By separating the context trigger from the pictorial or verbal response, responses can be updated independently of the rest of the installed system, and a single beacon source can trigger multiple responses in the PDA depending on the end-user and their specific tasks. A prototype is built and tested in field experiments involving eight individuals with cognitive impairments. The experimental results show the task load of the human-device interface is low or very low and the capabilities of helping with task engagement are high and reliable."", 'doi': '10.1145/1639642.1639648', 'url': 'https://doi.org/10.1145/1639642.1639648', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Context-aware prompting to transition autonomously through vocational tasks for individuals with cognitive impairments', 'author': 'Chang, Yao-Jen and Chang, Wan Chih and Wang, Tsen-Yung', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639648'}"
Customizing directions in an automated wayfinding system for individuals with cognitive impairment,10.1145/1639642.1639649,"Individuals with cognitive impairments would prefer to live independently, however issues in wayfinding prevent many from fully living, working, and participating in their community. Our research has focused on designing, prototyping, and evaluating a mobile wayfinding system to aid such individuals. Building on the feedback gathered from potential users, we have implemented the system's automated direction selection functionality. Using a decision-theoretic approach, we believe we can create better wayfinding experience that assists users to reach their destination more intuitively than traditional navigation systems. This paper describes the system and results from a study using system-generated directions that inform us of key customization factors that would provide improved wayfinding assistance for individual users.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'Markov decision process, cognitive impairments, user interface, wayfinding', 'numpages': '8', 'pages': '27–34', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Individuals with cognitive impairments would prefer to live independently, however issues in wayfinding prevent many from fully living, working, and participating in their community. Our research has focused on designing, prototyping, and evaluating a mobile wayfinding system to aid such individuals. Building on the feedback gathered from potential users, we have implemented the system's automated direction selection functionality. Using a decision-theoretic approach, we believe we can create better wayfinding experience that assists users to reach their destination more intuitively than traditional navigation systems. This paper describes the system and results from a study using system-generated directions that inform us of key customization factors that would provide improved wayfinding assistance for individual users."", 'doi': '10.1145/1639642.1639649', 'url': 'https://doi.org/10.1145/1639642.1639649', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Customizing directions in an automated wayfinding system for individuals with cognitive impairment', 'author': 'Liu, Alan L. and Hile, Harlan and Borriello, Gaetano and Brown, Pat A. and Harniss, Mark and Kautz, Henry and Johnson, Kurt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639649'}"
Session details: Getting around and having fun,10.1145/3252457,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252457', 'url': 'https://doi.org/10.1145/3252457', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Getting around and having fun', 'author': 'Leventhal, Laura', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252457'}"
Usability of a multimodal videogame to improve navigation skills for blind children,10.1145/1639642.1639651,"This work presents an evaluation study on the usability of a haptic device and a sound-based videogame for the development and use of orientation and mobility (O&amp;M) skills in closed, unfamiliar spaces by blind, school-aged children. A usability evaluation was implemented for a haptic device especially designed for this project (Digital Clock Carpet) and a 3D videogame (MOVA3D), in order to redesign and improve the usability, as well as to learn of its acceptance and the degree of the user's satisfaction with the interaction with these products for O&amp;M purposes. The results show that both the haptic device and the videogame are usable, accepted and pleasant regarding their use by blind children, and that they are ready to be used in the following stage, which will determine their impact on the development and use of O&amp;M skills.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'blind children, haptic and audio interfaces, navigation, virtual environments', 'numpages': '8', 'pages': '35–42', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This work presents an evaluation study on the usability of a haptic device and a sound-based videogame for the development and use of orientation and mobility (O&amp;M) skills in closed, unfamiliar spaces by blind, school-aged children. A usability evaluation was implemented for a haptic device especially designed for this project (Digital Clock Carpet) and a 3D videogame (MOVA3D), in order to redesign and improve the usability, as well as to learn of its acceptance and the degree of the user's satisfaction with the interaction with these products for O&amp;M purposes. The results show that both the haptic device and the videogame are usable, accepted and pleasant regarding their use by blind children, and that they are ready to be used in the following stage, which will determine their impact on the development and use of O&amp;M skills."", 'doi': '10.1145/1639642.1639651', 'url': 'https://doi.org/10.1145/1639642.1639651', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Usability of a multimodal videogame to improve navigation skills for blind children', 'author': ""S\\'{a}nchez, Jaime and S\\'{a}enz, Mauricio and Ripoll, Miguel"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639651'}"
Instant tactile-audio map: enabling access to digital maps for people with visual impairment,10.1145/1639642.1639652,"In this paper, we propose an automatic approach, complete with a prototype system, for supporting instant access to maps for local navigation by people with visual impairment. The approach first detects and segments texts from a map image and recreates the remaining graphical parts in a tactile form which can be reproduced immediately through a tactile printer. Then, it generates an SVG (Scalable Vector Graphics) file, which integrates both text and graphical information. The tactile hardcopy and the SVG file together are used to provide a user with interactive access to the map image through a touchpad, resulting in a tactile-audio representation of the original input image. This supports real-time access to the map without tedious conversion by a sighted professional. Evaluations with six users who are blind show that the created tactile-audio maps from our prototype system convey the most important map information and are deemed as potentially useful for local navigation.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, multi-modal system, tactile map, visual impairment', 'numpages': '8', 'pages': '43–50', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we propose an automatic approach, complete with a prototype system, for supporting instant access to maps for local navigation by people with visual impairment. The approach first detects and segments texts from a map image and recreates the remaining graphical parts in a tactile form which can be reproduced immediately through a tactile printer. Then, it generates an SVG (Scalable Vector Graphics) file, which integrates both text and graphical information. The tactile hardcopy and the SVG file together are used to provide a user with interactive access to the map image through a touchpad, resulting in a tactile-audio representation of the original input image. This supports real-time access to the map without tedious conversion by a sighted professional. Evaluations with six users who are blind show that the created tactile-audio maps from our prototype system convey the most important map information and are deemed as potentially useful for local navigation.', 'doi': '10.1145/1639642.1639652', 'url': 'https://doi.org/10.1145/1639642.1639652', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'author': 'Wang, Zheshen and Li, Baoxin and Hedgpeth, Terri and Haven, Teresa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639652'}"
Rock Vibe: Rock Band® computer games for people with no or limited vision,10.1145/1639642.1639653,"This paper reports Rock Vibe, a modification performed on Rock Band® computer game to represent visual information using haptic and audio feedback to allow people with no or limited vision to enjoy the game. We modified the drumming activity of Rock Band® by providing users with vibrations on upper and lower arms to represent the drumhead cues and on ankle to represent the kick drum cue. Auditory information is used to provide feedback on correct and timely hit (with various drumming sounds) or errors (with a click sound). Computer's standard speech synthesizer is used to read the menu, song title, instruction and score. A series of evaluations with people with various levels of visual impairment were performed at different stages of the system development. We found that users were able to master the system almost immediately, with some users making no error halfway through the first song.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'blindness, games, haptic, visual impairment', 'numpages': '8', 'pages': '51–58', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper reports Rock Vibe, a modification performed on Rock Band® computer game to represent visual information using haptic and audio feedback to allow people with no or limited vision to enjoy the game. We modified the drumming activity of Rock Band® by providing users with vibrations on upper and lower arms to represent the drumhead cues and on ankle to represent the kick drum cue. Auditory information is used to provide feedback on correct and timely hit (with various drumming sounds) or errors (with a click sound). Computer's standard speech synthesizer is used to read the menu, song title, instruction and score. A series of evaluations with people with various levels of visual impairment were performed at different stages of the system development. We found that users were able to master the system almost immediately, with some users making no error halfway through the first song."", 'doi': '10.1145/1639642.1639653', 'url': 'https://doi.org/10.1145/1639642.1639653', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Rock Vibe: Rock Band® computer games for people with no or limited vision', 'author': 'Allman, Troy and Dhillon, Rupinder K. and Landau, Molly A.E. and Kurniawan, Sri H.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639653'}"
TextSL: a command-based virtual world interface for the visually impaired,10.1145/1639642.1639654,"The immersive graphics, large amount of user-generated content, and social interaction opportunities offered by popular virtual worlds, such as Second Life, could eventually make for a more interactive and informative World Wide Web. Unfortunately, virtual worlds are currently not accessible to users who are visually impaired. This paper presents the work on developing TextSL, a client for Second life that can be accessed with a screen reader. Users interact with TextSL using a command-based interface, which allows for performing a plethora of different actions on large numbers of objects and avatars; characterizing features of such virtual worlds. User studies confirm that a command-based interface is a feasible approach towards making virtual worlds accessible, as it allows screen reader users to explore Second Life, communicate with other avatars, and interact with objects as well as sighted users. Command-based exploration and object interaction is significantly slower, but communication can be performed with the same efficiency as in the Second Life viewer. We further identify that at least 31\% of the objects in Second Life lack a descriptive name, which is a significant barrier towards making virtual worlds accessible to users who are visually impaired.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'games, screen reader, virtual worlds, visual impairments', 'numpages': '8', 'pages': '59–66', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The immersive graphics, large amount of user-generated content, and social interaction opportunities offered by popular virtual worlds, such as Second Life, could eventually make for a more interactive and informative World Wide Web. Unfortunately, virtual worlds are currently not accessible to users who are visually impaired. This paper presents the work on developing TextSL, a client for Second life that can be accessed with a screen reader. Users interact with TextSL using a command-based interface, which allows for performing a plethora of different actions on large numbers of objects and avatars; characterizing features of such virtual worlds. User studies confirm that a command-based interface is a feasible approach towards making virtual worlds accessible, as it allows screen reader users to explore Second Life, communicate with other avatars, and interact with objects as well as sighted users. Command-based exploration and object interaction is significantly slower, but communication can be performed with the same efficiency as in the Second Life viewer. We further identify that at least 31\\% of the objects in Second Life lack a descriptive name, which is a significant barrier towards making virtual worlds accessible to users who are visually impaired.', 'doi': '10.1145/1639642.1639654', 'url': 'https://doi.org/10.1145/1639642.1639654', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'TextSL: a command-based virtual world interface for the visually impaired', 'author': 'Folmer, Eelke and Yuan, Bei and Carr, Dave and Sapre, Manjari', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639654'}"
Session details: Visual language,10.1145/3252458,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252458', 'url': 'https://doi.org/10.1145/3252458', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Visual language', 'author': 'Hanson, Vicki', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252458'}"
ClassInFocus: enabling improved visual attention strategies for deaf and hard of hearing students,10.1145/1639642.1639656,"Deaf and hard of hearing students must juggle their visual attention in current classroom settings. Managing many visual sources of information (instructor, interpreter or captions, slides or whiteboard, classmates, and personal notes) can be a challenge. ClassInFocus automatically notifies students of classroom changes, such as slide changes or new speakers, helping them employ more beneficial observing strategies. A user study of notification techniques shows that students who liked the notifications were more likely to visually utilize them to improve performance.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'classroom technology, deaf and hard of hearing users, multimedia conferencing technology', 'numpages': '8', 'pages': '67–74', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Deaf and hard of hearing students must juggle their visual attention in current classroom settings. Managing many visual sources of information (instructor, interpreter or captions, slides or whiteboard, classmates, and personal notes) can be a challenge. ClassInFocus automatically notifies students of classroom changes, such as slide changes or new speakers, helping them employ more beneficial observing strategies. A user study of notification techniques shows that students who liked the notifications were more likely to visually utilize them to improve performance.', 'doi': '10.1145/1639642.1639656', 'url': 'https://doi.org/10.1145/1639642.1639656', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'ClassInFocus: enabling improved visual attention strategies for deaf and hard of hearing students', 'author': 'Cavender, Anna C. and Bigham, Jeffrey P. and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639656'}"
Spatial and temporal pyramids for grammatical expression recognition of American sign language,10.1145/1639642.1639657,"Given that sign language is used as a primary means of communication by as many as two million deaf individuals in the U.S. and as augmentative communication by hearing individuals with a variety of disabilities, the development of robust, real-time sign language recognition technologies would be a major step forward in making computers equally accessible to everyone. However, most research in the field of sign language recognition has focused on the manual component of signs, despite the fact that there is critical grammatical information expressed through facial expressions and head gestures.We propose a novel framework for robust tracking and analysis of facial expression and head gestures, with an application to sign language recognition. We then apply it to recognition with excellent accuracy (≥=95\%) of two classes of grammatical expressions, namely wh-questions and negative expressions. Our method is signer-independent and builds on the popular ""bag-of-words"" model, utilizing spatial pyramids to model facial appearance and temporal pyramids to represent patterns of head pose changes.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'expression recognition, face tracking, head pose estimation, kernel codebooks, pyramid match kernel, sign language recognition, soft quantization, spatio-temporal pyramids', 'numpages': '8', 'pages': '75–82', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Given that sign language is used as a primary means of communication by as many as two million deaf individuals in the U.S. and as augmentative communication by hearing individuals with a variety of disabilities, the development of robust, real-time sign language recognition technologies would be a major step forward in making computers equally accessible to everyone. However, most research in the field of sign language recognition has focused on the manual component of signs, despite the fact that there is critical grammatical information expressed through facial expressions and head gestures.We propose a novel framework for robust tracking and analysis of facial expression and head gestures, with an application to sign language recognition. We then apply it to recognition with excellent accuracy (≥=95\\%) of two classes of grammatical expressions, namely wh-questions and negative expressions. Our method is signer-independent and builds on the popular ""bag-of-words"" model, utilizing spatial pyramids to model facial appearance and temporal pyramids to represent patterns of head pose changes.', 'doi': '10.1145/1639642.1639657', 'url': 'https://doi.org/10.1145/1639642.1639657', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Spatial and temporal pyramids for grammatical expression recognition of American sign language', 'author': 'Michael, Nicholas and Metaxas, Dimitris and Neidle, Carol', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639657'}"
Accessible motion-capture glove calibration protocol for recording sign language data from deaf subjects,10.1145/1639642.1639658,"Motion-capture recordings of sign language are used in research on automatic recognition of sign language or generation of sign language animations, which have accessibility applications for deaf users with low levels of written-language literacy. Motion-capture gloves are used to record the wearer's handshape. Unfortunately, these gloves require a time-consuming and inexact manual calibration process each time they are worn. This paper describes the design and evaluation of a new calibration protocol for motion-capture gloves, which is designed to make the process more efficient and to be accessible for participants who are deaf and use American Sign Language (ASL). The protocol was evaluated experimentally; deaf ASL signers wore the gloves, were calibrated (using the new protocol and using a calibration routine provided by the glove manufacturer), and were asked to perform sequences of ASL handshapes. A native ASL signer rated the correctness and understandability of the collected handshape data. The new protocol received significantly higher scores than the standard calibration. The protocol has been made freely available online, and it includes directions for the researcher, images and videos of how participants move their hands during the process, and directions for participants (as ASL videos and English text).","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'CyberGlove?, accessibility technology for people who are deaf, american sign language, animation, calibration, motion-capture glove', 'numpages': '8', 'pages': '83–90', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Motion-capture recordings of sign language are used in research on automatic recognition of sign language or generation of sign language animations, which have accessibility applications for deaf users with low levels of written-language literacy. Motion-capture gloves are used to record the wearer's handshape. Unfortunately, these gloves require a time-consuming and inexact manual calibration process each time they are worn. This paper describes the design and evaluation of a new calibration protocol for motion-capture gloves, which is designed to make the process more efficient and to be accessible for participants who are deaf and use American Sign Language (ASL). The protocol was evaluated experimentally; deaf ASL signers wore the gloves, were calibrated (using the new protocol and using a calibration routine provided by the glove manufacturer), and were asked to perform sequences of ASL handshapes. A native ASL signer rated the correctness and understandability of the collected handshape data. The new protocol received significantly higher scores than the standard calibration. The protocol has been made freely available online, and it includes directions for the researcher, images and videos of how participants move their hands during the process, and directions for participants (as ASL videos and English text)."", 'doi': '10.1145/1639642.1639658', 'url': 'https://doi.org/10.1145/1639642.1639658', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Accessible motion-capture glove calibration protocol for recording sign language data from deaf subjects', 'author': 'Lu, Pengfei and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639658'}"
Session details: Text entry and mobile devices,10.1145/3252459,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252459', 'url': 'https://doi.org/10.1145/3252459', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Text entry and mobile devices', 'author': ""S\\'{a}nchez, Jaime"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252459'}"
The one-key challenge: searching for a fast one-key text entry method,10.1145/1639642.1639660,"A new one-key text entry method is presented. SAK, for ""scanning ambiguous keyboard"", combines one-key physical input (including error correction) with three virtual letter keys and a SPACE key. The virtual letter keys are highlighted in sequence (""scanned"") and selected when the key bearing the desired letter receives focus. There is only one selection per letter. Selecting SPACE transfers scanning to a word-selection region, which presents a list of candidate words. A novel feature of SAK is multiple-letter-selection in a single scanning interval. In an evaluation with 12 participants, average entry speeds reached 5.11 wpm (all trials, 99\% accuracy) or 7.03 wpm (error-free trials). A modification using ""timer restart on selection"" allowed for more time and more selections per scanning interval. One participant performed extended trials (5 blocks x 5 phrases/block) with the modification and reached an average entry speed of 9.28 wpm.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'ambiguous keyboards, assistive technologies, keyboards, mobile computing, scanning keyboards, text entry', 'numpages': '8', 'pages': '91–98', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A new one-key text entry method is presented. SAK, for ""scanning ambiguous keyboard"", combines one-key physical input (including error correction) with three virtual letter keys and a SPACE key. The virtual letter keys are highlighted in sequence (""scanned"") and selected when the key bearing the desired letter receives focus. There is only one selection per letter. Selecting SPACE transfers scanning to a word-selection region, which presents a list of candidate words. A novel feature of SAK is multiple-letter-selection in a single scanning interval. In an evaluation with 12 participants, average entry speeds reached 5.11 wpm (all trials, 99\\% accuracy) or 7.03 wpm (error-free trials). A modification using ""timer restart on selection"" allowed for more time and more selections per scanning interval. One participant performed extended trials (5 blocks x 5 phrases/block) with the modification and reached an average entry speed of 9.28 wpm.', 'doi': '10.1145/1639642.1639660', 'url': 'https://doi.org/10.1145/1639642.1639660', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'The one-key challenge: searching for a fast one-key text entry method', 'author': 'MacKenzie, I. Scott', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639660'}"
NavTap: a long term study with excluded blind users,10.1145/1639642.1639661,"NavTap is a navigational method that enables blind users to input text in a mobile device by reducing the associated cognitive load.In this paper, we present studies that go beyond a laboratorial setting, exploring the methods' effectiveness and learnability as well as its influence on the users' daily lives. Eight blind users participated in designing the prototype (3 weeks) while five took part in the studies along 16 more weeks. Results gathered in controlled weekly sessions and real life usage logs enabled us to better understand NavTap's advantages and limitations. The method revealed itself both as easy to learn and improve. Indeed, users were able to better control their mobile devices to send SMS and use other tasks that require text input such as managing a phonebook, from day one, in real-life settings.While individual user profiles play an important role in determining their evolution, even less capable users (with age-induced impairments or cognitive difficulties), were able to perform the assigned tasks (sms, directory) both in the laboratory and in everyday use, showing continuous improvement to their skills. According to interviews, none were able to input text before. Nav-Tap dramatically changed their relation with mobile devices and noticeably improved their social interaction capabilities.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'blind, evaluation, mobile accessibility, text-entry', 'numpages': '8', 'pages': '99–106', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""NavTap is a navigational method that enables blind users to input text in a mobile device by reducing the associated cognitive load.In this paper, we present studies that go beyond a laboratorial setting, exploring the methods' effectiveness and learnability as well as its influence on the users' daily lives. Eight blind users participated in designing the prototype (3 weeks) while five took part in the studies along 16 more weeks. Results gathered in controlled weekly sessions and real life usage logs enabled us to better understand NavTap's advantages and limitations. The method revealed itself both as easy to learn and improve. Indeed, users were able to better control their mobile devices to send SMS and use other tasks that require text input such as managing a phonebook, from day one, in real-life settings.While individual user profiles play an important role in determining their evolution, even less capable users (with age-induced impairments or cognitive difficulties), were able to perform the assigned tasks (sms, directory) both in the laboratory and in everyday use, showing continuous improvement to their skills. According to interviews, none were able to input text before. Nav-Tap dramatically changed their relation with mobile devices and noticeably improved their social interaction capabilities."", 'doi': '10.1145/1639642.1639661', 'url': 'https://doi.org/10.1145/1639642.1639661', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'NavTap: a long term study with excluded blind users', 'author': 'Guerreiro, Tiago and Nicolau, Hugo and Jorge, Joaquim and Gon\\c{c}alves, Daniel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639661'}"
Haptic handheld wayfinder with pseudo-attraction force for pedestrians with visual impairments,10.1145/1639642.1639662,"When visually impaired pedestrians walk from one place to another by themselves, they must update their orientation and position to find their way and avoid obstacles and hazards. We present the design of a new haptic direction indicator, whose purpose is to help blind pedestrians travel a path and avoid hazards intuitively and safely by means of haptic navigation. The haptic direction indicator uses a novel kinesthetic perception method called the ""pseudo-attraction force"" technique, which exploits the nonlinear relationship between perceived and physical acceleration to generate a force sensation. In an experiment performed to evaluate with the haptic direction indicator, we found that visually impaired users could safely walk along a predefined route at their usual walking pace, independent of the existence of auditory information. These results demonstrate the utility and usability of the haptic direction indicator, but there is still room for improvement.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'asymmetric oscillation, maze task, wayfinding', 'numpages': '8', 'pages': '107–114', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'When visually impaired pedestrians walk from one place to another by themselves, they must update their orientation and position to find their way and avoid obstacles and hazards. We present the design of a new haptic direction indicator, whose purpose is to help blind pedestrians travel a path and avoid hazards intuitively and safely by means of haptic navigation. The haptic direction indicator uses a novel kinesthetic perception method called the ""pseudo-attraction force"" technique, which exploits the nonlinear relationship between perceived and physical acceleration to generate a force sensation. In an experiment performed to evaluate with the haptic direction indicator, we found that visually impaired users could safely walk along a predefined route at their usual walking pace, independent of the existence of auditory information. These results demonstrate the utility and usability of the haptic direction indicator, but there is still room for improvement.', 'doi': '10.1145/1639642.1639662', 'url': 'https://doi.org/10.1145/1639642.1639662', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Haptic handheld wayfinder with pseudo-attraction force for pedestrians with visual impairments', 'author': 'Amemiya, Tomohiro and Sugiyama, Hisashi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639662'}"
Freedom to roam: a study of mobile device adoption and accessibility for people with visual and motor disabilities,10.1145/1639642.1639663,"Mobile devices provide people with disabilities new opportunities to act independently in the world. However, these empowering devices have their own accessibility challenges. We present a formative study that examines how people with visual and motor disabilities select, adapt, and use mobile devices in their daily lives. We interviewed 20 participants with visual and motor disabilities and asked about their current use of mobile devices, including how they select them, how they use them while away from home, and how they adapt to accessibility challenges when on the go. Following the interviews, 19 participants completed a diary study in which they recorded their experiences using mobile devices for one week. Our results show that people with visual and motor disabilities use a variety of strategies to adapt inaccessible mobile devices and successfully use them to perform everyday tasks and navigate independently. We provide guidelines for more accessible and empowering mobile device design.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, blindness, diary study, low vision, mobile devices, mobile phones, motor impairment', 'numpages': '8', 'pages': '115–122', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Mobile devices provide people with disabilities new opportunities to act independently in the world. However, these empowering devices have their own accessibility challenges. We present a formative study that examines how people with visual and motor disabilities select, adapt, and use mobile devices in their daily lives. We interviewed 20 participants with visual and motor disabilities and asked about their current use of mobile devices, including how they select them, how they use them while away from home, and how they adapt to accessibility challenges when on the go. Following the interviews, 19 participants completed a diary study in which they recorded their experiences using mobile devices for one week. Our results show that people with visual and motor disabilities use a variety of strategies to adapt inaccessible mobile devices and successfully use them to perform everyday tasks and navigate independently. We provide guidelines for more accessible and empowering mobile device design.', 'doi': '10.1145/1639642.1639663', 'url': 'https://doi.org/10.1145/1639642.1639663', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Freedom to roam: a study of mobile device adoption and accessibility for people with visual and motor disabilities', 'author': 'Kane, Shaun K. and Jayant, Chandrika and Wobbrock, Jacob O. and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639663'}"
Session details: Web accessibility I,10.1145/3252460,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252460', 'url': 'https://doi.org/10.1145/3252460', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Web accessibility I', 'author': 'Yesilada, Yeliz', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252460'}"
Enriching web information scent for blind users,10.1145/1639642.1639665,"Link annotation with the accessibility level of the target Web page is an adaptive navigation support technique aimed at increasing blind users' orientation in Web sites. In this work, the accessibility level of a page is measured by exploiting data from evaluation reports produced by two automatic assessment tools. These tools support evaluation of accessibility and usability guideline-sets. As a result, links are annotated with a score that indicates the conformance of the target Web page to blind user accessibility and usability guidelines. A user test with 16 users was conducted in order to observe the strategies they followed when links were annotated with these scores. With annotated links, the navigation paradigm changed from sequential to browsing randomly through the subset of those links with high scores. Even if there was not a general agreement on the correspondence between scores and user perception of accessibility, users found annotations helpful when browsing through links related to a given topic.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'adaptive navigation, blind users, information scent, web accessibility', 'numpages': '8', 'pages': '123–130', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Link annotation with the accessibility level of the target Web page is an adaptive navigation support technique aimed at increasing blind users' orientation in Web sites. In this work, the accessibility level of a page is measured by exploiting data from evaluation reports produced by two automatic assessment tools. These tools support evaluation of accessibility and usability guideline-sets. As a result, links are annotated with a score that indicates the conformance of the target Web page to blind user accessibility and usability guidelines. A user test with 16 users was conducted in order to observe the strategies they followed when links were annotated with these scores. With annotated links, the navigation paradigm changed from sequential to browsing randomly through the subset of those links with high scores. Even if there was not a general agreement on the correspondence between scores and user perception of accessibility, users found annotations helpful when browsing through links related to a given topic."", 'doi': '10.1145/1639642.1639665', 'url': 'https://doi.org/10.1145/1639642.1639665', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Enriching web information scent for blind users', 'author': 'Vigo, Markel and Leporini, Barbara and Patern\\`{o}, Fabio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639665'}"
Validity and reliability of web accessibility guidelines,10.1145/1639642.1639666,"Although widely used,Web Content Accessibility Guidelines (WCAG) have not been studied from the viewpoint of their validity and reliability. WCAG 2.0 explicitly claim that they are based on ""testable"" criteria, but no scientific evidence exists that this is actually the case. Validity (how well all and only the true problems can be identified) and reliability (the extent to which different evaluations of the same page lead to same results) are key factors for quality of accessibility evaluation methods. They need to be well studied and understood for methods, and guidelines, that are expected to have a major impact.This paper presents an experiment aimed at finding out what is the validity and reliability of different checkpoints taken from WCAG 1.0 and WCAG 2.0. The experiment employed 35 young web developers with some knowledge on web accessibility. Although this is a small-scale experiment, unlikely to provide definite and general answers, results un-equivocally show that with respect to the kind of evaluators chosen in the experiment, checkpoints in general fare very low in terms of reliability, and that from this perspective WCAG 2.0 are not an improvement over WCAG 1.0.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility evaluation evaluation, web accessibility guidelines', 'numpages': '8', 'pages': '131–138', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Although widely used,Web Content Accessibility Guidelines (WCAG) have not been studied from the viewpoint of their validity and reliability. WCAG 2.0 explicitly claim that they are based on ""testable"" criteria, but no scientific evidence exists that this is actually the case. Validity (how well all and only the true problems can be identified) and reliability (the extent to which different evaluations of the same page lead to same results) are key factors for quality of accessibility evaluation methods. They need to be well studied and understood for methods, and guidelines, that are expected to have a major impact.This paper presents an experiment aimed at finding out what is the validity and reliability of different checkpoints taken from WCAG 1.0 and WCAG 2.0. The experiment employed 35 young web developers with some knowledge on web accessibility. Although this is a small-scale experiment, unlikely to provide definite and general answers, results un-equivocally show that with respect to the kind of evaluators chosen in the experiment, checkpoints in general fare very low in terms of reliability, and that from this perspective WCAG 2.0 are not an improvement over WCAG 1.0.', 'doi': '10.1145/1639642.1639666', 'url': 'https://doi.org/10.1145/1639642.1639666', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Validity and reliability of web accessibility guidelines', 'author': 'Brajnik, Giorgio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639666'}"
Session details: Working and learning,10.1145/3252461,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252461', 'url': 'https://doi.org/10.1145/3252461', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Working and learning', 'author': 'Barreto, Armando', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252461'}"
Evaluating prosodic cues as a means to disambiguate algebraic expressions: an empirical study,10.1145/1639642.1639668,"The automatic translation of written mathematical expressions to their spoken equivalent is a difficult task. Written mathematics makes use of specialized symbols and a 2-dimensional layout that is hard to translate into clear and unambiguous spoken words. Our approach is to use prosody to help listeners follow along to mathematical expressions spoken aloud with text-to-speech synthesized voices. To achieve this, we developed and empirically tested XSL transformation rules that automatically translate mathematical expressions marked-up with Presentation MathML into corresponding markup using the Speech Synthesis Markup Language (SSML). In this paper, we report on the results from an empirical study we conducted that showed that the simple insertion of pauses inside spoken mathematical expressions dramatically improved subjects' ability to disambiguate between two similar algebraic expressions. Result from our study should benefit designers of screen readers and related audio-based tools that produce spoken renderings of mathematical expressions.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'DAISY, MathML, SSML, accessibility, synthetic speech', 'numpages': '8', 'pages': '139–146', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The automatic translation of written mathematical expressions to their spoken equivalent is a difficult task. Written mathematics makes use of specialized symbols and a 2-dimensional layout that is hard to translate into clear and unambiguous spoken words. Our approach is to use prosody to help listeners follow along to mathematical expressions spoken aloud with text-to-speech synthesized voices. To achieve this, we developed and empirically tested XSL transformation rules that automatically translate mathematical expressions marked-up with Presentation MathML into corresponding markup using the Speech Synthesis Markup Language (SSML). In this paper, we report on the results from an empirical study we conducted that showed that the simple insertion of pauses inside spoken mathematical expressions dramatically improved subjects' ability to disambiguate between two similar algebraic expressions. Result from our study should benefit designers of screen readers and related audio-based tools that produce spoken renderings of mathematical expressions."", 'doi': '10.1145/1639642.1639668', 'url': 'https://doi.org/10.1145/1639642.1639668', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Evaluating prosodic cues as a means to disambiguate algebraic expressions: an empirical study', 'author': 'Gellenbeck, Ed and Stefik, Andreas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639668'}"
Making Microsoft Excel™: multimodal presentation of charts,10.1145/1639642.1639669,"Several solutions, based on aural and haptic feedback, have been developed to enable access to complex on-line information for people with visual impairments. Nevertheless, there are several components of widely used software applications that are still beyond the reach of screen readers and Braille displays.This paper investigates the non-visual accessibility issues associated with the graphing component of Microsoft Excel"". The goal is to provide flexible multi-modal navigation schemes which can help visually impaired users in comprehending Excel charts. The methodology identifies the need for 3 strategies used in interaction: exploratory, guided, and summarization. Switching between them supports the development of a mental model of a chart. Aural cues and commentaries are integrated in a haptic presentation to help understanding the presented chart. The methodology has been implemented using the Novint Falcon haptic device.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessible graphs, assistive technology, haptic', 'numpages': '8', 'pages': '147–154', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Several solutions, based on aural and haptic feedback, have been developed to enable access to complex on-line information for people with visual impairments. Nevertheless, there are several components of widely used software applications that are still beyond the reach of screen readers and Braille displays.This paper investigates the non-visual accessibility issues associated with the graphing component of Microsoft Excel"". The goal is to provide flexible multi-modal navigation schemes which can help visually impaired users in comprehending Excel charts. The methodology identifies the need for 3 strategies used in interaction: exploratory, guided, and summarization. Switching between them supports the development of a mental model of a chart. Aural cues and commentaries are integrated in a haptic presentation to help understanding the presented chart. The methodology has been implemented using the Novint Falcon haptic device.', 'doi': '10.1145/1639642.1639669', 'url': 'https://doi.org/10.1145/1639642.1639669', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Making Microsoft Excel™: multimodal presentation of charts', 'author': 'Abu Doush, Iyad and Pontelli, Enrico and Simon, Dominic and Son, Tran Cao and Ma, Ou', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639669'}"
Including accessibility within and beyond undergraduate computing courses,10.1145/1639642.1639670,"This paper presents a unique approach to undergraduate teaching in which accessibility topics are completely integrated throughout the curriculum, treating accessibility not as a separate topic, but rather as an integral part of design and development. Means of accomplishing this integration throughout the entire four-year curriculum are presented. We also describe how our expertise in accessible design has extended beyond the education of computer science and engineering students to include Web content authors across campus.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, disability, higher education, inclusion, older adults', 'numpages': '8', 'pages': '155–162', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents a unique approach to undergraduate teaching in which accessibility topics are completely integrated throughout the curriculum, treating accessibility not as a separate topic, but rather as an integral part of design and development. Means of accomplishing this integration throughout the entire four-year curriculum are presented. We also describe how our expertise in accessible design has extended beyond the education of computer science and engineering students to include Web content authors across campus.', 'doi': '10.1145/1639642.1639670', 'url': 'https://doi.org/10.1145/1639642.1639670', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Including accessibility within and beyond undergraduate computing courses', 'author': 'Waller, Annalu and Hanson, Vicki L. and Sloan, David', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639670'}"
Session details: Assisted communication,10.1145/3252462,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252462', 'url': 'https://doi.org/10.1145/3252462', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Assisted communication', 'author': 'Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252462'}"
Speaking through pictures: images vs. icons,10.1145/1639642.1639672,"People with aphasia, a condition that impairs the ability to understand or generate written or spoken language, are aided by assistive technology that helps them communicate through a vocabulary of icons. These systems are akin to language translation systems, translating icon arrangements into spoken or written language and vice versa. However, these icon-based systems have little vocabulary breadth or depth, making it difficult for people with aphasia to apply their usage to multiple real world situations. Pictures from the web are numerous, varied, and easily accessible and thus, could potentially address the small size issues of icon-based systems. We present results from two studies that investigate this potential and demonstrate that images can be as effective as icons when used as a replacement for English language communication. The first study uses elderly subjects to investigate the efficacy of images vs. icons in conveying word meaning; the second study examines the retention of word-level meaning by both images and icons with a population of aphasics. We conclude that images collected from the web are as functional as icons in conveying information and thus, are feasible to use in assistive technology that supports people with aphasia.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'aphasia, computerized visual communication (C-VIC), visual communication (VIC)', 'numpages': '8', 'pages': '163–170', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with aphasia, a condition that impairs the ability to understand or generate written or spoken language, are aided by assistive technology that helps them communicate through a vocabulary of icons. These systems are akin to language translation systems, translating icon arrangements into spoken or written language and vice versa. However, these icon-based systems have little vocabulary breadth or depth, making it difficult for people with aphasia to apply their usage to multiple real world situations. Pictures from the web are numerous, varied, and easily accessible and thus, could potentially address the small size issues of icon-based systems. We present results from two studies that investigate this potential and demonstrate that images can be as effective as icons when used as a replacement for English language communication. The first study uses elderly subjects to investigate the efficacy of images vs. icons in conveying word meaning; the second study examines the retention of word-level meaning by both images and icons with a population of aphasics. We conclude that images collected from the web are as functional as icons in conveying information and thus, are feasible to use in assistive technology that supports people with aphasia.', 'doi': '10.1145/1639642.1639672', 'url': 'https://doi.org/10.1145/1639642.1639672', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Speaking through pictures: images vs. icons', 'author': 'Ma, Xiaojuan and Boyd-Graber, Jordan and Nikolova, Sonya and Cook, Perry R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639672'}"
Better vocabularies for assistive communication aids: connecting terms using semantic networks and untrained annotators,10.1145/1639642.1639673,"The difficulties of navigating vocabulary in an assistive communication device are exacerbated for individuals with lexical access disorders like those due to aphasia. We present the design and implementation of a vocabulary network based on WordNet, a resource that attempts to model human semantic memory, that enables users to find words easily. To correct for the sparsity of links among words, we augment WordNet with additional connections derived from human judgments of semantic similarity collected in an online experiment. We evaluate the resulting system, the visual vocabulary for aphasia (ViVA), and describe its potential to adapt to a user's profile and enable faster search and improved navigation.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'adaptive tools, aphasia, assistive communication, semantic networks, visual vocabularies', 'numpages': '8', 'pages': '171–178', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The difficulties of navigating vocabulary in an assistive communication device are exacerbated for individuals with lexical access disorders like those due to aphasia. We present the design and implementation of a vocabulary network based on WordNet, a resource that attempts to model human semantic memory, that enables users to find words easily. To correct for the sparsity of links among words, we augment WordNet with additional connections derived from human judgments of semantic similarity collected in an online experiment. We evaluate the resulting system, the visual vocabulary for aphasia (ViVA), and describe its potential to adapt to a user's profile and enable faster search and improved navigation."", 'doi': '10.1145/1639642.1639673', 'url': 'https://doi.org/10.1145/1639642.1639673', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Better vocabularies for assistive communication aids: connecting terms using semantic networks and untrained annotators', 'author': 'Nikolova, Sonya and Boyd-Graber, Jordan and Fellbaum, Christiane and Cook, Perry', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639673'}"
"Let's stay in touch: sharing photos for restoring social connectedness between rehabilitants, friends and family",10.1145/1639642.1639674,"A case study on the use of an existing photo sharing application in a spinal cord lesion rehabilitation centre is presented. The study focuses on enhancing social connectedness through sharing photos between rehabilitants and their families and friends. Four rehabilitants participated in this study for 6-7 weeks. Most photos sent related to sharing things in everyday life and keeping the rehabilitant informed about regular events. The combination of interviews and content analysis reveals that only a minority of the photos lead to follow-up communication about the contents of the photos. Rehabilitants were positively surprised how spontaneous photo sharing simplified the way they could reconnect to their friends and family, without the immediate need or obligation to engage in a (phone) conversation.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'photo sharing, rehabilitation, social connectedness', 'numpages': '8', 'pages': '179–186', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A case study on the use of an existing photo sharing application in a spinal cord lesion rehabilitation centre is presented. The study focuses on enhancing social connectedness through sharing photos between rehabilitants and their families and friends. Four rehabilitants participated in this study for 6-7 weeks. Most photos sent related to sharing things in everyday life and keeping the rehabilitant informed about regular events. The combination of interviews and content analysis reveals that only a minority of the photos lead to follow-up communication about the contents of the photos. Rehabilitants were positively surprised how spontaneous photo sharing simplified the way they could reconnect to their friends and family, without the immediate need or obligation to engage in a (phone) conversation.', 'doi': '10.1145/1639642.1639674', 'url': 'https://doi.org/10.1145/1639642.1639674', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': ""Let's stay in touch: sharing photos for restoring social connectedness between rehabilitants, friends and family"", 'author': 'Biemans, Margit and van Dijk, Betsy and Dadlani, Pavan and van Halteren, Aart', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639674'}"
Talking points: the differential impact of real-time computer generated audio/visual feedback on speech-like \&amp; non-speech-like vocalizations in low functioning children with ASD,10.1145/1639642.1639675,"Real-time computer feedback systems (CFS) have been shown to impact the communication of neurologically typical individuals. Promising new research appears to suggest the same for the vocalization of low functioning children with Autistic Spectrum Disorder (ASD). The distinction between speech-like versus non-speech-like vocalizations has rarely, if ever, been addressed in the HCI community. This distinction is critical as we strive to most effectively and efficiently facilitate speech development in children with ASD, while simultaneously helping decrease vocalizations that do not facilitate positive social interactions. This paper provided an extension of Hailpern et al. in 2009 by examining the influence of a computerized feedback system on both the speech-like and non-speech-like vocalizations of five nonverbal children with ASD. Results were largely positive, in that some form of computerized feedback was able to differentially facilitate speech-like vocalizations relative to nonspeech-like vocalizations in 4 of the 5 children. The main contribution of this work is in highlighting the importance of distinguishing between speech-like versus nonspeech-like vocalizations in the design of feedback systems focused on facilitating speech in similar populations.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, autism, children, feedback, speech, visualization, vocalization', 'numpages': '8', 'pages': '187–194', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Real-time computer feedback systems (CFS) have been shown to impact the communication of neurologically typical individuals. Promising new research appears to suggest the same for the vocalization of low functioning children with Autistic Spectrum Disorder (ASD). The distinction between speech-like versus non-speech-like vocalizations has rarely, if ever, been addressed in the HCI community. This distinction is critical as we strive to most effectively and efficiently facilitate speech development in children with ASD, while simultaneously helping decrease vocalizations that do not facilitate positive social interactions. This paper provided an extension of Hailpern et al. in 2009 by examining the influence of a computerized feedback system on both the speech-like and non-speech-like vocalizations of five nonverbal children with ASD. Results were largely positive, in that some form of computerized feedback was able to differentially facilitate speech-like vocalizations relative to nonspeech-like vocalizations in 4 of the 5 children. The main contribution of this work is in highlighting the importance of distinguishing between speech-like versus nonspeech-like vocalizations in the design of feedback systems focused on facilitating speech in similar populations.', 'doi': '10.1145/1639642.1639675', 'url': 'https://doi.org/10.1145/1639642.1639675', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Talking points: the differential impact of real-time computer generated audio/visual feedback on speech-like \\&amp; non-speech-like vocalizations in low functioning children with ASD', 'author': 'Hailpern, Joshua and Karahalios, Karrie and DeThorne, Laura and Halle, James', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639675'}"
Session details: Web accessibility II,10.1145/3252463,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252463', 'url': 'https://doi.org/10.1145/3252463', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Web accessibility II', 'author': 'Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252463'}"
Collaborative web accessibility improvement: challenges and possibilities,10.1145/1639642.1639677,"Collaborative accessibility improvement has great potential to make the Web more adaptive in a timely manner by inviting users into the improvement process. The Social Accessibility Project is an experimental service for a new needs-driven improvement model based on collaborative metadata authoring technologies. In 10 months, about 18,000 pieces of metadata were created for 2,930 webpages through collaboration. We encountered many challenges as we sought to create a new mainstream approach. The productivity of the volunteer activities exceeded our expectation, but we found large and important problems in the screen reader users' lack of awareness of their own accessibility problems. In this paper, we first introduce examples, analyze some statistics from the pilot service and then discuss our findings and challenges. Three future directions including site-wide authoring are considered.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, collaboration, metadata, social computing, web', 'numpages': '8', 'pages': '195–202', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Collaborative accessibility improvement has great potential to make the Web more adaptive in a timely manner by inviting users into the improvement process. The Social Accessibility Project is an experimental service for a new needs-driven improvement model based on collaborative metadata authoring technologies. In 10 months, about 18,000 pieces of metadata were created for 2,930 webpages through collaboration. We encountered many challenges as we sought to create a new mainstream approach. The productivity of the volunteer activities exceeded our expectation, but we found large and important problems in the screen reader users' lack of awareness of their own accessibility problems. In this paper, we first introduce examples, analyze some statistics from the pilot service and then discuss our findings and challenges. Three future directions including site-wide authoring are considered."", 'doi': '10.1145/1639642.1639677', 'url': 'https://doi.org/10.1145/1639642.1639677', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Collaborative web accessibility improvement: challenges and possibilities', 'author': 'Takagi, Hironobu and Kawanaka, Shinya and Kobayashi, Masatomo and Sato, Daisuke and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639677'}"
How much does expertise matter? a barrier walkthrough study with experts and non-experts,10.1145/1639642.1639678,"Manual accessibility evaluation plays an important role in validating the accessibility of Web pages. This role has become increasingly critical with the advent of the Web Content Accessibility Guidelines (WCAG) 2.0 and their reliance on user evaluation to validate certain conformance measures. However, the role of expertise, in such evaluations, is unknown and has not previously been studied. This paper sets out to investigate the interplay between expert and non-expert evaluation by conducting a Barrier Walkthrough (BW) study with 19 expert and 51 non-expert judges. The BW method provides an evaluation framework that can be used to manually assess the accessibility of Web pages for different user groups including motor impaired, hearing impaired, low vision, cognitive impaired, etc. We conclude that the level of expertise is an important factor in the quality of accessibility evaluation of Web pages. Expert judges spent significantly less time than non-experts; rated themselves as more productive and confident than non-experts; and ranked and rated pages differently against each type of disability. Finally, both effectiveness and reliability of the expert judges are significantly higher than non-expert judges.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'evaluation, expertise, guideline, web accessibility', 'numpages': '8', 'pages': '203–210', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Manual accessibility evaluation plays an important role in validating the accessibility of Web pages. This role has become increasingly critical with the advent of the Web Content Accessibility Guidelines (WCAG) 2.0 and their reliance on user evaluation to validate certain conformance measures. However, the role of expertise, in such evaluations, is unknown and has not previously been studied. This paper sets out to investigate the interplay between expert and non-expert evaluation by conducting a Barrier Walkthrough (BW) study with 19 expert and 51 non-expert judges. The BW method provides an evaluation framework that can be used to manually assess the accessibility of Web pages for different user groups including motor impaired, hearing impaired, low vision, cognitive impaired, etc. We conclude that the level of expertise is an important factor in the quality of accessibility evaluation of Web pages. Expert judges spent significantly less time than non-experts; rated themselves as more productive and confident than non-experts; and ranked and rated pages differently against each type of disability. Finally, both effectiveness and reliability of the expert judges are significantly higher than non-expert judges.', 'doi': '10.1145/1639642.1639678', 'url': 'https://doi.org/10.1145/1639642.1639678', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'How much does expertise matter? a barrier walkthrough study with experts and non-experts', 'author': 'Yesilada, Yeliz and Brajnik, Giorgio and Harper, Simon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639678'}"
Session details: Posters and system demonstrations,10.1145/3252464,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252464', 'url': 'https://doi.org/10.1145/3252464', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Posters and system demonstrations', 'author': 'Fell, Harriet', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252464'}"
3D sound for human-computer interaction: regions with different limitations in elevation localization,10.1145/1639642.1639680,"Spatialized (""3D"") audio may be useful as an alternative sensory channel to provide blind individuals with relevant spatial information in the physical world or while interacting with computers. However, an important limitation of this approach is the lower spatial resolution achievable through sound localization. While this limitation is widely acknowledged, few empirical evaluations of the sound localization achievable through audio spatialization techniques have been performed, particularly with respect to elevation localization. We performed such an empirical study and found quantitative confirmation that the localization accuracy deteriorates as the virtual sound position is set farther above or below the ear (height) level. This information may be valuable to HCI designers planning to use 3D sound.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': '3D sound, HRIR, HRTF, elevation', 'numpages': '2', 'pages': '211–212', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Spatialized (""3D"") audio may be useful as an alternative sensory channel to provide blind individuals with relevant spatial information in the physical world or while interacting with computers. However, an important limitation of this approach is the lower spatial resolution achievable through sound localization. While this limitation is widely acknowledged, few empirical evaluations of the sound localization achievable through audio spatialization techniques have been performed, particularly with respect to elevation localization. We performed such an empirical study and found quantitative confirmation that the localization accuracy deteriorates as the virtual sound position is set farther above or below the ear (height) level. This information may be valuable to HCI designers planning to use 3D sound.', 'doi': '10.1145/1639642.1639680', 'url': 'https://doi.org/10.1145/1639642.1639680', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': '3D sound for human-computer interaction: regions with different limitations in elevation localization', 'author': 'Barreto, Armando and Faller, Kenneth John and Adjouadi, Malek', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639680'}"
3DScan: an environment control system supporting persons with severe motor impairments,10.1145/1639642.1639681,"This proposal is about a poster dealing with a scanning-based software system, which aims at giving persons with severe motor impairments a means to interact with their immediate environment by issuing tiny contractions of an arbitrary muscle. The implementation makes use of an extension of row-column scanning, called three-dimensional scanning, which reduces the time required to select a certain item by eliminating the need to scan long rows or columns. A simple experiment comparing the resulting text entry capabilities to conventional row-column scanning shows that the entry rate can be increased by over 30 \%.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'activities of daily life, environment control, human-computer interaction, scanning', 'numpages': '2', 'pages': '213–214', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This proposal is about a poster dealing with a scanning-based software system, which aims at giving persons with severe motor impairments a means to interact with their immediate environment by issuing tiny contractions of an arbitrary muscle. The implementation makes use of an extension of row-column scanning, called three-dimensional scanning, which reduces the time required to select a certain item by eliminating the need to scan long rows or columns. A simple experiment comparing the resulting text entry capabilities to conventional row-column scanning shows that the entry rate can be increased by over 30 \\%.', 'doi': '10.1145/1639642.1639681', 'url': 'https://doi.org/10.1145/1639642.1639681', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': '3DScan: an environment control system supporting persons with severe motor impairments', 'author': 'Felzer, Torsten and Rinderknecht, Stephan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639681'}"
"A cheap, portable haptic device for a method to relay 2-D texture-enriched graphical information to individuals who are visually impaired",10.1145/1639642.1639682,"This paper considers the development of a haptic device needed for a method of relaying 2-D texture enriched graphical information. The focus here is on the conversion of the optical, color-based representation of the formatted diagram, which is efficient for storage and distribution, to its haptic texture enriched form. For this, the device has two main components, an RGB color sensor and piezoelectric actuator, mounted in a casing that is wrapped around the finger. The resulting device has a spatial sensitivity (&lt;2mm) comparable to natural touch (1.0mm), a temporal frequency bandwidth of 1 to 200 Hz, and can be used to output a variety of textures. The point contact device developed can also easily be expanded to the use of multiple devices on multiple fingerpads, while remaining affordable (&lt;100) and portable (&lt;500g).","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'haptic rendering, tactile devices and display, texture rendering', 'numpages': '2', 'pages': '215–216', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper considers the development of a haptic device needed for a method of relaying 2-D texture enriched graphical information. The focus here is on the conversion of the optical, color-based representation of the formatted diagram, which is efficient for storage and distribution, to its haptic texture enriched form. For this, the device has two main components, an RGB color sensor and piezoelectric actuator, mounted in a casing that is wrapped around the finger. The resulting device has a spatial sensitivity (&lt;2mm) comparable to natural touch (1.0mm), a temporal frequency bandwidth of 1 to 200 Hz, and can be used to output a variety of textures. The point contact device developed can also easily be expanded to the use of multiple devices on multiple fingerpads, while remaining affordable (&lt;100) and portable (&lt;500g).', 'doi': '10.1145/1639642.1639682', 'url': 'https://doi.org/10.1145/1639642.1639682', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'A cheap, portable haptic device for a method to relay 2-D texture-enriched graphical information to individuals who are visually impaired', 'author': 'Burch, David S. and Pawluk, Dianne T.V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639682'}"
A reconfigurable augmentative communication device,10.1145/1639642.1639683,"In this demonstration we present a highly reconfigurable augmentative and alternative communication (AAC) device. The people in need of these devices often have a wide range of disabilities, and the setup required to start a person using an AAC system is often time consuming and labor intensive. Our device streamlines the setup process, allowing caregivers to quickly configure the interface to best suit the user's needs. Setup times compared to previous AAC devices are reduced from hours to minutes. This allows the caregiver to maximize the effectiveness of the device for the end user. It also makes it possible for the device to be adapted over time as the user's needs change.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'assistive technology, augmentative communication, universal design', 'numpages': '2', 'pages': '217–218', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this demonstration we present a highly reconfigurable augmentative and alternative communication (AAC) device. The people in need of these devices often have a wide range of disabilities, and the setup required to start a person using an AAC system is often time consuming and labor intensive. Our device streamlines the setup process, allowing caregivers to quickly configure the interface to best suit the user's needs. Setup times compared to previous AAC devices are reduced from hours to minutes. This allows the caregiver to maximize the effectiveness of the device for the end user. It also makes it possible for the device to be adapted over time as the user's needs change."", 'doi': '10.1145/1639642.1639683', 'url': 'https://doi.org/10.1145/1639642.1639683', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'A reconfigurable augmentative communication device', 'author': 'Schindler, Kris and Dygert, Robert and Nagler, Eric', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639683'}"
Accessibility: understanding attitudes of CS students,10.1145/1639642.1639684,"Accessibility and usability have become increasingly important in design and development of technology. This poster briefly reviews how accessibility concepts may be included in computer science courses as students are educated to become practitioners. In a usability engineering course, the authors included a group development project that included an accessibility component. They conducted a survey of student attitudes toward these issues at the start and end of the course. Results of the survey indicate that students' awareness of issues related to usability and accessibility are increased after taking the course and completing the project. In particular, students showed a significant increase in their rating of importance for the item ""broadening the range of technology users"". The authors also performed a factor analysis of the survey responses and determined that items fell into three factors, one of which was concerned with accessibility and usability.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, computer science education, usability', 'numpages': '2', 'pages': '219–220', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Accessibility and usability have become increasingly important in design and development of technology. This poster briefly reviews how accessibility concepts may be included in computer science courses as students are educated to become practitioners. In a usability engineering course, the authors included a group development project that included an accessibility component. They conducted a survey of student attitudes toward these issues at the start and end of the course. Results of the survey indicate that students\' awareness of issues related to usability and accessibility are increased after taking the course and completing the project. In particular, students showed a significant increase in their rating of importance for the item ""broadening the range of technology users"". The authors also performed a factor analysis of the survey responses and determined that items fell into three factors, one of which was concerned with accessibility and usability.', 'doi': '10.1145/1639642.1639684', 'url': 'https://doi.org/10.1145/1639642.1639684', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Accessibility: understanding attitudes of CS students', 'author': 'Poor, G. M. and Leventhal, Laura M. and Barnes, Julie and Hutchings, Duke R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639684'}"
Accessible videodescription On-Demand,10.1145/1639642.1639685,"Providing blind and visually impaired people with the descriptions of key visual elements can greatly improve the accessibility of video, film and television. This project presents a Website platform for rendering videodescription (VD) using an adapted player. Our goal is to test the usability of an accessible player that provides end-users with various levels of VD, on-demand. This paper summarizes the user evaluations covering 1) the usability of the player and its controls, and 2) the quality and quantity of the VD selected. The complete results of these evaluations, including the accessibility of the Website, will be presented in the poster. Final results show that 90\% of the participants agreed on the relevancy of a multi-level VD player. All of them rated the player easy to use. Some improvements were also identified. We found that there is a great need to provide blind and visually impaired people with more flexible tool to access rich media content.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'audio description, blind and visual impairment, rich media, web accessibility', 'numpages': '2', 'pages': '221–222', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Providing blind and visually impaired people with the descriptions of key visual elements can greatly improve the accessibility of video, film and television. This project presents a Website platform for rendering videodescription (VD) using an adapted player. Our goal is to test the usability of an accessible player that provides end-users with various levels of VD, on-demand. This paper summarizes the user evaluations covering 1) the usability of the player and its controls, and 2) the quality and quantity of the VD selected. The complete results of these evaluations, including the accessibility of the Website, will be presented in the poster. Final results show that 90\\% of the participants agreed on the relevancy of a multi-level VD player. All of them rated the player easy to use. Some improvements were also identified. We found that there is a great need to provide blind and visually impaired people with more flexible tool to access rich media content.', 'doi': '10.1145/1639642.1639685', 'url': 'https://doi.org/10.1145/1639642.1639685', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Accessible videodescription On-Demand', 'author': 'Chapdelaine, Claude and Gagnon, Langis', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639685'}"
"An improved, low-cost tactile 'mouse' for use by individuals who are blind and visually impaired",10.1145/1639642.1639686,"Although tactile mice, such as the VT Player by virTouch, have been developed to enable access to 2-D graphical information by individuals who are blind and visually impaired, they have yet to really be adapted by the community. We suggest that this is due to the significant lack of accuracy in the haptic position information, which is critical for individuals to haptically piece together a 2-D graphic. In addition, the VT Player suffers from a noticeable lack of spatial and temporal concordance between the kinesthetic and tactile information. In this paper, we present a low-cost (&lt;400 US) alternative that avoids these problems. Furthermore, the dynamic response of the pins of our improved mouse can range from 0 to &gt; 300Hz. This will facilitate the use of vibration and texture, which our preliminary results show improves the saliency of graphical information.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'VT player, braille, embossed graphics, haptic mouse, raised line drawings, tactile graphics, visually impaired', 'numpages': '2', 'pages': '223–224', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Although tactile mice, such as the VT Player by virTouch, have been developed to enable access to 2-D graphical information by individuals who are blind and visually impaired, they have yet to really be adapted by the community. We suggest that this is due to the significant lack of accuracy in the haptic position information, which is critical for individuals to haptically piece together a 2-D graphic. In addition, the VT Player suffers from a noticeable lack of spatial and temporal concordance between the kinesthetic and tactile information. In this paper, we present a low-cost (&lt;400 US) alternative that avoids these problems. Furthermore, the dynamic response of the pins of our improved mouse can range from 0 to &gt; 300Hz. This will facilitate the use of vibration and texture, which our preliminary results show improves the saliency of graphical information.', 'doi': '10.1145/1639642.1639686', 'url': 'https://doi.org/10.1145/1639642.1639686', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': ""An improved, low-cost tactile 'mouse' for use by individuals who are blind and visually impaired"", 'author': ""Owen, Justin M. and Petro, Julie A. and D'Souza, Steve M. and Rastogi, Ravi and Pawluk, Dianne T.V."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639686'}"
Approaches to locating areas of interest related to questions in a document for non-visual readers,10.1145/1639642.1639687,"This poster describes an approach to creating a tool to aid blind, low-vision, dyslexic, and other non-visual readers in skimming a document to answer questions. The goal is to give them information similar to that obtained by a visual reader's skimming experience. Towards this goal, we examine approaches to locating areas of interest within a document that are related to a question. The areas of interest in relation to a question were determined through user studies in which visual readers skimmed through documents for answers to questions while being tracked by an eye tracking system. We then examined methods of automatically identifying the areas of interest using keywords related to the content of the question. This poster focuses on the effectiveness of these different methods in identifying the areas of interest.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'assistive technology, natural language processing, open domain question answering, text skimming', 'numpages': '2', 'pages': '225–226', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This poster describes an approach to creating a tool to aid blind, low-vision, dyslexic, and other non-visual readers in skimming a document to answer questions. The goal is to give them information similar to that obtained by a visual reader's skimming experience. Towards this goal, we examine approaches to locating areas of interest within a document that are related to a question. The areas of interest in relation to a question were determined through user studies in which visual readers skimmed through documents for answers to questions while being tracked by an eye tracking system. We then examined methods of automatically identifying the areas of interest using keywords related to the content of the question. This poster focuses on the effectiveness of these different methods in identifying the areas of interest."", 'doi': '10.1145/1639642.1639687', 'url': 'https://doi.org/10.1145/1639642.1639687', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Approaches to locating areas of interest related to questions in a document for non-visual readers', 'author': 'Yarrington, Debra and McCoy, Kathleen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639687'}"
Assistive device for the blind based on object recognition: an application to identify currency bills,10.1145/1639642.1639688,We have developed a real-time portable object recognition system based on a bio-inspired image analysis software to increase blind people autonomy by localizing and identifying surrounding objects. A working prototype of this system has been tested on the issue of currency bill recognition encountered by most of the blind people. Seven blind persons were involved in an experiment which demonstrated that the usability of the system was good enough for such a device to be used daily in real-life situations.,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'blindness, currency reader, low vision, object recognition', 'numpages': '2', 'pages': '227–228', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We have developed a real-time portable object recognition system based on a bio-inspired image analysis software to increase blind people autonomy by localizing and identifying surrounding objects. A working prototype of this system has been tested on the issue of currency bill recognition encountered by most of the blind people. Seven blind persons were involved in an experiment which demonstrated that the usability of the system was good enough for such a device to be used daily in real-life situations.', 'doi': '10.1145/1639642.1639688', 'url': 'https://doi.org/10.1145/1639642.1639688', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Assistive device for the blind based on object recognition: an application to identify currency bills', 'author': ""Parlouar, R\\'{e}mi and Dramas, Florian and Mac\\'{e}, Marc M-J and Jouffrais, Christophe"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639688'}"
Don't listen! I am dictating my password!,10.1145/1639642.1639689,"Speech recognition is a promising alternative input technology for individuals with upper-body motor impairments that hinder the use of the standard keyboard and mouse. A recent long-term field study found that the users employed speech techniques for a variety of tasks beyond generating text documents [1]. One challenge with hands-free speech-based interactions is user authentication, which requires the users to speak their user IDs and passwords character by character. Unfortunately, speaking a password presents both security and privacy threats as well as usability problems. To address this challenge, we propose a new speech-based authentication model. An initial proof-of-concept prototype has been implemented and a pilot study was conducted. Preliminary results suggest several problems for further examination.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'authentication, physical impairment, speech technology', 'numpages': '2', 'pages': '229–230', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Speech recognition is a promising alternative input technology for individuals with upper-body motor impairments that hinder the use of the standard keyboard and mouse. A recent long-term field study found that the users employed speech techniques for a variety of tasks beyond generating text documents [1]. One challenge with hands-free speech-based interactions is user authentication, which requires the users to speak their user IDs and passwords character by character. Unfortunately, speaking a password presents both security and privacy threats as well as usability problems. To address this challenge, we propose a new speech-based authentication model. An initial proof-of-concept prototype has been implemented and a pilot study was conducted. Preliminary results suggest several problems for further examination.', 'doi': '10.1145/1639642.1639689', 'url': 'https://doi.org/10.1145/1639642.1639689', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': ""Don't listen! I am dictating my password!"", 'author': 'Zhu, Shaojian and Ma, Yao and Feng, Jinjuan and Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639689'}"
Dundee user centre: a space where older people and technology meet,10.1145/1639642.1639690,"In this paper, we describe the User Centre at the University of Dundee which provides a space for older people and technology to come together for the benefit of new learning opportunities, social interaction and research.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'computing, digital inclusion, older people, technology', 'numpages': '2', 'pages': '231–232', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we describe the User Centre at the University of Dundee which provides a space for older people and technology to come together for the benefit of new learning opportunities, social interaction and research.', 'doi': '10.1145/1639642.1639690', 'url': 'https://doi.org/10.1145/1639642.1639690', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Dundee user centre: a space where older people and technology meet', 'author': 'Forbes, Paula and Gibson, Lorna and Hanson, Vicki L. and Gregor, Peter and Newell, Alan F.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639690'}"
End-user moderation of cognitive accessibility in online communities: case study of brain fog in the lyme community,10.1145/1639642.1639691,"With the advent of Web 2.0 technologies, more and more online content is being generated by users. Even trained web developers often fail to take accessibility issues into consideration, so it is no surprise that users may fail to do so as well. In this paper, we examine two self-moderating communities of individuals with Lyme disease who are affected by """"brain fog"""". Through qualitative analysis of over 100 discussion threads that deal with issues of accessibility, we explore how the individuals in these communities fail and succeed to establish and enforce, through moderation, the creation of cognitively accessible content.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'cognitive accessibility, user-generated content, web 2.0', 'numpages': '2', 'pages': '233–234', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'With the advent of Web 2.0 technologies, more and more online content is being generated by users. Even trained web developers often fail to take accessibility issues into consideration, so it is no surprise that users may fail to do so as well. In this paper, we examine two self-moderating communities of individuals with Lyme disease who are affected by """"brain fog"""". Through qualitative analysis of over 100 discussion threads that deal with issues of accessibility, we explore how the individuals in these communities fail and succeed to establish and enforce, through moderation, the creation of cognitively accessible content.', 'doi': '10.1145/1639642.1639691', 'url': 'https://doi.org/10.1145/1639642.1639691', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'End-user moderation of cognitive accessibility in online communities: case study of brain fog in the lyme community', 'author': 'Kuksenok, Kateryna and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639691'}"
Evaluation of software tools with deaf children,10.1145/1639642.1639692,"Evaluating software applications with deaf or hard of hearing children requires methods and procedures tuned to them. Indeed, they are unusual users with special communication needs. This paper proposes a list of guidelines for organizing effective evaluations of interactive tools with deaf children. The novelty of this work is that such guidelines are not based on theoretical thinking. Instead, they are built on data collected through questionnaires proposed to experts working with deaf children. The questionnaire's data are reinforced by my experience which was gained during usability tests with deaf children. In future work, the effectiveness of these guidelines will be checked during the evaluation of an e-learning tool for Italian deaf children.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'deaf children, guidelines for testing, unusual users', 'numpages': '2', 'pages': '235–236', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Evaluating software applications with deaf or hard of hearing children requires methods and procedures tuned to them. Indeed, they are unusual users with special communication needs. This paper proposes a list of guidelines for organizing effective evaluations of interactive tools with deaf children. The novelty of this work is that such guidelines are not based on theoretical thinking. Instead, they are built on data collected through questionnaires proposed to experts working with deaf children. The questionnaire's data are reinforced by my experience which was gained during usability tests with deaf children. In future work, the effectiveness of these guidelines will be checked during the evaluation of an e-learning tool for Italian deaf children."", 'doi': '10.1145/1639642.1639692', 'url': 'https://doi.org/10.1145/1639642.1639692', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Evaluation of software tools with deaf children', 'author': 'Mich, Ornella', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639692'}"
EYECane: navigating with camera embedded white cane for visually impaired person,10.1145/1639642.1639693,"We demonstrate a novel assistive device which can help the visually impaired or blind people to gain more safe mobility, which is called as ""EYECane"". The EYECane is the white-cane with embedding a camera and a computer. It automatically detects obstacles and recommends some avoidable paths to the user through acoustic interface. For this, it is performed by three steps: Firstly, it extracts obstacles from image streaming using online background estimation, thereafter generates the occupancy grid map, which is given to neural network. Finally, the system notifies a user of an paths recommended by machine learning. To assess the effectiveness of the proposed EYECane, it was tested with 5 users and the results show that it can support more safe navigation, and diminish the practice and efforts to be adept in using the white cane.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'EYECane, navigtion, vision based navigation system, visually impaired', 'numpages': '2', 'pages': '237–238', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We demonstrate a novel assistive device which can help the visually impaired or blind people to gain more safe mobility, which is called as ""EYECane"". The EYECane is the white-cane with embedding a camera and a computer. It automatically detects obstacles and recommends some avoidable paths to the user through acoustic interface. For this, it is performed by three steps: Firstly, it extracts obstacles from image streaming using online background estimation, thereafter generates the occupancy grid map, which is given to neural network. Finally, the system notifies a user of an paths recommended by machine learning. To assess the effectiveness of the proposed EYECane, it was tested with 5 users and the results show that it can support more safe navigation, and diminish the practice and efforts to be adept in using the white cane.', 'doi': '10.1145/1639642.1639693', 'url': 'https://doi.org/10.1145/1639642.1639693', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'EYECane: navigating with camera embedded white cane for visually impaired person', 'author': 'Ju, Jin Sun and Ko, Eunjeong and Kim, Eun Yi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639693'}"
Eye-writing communication for patients with amyotrophic lateral sclerosis,10.1145/1639642.1639694,"The eye-writing method predefines a symbol set containing symbols with distinct writing traces. A user of this method rotates his or her eye balls to ""write"" a symbol according to its designated writing trace. Meanwhile, the eye movement is detected using a suitable technique such as the electro-oculography, which measures voltage differences on the skin around the user's eyes. Distinct features of the acquired eye-movement signals are extracted in order to determine which symbol, among those in the symbol set, the user's eyes have just written. An eye-writing system has been implemented in this study. Tests on subjects with no known disabilities have been conducted and the performance has been evaluated. The study found that eye-writing system is potentially useful for facilitating communication of sever ALS patients who have lost most of their oral speaking and handwriting abilities.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'ALS, communication, electro-oculography, eye, writing', 'numpages': '2', 'pages': '239–240', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The eye-writing method predefines a symbol set containing symbols with distinct writing traces. A user of this method rotates his or her eye balls to ""write"" a symbol according to its designated writing trace. Meanwhile, the eye movement is detected using a suitable technique such as the electro-oculography, which measures voltage differences on the skin around the user\'s eyes. Distinct features of the acquired eye-movement signals are extracted in order to determine which symbol, among those in the symbol set, the user\'s eyes have just written. An eye-writing system has been implemented in this study. Tests on subjects with no known disabilities have been conducted and the performance has been evaluated. The study found that eye-writing system is potentially useful for facilitating communication of sever ALS patients who have lost most of their oral speaking and handwriting abilities.', 'doi': '10.1145/1639642.1639694', 'url': 'https://doi.org/10.1145/1639642.1639694', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Eye-writing communication for patients with amyotrophic lateral sclerosis', 'author': 'Tsai, Jang-Zern and Chen, Tsai-Shih', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639694'}"
Fall and emergency detection with mobile phones,10.1145/1639642.1639695,"In this demo, we present an application for mobile phones which can monitor physical activities of users and detect unexpected emergency situations such as a sudden fall or accident. Upon detection of such an event, the mobile phone can inform a designated center (by automatically calling or sending message) about the incident and its location. This can facilitate and speed up recovery and help process especially if the user is alone or the accident has happened in a deserted place. Such an application can be particularly useful for elderly people or people with physical and movement disabilities. The application operates based on analysis of user movements using data provided by accelerometers integrated in mobile phones.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'acceleration sensors, automatic emergency call, emergency situations, fall and accident, mobile phones, physical shock', 'numpages': '2', 'pages': '241–242', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this demo, we present an application for mobile phones which can monitor physical activities of users and detect unexpected emergency situations such as a sudden fall or accident. Upon detection of such an event, the mobile phone can inform a designated center (by automatically calling or sending message) about the incident and its location. This can facilitate and speed up recovery and help process especially if the user is alone or the accident has happened in a deserted place. Such an application can be particularly useful for elderly people or people with physical and movement disabilities. The application operates based on analysis of user movements using data provided by accelerometers integrated in mobile phones.', 'doi': '10.1145/1639642.1639695', 'url': 'https://doi.org/10.1145/1639642.1639695', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Fall and emergency detection with mobile phones', 'author': 'Ketabdar, Hamed and Polzehl, Tim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639695'}"
Johar: a framework for developing accessible applications,10.1145/1639642.1639696,"We describe the Johar framework, which supports the development of applications that are accessible to users with a wide range of abilities. A user of Johar applications chooses an ""interface interpreter"" that best suits them, and then uses it to interact with all Johar applications.Interface interpreters and applications are written by developers using the Johar package. An application consists of an application engine, and an interface definition file that describes the interface to interface interpreters.In this poster, we compare our work on Johar with previous research, and briefly describe the work completed so far and the further development planned for the near future.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessible computing, application programs', 'numpages': '2', 'pages': '243–244', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We describe the Johar framework, which supports the development of applications that are accessible to users with a wide range of abilities. A user of Johar applications chooses an ""interface interpreter"" that best suits them, and then uses it to interact with all Johar applications.Interface interpreters and applications are written by developers using the Johar package. An application consists of an application engine, and an interface definition file that describes the interface to interface interpreters.In this poster, we compare our work on Johar with previous research, and briefly describe the work completed so far and the further development planned for the near future.', 'doi': '10.1145/1639642.1639696', 'url': 'https://doi.org/10.1145/1639642.1639696', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Johar: a framework for developing accessible applications', 'author': 'Andrews, James H. and Hussain, Fatima', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639696'}"
Learning how older adults undertake computer tasks,10.1145/1639642.1639697,"This paper describes a study that was conducted to learn more about how older adults use the tools in a GUI to undertake tasks in Windows applications. The objective was to gain insight into what people did and what they found most difficult. File and folder manipulation, and some aspects of formatting presented difficulties, and these were thought to be related to a lack of understanding of the task model, the correct interpretation of the visual cues presented by the interface, and the recall and translation of the task model into a suitable sequence of actions.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'cognition, file systems, older adults, task models', 'numpages': '2', 'pages': '245–246', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes a study that was conducted to learn more about how older adults use the tools in a GUI to undertake tasks in Windows applications. The objective was to gain insight into what people did and what they found most difficult. File and folder manipulation, and some aspects of formatting presented difficulties, and these were thought to be related to a lack of understanding of the task model, the correct interpretation of the visual cues presented by the interface, and the recall and translation of the task model into a suitable sequence of actions.', 'doi': '10.1145/1639642.1639697', 'url': 'https://doi.org/10.1145/1639642.1639697', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Learning how older adults undertake computer tasks', 'author': 'Hollinworth, Nic and Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639697'}"
Naming practice for people with aphasia as a mobile web application,10.1145/1639642.1639698,"Bangagears is a new version of Banga, a smart phone application that supports word finding practice, a form of therapy for people with aphasia [1]. While Banga was implemented as a native application, a program specific to a particular kind of phone, Bangagears uses the emerging HTML5 technology to operate, in principle, on many different kinds of phones and other Web platforms, and to offer simpler development and deployment. Lessons from Bangagears will be useful to other developers of applications for people with disabilities","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'aphasia, mobile platform, therapy, web applications, word finding', 'numpages': '2', 'pages': '247–248', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Bangagears is a new version of Banga, a smart phone application that supports word finding practice, a form of therapy for people with aphasia [1]. While Banga was implemented as a native application, a program specific to a particular kind of phone, Bangagears uses the emerging HTML5 technology to operate, in principle, on many different kinds of phones and other Web platforms, and to offer simpler development and deployment. Lessons from Bangagears will be useful to other developers of applications for people with disabilities', 'doi': '10.1145/1639642.1639698', 'url': 'https://doi.org/10.1145/1639642.1639698', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Naming practice for people with aphasia as a mobile web application', 'author': 'Chandler, Skye and Harris, Jesse and Moncrief, Alex and Lewis, Clayton', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639698'}"
Providing synthesized audio description for online videos,10.1145/1639642.1639699,"We describe an initial attempt to develop a common platform for adding an audio description (AD) to an online video so that blind and visually impaired people can enjoy such material. A speech synthesis technology allows content providers to offer the AD at minimal cost. We exploit external metadata so that the AD can be independent of the video format. The external approach also allows external supporters to add ADs to any online videos. Our technology includes an authoring tool for writing AD scripts, a Web browser add-on for synthesizing ADs synchronized with original videos, and a text-based format to exchange AD scripts.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'audio description, external metadata, online videos, speech synthesis, text-to-speech (tts), web accessibility', 'numpages': '2', 'pages': '249–250', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We describe an initial attempt to develop a common platform for adding an audio description (AD) to an online video so that blind and visually impaired people can enjoy such material. A speech synthesis technology allows content providers to offer the AD at minimal cost. We exploit external metadata so that the AD can be independent of the video format. The external approach also allows external supporters to add ADs to any online videos. Our technology includes an authoring tool for writing AD scripts, a Web browser add-on for synthesizing ADs synchronized with original videos, and a text-based format to exchange AD scripts.', 'doi': '10.1145/1639642.1639699', 'url': 'https://doi.org/10.1145/1639642.1639699', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Providing synthesized audio description for online videos', 'author': 'Kobayashi, Masatomo and Fukuda, Kentarou and Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639699'}"
SmartKey: a multi purpose target expansion based virtual keyboard,10.1145/1639642.1639700,SmartKey is a new virtual keyboard animation for handheld devices designed to make key selection easier for people with situational and motor impairments. The nearest key to cursor expands in four directions using the available space of nearby keys. Target expansion is accomplished with an occlusion factor of 0\% and without any sideways motion. The two studies conducted with able-bodied and motor-impaired users showed that subjects performed better with SmartKey than with traditional virtual keyboard.,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, handheld devices, target expansion, text input', 'numpages': '2', 'pages': '251–252', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'SmartKey is a new virtual keyboard animation for handheld devices designed to make key selection easier for people with situational and motor impairments. The nearest key to cursor expands in four directions using the available space of nearby keys. Target expansion is accomplished with an occlusion factor of 0\\% and without any sideways motion. The two studies conducted with able-bodied and motor-impaired users showed that subjects performed better with SmartKey than with traditional virtual keyboard.', 'doi': '10.1145/1639642.1639700', 'url': 'https://doi.org/10.1145/1639642.1639700', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'SmartKey: a multi purpose target expansion based virtual keyboard', 'author': 'Al Faraj, Khaldoun and Vigouroux, Nadine and Mojahid, Mustapha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639700'}"
Tactile and visual alerts for deaf people by mobile phones,10.1145/1639642.1639701,"In this demo, we present an application for mobile phones which can analyse audio context and issue tactile or visual alerts if an audio event happens. This application can be useful especially for deaf or hard of hearing people to be alerted of audio events happening around them. The audio context analysis algorithm captures data using mobile phone's microphone and checks for changes in audio activities around the user. If such a change happens and also some other circumstances are met, the application issues visual or vibro-tactile alerts (by vibrating mobile phone) proportional to the change in audio context. This informs the user about an event. The functionality of this algorithm can be further enhanced by analysis of user movements.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'audio events, change of audio pattern, deaf or hard of hearing people, mobile phones, vibro-tactile and visual alerts', 'numpages': '2', 'pages': '253–254', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this demo, we present an application for mobile phones which can analyse audio context and issue tactile or visual alerts if an audio event happens. This application can be useful especially for deaf or hard of hearing people to be alerted of audio events happening around them. The audio context analysis algorithm captures data using mobile phone's microphone and checks for changes in audio activities around the user. If such a change happens and also some other circumstances are met, the application issues visual or vibro-tactile alerts (by vibrating mobile phone) proportional to the change in audio context. This informs the user about an event. The functionality of this algorithm can be further enhanced by analysis of user movements."", 'doi': '10.1145/1639642.1639701', 'url': 'https://doi.org/10.1145/1639642.1639701', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Tactile and visual alerts for deaf people by mobile phones', 'author': 'Ketabdar, Hamed and Polzehl, Tim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639701'}"
The one octave scale interface for graphical representation for visually impaired people,10.1145/1639642.1639702,"Protecting the lives and the rights of the impaired people and promoting their social participation is a paramount principle today. Especially for visually impaired people, mobility is important function for promoting social participation. To support their mobility, improvements on map usage and route recognition are indispensable. But visually impaired people have so many difficulties to read maps and to use spatial information in the field. Maps have been made in the past for visually impaired people but people felt uncomfortable using them. So we have been developing a new method which visually impaired people can intuitively recognize the map using audio and touch panels which are recently seen in PCs and smart-phones. The method is universal-designed to enable not only the visually impaired people but also the non-impaired people to enjoy using interactive digital map contents together. This paper introduces our recent progress about the method called the One Octave Scale Interface. The effectiveness of the interface was confirmed by doing experiments of graph and map recognition and a walking experiment after presenting route guide map.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'blind, map, recognition, touchscreen, universal design, visual impairment', 'numpages': '2', 'pages': '255–256', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Protecting the lives and the rights of the impaired people and promoting their social participation is a paramount principle today. Especially for visually impaired people, mobility is important function for promoting social participation. To support their mobility, improvements on map usage and route recognition are indispensable. But visually impaired people have so many difficulties to read maps and to use spatial information in the field. Maps have been made in the past for visually impaired people but people felt uncomfortable using them. So we have been developing a new method which visually impaired people can intuitively recognize the map using audio and touch panels which are recently seen in PCs and smart-phones. The method is universal-designed to enable not only the visually impaired people but also the non-impaired people to enjoy using interactive digital map contents together. This paper introduces our recent progress about the method called the One Octave Scale Interface. The effectiveness of the interface was confirmed by doing experiments of graph and map recognition and a walking experiment after presenting route guide map.', 'doi': '10.1145/1639642.1639702', 'url': 'https://doi.org/10.1145/1639642.1639702', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'The one octave scale interface for graphical representation for visually impaired people', 'author': 'Yairi, Ikuko Eguchi and Azuma, Yoshiteru and Takano, Masamitsu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639702'}"
Towards identifying distinguishable tactons for use with mobile devices,10.1145/1639642.1639703,"This paper describes a study designed to identify salient tactile cues which can be integrated with a cellular telephone interface, to provide non-visual feedback to users when accessing mobile applications. A set of tactile icons (tactons) have been developed by manipulating the pulse duration and interval of vibrotactile signals. Participants were presented with pairs of tactons, and asked to differentiate between each respective pair and rank their salience. Results suggested that the combination of two static tactons is the most effective way to convey tactile information, when compared with dynamic or mixed tactile cues. Further studies will be conducted to refine feedback in order to communicate the presence of graphical objects on a mobile device interface, or to present events and alerts more effectively. The long term goal is to improve access to an interface by using the tactile channel, thereby freeing the visual and auditory channels to perform other tasks.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'mobile and wearable devices, non-visual interaction, tactile sense, usability, vibration pattern', 'numpages': '2', 'pages': '257–258', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes a study designed to identify salient tactile cues which can be integrated with a cellular telephone interface, to provide non-visual feedback to users when accessing mobile applications. A set of tactile icons (tactons) have been developed by manipulating the pulse duration and interval of vibrotactile signals. Participants were presented with pairs of tactons, and asked to differentiate between each respective pair and rank their salience. Results suggested that the combination of two static tactons is the most effective way to convey tactile information, when compared with dynamic or mixed tactile cues. Further studies will be conducted to refine feedback in order to communicate the presence of graphical objects on a mobile device interface, or to present events and alerts more effectively. The long term goal is to improve access to an interface by using the tactile channel, thereby freeing the visual and auditory channels to perform other tasks.', 'doi': '10.1145/1639642.1639703', 'url': 'https://doi.org/10.1145/1639642.1639703', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Towards identifying distinguishable tactons for use with mobile devices', 'author': 'Qian, Huimin and Kuber, Ravi and Sears, Andrew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639703'}"
VocaliD: personalizing text-to-speech synthesis for individuals with severe speech impairment,10.1145/1639642.1639704,"Speech synthesis options on assistive communication devices are very limited and do not reflect the user's vocal quality or personality. Previous work suggests that speakers with severe speech impairment can control prosodic aspects of their voice, and often retain the ability to produce sustained vowel-like utterances. This project leverages these residual phonatory abilities in order to build an adaptive text-to-speech synthesizer that is intelligible, yet conveys the user's vocal identity. Our VocaliD system combines the source characteristics of the disordered speaker with the filter characteristics of an age-matched healthy speaker using voice transformation techniques, in order to produce a personalized voice. Usability testing indicated that listeners were 94\% accurate in transcribing morphed samples and 79.5\% accurate in matching morphed samples from the same speaker.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'assistive communication, dysarthria, speech generation devices, synthesis, text-to-speech', 'numpages': '2', 'pages': '259–260', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Speech synthesis options on assistive communication devices are very limited and do not reflect the user's vocal quality or personality. Previous work suggests that speakers with severe speech impairment can control prosodic aspects of their voice, and often retain the ability to produce sustained vowel-like utterances. This project leverages these residual phonatory abilities in order to build an adaptive text-to-speech synthesizer that is intelligible, yet conveys the user's vocal identity. Our VocaliD system combines the source characteristics of the disordered speaker with the filter characteristics of an age-matched healthy speaker using voice transformation techniques, in order to produce a personalized voice. Usability testing indicated that listeners were 94\\% accurate in transcribing morphed samples and 79.5\\% accurate in matching morphed samples from the same speaker."", 'doi': '10.1145/1639642.1639704', 'url': 'https://doi.org/10.1145/1639642.1639704', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'VocaliD: personalizing text-to-speech synthesis for individuals with severe speech impairment', 'author': 'Jreige, Camil and Patel, Rupal and Bunnell, H. Timothy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639704'}"
Session details: Microsoft student research competition,10.1145/3252465,Abstract not available,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3252465', 'url': 'https://doi.org/10.1145/3252465', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Session details: Microsoft student research competition', 'author': 'Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3252465'}"
A respite care information system for families with developmental delay children through mobile networks,10.1145/1639642.1639706,"In the collaboration of Internet technology and humanities, a matching and appraisal system of the respite care service for families with Children of Developmental Delay (CDD) is designed and implemented through mobile networks. Volunteers and families with CDD form a mobile social network to share their experiences, know-how and expertise in childcare. Moreover, a service management system is also included. Results of half-year field trials demonstrate the superiority and feasibility of the implemented system in quality improvement of the respite care services.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'appraisal system, matching system, mobile networks, respite care service, service management', 'numpages': '2', 'pages': '261–262', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In the collaboration of Internet technology and humanities, a matching and appraisal system of the respite care service for families with Children of Developmental Delay (CDD) is designed and implemented through mobile networks. Volunteers and families with CDD form a mobile social network to share their experiences, know-how and expertise in childcare. Moreover, a service management system is also included. Results of half-year field trials demonstrate the superiority and feasibility of the implemented system in quality improvement of the respite care services.', 'doi': '10.1145/1639642.1639706', 'url': 'https://doi.org/10.1145/1639642.1639706', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'A respite care information system for families with developmental delay children through mobile networks', 'author': 'Yang, Jyun-Yan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639706'}"
Defining virtualization based system abstractions for an indoor assistive living for elderly care,10.1145/1639642.1639707,We consider an indoor assistive living center for elderly care which requires constant monitoring facility without hampering the privacy of the individuals. We use virtualization technique to provide assistance to individuals and monitor them as virtual units of location. We use a distributed server as information provider and handheld computational devices for local assistance for users.,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'RFID technology, indoor assistive living, monitoring', 'numpages': '2', 'pages': '263–264', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We consider an indoor assistive living center for elderly care which requires constant monitoring facility without hampering the privacy of the individuals. We use virtualization technique to provide assistance to individuals and monitor them as virtual units of location. We use a distributed server as information provider and handheld computational devices for local assistance for users.', 'doi': '10.1145/1639642.1639707', 'url': 'https://doi.org/10.1145/1639642.1639707', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Defining virtualization based system abstractions for an indoor assistive living for elderly care', 'author': 'Ahmed, Nova', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639707'}"
Designing AAC interfaces for commercial brain-computer interaction gaming hardware,10.1145/1639642.1639708,Augmentative and Alternative Communication devices strive to provide improved independence for people with severe speech and motor impairments. Recent advances in neural technology have led to devices that can allow the use of electrical signals from the brain to be used as a means of interaction with computers. In this paper we report on the application of a low-cost implementation of this technology to allow for greater independence when using computers.,"{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'brain actuated', 'numpages': '2', 'pages': '265–266', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Augmentative and Alternative Communication devices strive to provide improved independence for people with severe speech and motor impairments. Recent advances in neural technology have led to devices that can allow the use of electrical signals from the brain to be used as a means of interaction with computers. In this paper we report on the application of a low-cost implementation of this technology to allow for greater independence when using computers.', 'doi': '10.1145/1639642.1639708', 'url': 'https://doi.org/10.1145/1639642.1639708', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Designing AAC interfaces for commercial brain-computer interaction gaming hardware', 'author': 'Steward, Stephen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639708'}"
Haptic user interface design for students with visual impairments,10.1145/1639642.1639709,"Many students with visual impairments (VIs) study in public schools instead of special education programs. They should have equal opportunities of learning in competitive educational environments with the most appropriate assistive technology. Yet, today's assistive technology is less likely to support students with VIs in learning visually complex science concepts (e.g., heat and temperature). There is a need of a new means to facilitate their understanding. Haptic technology is considered a useful tool of effectively obtaining information because it enables students with VIs to directly interact with virtual objects and also access sensory cues to feel the objects' various characteristics. This paper aims to explore the haptic user interfaces (UIs) that help students easily understand the concepts of heat and temperature. Archival research and participatory design with teachers were performed to develop haptic UIs and educational contents. Archival research resulted in 44 misconceptions related to heat and temperature. A multimodal interaction was recommended to contribute to user's successful interacting with haptic UIs.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'accessibility, haptic, visual impairments', 'numpages': '2', 'pages': '267–268', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Many students with visual impairments (VIs) study in public schools instead of special education programs. They should have equal opportunities of learning in competitive educational environments with the most appropriate assistive technology. Yet, today's assistive technology is less likely to support students with VIs in learning visually complex science concepts (e.g., heat and temperature). There is a need of a new means to facilitate their understanding. Haptic technology is considered a useful tool of effectively obtaining information because it enables students with VIs to directly interact with virtual objects and also access sensory cues to feel the objects' various characteristics. This paper aims to explore the haptic user interfaces (UIs) that help students easily understand the concepts of heat and temperature. Archival research and participatory design with teachers were performed to develop haptic UIs and educational contents. Archival research resulted in 44 misconceptions related to heat and temperature. A multimodal interaction was recommended to contribute to user's successful interacting with haptic UIs."", 'doi': '10.1145/1639642.1639709', 'url': 'https://doi.org/10.1145/1639642.1639709', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Haptic user interface design for students with visual impairments', 'author': 'Kim, Hyung Nam', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639709'}"
iSET: enabling in situ \&amp; post hoc video labeling,10.1145/1639642.1639710,"Video annotation is an important component of many behavioral interventions for autistic populations. This demonstration presents the interactive Social-Emotional Toolkit (iSET), a highly portable system for in situ video recording and labeling. This tool enables the recording of event labels in a variety of contexts, including behavioral interventions, usability assessments, and interaction studies. With iSET, video can be easily collected and annotated in situ with custom labels and reviewed on-site or later, with labels added or removed to assist video analysis. We describe the current usage as a tool enabling a social-behavioral intervention allowing persons with Autism Spectrum Disorders to capture and review expressions of affect during social interactions.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'autism, user interaction studies, video annotation, video review', 'numpages': '2', 'pages': '269–270', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Video annotation is an important component of many behavioral interventions for autistic populations. This demonstration presents the interactive Social-Emotional Toolkit (iSET), a highly portable system for in situ video recording and labeling. This tool enables the recording of event labels in a variety of contexts, including behavioral interventions, usability assessments, and interaction studies. With iSET, video can be easily collected and annotated in situ with custom labels and reviewed on-site or later, with labels added or removed to assist video analysis. We describe the current usage as a tool enabling a social-behavioral intervention allowing persons with Autism Spectrum Disorders to capture and review expressions of affect during social interactions.', 'doi': '10.1145/1639642.1639710', 'url': 'https://doi.org/10.1145/1639642.1639710', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'iSET: enabling in situ \\&amp; post hoc video labeling', 'author': 'Madsen, Mish and Mahmoud, Abdelrahman N. and Kashef, Youssef', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639710'}"
MGuider: mobile guiding and tracking system in publictransit system for individuals with cognitive impairments,10.1145/1639642.1639711,"In collaboration with NGOs dedicated to supported employment programs, we propose the use of MGuider in public transit systems: a novel mobile guiding and tracking service, to increase work and life independence for cognitive-impaired patients such as people with traumatic brain injury, cerebral palsy, mental retardation, schizophrenia, dementia, and Alzheimer's disease.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'cognitively impaired, mobile social network services, social services, ubiquitous computing', 'numpages': '2', 'pages': '271–272', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In collaboration with NGOs dedicated to supported employment programs, we propose the use of MGuider in public transit systems: a novel mobile guiding and tracking service, to increase work and life independence for cognitive-impaired patients such as people with traumatic brain injury, cerebral palsy, mental retardation, schizophrenia, dementia, and Alzheimer's disease."", 'doi': '10.1145/1639642.1639711', 'url': 'https://doi.org/10.1145/1639642.1639711', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'MGuider: mobile guiding and tracking system in publictransit system for individuals with cognitive impairments', 'author': 'Chen, Wei-Hsun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639711'}"
Real-time anomaly detection for traveling individuals,10.1145/1639642.1639712,"We study real-time anomaly detection in a context that considers user trajectories as input and tries to identify anomaly for users following normal routes such as taking public transportation from the workplace to home or vice versa. Trajectories are modeled as a discrete-time series of axis-parallel constraints (""""boxes"") in the 2D space. The incremental comparison between two trajectories where one trajectory has the current movement pattern and the other is a norm can be calculated according to similarity between two boxes. The proposed system was implemented and evaluated with eight individuals with cognitive impairments. The experimental results showed that recall was 95.0\% and precision was 90.9\% on average without false alarm suppression. False alarms and false negatives dropped when axis rotation was applied. The precision with axis rotation was 97.6\% and the recall was 98.8\%. The average time used for sending locations, running anomaly detection, and issuing warnings was in the range of 15.1 to 22.7 seconds.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'assistive technology, deviation detection, emergency notification, location awareness, ubiquitous computing', 'numpages': '2', 'pages': '273–274', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We study real-time anomaly detection in a context that considers user trajectories as input and tries to identify anomaly for users following normal routes such as taking public transportation from the workplace to home or vice versa. Trajectories are modeled as a discrete-time series of axis-parallel constraints (""""boxes"") in the 2D space. The incremental comparison between two trajectories where one trajectory has the current movement pattern and the other is a norm can be calculated according to similarity between two boxes. The proposed system was implemented and evaluated with eight individuals with cognitive impairments. The experimental results showed that recall was 95.0\\% and precision was 90.9\\% on average without false alarm suppression. False alarms and false negatives dropped when axis rotation was applied. The precision with axis rotation was 97.6\\% and the recall was 98.8\\%. The average time used for sending locations, running anomaly detection, and issuing warnings was in the range of 15.1 to 22.7 seconds.', 'doi': '10.1145/1639642.1639712', 'url': 'https://doi.org/10.1145/1639642.1639712', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Real-time anomaly detection for traveling individuals', 'author': 'Ma, Tian-Shya', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639712'}"
Sensation augmentation to relieve pressure sore formation in wheelchair users,10.1145/1639642.1639713,"Pressure sores are a significant cause of injury and death in patients with spinal cord lesions above the waist. Sores can be prevented by body movement. However, patients with spinal cord lesions lose awareness of body parts and can forget to move body areas frequently enough to prevent sore formation. The SoreStop system unobtrusively encourages patients to move their limbs. It consists of a vibrating armband, sensor inputs, and an Arduino microcontroller. The armband vibrates if the user has not moved enough during the previous 15 minutes. The microcontroller responds to force-sensitive resistors attached to the user's buttocks or position sensors mounted on paralyzed limbs. SoreStop will allow for the development of further devices that may significantly reduce the formation of deadly pressure sores in paraplegics and other patients with sensory loss.","{'series': ""Assets '09"", 'location': 'Pittsburgh, Pennsylvania, USA', 'keywords': 'decubiti, decubitus ulcers, pressure sores, sensory augmentation, wheelchairs', 'numpages': '2', 'pages': '275–276', 'booktitle': 'Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Pressure sores are a significant cause of injury and death in patients with spinal cord lesions above the waist. Sores can be prevented by body movement. However, patients with spinal cord lesions lose awareness of body parts and can forget to move body areas frequently enough to prevent sore formation. The SoreStop system unobtrusively encourages patients to move their limbs. It consists of a vibrating armband, sensor inputs, and an Arduino microcontroller. The armband vibrates if the user has not moved enough during the previous 15 minutes. The microcontroller responds to force-sensitive resistors attached to the user's buttocks or position sensors mounted on paralyzed limbs. SoreStop will allow for the development of further devices that may significantly reduce the formation of deadly pressure sores in paraplegics and other patients with sensory loss."", 'doi': '10.1145/1639642.1639713', 'url': 'https://doi.org/10.1145/1639642.1639713', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781605585581', 'year': '2009', 'title': 'Sensation augmentation to relieve pressure sore formation in wheelchair users', 'author': 'Rush, Raphael P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/1639642.1639713'}"