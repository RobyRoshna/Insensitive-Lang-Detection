Title,DOI,Abstract,BibTeX
Session details: Keynote Presentation,10.1145/3254063,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254063', 'url': 'https://doi.org/10.1145/3254063', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Keynote Presentation', 'author': 'Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254063'}"
Accessibility is Becoming Mainstream,10.1145/2982142.2982180,"Since 1976, when California State University Northridge (CSUN) began its Annual International Technology and Persons with Disabilities Conference, there have been specialized conferences with an accessibility theme. The first ACM ASSETS Conference was held in 1994 when 22 papers were presented. The Rehabilitation Engineering and Assistive Technology Society of North America (RESNA) began its conference in 1979. The first biennial International Conference on Computers Helping People with Special Needs (under a different name) was held in 1988. Accessibility focused journals have existed since at least 1986. This history demonstrates that accessibility has grown into a separate field in research and practice. While this is true, more and more, accessibility has become mainstream.The mainstreaming of accessibility can be seen in its integration into academic computing departments, HCI conferences, and conferences in supporting fields such as computer vision and natural language processing. Most importantly, accessibility can be seen in products and services provided by mainstream industry. One early example of this is the standardization of closed captioning for television. We now have built-in screen readers for iOS and Android devices and Augmentative and Alternative Communication (AAC) devices are being supplemented by lower cost AAC apps on mainstream touchscreen tablets. Technologies like video chat, personal texting, speech recognition, optical character recognition, and speech synthesis have their roots in solving accessibility problems. Slowly, accessibility is moving into the academic curriculum in computing departments [1]. Web design and development courses are starting to cover accessibility in the WCAG 2.0 and ARIA standards. There are capstone courses that focus on accessibility at several universities.There will always be a need for specialized accessibility related devices and services, but moving forward accessibility will be provided by mainstream companies and accessibility solutions will become valuable to everyone, disabled or not. Mainstream technology companies are asking for more people with disabilities to join their diverse workforces.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'disability, accessibility', 'numpages': '1', 'pages': '1', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Since 1976, when California State University Northridge (CSUN) began its Annual International Technology and Persons with Disabilities Conference, there have been specialized conferences with an accessibility theme. The first ACM ASSETS Conference was held in 1994 when 22 papers were presented. The Rehabilitation Engineering and Assistive Technology Society of North America (RESNA) began its conference in 1979. The first biennial International Conference on Computers Helping People with Special Needs (under a different name) was held in 1988. Accessibility focused journals have existed since at least 1986. This history demonstrates that accessibility has grown into a separate field in research and practice. While this is true, more and more, accessibility has become mainstream.The mainstreaming of accessibility can be seen in its integration into academic computing departments, HCI conferences, and conferences in supporting fields such as computer vision and natural language processing. Most importantly, accessibility can be seen in products and services provided by mainstream industry. One early example of this is the standardization of closed captioning for television. We now have built-in screen readers for iOS and Android devices and Augmentative and Alternative Communication (AAC) devices are being supplemented by lower cost AAC apps on mainstream touchscreen tablets. Technologies like video chat, personal texting, speech recognition, optical character recognition, and speech synthesis have their roots in solving accessibility problems. Slowly, accessibility is moving into the academic curriculum in computing departments [1]. Web design and development courses are starting to cover accessibility in the WCAG 2.0 and ARIA standards. There are capstone courses that focus on accessibility at several universities.There will always be a need for specialized accessibility related devices and services, but moving forward accessibility will be provided by mainstream companies and accessibility solutions will become valuable to everyone, disabled or not. Mainstream technology companies are asking for more people with disabilities to join their diverse workforces.', 'doi': '10.1145/2982142.2982180', 'url': 'https://doi.org/10.1145/2982142.2982180', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Accessibility is Becoming Mainstream', 'author': 'Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982180'}"
Session details: Deaf and Hard of Hearing Users,10.1145/3254064,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254064', 'url': 'https://doi.org/10.1145/3254064', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Deaf and Hard of Hearing Users', 'author': 'Vogler, Christian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254064'}"
A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users,10.1145/2982142.2982171,"Sounds provide informative signals about the world around us. In situations where non-auditory cues are inaccessible, it can be useful for deaf and hard-of-hearing people to be notified about sounds. Through a survey, we explored which sounds are of interest to deaf and hard-of-hearing people, and which means of notification are appropriate. Motivated by these findings, we designed a mobile phone app that alerts deaf and hard-of-hearing people to sounds they care about. The app uses training examples of personally relevant sounds recorded by the user to learn a model of those sounds. It then screens the incoming audio stream from the phone's microphone for those sounds. When it detects a sound, it alerts the user by vibrating and providing a pop-up notification. To evaluate the interface design independent of sound detection errors, we ran a Wizard-of-Oz user study, and found that the app design successfully facilitated deaf and hard-of-hearing users recording training examples. We also explored the viability of a basic machine learning algorithm for sound detection.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'sound detection, hard-of-hearing, deaf, accessibility', 'numpages': '11', 'pages': '3–13', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Sounds provide informative signals about the world around us. In situations where non-auditory cues are inaccessible, it can be useful for deaf and hard-of-hearing people to be notified about sounds. Through a survey, we explored which sounds are of interest to deaf and hard-of-hearing people, and which means of notification are appropriate. Motivated by these findings, we designed a mobile phone app that alerts deaf and hard-of-hearing people to sounds they care about. The app uses training examples of personally relevant sounds recorded by the user to learn a model of those sounds. It then screens the incoming audio stream from the phone's microphone for those sounds. When it detects a sound, it alerts the user by vibrating and providing a pop-up notification. To evaluate the interface design independent of sound detection errors, we ran a Wizard-of-Oz user study, and found that the app design successfully facilitated deaf and hard-of-hearing users recording training examples. We also explored the viability of a basic machine learning algorithm for sound detection."", 'doi': '10.1145/2982142.2982171', 'url': 'https://doi.org/10.1145/2982142.2982171', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users', 'author': 'Bragg, Danielle and Huynh, Nicholas and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982171'}"
Improving Real-Time Captioning Experiences for Deaf and Hard of Hearing Students,10.1145/2982142.2982164,"We take a qualitative approach to understanding deaf and hard of hearing (DHH) students' experiences with real-time captioning as an access technology in mainstream university classrooms. We consider both existing human-based captioning as well as new machine-based solutions that use automatic speech recognition (ASR). We employed a variety of qualitative research methods to gather data about students' captioning experiences including in-class observations, interviews, diary studies, and usability evaluations. We also conducted a co-design workshop with 8 stakeholders after our initial research findings. Our results show that accuracy and reliability of the technology are still the most important issues across captioning solutions. However, we additionally found that current captioning solutions tend to limit students' autonomy in the classroom and present a variety of user experience shortcomings, such as complex setups, poor feedback and limited control over caption presentation. Based on these findings, we propose design requirements and recommend features for real-time captioning in mainstream classrooms.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'real-time captions, inclusive classrooms, human factors., deaf and hard of hearing, co-design, automatic speech recognition, access technology', 'numpages': '9', 'pages': '15–23', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We take a qualitative approach to understanding deaf and hard of hearing (DHH) students' experiences with real-time captioning as an access technology in mainstream university classrooms. We consider both existing human-based captioning as well as new machine-based solutions that use automatic speech recognition (ASR). We employed a variety of qualitative research methods to gather data about students' captioning experiences including in-class observations, interviews, diary studies, and usability evaluations. We also conducted a co-design workshop with 8 stakeholders after our initial research findings. Our results show that accuracy and reliability of the technology are still the most important issues across captioning solutions. However, we additionally found that current captioning solutions tend to limit students' autonomy in the classroom and present a variety of user experience shortcomings, such as complex setups, poor feedback and limited control over caption presentation. Based on these findings, we propose design requirements and recommend features for real-time captioning in mainstream classrooms."", 'doi': '10.1145/2982142.2982164', 'url': 'https://doi.org/10.1145/2982142.2982164', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Improving Real-Time Captioning Experiences for Deaf and Hard of Hearing Students', 'author': 'Kawas, Saba and Karalis, George and Wen, Tzu and Ladner, Richard E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982164'}"
SlidePacer: A Presentation Delivery Tool for Instructors of Deaf and Hard of Hearing Students,10.1145/2982142.2982177,"Following multimedia lectures in mainstream classrooms is challenging for deaf and hard-of-hearing (DHH) students, even when provided with accessibility services. Due to multiple visual sources of information (e.g. teacher, slides, interpreter), these students struggle to divide their attention among several simultaneous sources, which may result in missing important parts of the lecture; as a result, access to information is limited in comparison to their hearing peers, having a negative effect in their academic achievements. In this paper we propose a novel approach to improve classroom accessibility, which focuses on improving the delivery of multimedia lectures. We introduce SlidePacer, a tool that promotes coordination between instructors and sign language interpreters, creating a single instructional unit and synchronizing verbal and visual information sources. We conducted a user study with 60 participants on the effects of SlidePacer in terms of learning performance and gaze behaviors. Results show that SlidePacer is effective in providing increased access to multimedia information; however, we did not find significant improvements in learning performance. We finish by discussing our results and limitations of our user study, and suggest future research avenues that build on these insights.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual sources, presentation., pace, multimedia, lecture, learning, interpreter, deaf', 'numpages': '8', 'pages': '25–32', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Following multimedia lectures in mainstream classrooms is challenging for deaf and hard-of-hearing (DHH) students, even when provided with accessibility services. Due to multiple visual sources of information (e.g. teacher, slides, interpreter), these students struggle to divide their attention among several simultaneous sources, which may result in missing important parts of the lecture; as a result, access to information is limited in comparison to their hearing peers, having a negative effect in their academic achievements. In this paper we propose a novel approach to improve classroom accessibility, which focuses on improving the delivery of multimedia lectures. We introduce SlidePacer, a tool that promotes coordination between instructors and sign language interpreters, creating a single instructional unit and synchronizing verbal and visual information sources. We conducted a user study with 60 participants on the effects of SlidePacer in terms of learning performance and gaze behaviors. Results show that SlidePacer is effective in providing increased access to multimedia information; however, we did not find significant improvements in learning performance. We finish by discussing our results and limitations of our user study, and suggest future research avenues that build on these insights.', 'doi': '10.1145/2982142.2982177', 'url': 'https://doi.org/10.1145/2982142.2982177', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'SlidePacer: A Presentation Delivery Tool for Instructors of Deaf and Hard of Hearing Students', 'author': 'Brand\\~{a}o, Alessandra and Nicolau, Hugo and Tadas, Shreya and Hanson, Vicki L.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982177'}"
Session details: Users with Developmental Disabilities,10.1145/3254065,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254065', 'url': 'https://doi.org/10.1145/3254065', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Users with Developmental Disabilities', 'author': 'Rector, Kyle', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254065'}"
Would You Be Mine: Appropriating Minecraft as an Assistive Technology for Youth with Autism,10.1145/2982142.2982172,"Those with disabilities have long adopted, adapted, and appropriated collaborative systems to serve as assistive devices. In this paper, we present the results of a digital ethnography in a Minecraft virtual world for children with autism, specifically examining how this community has used do-it-yourself (DIY) making activities to transform the game into a variety of assistive technologies. Our results demonstrate how players and administrators ""mod"" the Minecraft system to support self-regulation and community engagement. This work highlights the ways in which we, as researchers concerned with accessible and equitable computing spaces, might reevaluate the scope of our inquiry, and how designers might encourage and support appropriation, enhancing users' experience and long-term adoption.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'virtual worlds, modding, minecraft, diy, disability., autism, assistive technology, appropriation', 'numpages': '9', 'pages': '33–41', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Those with disabilities have long adopted, adapted, and appropriated collaborative systems to serve as assistive devices. In this paper, we present the results of a digital ethnography in a Minecraft virtual world for children with autism, specifically examining how this community has used do-it-yourself (DIY) making activities to transform the game into a variety of assistive technologies. Our results demonstrate how players and administrators ""mod"" the Minecraft system to support self-regulation and community engagement. This work highlights the ways in which we, as researchers concerned with accessible and equitable computing spaces, might reevaluate the scope of our inquiry, and how designers might encourage and support appropriation, enhancing users\' experience and long-term adoption.', 'doi': '10.1145/2982142.2982172', 'url': 'https://doi.org/10.1145/2982142.2982172', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Would You Be Mine: Appropriating Minecraft as an Assistive Technology for Youth with Autism', 'author': 'Ringland, Kathryn E. and Wolf, Christine T. and Boyd, LouAnne E. and Baldwin, Mark S. and Hayes, Gillian R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982172'}"
Online Learning System to Help People with Developmental Disabilities Reinforce Basic Skills,10.1145/2982142.2982174,"We present the development and evaluation of an online learning system for people with developmental disabilities (DD) of all ages in collaboration with Imagine! and Hope Services, two not-for-profit organizations that provide care services to people with DD. The system was implemented as an HTML5-based web application for iPad. It includes activities that aim to support and improve the process through which people with DD of all ages reinforce basic skills such as recognizing numbers, letters, money, shapes, and colors. User evaluations suggest that a system such as ours will be: 1) helpful in supporting people with DD reinforce basic skills, and 2) well-received by users.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'web application, online learning, ipad, developmental disability, basic skills', 'numpages': '9', 'pages': '43–51', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present the development and evaluation of an online learning system for people with developmental disabilities (DD) of all ages in collaboration with Imagine! and Hope Services, two not-for-profit organizations that provide care services to people with DD. The system was implemented as an HTML5-based web application for iPad. It includes activities that aim to support and improve the process through which people with DD of all ages reinforce basic skills such as recognizing numbers, letters, money, shapes, and colors. User evaluations suggest that a system such as ours will be: 1) helpful in supporting people with DD reinforce basic skills, and 2) well-received by users.', 'doi': '10.1145/2982142.2982174', 'url': 'https://doi.org/10.1145/2982142.2982174', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Online Learning System to Help People with Developmental Disabilities Reinforce Basic Skills', 'author': 'Morales-Villaverde, Lourdes M. and Caro, Karina and Gotfrid, Taylor and Kurniawan, Sri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982174'}"
"Comparing Tactile, Auditory, and Visual Assembly Error-Feedback for Workers with Cognitive Impairments",10.1145/2982142.2982157,"More and more industrial manufacturing companies are outsourcing assembly tasks to sheltered work organizations where cognitively impaired workers are employed. To facilitate these assembly tasks assistive systems have been introduced to provide cognitive assistance. While previous work found that these assistive systems have a great impact on the workers' performance in giving assembly instructions, these systems are further capable of detecting errors and notifying the worker of an assembly error. However, the topic of how assembly errors are presented to cognitively impaired workers has not been analyzed scientifically. In this paper, we close this gap by comparing tactile, auditory, and visual error feedback in a user study with 16 cognitively impaired workers. The results reveal that visual error feedback leads to a significantly faster assembly time compared to tactile error feedback. Further, we discuss design implications for providing error feedback for workers with cognitive impairments.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'multimodal interfaces, error feedback, cognitively impaired workers, augmented reality, assistive systems', 'numpages': '8', 'pages': '53–60', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""More and more industrial manufacturing companies are outsourcing assembly tasks to sheltered work organizations where cognitively impaired workers are employed. To facilitate these assembly tasks assistive systems have been introduced to provide cognitive assistance. While previous work found that these assistive systems have a great impact on the workers' performance in giving assembly instructions, these systems are further capable of detecting errors and notifying the worker of an assembly error. However, the topic of how assembly errors are presented to cognitively impaired workers has not been analyzed scientifically. In this paper, we close this gap by comparing tactile, auditory, and visual error feedback in a user study with 16 cognitively impaired workers. The results reveal that visual error feedback leads to a significantly faster assembly time compared to tactile error feedback. Further, we discuss design implications for providing error feedback for workers with cognitive impairments."", 'doi': '10.1145/2982142.2982157', 'url': 'https://doi.org/10.1145/2982142.2982157', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Comparing Tactile, Auditory, and Visual Assembly Error-Feedback for Workers with Cognitive Impairments', 'author': 'Kosch, Thomas and Kettner, Romina and Funk, Markus and Schmidt, Albrecht', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982157'}"
Gesture-based Interaction for Individuals with Developmental Disabilities in India,10.1145/2982142.2982166,"Gesture-based interaction provides a multitude of benefits to individuals with disabilities, for example, enhancing social, motor and cognitive skills. However, applications that encourage self-efficacy by promoting a life-skill through simulations of real world scenarios are largely missing. We explore the benefits of using a gesture-based application for individuals with developmental disabilities. The context is a special school in New Delhi, Nai Disha, where we designed and developed an application, Kirana, that integrates arithmetic and social interaction to teach purchasing of items from a local grocery store. In our study, 18 participants with developmental disabilities, previously unable to visit a grocery store, used Kirana for three weeks. Our results indicate that gesture-based applications can teach a life skill and enable self-efficacy for individuals with developmental disabilities by breaking down complex tasks that require social, mathematical and decision-making skills.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'individuals with developmental disabilities, gesture-based interaction, developing countries', 'numpages': '10', 'pages': '61–70', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Gesture-based interaction provides a multitude of benefits to individuals with disabilities, for example, enhancing social, motor and cognitive skills. However, applications that encourage self-efficacy by promoting a life-skill through simulations of real world scenarios are largely missing. We explore the benefits of using a gesture-based application for individuals with developmental disabilities. The context is a special school in New Delhi, Nai Disha, where we designed and developed an application, Kirana, that integrates arithmetic and social interaction to teach purchasing of items from a local grocery store. In our study, 18 participants with developmental disabilities, previously unable to visit a grocery store, used Kirana for three weeks. Our results indicate that gesture-based applications can teach a life skill and enable self-efficacy for individuals with developmental disabilities by breaking down complex tasks that require social, mathematical and decision-making skills.', 'doi': '10.1145/2982142.2982166', 'url': 'https://doi.org/10.1145/2982142.2982166', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Gesture-based Interaction for Individuals with Developmental Disabilities in India', 'author': 'Sharma, Sumita and Srivastava, Saurabh and Achary, Krishnaveni and Varkey, Blessin and Heimonen, Tomi and Hakulinen, Jaakko and Turunen, Markku and Rajput, Nitendra', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982166'}"
Session details: Tactile Information for Blind Users,10.1145/3254066,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254066', 'url': 'https://doi.org/10.1145/3254066', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Tactile Information for Blind Users', 'author': 'Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254066'}"
Customizable 3D Printed Tactile Maps as Interactive Overlays,10.1145/2982142.2982167,"Though tactile maps have been shown to be useful tools for visually impaired individuals, their availability has been limited by manufacturing and design costs. In this paper, we present a system that uses 3D printing to (1) make tactile maps more affordable to produce, (2) allow visually impaired individuals to independently design and customize maps, and (3) provide interactivity using widely available mobile devices. Our system consists of three parts: a web interface, a modeling algorithm, and an interactive touchscreen application. Our web interface, hosted at www.tactilemaps.net, allows visually impaired individuals to create maps of any location on the globe while specifying (1) what features to map, (2) how the features should be represented by textures, and (3) where to place markers and labels. Our modeling algorithm accommodates user specifications to create map models with (1) multiple layers of continuously varying textures and (2) markers of various geometric shapes or braille characters. Our interactive application uses a novel approach to 3D printing tactile maps using conductive filament to provide touchscreen overlays that allow users to dynamically interact with the maps on a wide range of mobile devices. This paper details the implementation of our system. We also present findings from a user study validating the usability of our mapping interface and the utility of the maps produced. Finally, we discuss the limitations of our current implementation and the plans we have to improve our system based on feedback from our user study and additional interviews.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'tactile maps, 3d printing', 'numpages': '9', 'pages': '71–79', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Though tactile maps have been shown to be useful tools for visually impaired individuals, their availability has been limited by manufacturing and design costs. In this paper, we present a system that uses 3D printing to (1) make tactile maps more affordable to produce, (2) allow visually impaired individuals to independently design and customize maps, and (3) provide interactivity using widely available mobile devices. Our system consists of three parts: a web interface, a modeling algorithm, and an interactive touchscreen application. Our web interface, hosted at www.tactilemaps.net, allows visually impaired individuals to create maps of any location on the globe while specifying (1) what features to map, (2) how the features should be represented by textures, and (3) where to place markers and labels. Our modeling algorithm accommodates user specifications to create map models with (1) multiple layers of continuously varying textures and (2) markers of various geometric shapes or braille characters. Our interactive application uses a novel approach to 3D printing tactile maps using conductive filament to provide touchscreen overlays that allow users to dynamically interact with the maps on a wide range of mobile devices. This paper details the implementation of our system. We also present findings from a user study validating the usability of our mapping interface and the utility of the maps produced. Finally, we discuss the limitations of our current implementation and the plans we have to improve our system based on feedback from our user study and additional interviews.', 'doi': '10.1145/2982142.2982167', 'url': 'https://doi.org/10.1145/2982142.2982167', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Customizable 3D Printed Tactile Maps as Interactive Overlays', 'author': 'Taylor, Brandon and Dey, Anind and Siewiorek, Dan and Smailagic, Asim', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982167'}"
LucentMaps: 3D Printed Audiovisual Tactile Maps for Blind and Visually Impaired People,10.1145/2982142.2982163,"Tactile maps support blind and visually impaired people in orientation and to familiarize with unfamiliar environments. Interactive approaches complement these maps with auditory feedback. However, commonly these approaches focus on blind people. We present an approach which incorporates visually impaired people by visually augmenting relevant parts of tactile maps. These audiovisual tactile maps can be used in conjunction with common tablet computers and smartphones. By integrating conductive elements into 3D printed tactile maps, they can be recognized by a single touch on the mobile device's display, which eases the handling for blind and visually impaired people. To allow multiple elevation levels in our transparent tactile maps, we conducted a study to reconcile technical and physiological requirements of off-the-shelf 3D printers, capacitive touch inputs and the human tactile sense. We propose an interaction concept for 3D printed audiovisual tactile maps, verify its feasibility and test it with a user study. Our discussion includes economic considerations crucial for a broad dissemination of tactile maps for both blind and visually impaired people.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'touch screen, tangible user interfaces, tactile maps, orientation, marker, global, functional, capacitive sensing, capacitive, blind, audio-tactile, accessibility, 3d printing', 'numpages': '10', 'pages': '81–90', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Tactile maps support blind and visually impaired people in orientation and to familiarize with unfamiliar environments. Interactive approaches complement these maps with auditory feedback. However, commonly these approaches focus on blind people. We present an approach which incorporates visually impaired people by visually augmenting relevant parts of tactile maps. These audiovisual tactile maps can be used in conjunction with common tablet computers and smartphones. By integrating conductive elements into 3D printed tactile maps, they can be recognized by a single touch on the mobile device's display, which eases the handling for blind and visually impaired people. To allow multiple elevation levels in our transparent tactile maps, we conducted a study to reconcile technical and physiological requirements of off-the-shelf 3D printers, capacitive touch inputs and the human tactile sense. We propose an interaction concept for 3D printed audiovisual tactile maps, verify its feasibility and test it with a user study. Our discussion includes economic considerations crucial for a broad dissemination of tactile maps for both blind and visually impaired people."", 'doi': '10.1145/2982142.2982163', 'url': 'https://doi.org/10.1145/2982142.2982163', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'LucentMaps: 3D Printed Audiovisual Tactile Maps for Blind and Visually Impaired People', 'author': 'G\\""{o}tzelmann, Timo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982163'}"
Gesture-Based Interactive Audio Guide on Tactile Reliefs,10.1145/2982142.2982176,"For blind and visually impaired people, tactile reliefs offer many benefits over the more classic raised line drawings or tactile diagrams, as depth, 3D shape and surface textures are directly perceivable. However, without proper guidance some reliefs are still difficult to explore autonomously.In this work, we present a gesture-controlled interactive audio guide (IAG) based on recent low-cost depth cameras that operates directly on relief surfaces. The interactively explorable, location-dependent verbal descriptions promise rapid tactile accessibility to 2.5D spatial information in a home or education setting, to on-line resources, or as a kiosk installation at public places.We present a working prototype, discuss design decisions and present the results of two evaluation sessions with a total of 20 visually impaired test users.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'tactile reliefs, interactive audio guide, gesture detection, finger tracking, evaluation, blind users', 'numpages': '10', 'pages': '91–100', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'For blind and visually impaired people, tactile reliefs offer many benefits over the more classic raised line drawings or tactile diagrams, as depth, 3D shape and surface textures are directly perceivable. However, without proper guidance some reliefs are still difficult to explore autonomously.In this work, we present a gesture-controlled interactive audio guide (IAG) based on recent low-cost depth cameras that operates directly on relief surfaces. The interactively explorable, location-dependent verbal descriptions promise rapid tactile accessibility to 2.5D spatial information in a home or education setting, to on-line resources, or as a kiosk installation at public places.We present a working prototype, discuss design decisions and present the results of two evaluation sessions with a total of 20 visually impaired test users.', 'doi': '10.1145/2982142.2982176', 'url': 'https://doi.org/10.1145/2982142.2982176', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Gesture-Based Interactive Audio Guide on Tactile Reliefs', 'author': 'Reichinger, Andreas and Fuhrmann, Anton and Maierhofer, Stefan and Purgathofer, Werner', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982176'}"
Tactile Accessibility: Does Anyone Need a Haptic Glove?,10.1145/2982142.2982175,"Graphical user interfaces (GUIs) are widely used on smartphones, tablets, and laptops. While GUIs are convenient for sighted users, their accessibility for blind people, who use screen readers to interact with GUIs, remains to be problematic. Even the most screen-reader accessible GUIs are far less usable for blind people compared to sighted people, because the former group cannot benefit from the geometric layout of GUIs. As a result, blind people often have to listen through a lot of irrelevant content before they find what they are looking for. Haptic interfaces (those providing tactile feedback) have the potential to make GUI interfaces more accessible and usable for blind people. Alas, mainstream computer devices do not have haptic screens that would enable high-resolution tactile feedback, and specialized haptic devices are very limited and/or are exuberantly expensive and bulky.  In this paper, we describe a low-cost haptic-glove system, FeelX, which can potentially enable usable tactile interaction with GUIs. The vision of FeelX is to enable blind users to connect it to any computer or smartphone, and then interact with it by moving their hands on any flat surface such as the desk or table. To establish the practicality and the desirability of using haptic gloves, we evaluated the initial prototype of the glove in a user study with 20 blind participants. Throughout the study, we performed a comparative evaluation of several design options for the tactile interface. The participants were asked to identify simple geometric figures such as lines, rectangles, circles, and triangles that are the basic building blocks of any GUI interface. Although the FeelX prototype is far from being a usable product, the results of the study indicate that blind users want to use haptic gloves.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'tactile interaction, tactile exploration, screen reader, haptic glove, haptic display, gui accessibility, blindness', 'numpages': '9', 'pages': '101–109', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Graphical user interfaces (GUIs) are widely used on smartphones, tablets, and laptops. While GUIs are convenient for sighted users, their accessibility for blind people, who use screen readers to interact with GUIs, remains to be problematic. Even the most screen-reader accessible GUIs are far less usable for blind people compared to sighted people, because the former group cannot benefit from the geometric layout of GUIs. As a result, blind people often have to listen through a lot of irrelevant content before they find what they are looking for. Haptic interfaces (those providing tactile feedback) have the potential to make GUI interfaces more accessible and usable for blind people. Alas, mainstream computer devices do not have haptic screens that would enable high-resolution tactile feedback, and specialized haptic devices are very limited and/or are exuberantly expensive and bulky.  In this paper, we describe a low-cost haptic-glove system, FeelX, which can potentially enable usable tactile interaction with GUIs. The vision of FeelX is to enable blind users to connect it to any computer or smartphone, and then interact with it by moving their hands on any flat surface such as the desk or table. To establish the practicality and the desirability of using haptic gloves, we evaluated the initial prototype of the glove in a user study with 20 blind participants. Throughout the study, we performed a comparative evaluation of several design options for the tactile interface. The participants were asked to identify simple geometric figures such as lines, rectangles, circles, and triangles that are the basic building blocks of any GUI interface. Although the FeelX prototype is far from being a usable product, the results of the study indicate that blind users want to use haptic gloves.', 'doi': '10.1145/2982142.2982175', 'url': 'https://doi.org/10.1145/2982142.2982175', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Tactile Accessibility: Does Anyone Need a Haptic Glove?', 'author': 'Soviak, Andrii and Borodin, Anatoliy and Ashok, Vikas and Borodin, Yevgen and Puzis, Yury and Ramakrishnan, I.V.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982175'}"
Session details: Communication and Aging,10.1145/3254067,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254067', 'url': 'https://doi.org/10.1145/3254067', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Communication and Aging', 'author': 'Moffatt, Karyn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254067'}"
The Cost of Turning Heads: A Comparison of a Head-Worn Display to a Smartphone for Supporting Persons with Aphasia in Conversation,10.1145/2982142.2982165,"Current symbol-based dictionaries providing vocabulary support for persons with the language disorder, aphasia, are housed on smartphones or other portable devices. To employ the support on these external devices requires the user to divert their attention away from their conversation partner, to the neglect of conversation dynamics like eye contact or verbal inflection. A prior study investigated head-worn displays (HWDs) as an alternative form factor for supporting glanceable, unobtrusive, and always-available conversation support, but it did not directly compare the HWD to a control condition. To address this limitation, we compared vocabulary support on a HWD to equivalent support on a smartphone in terms of overall experience, perceived focus, and conversational success. Lastly, we elicited critical discussion of how each device might be better designed for conversation support. Our work contributes (1) evidence that a HWD can support more efficient communication, (2) preliminary results that a HWD can provide a better overall experience using assistive vocabulary, and (3) a characterization of the design features persons with aphasia value in portable conversation support technologies. Our findings should motivate further work on head-worn conversation support for persons with aphasia.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wearable computing, head-worn display, conversational support, aphasia, accessibility., aac', 'numpages': '10', 'pages': '111–120', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Current symbol-based dictionaries providing vocabulary support for persons with the language disorder, aphasia, are housed on smartphones or other portable devices. To employ the support on these external devices requires the user to divert their attention away from their conversation partner, to the neglect of conversation dynamics like eye contact or verbal inflection. A prior study investigated head-worn displays (HWDs) as an alternative form factor for supporting glanceable, unobtrusive, and always-available conversation support, but it did not directly compare the HWD to a control condition. To address this limitation, we compared vocabulary support on a HWD to equivalent support on a smartphone in terms of overall experience, perceived focus, and conversational success. Lastly, we elicited critical discussion of how each device might be better designed for conversation support. Our work contributes (1) evidence that a HWD can support more efficient communication, (2) preliminary results that a HWD can provide a better overall experience using assistive vocabulary, and (3) a characterization of the design features persons with aphasia value in portable conversation support technologies. Our findings should motivate further work on head-worn conversation support for persons with aphasia.', 'doi': '10.1145/2982142.2982165', 'url': 'https://doi.org/10.1145/2982142.2982165', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'The Cost of Turning Heads: A Comparison of a Head-Worn Display to a Smartphone for Supporting Persons with Aphasia in Conversation', 'author': 'Williams, Kristin and Moffatt, Karyn and Hong, Jonggi and Faroqi-Shah, Yasmeen and Findlater, Leah', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982165'}"
Session details: Rehabilitation and Clinical Technologies,10.1145/3254068,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254068', 'url': 'https://doi.org/10.1145/3254068', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Rehabilitation and Clinical Technologies', 'author': 'Kane, Shaun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254068'}"
A Computer Vision-Based System for Stride Length Estimation using a Mobile Phone Camera,10.1145/2982142.2982156,"Conditions such as Parkinson's disease (PD), a chronic neurodegenerative disorder which severely affects the motor system, will be an increasingly common problem for our growing and aging population. Gait analysis is widely used as a noninvasive method for PD diagnosis and assessment. However, current clinical systems for gait analysis usually require highly specialized cameras and lab settings, which are expensive and not scalable. This paper presents a computer vision-based gait analysis system using a camera on a common mobile phone. A simple PVC mat was designed with markers printed on it, on which a subject can walk whilst being recorded by a mobile phone camera. A set of video analysis methods were developed to segment the walking video, detect the mat and feet locations, and calculate gait parameters such as stride length. Experiments showed that stride length measurement has a mean absolute error of 0.62 cm, which is comparable with the ""gold standard"" walking mat system GAITRite. We also tested our system on Parkinson's disease patients in a real clinical environment. Our system is affordable, portable, and scalable, indicating a potential clinical gait measurement tool for use in both hospitals and the homes of patients.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': ""video analysis, parkinson's disease, movement disorder, mobile camera, gait analysis, computer vision"", 'numpages': '10', 'pages': '121–130', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Conditions such as Parkinson\'s disease (PD), a chronic neurodegenerative disorder which severely affects the motor system, will be an increasingly common problem for our growing and aging population. Gait analysis is widely used as a noninvasive method for PD diagnosis and assessment. However, current clinical systems for gait analysis usually require highly specialized cameras and lab settings, which are expensive and not scalable. This paper presents a computer vision-based gait analysis system using a camera on a common mobile phone. A simple PVC mat was designed with markers printed on it, on which a subject can walk whilst being recorded by a mobile phone camera. A set of video analysis methods were developed to segment the walking video, detect the mat and feet locations, and calculate gait parameters such as stride length. Experiments showed that stride length measurement has a mean absolute error of 0.62 cm, which is comparable with the ""gold standard"" walking mat system GAITRite. We also tested our system on Parkinson\'s disease patients in a real clinical environment. Our system is affordable, portable, and scalable, indicating a potential clinical gait measurement tool for use in both hospitals and the homes of patients.', 'doi': '10.1145/2982142.2982156', 'url': 'https://doi.org/10.1145/2982142.2982156', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'A Computer Vision-Based System for Stride Length Estimation using a Mobile Phone Camera', 'author': 'Zhu, Wei and Anderson, Boyd and Zhu, Shenggao and Wang, Ye', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982156'}"
Uncovering Challenges and Opportunities for 3D Printing Assistive Technology with Physical Therapists,10.1145/2982142.2982162,"Physical therapists have a history of modifying and making assistive technology (AT) to fit the unique needs of their patients. However, lack of materials, time, and access to training can restrict what they can create. While 3D printing has the opportunity to empower physical therapists to develop highly customized, economical, and timely assistive technology; little is known about the feasibility of using 3D printing in a clinical setting, and how to teach and engage physical therapists in physical prototyping. We collaborated with physical therapy professors and students at a medical university to integrate 3D printing and AT design into a graduate-level physical therapy class. Our investigation showed 3D printing is a viable tool for clinical production of AT. We found opportunities and barriers to 3D printing in the physical therapy field, and we present four considerations relevant to integrating 3D printing into clinical practice: 1) exploring augmentations versus novel AT designs, 2) improvements to novice 3D modeling software, 3) adjusting for prototype fidelity, and 4) selecting 3D printing materials. This paper contributes knowledge toward the understanding of practical applications of 3D printing in a clinical setting and teaching 3D modeling to non-engineers.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'physical therapy., physical fabrication, education, digital fabrication, assistive technology, 3d printing, 3d modeling', 'numpages': '9', 'pages': '131–139', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Physical therapists have a history of modifying and making assistive technology (AT) to fit the unique needs of their patients. However, lack of materials, time, and access to training can restrict what they can create. While 3D printing has the opportunity to empower physical therapists to develop highly customized, economical, and timely assistive technology; little is known about the feasibility of using 3D printing in a clinical setting, and how to teach and engage physical therapists in physical prototyping. We collaborated with physical therapy professors and students at a medical university to integrate 3D printing and AT design into a graduate-level physical therapy class. Our investigation showed 3D printing is a viable tool for clinical production of AT. We found opportunities and barriers to 3D printing in the physical therapy field, and we present four considerations relevant to integrating 3D printing into clinical practice: 1) exploring augmentations versus novel AT designs, 2) improvements to novice 3D modeling software, 3) adjusting for prototype fidelity, and 4) selecting 3D printing materials. This paper contributes knowledge toward the understanding of practical applications of 3D printing in a clinical setting and teaching 3D modeling to non-engineers.', 'doi': '10.1145/2982142.2982162', 'url': 'https://doi.org/10.1145/2982142.2982162', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Uncovering Challenges and Opportunities for 3D Printing Assistive Technology with Physical Therapists', 'author': 'McDonald, Samantha and Comrie, Niara and Buehler, Erin and Carter, Nicholas and Dubin, Braxton and Gordes, Karen and McCombe-Waller, Sandy and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982162'}"
Session details: Big Data and Blind Users,10.1145/3254069,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254069', 'url': 'https://doi.org/10.1145/3254069', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Big Data and Blind Users', 'author': 'McCoy, Kathleen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254069'}"
WeAllWalk: An Annotated Data Set of Inertial Sensor Time Series from Blind Walkers,10.1145/2982142.2982179,"We introduce WeAllWalk, a data set of inertial sensor time series collected from blind walkers using a long cane or a guide dog. Blind participants walked through fairly long and complex indoor routes that included obstacles to be avoided and doors to be opened. Inertial data was recorded by two iPhone 6s carried by our participants in their pockets and carefully annotated. Ground truth heel strike times were measured by two small inertial sensor units clipped to the participants' shoes. We also show comparative examples of application of step counting and turn detection algorithms to selected data from WeAllWalk.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wayfinding, step counting., inertial sensing', 'numpages': '10', 'pages': '141–150', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We introduce WeAllWalk, a data set of inertial sensor time series collected from blind walkers using a long cane or a guide dog. Blind participants walked through fairly long and complex indoor routes that included obstacles to be avoided and doors to be opened. Inertial data was recorded by two iPhone 6s carried by our participants in their pockets and carefully annotated. Ground truth heel strike times were measured by two small inertial sensor units clipped to the participants' shoes. We also show comparative examples of application of step counting and turn detection algorithms to selected data from WeAllWalk."", 'doi': '10.1145/2982142.2982179', 'url': 'https://doi.org/10.1145/2982142.2982179', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'WeAllWalk: An Annotated Data Set of Inertial Sensor Time Series from Blind Walkers', 'author': 'Flores, German H. and Manduchi, Roberto', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982179'}"
Supporting Orientation of People with Visual Impairment: Analysis of Large Scale Usage Data,10.1145/2982142.2982178,"In the field of assistive technology, large scale user studies are hindered by the fact that potential participants are geographically sparse and longitudinal studies are often time consuming. In this contribution, we rely on remote usage data to perform large scale and long duration behavior analysis on users of iMove, a mobile app that supports the orientation of people with visual impairments.Exploratory analysis highlights popular functions, common configuration settings, and usage patterns among iMove users. The study shows stark differences between users accessing the app through VoiceOver and other users, who tend to use the app more scarcely and sporadically.Analysis through clustering of VoiceOver iMove user interactions discovers four distinct user groups: 1) users interested in surrounding points of interest, 2) users keeping the app active for long sessions while in movement, 3) users interacting in short bursts to inquire about current location, and 4) users querying in bursts about surrounding points of interest and addresses.Our analysis provides insights into iMove's user base and can inform decisions for tailoring the app to diverse user groups, developing future improvements of the software, or guiding the design process of similar assistive tools.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairment, user behavior models, outdoor navigation, interaction stream analysis', 'numpages': '9', 'pages': '151–159', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In the field of assistive technology, large scale user studies are hindered by the fact that potential participants are geographically sparse and longitudinal studies are often time consuming. In this contribution, we rely on remote usage data to perform large scale and long duration behavior analysis on users of iMove, a mobile app that supports the orientation of people with visual impairments.Exploratory analysis highlights popular functions, common configuration settings, and usage patterns among iMove users. The study shows stark differences between users accessing the app through VoiceOver and other users, who tend to use the app more scarcely and sporadically.Analysis through clustering of VoiceOver iMove user interactions discovers four distinct user groups: 1) users interested in surrounding points of interest, 2) users keeping the app active for long sessions while in movement, 3) users interacting in short bursts to inquire about current location, and 4) users querying in bursts about surrounding points of interest and addresses.Our analysis provides insights into iMove's user base and can inform decisions for tailoring the app to diverse user groups, developing future improvements of the software, or guiding the design process of similar assistive tools."", 'doi': '10.1145/2982142.2982178', 'url': 'https://doi.org/10.1145/2982142.2982178', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Supporting Orientation of People with Visual Impairment: Analysis of Large Scale Usage Data', 'author': 'Kacorri, Hernisa and Mascetti, Sergio and Gerino, Andrea and Ahmetovic, Dragan and Takagi, Hironobu and Asakawa, Chieko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982178'}"
Session details: Text Entry Challenge in Memory of Torsten Felzer,10.1145/3254070,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254070', 'url': 'https://doi.org/10.1145/3254070', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Text Entry Challenge in Memory of Torsten Felzer', 'author': 'Sporka, Adam', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254070'}"
An Evaluation of SingleTapBraille Keyboard: A Text Entry Method that Utilizes Braille Patterns on Touchscreen Devices,10.1145/2982142.2982161,"This paper provides an evaluation of the SingleTapBraille keyboard, designed to assist people with no or low vision in using touchscreen smartphones. This application allows blind users to input characters based on braille patterns. To assess SingleTapBraille, this study compares its performance with that of the commonly used QWERTY keyboard. We conducted an evaluation study with 7 blind participants to examine the performance of both keyboards on Android platforms. Overall, participants were able to quickly adjust to SingleTapBraille and type on touchscreen devices using their knowledge of Braille patterns within fifteen to twenty minutes of introduction to the system. The SingleTapBraille keyboard was better than the QWERTY keyboard in terms of both speed and accuracy, indicating that SingleTapBraille represents an improvement over existing alternatives in making touchscreen keyboards more accessible for blind users. Based on the evaluation results and the feedback of our participants, we discuss the strengths and weaknesses of previous keyboards that have been used by participants, as well as those of SingleTapBraille. In doing so, we consider possible design improvements for the future development of accessible keyboards for blind users.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'touchscreens, text entry, tapping, smartphone devices, single-touch interaction, gestures., braille patterns, blindness, accessibility', 'numpages': '9', 'pages': '161–169', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper provides an evaluation of the SingleTapBraille keyboard, designed to assist people with no or low vision in using touchscreen smartphones. This application allows blind users to input characters based on braille patterns. To assess SingleTapBraille, this study compares its performance with that of the commonly used QWERTY keyboard. We conducted an evaluation study with 7 blind participants to examine the performance of both keyboards on Android platforms. Overall, participants were able to quickly adjust to SingleTapBraille and type on touchscreen devices using their knowledge of Braille patterns within fifteen to twenty minutes of introduction to the system. The SingleTapBraille keyboard was better than the QWERTY keyboard in terms of both speed and accuracy, indicating that SingleTapBraille represents an improvement over existing alternatives in making touchscreen keyboards more accessible for blind users. Based on the evaluation results and the feedback of our participants, we discuss the strengths and weaknesses of previous keyboards that have been used by participants, as well as those of SingleTapBraille. In doing so, we consider possible design improvements for the future development of accessible keyboards for blind users.', 'doi': '10.1145/2982142.2982161', 'url': 'https://doi.org/10.1145/2982142.2982161', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'An Evaluation of SingleTapBraille Keyboard: A Text Entry Method that Utilizes Braille Patterns on Touchscreen Devices', 'author': 'Alnfiai, Maraim and Sampalli, Srinivas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982161'}"
Session details: Users with Visual Impairments,10.1145/3254071,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254071', 'url': 'https://doi.org/10.1145/3254071', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Users with Visual Impairments', 'author': 'Mascetti, Sergio', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254071'}"
How People with Low Vision Access Computing Devices: Understanding Challenges and Opportunities,10.1145/2982142.2982168,"Low vision is a pervasive condition in which people have difficulty seeing even with corrective lenses. People with low vision frequently use mainstream computing devices, however how they use their devices to access information and whether digital low vision accessibility tools provide adequate support remains understudied. We addressed these questions with a contextual inquiry study. We observed 11 low vision participants using their smartphones, tablets, and computers when performing simple tasks such as reading email. We found that participants preferred accessing information visually than aurally (e.g., screen readers), and juggled a variety of accessibility tools. However, accessibility tools did not provide them with appropriate support. Moreover, participants had to constantly perform multiple gestures in order to see content comfortably. These challenges made participants inefficient-they were slow and often made mistakes; even tech savvy participants felt frustrated and not in control. Our findings reveal the unique needs of low vision people, which differ from those of people with no vision and design opportunities for improving low vision accessibility tools.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'low vision, contextual inquiry, computing devices, accessibility', 'numpages': '10', 'pages': '171–180', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Low vision is a pervasive condition in which people have difficulty seeing even with corrective lenses. People with low vision frequently use mainstream computing devices, however how they use their devices to access information and whether digital low vision accessibility tools provide adequate support remains understudied. We addressed these questions with a contextual inquiry study. We observed 11 low vision participants using their smartphones, tablets, and computers when performing simple tasks such as reading email. We found that participants preferred accessing information visually than aurally (e.g., screen readers), and juggled a variety of accessibility tools. However, accessibility tools did not provide them with appropriate support. Moreover, participants had to constantly perform multiple gestures in order to see content comfortably. These challenges made participants inefficient-they were slow and often made mistakes; even tech savvy participants felt frustrated and not in control. Our findings reveal the unique needs of low vision people, which differ from those of people with no vision and design opportunities for improving low vision accessibility tools.', 'doi': '10.1145/2982142.2982168', 'url': 'https://doi.org/10.1145/2982142.2982168', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'How People with Low Vision Access Computing Devices: Understanding Challenges and Opportunities', 'author': 'Szpiro, Sarit Felicia Anais and Hashash, Shafeka and Zhao, Yuhang and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982168'}"
Real-Time Mobile Personalized Simulations of Impaired Colour Vision,10.1145/2982142.2982170,"Colour forms an essential element of day-to-day life for most people, but at least 5\% of the world have Impaired Colour Vision (ICV) - seeing fewer colours than everyone else. Those with typical colour vision find it difficult to understand how people with ICV perceive colour, leading to misunderstanding and challenges for people with ICV. To help improve understanding, personalized simulations of ICV have been developed, but are computationally demanding (so limited to static images), which limits the value of these simulations. To address this, we extended personalized ICV simulations to work in real time on a mobile device to allow people with typical colour vision greater freedom in exploring ICV. To validate our approach, we compared our real-time simulation technique to an existing adjustable simulation technique and found general agreement between the two. We then deployed three real-time personalized ICV simulations to nine people with typical colour vision, encouraging them to take photos of interesting colour situations. In just over one week, participants recorded over 450 real-world images of situations where their simulation presented a distinct challenge for their respective ICV participant. Through a questionnaire and discussion of photos with participants, we found that our solution provides a valuable mechanism for building understanding of ICV for people with typical colour vision.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'mobile personalized simulation, impaired colour vision, colourblindness, colour vision deficiency', 'numpages': '9', 'pages': '181–189', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Colour forms an essential element of day-to-day life for most people, but at least 5\\% of the world have Impaired Colour Vision (ICV) - seeing fewer colours than everyone else. Those with typical colour vision find it difficult to understand how people with ICV perceive colour, leading to misunderstanding and challenges for people with ICV. To help improve understanding, personalized simulations of ICV have been developed, but are computationally demanding (so limited to static images), which limits the value of these simulations. To address this, we extended personalized ICV simulations to work in real time on a mobile device to allow people with typical colour vision greater freedom in exploring ICV. To validate our approach, we compared our real-time simulation technique to an existing adjustable simulation technique and found general agreement between the two. We then deployed three real-time personalized ICV simulations to nine people with typical colour vision, encouraging them to take photos of interesting colour situations. In just over one week, participants recorded over 450 real-world images of situations where their simulation presented a distinct challenge for their respective ICV participant. Through a questionnaire and discussion of photos with participants, we found that our solution provides a valuable mechanism for building understanding of ICV for people with typical colour vision.', 'doi': '10.1145/2982142.2982170', 'url': 'https://doi.org/10.1145/2982142.2982170', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Real-Time Mobile Personalized Simulations of Impaired Colour Vision', 'author': 'MacAlpine, Rhouri and Flatla, David R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982170'}"
Should I Trust It When I Cannot See It? Credibility Assessment for Blind Web Users,10.1145/2982142.2982173,"As users become increasingly more reliant on online resources to satisfy their information needs, care is needed to ensure that these resources are credible in nature, especially if a decision is to be taken based upon the information accessed. The credibility of a web site is known to be heavily influenced by its visual appearance. However, for individuals who are blind, challenges are often faced accessing these visual cues when using assistive technologies. In this paper, we describe an observational study to examine the strategies and workarounds developed by individuals who are blind to perform credibility assessments. These are compared with those used by sighted users. Findings from the study have highlighted the relationship between accessibility and credibility. The features used to form assessments non-visually have also been identified. Insights from the study can be used to support the design of highly credible interfaces for blind screen reader users.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'web credibility, visually-impaired, blind, accessibility', 'numpages': '9', 'pages': '191–199', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'As users become increasingly more reliant on online resources to satisfy their information needs, care is needed to ensure that these resources are credible in nature, especially if a decision is to be taken based upon the information accessed. The credibility of a web site is known to be heavily influenced by its visual appearance. However, for individuals who are blind, challenges are often faced accessing these visual cues when using assistive technologies. In this paper, we describe an observational study to examine the strategies and workarounds developed by individuals who are blind to perform credibility assessments. These are compared with those used by sighted users. Findings from the study have highlighted the relationship between accessibility and credibility. The features used to form assessments non-visually have also been identified. Insights from the study can be used to support the design of highly credible interfaces for blind screen reader users.', 'doi': '10.1145/2982142.2982173', 'url': 'https://doi.org/10.1145/2982142.2982173', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Should I Trust It When I Cannot See It? Credibility Assessment for Blind Web Users', 'author': 'Abdolrahmani, Ali and Kuber, Ravi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982173'}"
Session details: Haptic and Audio Feedback for Blind Users,10.1145/3254072,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254072', 'url': 'https://doi.org/10.1145/3254072', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Haptic and Audio Feedback for Blind Users', 'author': 'Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254072'}"
Blind Photographers and VizSnap: A Long-Term Study,10.1145/2982142.2982169,"This paper describes a long term user study in which 13 blind participants were asked to use a blind friendly iPhone app, VizSnap -- an app designed to assist blind people in organizing and browsing a photo library without sight -- for a total of two months. VizSnap records audio while the user is aiming the camera, and allows an optional voice memo to be recorded, to allow the user to give custom information to accompany the photo, as well as capturing time, date, and location the photo was taken. All this information is available to the user when browsing through VizSnap's photo library. The participants met with us every two weeks, in which we discuss general VizSnap usage, conduct a short user study with their photos, as well as upload all data that was gathered using VizSnap. The user study aims to determine whether accompanying audio, time, date, and location metadata assists in memory retrieval of photos by blind people. We found that in general, both ambient audio and voice memo are considered most helpful for memory retrieval.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'photography, mobile, blind users, accessibility.', 'numpages': '8', 'pages': '201–208', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper describes a long term user study in which 13 blind participants were asked to use a blind friendly iPhone app, VizSnap -- an app designed to assist blind people in organizing and browsing a photo library without sight -- for a total of two months. VizSnap records audio while the user is aiming the camera, and allows an optional voice memo to be recorded, to allow the user to give custom information to accompany the photo, as well as capturing time, date, and location the photo was taken. All this information is available to the user when browsing through VizSnap's photo library. The participants met with us every two weeks, in which we discuss general VizSnap usage, conduct a short user study with their photos, as well as upload all data that was gathered using VizSnap. The user study aims to determine whether accompanying audio, time, date, and location metadata assists in memory retrieval of photos by blind people. We found that in general, both ambient audio and voice memo are considered most helpful for memory retrieval."", 'doi': '10.1145/2982142.2982169', 'url': 'https://doi.org/10.1145/2982142.2982169', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Blind Photographers and VizSnap: A Long-Term Study', 'author': 'Adams, Dustin and Kurniawan, Sri and Herrera, Cynthia and Kang, Veronica and Friedman, Natalie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982169'}"
Using Dynamic Audio Feedback to Support Peripersonal Reaching in Young Visually Impaired People,10.1145/2982142.2982160,"Blind children engage with their immediate environment much less than sighted children, particularly through self-initiated movement or exploration. Research has suggested that providing dynamic feedback about the environment and the child's actions within/against it may help to encourage reaching activity and support spatial cognitive learning. This paper investigated whether the accuracy of peripersonal reaching (space within arm's reach) can be improved by the use of dynamic sound from both the objects to reach for and the reaching hand itself (via a worn speaker). We ran two studies that tested the efficacy of static and dynamic audio feedback designs with blind and visually impaired young people, to identify optimal feedback designs. Study 1 was with young adults aged 18 to 22 and Study 2 involved children aged 12 to 17. The results showed that dynamic audio feedback helps to build spatial connections between the objects and the reaching hand and participants were able to reach more accurately, compared to unchanging feedback.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairment, sound perception, reaching', 'numpages': '10', 'pages': '209–218', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Blind children engage with their immediate environment much less than sighted children, particularly through self-initiated movement or exploration. Research has suggested that providing dynamic feedback about the environment and the child's actions within/against it may help to encourage reaching activity and support spatial cognitive learning. This paper investigated whether the accuracy of peripersonal reaching (space within arm's reach) can be improved by the use of dynamic sound from both the objects to reach for and the reaching hand itself (via a worn speaker). We ran two studies that tested the efficacy of static and dynamic audio feedback designs with blind and visually impaired young people, to identify optimal feedback designs. Study 1 was with young adults aged 18 to 22 and Study 2 involved children aged 12 to 17. The results showed that dynamic audio feedback helps to build spatial connections between the objects and the reaching hand and participants were able to reach more accurately, compared to unchanging feedback."", 'doi': '10.1145/2982142.2982160', 'url': 'https://doi.org/10.1145/2982142.2982160', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Using Dynamic Audio Feedback to Support Peripersonal Reaching in Young Visually Impaired People', 'author': 'Wilson, Graham and Brewster, Stephen A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982160'}"
Session details: Social Issues and Assistive Technology,10.1145/3254073,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254073', 'url': 'https://doi.org/10.1145/3254073', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Social Issues and Assistive Technology', 'author': 'Brady, Erin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254073'}"
Nothing to Hide: Aesthetic Customization of Hearing Aids and Cochlear Implants in an Online Community,10.1145/2982142.2982159,"Hearing aids and cochlear implants can improve accessibility and quality of life for people with hearing impairments. However, use of these devices may cause concern amongst some users due to sociocultural issues such as unwanted attention and perceived stigma. While some individuals may respond to these concerns by attempting to conceal their devices, or even abandoning their devices, others have responded by making their devices more visible through aesthetic customization, and some have begun to share these customizations online. In this paper, we describe community interactions in an online forum dedicated to customized hearing aids and cochlear implants. We found that community members discussed customization tools and techniques, shared their customizations, and provided each other with encouragement and support. Community members customized their devices as a means of self-expression that demonstrated the wearer's fashion sense, revealed favorite sports teams and characters, and marked holidays and personal milestones. Our findings may inform the design of assistive technologies that better support personalization, customization, and self-expression.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'social acceptability, online communities, hearing aids, diy assistive technology, deafness, cochlear implants', 'numpages': '9', 'pages': '219–227', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Hearing aids and cochlear implants can improve accessibility and quality of life for people with hearing impairments. However, use of these devices may cause concern amongst some users due to sociocultural issues such as unwanted attention and perceived stigma. While some individuals may respond to these concerns by attempting to conceal their devices, or even abandoning their devices, others have responded by making their devices more visible through aesthetic customization, and some have begun to share these customizations online. In this paper, we describe community interactions in an online forum dedicated to customized hearing aids and cochlear implants. We found that community members discussed customization tools and techniques, shared their customizations, and provided each other with encouragement and support. Community members customized their devices as a means of self-expression that demonstrated the wearer's fashion sense, revealed favorite sports teams and characters, and marked holidays and personal milestones. Our findings may inform the design of assistive technologies that better support personalization, customization, and self-expression."", 'doi': '10.1145/2982142.2982159', 'url': 'https://doi.org/10.1145/2982142.2982159', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Nothing to Hide: Aesthetic Customization of Hearing Aids and Cochlear Implants in an Online Community', 'author': 'Profita, Halley P. and Stangl, Abigale and Matuszewska, Laura and Sky, Sigrunn and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982159'}"
Session details: Accessibility Education,10.1145/3254074,Abstract not available,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'doi': '10.1145/3254074', 'url': 'https://doi.org/10.1145/3254074', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Session details: Accessibility Education', 'author': 'Martin-Hammond, Aqueasha', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3254074'}"
How Designing for People With and Without Disabilities Shapes Student Design Thinking,10.1145/2982142.2982158,"Despite practices addressing disability in design and advocating user-centered design (UCD) approaches, popular mainstream technologies remain largely inaccessible for people with disabilities. We conducted a design course study investigating how student designers regard disability and explored how designing for both disabled and non-disabled users encouraged students to think about accessibility throughout the design process. Students focused on a design project while learning UCD concepts and techniques, working with people with and without disabilities throughout the project. We found that designing for both disabled and non-disabled users surfaced challenges and tensions in finding solutions to satisfy both groups, influencing students' attitudes toward accessible design. In addressing these tensions, non-functional aspects of accessible design emerged as important complements to functional aspects for users with and without disabilities.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'design thinking, design, assistive technology, accessibility', 'numpages': '9', 'pages': '229–237', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Despite practices addressing disability in design and advocating user-centered design (UCD) approaches, popular mainstream technologies remain largely inaccessible for people with disabilities. We conducted a design course study investigating how student designers regard disability and explored how designing for both disabled and non-disabled users encouraged students to think about accessibility throughout the design process. Students focused on a design project while learning UCD concepts and techniques, working with people with and without disabilities throughout the project. We found that designing for both disabled and non-disabled users surfaced challenges and tensions in finding solutions to satisfy both groups, influencing students' attitudes toward accessible design. In addressing these tensions, non-functional aspects of accessible design emerged as important complements to functional aspects for users with and without disabilities."", 'doi': '10.1145/2982142.2982158', 'url': 'https://doi.org/10.1145/2982142.2982158', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'How Designing for People With and Without Disabilities Shapes Student Design Thinking', 'author': 'Shinohara, Kristen and Bennett, Cynthia L. and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982158'}"
Breaking Barriers to Digital Literacy: An Intergenerational Social-Cognitive Approach,10.1145/2982142.2982183,"In entering the digital realm, older adults face obstacles beyond the more clearly understood physical and cognitive barriers traditionally associated with accessibility. This experience report is a collection of narratives from learners and student tutors who participate in our digital literacy sessions for seniors. We point out ways in which attitudes and motivations, framed by social and cultural factors, can either hinder or assist with adoption of commodity digital technology among older newcomers. We also show how a social-cognitive approach can help learners overcome barriers to digital literacy.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'senior citizens, digital literacy, collaborative learning, ac- cessibility', 'numpages': '6', 'pages': '239–244', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In entering the digital realm, older adults face obstacles beyond the more clearly understood physical and cognitive barriers traditionally associated with accessibility. This experience report is a collection of narratives from learners and student tutors who participate in our digital literacy sessions for seniors. We point out ways in which attitudes and motivations, framed by social and cultural factors, can either hinder or assist with adoption of commodity digital technology among older newcomers. We also show how a social-cognitive approach can help learners overcome barriers to digital literacy.', 'doi': '10.1145/2982142.2982183', 'url': 'https://doi.org/10.1145/2982142.2982183', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Breaking Barriers to Digital Literacy: An Intergenerational Social-Cognitive Approach', 'author': 'Atkinson, Keith and Barnes, Jaclyn and Albee, Judith and Anttila, Peter and Haataja, Judith and Nanavati, Kanak and Steelman, Kelly and Wallace, Charles', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982183'}"
Remote Access Programs to Better Integrate Individuals with Disabilities,10.1145/2982142.2982182,"Sensory impaired individuals are at a disadvantage in accessing and processing electronic information. The first author (i.e. Thomas Hahn) is legally blind due to Albinism. In this experience report we describe challenges faced by the visually impaired and explain how remote access programs in combination with voice communication programs can be used to---at least partially---compensate for those disadvantages because they don't transmit magnification. This property is especially important to effectively train visually impaired individuals on new applications and interfaces remotely because it allows them to view exactly the same information simultaneously with their sighted trainers.Since the technical prerequisites for this information exchange, skill transfer, and knowledge acquisition approach have already been freely available for at least 7 years, but are still not widely used, this approach needs to be impressively demonstrated at conferences like this one to increase the odds that its participants will share this approach with those who could potentially benefit from it. This approach could make computer labs with expensive software not only accessible to the disabled, but instead, to everyone around the clock while saving money, which is still being spent to pay lab supervisors to keep the labs open for a few hours without losing---but instead---gaining functionality. Offering virtual remote office hours would benefit disabled and non-handicapped students and faculty alike.Providing remote access to lectures can make them available to a wider audience and thus could decrease costs for tuition. Obvious benefits of this approach for the mobility impaired and soon to be expected benefits for the hearing impaired are mentioned. Allowing faculty to remotely participate in oral exams increases choices for possible specializations. Making information more accessible to the disabled has obvious synergistic benefits for non-handicapped people alike as reflected by the importance of the concept of workforce diversification for overcoming unexpected future challenges and potential stumbling blocks. This approach makes it possible to magnify lecture presentations directly onto the screen of visually impaired students and could improve real-time interactions in the classroom. Remote access for everyone could reduce the perception of disabilities. Handicapped people could be considered early adopters because they are more in need of improvements since the present circumstances and limitations are much less acceptable to them. This article concludes by describing current bottlenecks to accessibility and information transfer, and ends with an overall optimistic outlook to the future.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairment, virtual classroom, tutoring, skills-, remote control, magnification, knowledge-, inclusive design, education, e-learning, collaboration, and information transfer', 'numpages': '6', 'pages': '245–250', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Sensory impaired individuals are at a disadvantage in accessing and processing electronic information. The first author (i.e. Thomas Hahn) is legally blind due to Albinism. In this experience report we describe challenges faced by the visually impaired and explain how remote access programs in combination with voice communication programs can be used to---at least partially---compensate for those disadvantages because they don't transmit magnification. This property is especially important to effectively train visually impaired individuals on new applications and interfaces remotely because it allows them to view exactly the same information simultaneously with their sighted trainers.Since the technical prerequisites for this information exchange, skill transfer, and knowledge acquisition approach have already been freely available for at least 7 years, but are still not widely used, this approach needs to be impressively demonstrated at conferences like this one to increase the odds that its participants will share this approach with those who could potentially benefit from it. This approach could make computer labs with expensive software not only accessible to the disabled, but instead, to everyone around the clock while saving money, which is still being spent to pay lab supervisors to keep the labs open for a few hours without losing---but instead---gaining functionality. Offering virtual remote office hours would benefit disabled and non-handicapped students and faculty alike.Providing remote access to lectures can make them available to a wider audience and thus could decrease costs for tuition. Obvious benefits of this approach for the mobility impaired and soon to be expected benefits for the hearing impaired are mentioned. Allowing faculty to remotely participate in oral exams increases choices for possible specializations. Making information more accessible to the disabled has obvious synergistic benefits for non-handicapped people alike as reflected by the importance of the concept of workforce diversification for overcoming unexpected future challenges and potential stumbling blocks. This approach makes it possible to magnify lecture presentations directly onto the screen of visually impaired students and could improve real-time interactions in the classroom. Remote access for everyone could reduce the perception of disabilities. Handicapped people could be considered early adopters because they are more in need of improvements since the present circumstances and limitations are much less acceptable to them. This article concludes by describing current bottlenecks to accessibility and information transfer, and ends with an overall optimistic outlook to the future."", 'doi': '10.1145/2982142.2982182', 'url': 'https://doi.org/10.1145/2982142.2982182', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Remote Access Programs to Better Integrate Individuals with Disabilities', 'author': 'Hahn, Thomas and Rahman, Hidayat Ur and Segall, Richard and Heim, Christoph and Brunson, Raphaela and Sharma, Ankush and Aslam, Maryam and Lara-Rodriguez, Ana and Islam, Md. Sahidul and Gupta, Neha and Embry, Charles S. and Grossmann, Patrick and Babar, Shahrukh and Skibinski, Gregory A. and Tang, Fusheng', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982182'}"
Clinical and Maker Perspectives on the Design of Assistive Technology with Rapid Prototyping Technologies,10.1145/2982142.2982181,"In this experience report, we describe the experiences of volunteer assistive device designers, clinicians, and human computer interaction and fabrication researchers who met at a summit on Do-It-Yourself Assistive Technology. From the perspectives of these stakeholders, we elucidate significant challenges of introducing rapid prototyping to the design of professional assistive technology, and opportunities for advancing assistive technology. We describe these challenges and opportunities in the context of an emerging gap between clinical and volunteer assistive device design. Whereas clinical process is fully led by the question, ""will this do harm"", while volunteers chaotically pursue the lofty goal of providing assistive technology to all. While all stakeholders hold the same core goals, there are many practical limitations to collaboration and development.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'safety, regulation, rapid fabrication, prototyping, prosthetist, prosthetic, experience report, do no harm, design, clinician, clinical practice, assistive technology, 3d scanning, 3d printing', 'numpages': '6', 'pages': '251–256', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this experience report, we describe the experiences of volunteer assistive device designers, clinicians, and human computer interaction and fabrication researchers who met at a summit on Do-It-Yourself Assistive Technology. From the perspectives of these stakeholders, we elucidate significant challenges of introducing rapid prototyping to the design of professional assistive technology, and opportunities for advancing assistive technology. We describe these challenges and opportunities in the context of an emerging gap between clinical and volunteer assistive device design. Whereas clinical process is fully led by the question, ""will this do harm"", while volunteers chaotically pursue the lofty goal of providing assistive technology to all. While all stakeholders hold the same core goals, there are many practical limitations to collaboration and development.', 'doi': '10.1145/2982142.2982181', 'url': 'https://doi.org/10.1145/2982142.2982181', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Clinical and Maker Perspectives on the Design of Assistive Technology with Rapid Prototyping Technologies', 'author': 'Hofmann, Megan and Burke, Julie and Pearlman, Jon and Fiedler, Goeran and Hess, Andrea and Schull, Jon and Hudson, Scott E. and Mankoff, Jennifer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982181'}"
OnScreenDualScribe with Point-and-Click Interface: A Viable Computer Interaction Alternative based on a Virtual Modified Numerical Keypad,10.1145/2982142.2982184,"This paper describes the experience of the first author with the Point-and-Click Interface of the OnScreenDualScribe, created by the last author. The new interface is an innovative extension to the previous interface which required the use of the DualPad. The main differences between the two interfaces are highlighted. The user took several writing tests with the Point-and Click Interface and compares her results with two of interfaces she uses the most for writing, Dragon NaturallySpeaking and SofType. Finally, the first author recommends several improvements to the interface which would make the software a better alternative for her.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'virtual keyboard, text entry, assistive technology', 'numpages': '6', 'pages': '257–262', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper describes the experience of the first author with the Point-and-Click Interface of the OnScreenDualScribe, created by the last author. The new interface is an innovative extension to the previous interface which required the use of the DualPad. The main differences between the two interfaces are highlighted. The user took several writing tests with the Point-and Click Interface and compares her results with two of interfaces she uses the most for writing, Dragon NaturallySpeaking and SofType. Finally, the first author recommends several improvements to the interface which would make the software a better alternative for her.', 'doi': '10.1145/2982142.2982184', 'url': 'https://doi.org/10.1145/2982142.2982184', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'OnScreenDualScribe with Point-and-Click Interface: A Viable Computer Interaction Alternative based on a Virtual Modified Numerical Keypad', 'author': ""Krishnaswamy, Kavita and Ord\\'{o}\\~{n}ez, Patricia and Beckerle, Phillip and Rinderknecht, Stephan and Felzer, Torsten"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982184'}"
Exploring the Use of a Drone to Guide Blind Runners,10.1145/2982142.2982204,"People with visual impairments have a hard time getting consistent physical exercise, as they can not do some exercises, such as running outside, without a sighted guide. People with visual impairments have been shown to have higher spatial localization skills than sighted people, which lead us to believe that they could follow a drone on a running-track environment. This paper presents a feasibility study where we investigate the ability to localize and follow a low-cost flying drone in people with visual impairments. A Wizard of Oz style study was conducted with 2 blind participants. Our results indicate that blind individuals can accurately localize the drone and follow it. Qualitative results also indicate that the participants were comfortable with following the drone and had high efficacy when it came to following and localizing the drone. The study supports future development of a fully functioning prototype.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'running, obesity, health disparities, exercise, drones', 'numpages': '2', 'pages': '263–264', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with visual impairments have a hard time getting consistent physical exercise, as they can not do some exercises, such as running outside, without a sighted guide. People with visual impairments have been shown to have higher spatial localization skills than sighted people, which lead us to believe that they could follow a drone on a running-track environment. This paper presents a feasibility study where we investigate the ability to localize and follow a low-cost flying drone in people with visual impairments. A Wizard of Oz style study was conducted with 2 blind participants. Our results indicate that blind individuals can accurately localize the drone and follow it. Qualitative results also indicate that the participants were comfortable with following the drone and had high efficacy when it came to following and localizing the drone. The study supports future development of a fully functioning prototype.', 'doi': '10.1145/2982142.2982204', 'url': 'https://doi.org/10.1145/2982142.2982204', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Exploring the Use of a Drone to Guide Blind Runners', 'author': 'Al Zayer, Majed and Tregillus, Sam and Bhandari, Jiwan and Feil-Seifer, Dave and Folmer, Eelke', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982204'}"
Impact of Word Presentation for Dyslexia,10.1145/2982142.2982191,"In this paper, we present an experiment that uses eye-tracking system to measure the effect of word presentation on reading performance and fixation duration. Twelve subjects without dyslexia and eight with dyslexia read thirty-six words and non-words with three kind of presentation. We show that one type of presentation leads to significant better results for people with dyslexia","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'experimentation, dyslexia, design', 'numpages': '2', 'pages': '265–266', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we present an experiment that uses eye-tracking system to measure the effect of word presentation on reading performance and fixation duration. Twelve subjects without dyslexia and eight with dyslexia read thirty-six words and non-words with three kind of presentation. We show that one type of presentation leads to significant better results for people with dyslexia', 'doi': '10.1145/2982142.2982191', 'url': 'https://doi.org/10.1145/2982142.2982191', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Impact of Word Presentation for Dyslexia', 'author': 'Appert, Damien and Truillet, Philippe', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982191'}"
A Tool for Capturing Essential Preferences,10.1145/2982142.2982155,"For some people, interaction preference settings like large fonts or speech output are essential for technology access. We demonstrate a 'First Discovery Tool' intended as an easy and accessible way for people to discover and set preferences to address major access barriers. The tool is designed to support people who have limited technology experience or confidence. Testing in educational and senior settings found that most participants were able to understand the preferences offered, and some discovered helpful options they were previously not aware of.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'preferences, older adults, independence, education, disability, accessibility', 'numpages': '2', 'pages': '267–268', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""For some people, interaction preference settings like large fonts or speech output are essential for technology access. We demonstrate a 'First Discovery Tool' intended as an easy and accessible way for people to discover and set preferences to address major access barriers. The tool is designed to support people who have limited technology experience or confidence. Testing in educational and senior settings found that most participants were able to understand the preferences offered, and some discovered helpful options they were previously not aware of."", 'doi': '10.1145/2982142.2982155', 'url': 'https://doi.org/10.1145/2982142.2982155', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'A Tool for Capturing Essential Preferences', 'author': 'Ayotte, Dana and Brennan, Michelle and Frishberg, Nancy and Jimes, Cynthia and Petrides, Lisa and Quesenbery, Whitney and Rothberg, Madeleine and Schwerdtfeger, Rich and Tobias, Jim and Treviranus, Jutta and Trewin, Shari and Vanderheiden, Gregg C.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982155'}"
Designing a Kinect2Scratch Game to Help Teachers Train Children with Intellectual Disabilities for Pedestrian Safety,10.1145/2982142.2982185,"Children with intellectual disabilities (ID) may need to undergo long-term cognitive training to enhance the possibility of social inclusion. Pedestrian safety is a critical issue when it comes to participating in community activities for children with ID. Currently, no commercial pedestrian safety training products are available for public special education schools. Consequently, teachers normally gave lectures with the support of slides and pictures to enhance children's ability of getting around in the community. This study employs the Microsoft Kinect technology and image recognition technology to create a pedestrian safety training system which may be applicable for people with ID. To motivate people with ID to engage in the training, we gamified the training of pedestrian safety for children with ID in special education school settings. By leveraging the Scratch language and Kinect2Scratch tool, the teacher who will use the system may be able to do the customization without technical support. Preliminary results of 15 children with ID, aged 9-10, testing the game are presented.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'serious games, scratch, pedestrian safety, kinect2scratch, kinect, gamification', 'numpages': '2', 'pages': '269–270', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Children with intellectual disabilities (ID) may need to undergo long-term cognitive training to enhance the possibility of social inclusion. Pedestrian safety is a critical issue when it comes to participating in community activities for children with ID. Currently, no commercial pedestrian safety training products are available for public special education schools. Consequently, teachers normally gave lectures with the support of slides and pictures to enhance children's ability of getting around in the community. This study employs the Microsoft Kinect technology and image recognition technology to create a pedestrian safety training system which may be applicable for people with ID. To motivate people with ID to engage in the training, we gamified the training of pedestrian safety for children with ID in special education school settings. By leveraging the Scratch language and Kinect2Scratch tool, the teacher who will use the system may be able to do the customization without technical support. Preliminary results of 15 children with ID, aged 9-10, testing the game are presented."", 'doi': '10.1145/2982142.2982185', 'url': 'https://doi.org/10.1145/2982142.2982185', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Designing a Kinect2Scratch Game to Help Teachers Train Children with Intellectual Disabilities for Pedestrian Safety', 'author': 'Chang, Yao-Jen and Kang, Ya-Shu and Chang, Yao-Sheng and Liu, Hung-Huan and Chiu, Yu-Ling and Kao, Chia Chun', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982185'}"
Deaf and Hard of Hearing Individuals' Perceptions of Communication with Hearing Colleagues in Small Groups,10.1145/2982142.2982198,This survey-based study investigated deaf and hard of hearing (DHH) individuals' perceived need for technologies that may facilitate communication when meeting in small groups with hearing colleagues. Participants were 108 DHH postsecondary students who participated in co-op (internship) and capstone experiences at workplaces with hearing employees within the past two years. Participants' responses to a survey indicated that they were generally not satisfied with their current strategies and technologies for communicating with hearing persons in small groups.,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'survey, small groups, hard-of-hearing, deaf, communication', 'numpages': '2', 'pages': '271–272', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This survey-based study investigated deaf and hard of hearing (DHH) individuals' perceived need for technologies that may facilitate communication when meeting in small groups with hearing colleagues. Participants were 108 DHH postsecondary students who participated in co-op (internship) and capstone experiences at workplaces with hearing employees within the past two years. Participants' responses to a survey indicated that they were generally not satisfied with their current strategies and technologies for communicating with hearing persons in small groups."", 'doi': '10.1145/2982142.2982198', 'url': 'https://doi.org/10.1145/2982142.2982198', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': ""Deaf and Hard of Hearing Individuals' Perceptions of Communication with Hearing Colleagues in Small Groups"", 'author': 'Elliot, Lisa and Stinson, Michael and Mallory, James and Easton, Donna and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982198'}"
VizMap: Accessible Visual Information Through Crowdsourced Map Reconstruction,10.1145/2982142.2982200,"When navigating indoors, blind people are often unaware of key visual information, such as posters, signs, and exit doors. Our VizMap system uses computer vision and crowdsourcing to collect this information and make it available non-visually. VizMap starts with videos taken by on-site sighted volunteers and uses these to create a 3D spatial model. These video frames are semantically labeled by remote crowd workers with key visual information. These semantic labels are located within and embedded into the reconstructed 3D model, forming a query-able spatial representation of the environment. VizMap can then localize the user with a photo from their smartphone, and enable them to explore the visual elements that are nearby. We explore a range of example applications enabled by our reconstructed spatial representation. With VizMap, we move towards integrating the strengths of the end user, on-site crowd, online crowd, and computer vision to solve a long-standing challenge in indoor blind exploration.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'indoor navigation, crowdsourcing, blind users, accessibility', 'numpages': '2', 'pages': '273–274', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'When navigating indoors, blind people are often unaware of key visual information, such as posters, signs, and exit doors. Our VizMap system uses computer vision and crowdsourcing to collect this information and make it available non-visually. VizMap starts with videos taken by on-site sighted volunteers and uses these to create a 3D spatial model. These video frames are semantically labeled by remote crowd workers with key visual information. These semantic labels are located within and embedded into the reconstructed 3D model, forming a query-able spatial representation of the environment. VizMap can then localize the user with a photo from their smartphone, and enable them to explore the visual elements that are nearby. We explore a range of example applications enabled by our reconstructed spatial representation. With VizMap, we move towards integrating the strengths of the end user, on-site crowd, online crowd, and computer vision to solve a long-standing challenge in indoor blind exploration.', 'doi': '10.1145/2982142.2982200', 'url': 'https://doi.org/10.1145/2982142.2982200', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'VizMap: Accessible Visual Information Through Crowdsourced Map Reconstruction', 'author': 'Gleason, Cole and Guo, Anhong and Laput, Gierad and Kitani, Kris and Bigham, Jeffrey P.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982200'}"
Promoting Strategic Research on Inclusive Access to Rich Online Content and Services,10.1145/2982142.2982193,"How can the broader field of computer science research be harnessed to address challenges and opportunities in accessibility? This poster summarizes the findings of a workshop, sponsored by the Computing Community Consortium (USA), that brought together computer scientists, representatives of disability advocacy organizations, people from industry, and government employees to develop an agenda for strategic research. Members of the ASSETS community may find the reports useful in organizing collaborative projects with others in the computer science community.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'strategic research, collaborative research', 'numpages': '2', 'pages': '275–276', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'How can the broader field of computer science research be harnessed to address challenges and opportunities in accessibility? This poster summarizes the findings of a workshop, sponsored by the Computing Community Consortium (USA), that brought together computer scientists, representatives of disability advocacy organizations, people from industry, and government employees to develop an agenda for strategic research. Members of the ASSETS community may find the reports useful in organizing collaborative projects with others in the computer science community.', 'doi': '10.1145/2982142.2982193', 'url': 'https://doi.org/10.1145/2982142.2982193', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Promoting Strategic Research on Inclusive Access to Rich Online Content and Services', 'author': 'Lewis, Clayton and Kane, Shaun K. and Ladner, Richard', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982193'}"
#accessibilityFail: Categorizing Shared Photographs of Physical Accessibility Problems,10.1145/2982142.2982186,"Social media platforms are existing online spaces where users share their daily encounters, providing a large dataset of photographs of inaccessible environments. We analyzed 100 posts from Twitter and Instagram that describe accessibility problems. Our findings suggest these posts are helpful to locate, identify and communicate accessibility problems, and provide design ideas for potential assistive technologies. We suggest design implications using social media posts to improve physical accessibility.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'social media., physical accessibility, photography', 'numpages': '2', 'pages': '277–278', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social media platforms are existing online spaces where users share their daily encounters, providing a large dataset of photographs of inaccessible environments. We analyzed 100 posts from Twitter and Instagram that describe accessibility problems. Our findings suggest these posts are helpful to locate, identify and communicate accessibility problems, and provide design ideas for potential assistive technologies. We suggest design implications using social media posts to improve physical accessibility.', 'doi': '10.1145/2982142.2982186', 'url': 'https://doi.org/10.1145/2982142.2982186', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': '#accessibilityFail: Categorizing Shared Photographs of Physical Accessibility Problems', 'author': 'Li, Hanlin and Brady, Erin', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982186'}"
Exploration of the Use of Auditory Cues in Code Comprehension and Navigation for Individuals with Visual Impairments in a Visual Programming Environment,10.1145/2982142.2982206,"Visual programming languages are commonplace in engaging novice programmers. Accessibility challenges persist in these systems. This study investigates whether auditory cues improves a visually impaired programmer's ability to navigate and understand source code in a block-based language. The type of auditory cue that best serves this purpose is also investigated. The participants' comprehension of source code using three trials with two tests each is presented, with each trial corresponding to a different form of audio cue. Participants are graded on how accurate their written source code is in comparison to the actual source code.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visually impaired, program understanding, block-based programming, audio cues, accessibility', 'numpages': '2', 'pages': '279–280', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Visual programming languages are commonplace in engaging novice programmers. Accessibility challenges persist in these systems. This study investigates whether auditory cues improves a visually impaired programmer's ability to navigate and understand source code in a block-based language. The type of auditory cue that best serves this purpose is also investigated. The participants' comprehension of source code using three trials with two tests each is presented, with each trial corresponding to a different form of audio cue. Participants are graded on how accurate their written source code is in comparison to the actual source code."", 'doi': '10.1145/2982142.2982206', 'url': 'https://doi.org/10.1145/2982142.2982206', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Exploration of the Use of Auditory Cues in Code Comprehension and Navigation for Individuals with Visual Impairments in a Visual Programming Environment', 'author': 'Ludi, Stephanie and Simpson, Jamie and Merchant, Wil', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982206'}"
Tag Thunder: Towards Non-Visual Web Page Skimming,10.1145/2982142.2982152,"Tag thunder is an audio version of a visual tag cloud content representation. Tag thunders aim to bring quick reading strategies, such as skimming, to blind people. Tag thunders vocalize the key terms of a page using concurrent speech paradigm coupled with additional audio effects, similar to visual effects in a tag cloud. In this paper we present our implementation of the tag thunder concept. Our system comprises three modules: page segmentation, key term extraction and tag thunder vocalization. The evaluation results show the viability of the tag thunder concept.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'web content accessibility, speech synthesis, keyword extraction, content segmentation', 'numpages': '2', 'pages': '281–282', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Tag thunder is an audio version of a visual tag cloud content representation. Tag thunders aim to bring quick reading strategies, such as skimming, to blind people. Tag thunders vocalize the key terms of a page using concurrent speech paradigm coupled with additional audio effects, similar to visual effects in a tag cloud. In this paper we present our implementation of the tag thunder concept. Our system comprises three modules: page segmentation, key term extraction and tag thunder vocalization. The evaluation results show the viability of the tag thunder concept.', 'doi': '10.1145/2982142.2982152', 'url': 'https://doi.org/10.1145/2982142.2982152', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Tag Thunder: Towards Non-Visual Web Page Skimming', 'author': ""Manishina, Elena and Lecarpentier, Jean-Marc and Maurel, Fabrice and Ferrari, St\\'{e}phane and Busson, Maxence"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982152'}"
A Platform Agnostic Remote Desktop System for Screen Reading,10.1145/2982142.2982151,"Remote desktop technology, the enabler of access to applications hosted on remote hosts, relies primarily on scraping the pixels on the remote screen and redrawing them as a simple bitmap on the client's local screen. Such a technology will simply not work with screen readers since the latter are innately tied to reading text. Since screen readers are locked-in to a specific OS platform, extant solutions that enable remote access with screen readers such as NVDARemote and JAWS Tandem require homogeneity of OS platforms at both the client and remote sites. This demo will present Sinter, a system that eliminates this requirement. With Sinter, a blind Mac user, for example, can now access a remote Windows application with VoiceOver, a scenario heretofore not possible.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'ui virtualization, screen reader, remote access, platform independence, accessibility', 'numpages': '2', 'pages': '283–284', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Remote desktop technology, the enabler of access to applications hosted on remote hosts, relies primarily on scraping the pixels on the remote screen and redrawing them as a simple bitmap on the client's local screen. Such a technology will simply not work with screen readers since the latter are innately tied to reading text. Since screen readers are locked-in to a specific OS platform, extant solutions that enable remote access with screen readers such as NVDARemote and JAWS Tandem require homogeneity of OS platforms at both the client and remote sites. This demo will present Sinter, a system that eliminates this requirement. With Sinter, a blind Mac user, for example, can now access a remote Windows application with VoiceOver, a scenario heretofore not possible."", 'doi': '10.1145/2982142.2982151', 'url': 'https://doi.org/10.1145/2982142.2982151', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'A Platform Agnostic Remote Desktop System for Screen Reading', 'author': 'Billah, Syed Masum and Ashok, Vikas and Porter, Donald E. and Ramakrishnan, IV', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982151'}"
Ad-Hoc Access to Musical Sound for Deaf Individuals,10.1145/2982142.2982213,"Learning a musical instrument can be a challenging task for a deaf person due to limited access to sound. Prior work has developed visual and vibrotactile approaches to provide music-to-sound feedback to deaf people. However, these systems are not designed for ad-hoc access to sound, which enables a deaf person to explore sound from various audio sources and receive real-time feedback. In this paper we present the development of a music sensory substitution system that enables ad-hoc access to musical sounds. It provides the technical basis to study deeper research questions about understanding and creating sound.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'sensory substitution, music, deaf, assistive technologies', 'numpages': '2', 'pages': '285–286', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Learning a musical instrument can be a challenging task for a deaf person due to limited access to sound. Prior work has developed visual and vibrotactile approaches to provide music-to-sound feedback to deaf people. However, these systems are not designed for ad-hoc access to sound, which enables a deaf person to explore sound from various audio sources and receive real-time feedback. In this paper we present the development of a music sensory substitution system that enables ad-hoc access to musical sounds. It provides the technical basis to study deeper research questions about understanding and creating sound.', 'doi': '10.1145/2982142.2982213', 'url': 'https://doi.org/10.1145/2982142.2982213', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Ad-Hoc Access to Musical Sound for Deaf Individuals', 'author': 'Petry, Benjamin and Illandara, Thavishi and Forero, Juan Pablo and Nanayakkara, Suranga', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982213'}"
Towards a Sign-Based Indoor Navigation System for People with Visual Impairments,10.1145/2982142.2982202,"Navigation is a challenging task for many travelers with visual impairments. While a variety of GPS-enabled tools can provide wayfinding assistance in outdoor settings, GPS provides no useful localization information indoors. A variety of indoor navigation tools are being developed, but most of them require potentially costly physical infrastructure to be installed and maintained, or else the creation of detailed visual models of the environment. We report development of a new smartphone-based navigation aid, which combines inertial sensing, computer vision and floor plan information to estimate the user's location with no additional physical infrastructure and requiring only the locations of signs relative to the floor plan. A formative study was conducted with three blind volunteer participants demonstrating the feasibility of the approach and highlighting the areas needing improvement.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wayfinding, navigation, low vision., blindness', 'numpages': '2', 'pages': '287–288', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Navigation is a challenging task for many travelers with visual impairments. While a variety of GPS-enabled tools can provide wayfinding assistance in outdoor settings, GPS provides no useful localization information indoors. A variety of indoor navigation tools are being developed, but most of them require potentially costly physical infrastructure to be installed and maintained, or else the creation of detailed visual models of the environment. We report development of a new smartphone-based navigation aid, which combines inertial sensing, computer vision and floor plan information to estimate the user's location with no additional physical infrastructure and requiring only the locations of signs relative to the floor plan. A formative study was conducted with three blind volunteer participants demonstrating the feasibility of the approach and highlighting the areas needing improvement."", 'doi': '10.1145/2982142.2982202', 'url': 'https://doi.org/10.1145/2982142.2982202', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Towards a Sign-Based Indoor Navigation System for People with Visual Impairments', 'author': 'Rituerto, Alejandro and Fusco, Giovanni and Coughlan, James M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982202'}"
"""Holy Starches Batman!! We are Getting Walloped!"": Crowdsourcing Comic Book Transcriptions",10.1145/2982142.2982211,"Comic books are among the most popular forms of popular media, but most comics are not provided in an accessible format. Creating an accessible transcript of a comic book may be more challenging than simply describing the images, as comics involve complex interplay between words and images, and often feature long-running and complex storylines. In this poster we describe a pilot study exploring the feasibility of crowdsourcing transcriptions of comic book pages. We recruited 60 crowd workers and asked them to transcribe a page of a comic book; half were told that the description was for a blind person, and half were not. We found that people who knew that they were transcribing for a blind person produced longer, more detailed descriptions. Our results also suggest that comic book knowledge may have at least some small impact on description detail.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairment, fandom, crowdsourcing, comics', 'numpages': '2', 'pages': '289–290', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Comic books are among the most popular forms of popular media, but most comics are not provided in an accessible format. Creating an accessible transcript of a comic book may be more challenging than simply describing the images, as comics involve complex interplay between words and images, and often feature long-running and complex storylines. In this poster we describe a pilot study exploring the feasibility of crowdsourcing transcriptions of comic book pages. We recruited 60 crowd workers and asked them to transcribe a page of a comic book; half were told that the description was for a blind person, and half were not. We found that people who knew that they were transcribing for a blind person produced longer, more detailed descriptions. Our results also suggest that comic book knowledge may have at least some small impact on description detail.', 'doi': '10.1145/2982142.2982211', 'url': 'https://doi.org/10.1145/2982142.2982211', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': '""Holy Starches Batman!! We are Getting Walloped!"": Crowdsourcing Comic Book Transcriptions', 'author': 'Samson, Christine and Fiesler, Casey and Kane, Shaun K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982211'}"
Kirana: A Gesture-based Market App for Life Skills Learning for Individuals with Developmental Disabilities,10.1145/2982142.2982149,"Kirana is a gesture-based application that simulates purchasing experience at a local Indian grocery store. It provides individuals with developmental difficulties a safe and controlled environment to explore the processes of purchasing an item: namely, deciding items to buy (decision making), calculating costs and balance (mathematical skills), and interactions via pointing (social interaction). Previous research has established that gesture-based interaction has the potential to enhance social, motor and cognitive skills for individuals with developmental disabilities. Currently, translating learnings from gesture-based virtual applications to real world scenarios is underexplored. Kirana is an approach to simulating practical real interactions, by breaking down complex tasks that require social, mathematical and decision-making skills, and encouraging self-efficacy. Skills learnt by purchasing items with Kirana, are potentially transferable to a real world store.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'individuals with developmental disabilities, gesture-based interaction, developing countries', 'numpages': '2', 'pages': '291–292', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Kirana is a gesture-based application that simulates purchasing experience at a local Indian grocery store. It provides individuals with developmental difficulties a safe and controlled environment to explore the processes of purchasing an item: namely, deciding items to buy (decision making), calculating costs and balance (mathematical skills), and interactions via pointing (social interaction). Previous research has established that gesture-based interaction has the potential to enhance social, motor and cognitive skills for individuals with developmental disabilities. Currently, translating learnings from gesture-based virtual applications to real world scenarios is underexplored. Kirana is an approach to simulating practical real interactions, by breaking down complex tasks that require social, mathematical and decision-making skills, and encouraging self-efficacy. Skills learnt by purchasing items with Kirana, are potentially transferable to a real world store.', 'doi': '10.1145/2982142.2982149', 'url': 'https://doi.org/10.1145/2982142.2982149', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Kirana: A Gesture-based Market App for Life Skills Learning for Individuals with Developmental Disabilities', 'author': 'Sharma, Sumita and Srivastava, Saurabh and Achary, Krishnaveni and Varkey, Blessin and Heimonen, Tomi and Hakulinen, Jaakko and Turunen, Markku and Rajput, Nitendra', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982149'}"
Autonomous Training Assistant: A System and Framework for Guided At-Home Motor Learning,10.1145/2982142.2982192,"We present a novel framework and system for at-home rehabilitative exercise in the absence of a physical therapist. The framework includes metrics for assessing motor performance on a wide variety of exercises. We present our system, the Autonomous Training Assistant, which utilizes this framework and a low-cost accessible exercise device called the Intelligent Stick to deliver feedback as a user trains at home. We evaluated the system's multimodal feedback mechanism in a case study whose results indicate that individual preference may have a significant effect on modality assignment for optimal learning. We conclude with ideas for future work.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'rehabilitation, motor learning, human-computer interaction, at-home training', 'numpages': '2', 'pages': '293–294', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""We present a novel framework and system for at-home rehabilitative exercise in the absence of a physical therapist. The framework includes metrics for assessing motor performance on a wide variety of exercises. We present our system, the Autonomous Training Assistant, which utilizes this framework and a low-cost accessible exercise device called the Intelligent Stick to deliver feedback as a user trains at home. We evaluated the system's multimodal feedback mechanism in a case study whose results indicate that individual preference may have a significant effect on modality assignment for optimal learning. We conclude with ideas for future work."", 'doi': '10.1145/2982142.2982192', 'url': 'https://doi.org/10.1145/2982142.2982192', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Autonomous Training Assistant: A System and Framework for Guided At-Home Motor Learning', 'author': 'Tadayon, Ramin and McDaniel, Troy and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982192'}"
"""Turn Left After the Heater"": Landmark Navigation for Visually Impaired Users",10.1145/2982142.2982195,"Indoor navigation is a challenging task for visually impaired people. Existing technologies promise to provide support for autonomous way finding; however, the accuracy of low-budget approaches is low and can lead to frustration amongst users. The presented ongoing work is based on suggestions in the literature that contextual information such as sudden changes in the surface structure or landmarks could supplement distance estimations to improve the user experience during navigation tasks. Following a user-centered design approach, a real-time interactive prototype with localization was implemented and evaluated. First results from a pilot study confirmed the hypothesis that user experience is improved by contextual information and showed that contextual information are accepted and appreciated by users.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visually impaired people, indoor navigation, ibeacons', 'numpages': '2', 'pages': '295–296', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Indoor navigation is a challenging task for visually impaired people. Existing technologies promise to provide support for autonomous way finding; however, the accuracy of low-budget approaches is low and can lead to frustration amongst users. The presented ongoing work is based on suggestions in the literature that contextual information such as sudden changes in the surface structure or landmarks could supplement distance estimations to improve the user experience during navigation tasks. Following a user-centered design approach, a real-time interactive prototype with localization was implemented and evaluated. First results from a pilot study confirmed the hypothesis that user experience is improved by contextual information and showed that contextual information are accepted and appreciated by users.', 'doi': '10.1145/2982142.2982195', 'url': 'https://doi.org/10.1145/2982142.2982195', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': '""Turn Left After the Heater"": Landmark Navigation for Visually Impaired Users', 'author': 'Tscharn, Robert and Au\\ss{}enhofer, Tom and Reisler, Dimitri and Hurtienne, J\\""{o}rn', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982195'}"
Eye-Gaze With Predictive Link Following Improves Accessibility as a Mouse Pointing Interface,10.1145/2982142.2982208,"We propose a target-aware pointing approach to address one predominant problem in using eye-controlled mouse replacement software: the lack of high-precision movement. Our approach is based on Predictive Link Following, which alleviates the difficulties with link selection when using mouse replacement interfaces by predicting which link should be clicked based on the proximity of the cursor to the link. For cursor control via eye movement, an eye tracking algorithm was implemented using the Tobii EyeX device to detect and translate gaze location to screen coordinates. We conducted an experement comparing eye-gaze controlled mouse pointing with and without the Predictive Link following approach. Our results demonstrate increased accuracy of our system compared to just using eye-controlled mouse pointing.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'target-aware pointing, mouse replacement interfaces, eye-gaze interfaces, accessibilty', 'numpages': '2', 'pages': '297–298', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We propose a target-aware pointing approach to address one predominant problem in using eye-controlled mouse replacement software: the lack of high-precision movement. Our approach is based on Predictive Link Following, which alleviates the difficulties with link selection when using mouse replacement interfaces by predicting which link should be clicked based on the proximity of the cursor to the link. For cursor control via eye movement, an eye tracking algorithm was implemented using the Tobii EyeX device to detect and translate gaze location to screen coordinates. We conducted an experement comparing eye-gaze controlled mouse pointing with and without the Predictive Link following approach. Our results demonstrate increased accuracy of our system compared to just using eye-controlled mouse pointing.', 'doi': '10.1145/2982142.2982208', 'url': 'https://doi.org/10.1145/2982142.2982208', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Eye-Gaze With Predictive Link Following Improves Accessibility as a Mouse Pointing Interface', 'author': 'Vazquez-Li, Jason and Pierson Stachecki, Lyle and Magee, John', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982208'}"
Social Dimensions of Technology-Mediated Sight,10.1145/2982142.2982190,"Users of wearable vision technology, such as eSight assistive eyewear, have a distinct relationship with sight influenced by personal, social, and cultural perceptions and practices. In order to better understand the ways in which vision is socially constructed through technology-mediated sight, we conducted qualitative, semi-structured interviews with 13 users of eSight glasses. Our interviews focused on eliciting narratives about eSight use from initial introduction of the technology to current daily practices. Emerging findings describe ways in which technology-mediated vision is experienced in relation to (1) adaptive practices, (2) social participation, (3) experiences of space, and (4) opportunities for choice and self-determination.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'low vision, head mounted display, assistive technology, accessibility', 'numpages': '2', 'pages': '299–300', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Users of wearable vision technology, such as eSight assistive eyewear, have a distinct relationship with sight influenced by personal, social, and cultural perceptions and practices. In order to better understand the ways in which vision is socially constructed through technology-mediated sight, we conducted qualitative, semi-structured interviews with 13 users of eSight glasses. Our interviews focused on eliciting narratives about eSight use from initial introduction of the technology to current daily practices. Emerging findings describe ways in which technology-mediated vision is experienced in relation to (1) adaptive practices, (2) social participation, (3) experiences of space, and (4) opportunities for choice and self-determination.', 'doi': '10.1145/2982142.2982190', 'url': 'https://doi.org/10.1145/2982142.2982190', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Social Dimensions of Technology-Mediated Sight', 'author': 'Zolyomi, Annuska and Shukla, Anushree and Snyder, Jaime', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982190'}"
Not All Errors are Created Equal: Factors that Impact Acceptance of an Indoor Navigation Aid for the Blind,10.1145/2982142.2982210,"Large indoor spaces continue to pose challenges to independent navigation for people who are blind. Unfortunately, assistive technologies designed to support indoor navigation frequently make errors that are technically difficult or impossible to eliminate. We conducted a study to explore whether there are strategic ways designers can minimize the impact of inevitable errors on user experience. This paper summarizes an online survey of 41 blind individuals regarding their projected acceptance to three types of errors expected of these devices. We found that some errors were more acceptable than others. Factors that impacted results included the error type and the social/environmental setting.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'navigation, errors, blindness, assistive technology, acceptance', 'numpages': '2', 'pages': '301–302', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Large indoor spaces continue to pose challenges to independent navigation for people who are blind. Unfortunately, assistive technologies designed to support indoor navigation frequently make errors that are technically difficult or impossible to eliminate. We conducted a study to explore whether there are strategic ways designers can minimize the impact of inevitable errors on user experience. This paper summarizes an online survey of 41 blind individuals regarding their projected acceptance to three types of errors expected of these devices. We found that some errors were more acceptable than others. Factors that impacted results included the error type and the social/environmental setting.', 'doi': '10.1145/2982142.2982210', 'url': 'https://doi.org/10.1145/2982142.2982210', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Not All Errors are Created Equal: Factors that Impact Acceptance of an Indoor Navigation Aid for the Blind', 'author': 'Abdolrahmani, Ali and Easley, William and Williams, Michele A. and Ronquillo, Erick and Branham, Stacy and Chen, Tiffany and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982210'}"
Using a Design Workshop To Explore Accessible Ideation,10.1145/2982142.2982209,"Although a critical step in the technology design process, ideation is often not accessible for people with disabilities. We present findings from a design workshop facilitated to brainstorm accessible ideation methods. Groups, mostly engineers, ideated on a design challenge and documented access barriers encountered by participants with disabilities. They then ideated and prototyped potential solutions for decreasing access barriers. We offer suggestions for more accessible communication and ideation on a design team and insights from using a workshop as a site for rethinking ideation.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'accessibility, assistive technology, design, design thinking', 'numpages': '2', 'pages': '303–304', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Although a critical step in the technology design process, ideation is often not accessible for people with disabilities. We present findings from a design workshop facilitated to brainstorm accessible ideation methods. Groups, mostly engineers, ideated on a design challenge and documented access barriers encountered by participants with disabilities. They then ideated and prototyped potential solutions for decreasing access barriers. We offer suggestions for more accessible communication and ideation on a design team and insights from using a workshop as a site for rethinking ideation.', 'doi': '10.1145/2982142.2982209', 'url': 'https://doi.org/10.1145/2982142.2982209', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Using a Design Workshop To Explore Accessible Ideation', 'author': 'Bennett, Cynthia L. and Shinohara, Kristen and Blaser, Brianna and Davidson, Andrew and Steele, Kat M.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982209'}"
Study of a Smart Cup for Home Monitoring of the Arm and Hand of Stroke Patients,10.1145/2982142.2982188,"In this work, we present a platform for continuously monitor and guide stroke patient at home during Activities of the Daily Living. The platform consists of a smart cup which embeds sensors that monitor the patient's hand and arm motor activity at different times of the day. The cup detects its orientation, the liquid level, its position on a specific target, as well as tremors. Moreover, displays are provided to guide the patient's movement. Finally, the planned studies with both the therapists and patients are presented.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'cup, home, internet of things, monitoring, stroke', 'numpages': '2', 'pages': '305–306', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this work, we present a platform for continuously monitor and guide stroke patient at home during Activities of the Daily Living. The platform consists of a smart cup which embeds sensors that monitor the patient's hand and arm motor activity at different times of the day. The cup detects its orientation, the liquid level, its position on a specific target, as well as tremors. Moreover, displays are provided to guide the patient's movement. Finally, the planned studies with both the therapists and patients are presented."", 'doi': '10.1145/2982142.2982188', 'url': 'https://doi.org/10.1145/2982142.2982188', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Study of a Smart Cup for Home Monitoring of the Arm and Hand of Stroke Patients', 'author': 'Bobin, Maxence and Boukallel, Mehdi and Anastassova, Margarita and Ammi, Mehdi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982188'}"
An Approach to Audio-Only Editing for Visually Impaired Seniors,10.1145/2982142.2982196,Older adults and people with vision impairments are increasingly using phones to receive audio-based information and want to publish content online but must use complex audio recording/editing tools that often rely on inaccessible graphical interfaces. This poster describes the design of an accessible audio-based interface for post-processing audio content created by visually impaired seniors. We conducted a diary study with five older adults with vision impairments to understand how to design a system that would allow them to edit content they record using an audio-only interface. Our findings can help inform the development of accessible audio-editing interfaces for people with vision impairments more broadly.,"{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'vision impairments, older adults, editing, audio interface', 'numpages': '2', 'pages': '307–308', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Older adults and people with vision impairments are increasingly using phones to receive audio-based information and want to publish content online but must use complex audio recording/editing tools that often rely on inaccessible graphical interfaces. This poster describes the design of an accessible audio-based interface for post-processing audio content created by visually impaired seniors. We conducted a diary study with five older adults with vision impairments to understand how to design a system that would allow them to edit content they record using an audio-only interface. Our findings can help inform the development of accessible audio-editing interfaces for people with vision impairments more broadly.', 'doi': '10.1145/2982142.2982196', 'url': 'https://doi.org/10.1145/2982142.2982196', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'An Approach to Audio-Only Editing for Visually Impaired Seniors', 'author': 'Brewer, Robin N. and Cartwright, Mark and Karp, Aaron and Pardo, Bryan and Piper, Anne Marie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982196'}"
Accessible Online Indoor Maps for Blind and Visually Impaired Users,10.1145/2982142.2982201,"This paper proposes alternatives for the development and improvement of maps to aid accessibility. Based on our analysis, we present an accessible online indoor map prototype that complies with WCAG 2.0. For the case study, the prototype displays an indoor map that is designed using Scalable Vector Graphics (SVG) format. This format can include information that helps the screen reader to interpret the visual graph information. In addition, the prototype can simulate the route that the users select so they can get an idea of the environment where they will mobilize. We tested the prototype in different browsers with the help of blind people.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'web accessibility, wcag 2.0, visually impaired people., svg, online maps, indoor maps, blind people, accessibility guidelines', 'numpages': '2', 'pages': '309–310', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper proposes alternatives for the development and improvement of maps to aid accessibility. Based on our analysis, we present an accessible online indoor map prototype that complies with WCAG 2.0. For the case study, the prototype displays an indoor map that is designed using Scalable Vector Graphics (SVG) format. This format can include information that helps the screen reader to interpret the visual graph information. In addition, the prototype can simulate the route that the users select so they can get an idea of the environment where they will mobilize. We tested the prototype in different browsers with the help of blind people.', 'doi': '10.1145/2982142.2982201', 'url': 'https://doi.org/10.1145/2982142.2982201', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Accessible Online Indoor Maps for Blind and Visually Impaired Users', 'author': ""Calle-Jimenez, Tania and Luj\\'{a}n-Mora, Sergio"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982201'}"
FOQUS: A Smartwatch Application for Individuals with ADHD and Mental Health Challenges,10.1145/2982142.2982207,"This paper reports on the design of FOQUS, an app running on a smartwatch to aid adults with mental health issues like ADHD and mild forms of attention deficiency through two main routes -- tools to foster extended focus and tools to reduce anxiety/stress. Using a user-centric design approach, three important features are identified, implemented and evaluated which aim to leverage the benefits of wearable devices: a flexible implementation of the Pomodoro time management technique, a tool for guided meditation, and positive message priming. Initial user test results suggest smartwatch-based interventions as a viable, ubiquitous tool for addressing mental health and stress related conditions.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wearables, smartwatches, mental health., attention deficiency, adhd', 'numpages': '2', 'pages': '311–312', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper reports on the design of FOQUS, an app running on a smartwatch to aid adults with mental health issues like ADHD and mild forms of attention deficiency through two main routes -- tools to foster extended focus and tools to reduce anxiety/stress. Using a user-centric design approach, three important features are identified, implemented and evaluated which aim to leverage the benefits of wearable devices: a flexible implementation of the Pomodoro time management technique, a tool for guided meditation, and positive message priming. Initial user test results suggest smartwatch-based interventions as a viable, ubiquitous tool for addressing mental health and stress related conditions.', 'doi': '10.1145/2982142.2982207', 'url': 'https://doi.org/10.1145/2982142.2982207', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'FOQUS: A Smartwatch Application for Individuals with ADHD and Mental Health Challenges', 'author': 'Dibia, Victor', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982207'}"
Tactile Interface for Electric Wheelchair,10.1145/2982142.2982189,"In the framework of an augmented multimodal electric wheelchair for people with multiple disabilities, we propose a new user interface based on an Android application on a tablet to steer the wheelchair. The proposed system aims at overcoming some of the problems encountered with the traditional joystick interface like the involuntary arm extensions due to spasticity conditions. These often lead to unwanted movement of the chair and, in many cases, to accidents. The application uses different output modalities to allow the user keep his/her attention on the navigation task without having to visually focus on the tablet screen. We conducted some preliminary tests with some people with disabilities to engage them in the design process and get their feedback on the first prototype. The general impression was positive with insight on future improvements to the system.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'tactile interface, interaction modalities, electric wheelchair, design.', 'numpages': '2', 'pages': '313–314', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In the framework of an augmented multimodal electric wheelchair for people with multiple disabilities, we propose a new user interface based on an Android application on a tablet to steer the wheelchair. The proposed system aims at overcoming some of the problems encountered with the traditional joystick interface like the involuntary arm extensions due to spasticity conditions. These often lead to unwanted movement of the chair and, in many cases, to accidents. The application uses different output modalities to allow the user keep his/her attention on the navigation task without having to visually focus on the tablet screen. We conducted some preliminary tests with some people with disabilities to engage them in the design process and get their feedback on the first prototype. The general impression was positive with insight on future improvements to the system.', 'doi': '10.1145/2982142.2982189', 'url': 'https://doi.org/10.1145/2982142.2982189', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Tactile Interface for Electric Wheelchair', 'author': ""Guedira, Youssef and Jordan, Liam and Favey, Cl\\'{e}ment and Farcy, Ren\\'{e} and Bellik, Yacine"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982189'}"
Facade: Auto-generating Tactile Interfaces to Appliances,10.1145/2982142.2982187,"Digital keypads have proliferated on common appliances, from microwaves and refrigerators to printers and remote controls. For blind people, such interfaces are inaccessible. We conducted a formative study with 6 blind people which demonstrated a need for custom designs for tactile labels without dependence on sighted assistance. To address this need, we introduce Facade - a crowdsourced fabrication pipeline to make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Blind users capture a photo of an inaccessible interface with a standard marker for absolute measurements using perspective transformation. Then this image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. These labels are then used to generate 3D models for a layer of tactile and pressable buttons that fits over the original controls. Users can customize the shape and labels of the buttons using a web interface. Finally, a consumer-grade 3D printer fabricates the layer, which is then attached to the interface using adhesives. Such fabricated overlay is an inexpensive ($10) and more general solution to making physical interfaces accessible.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'personal fabrication, crowdsourcing, blind users, accessibility', 'numpages': '2', 'pages': '315–316', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Digital keypads have proliferated on common appliances, from microwaves and refrigerators to printers and remote controls. For blind people, such interfaces are inaccessible. We conducted a formative study with 6 blind people which demonstrated a need for custom designs for tactile labels without dependence on sighted assistance. To address this need, we introduce Facade - a crowdsourced fabrication pipeline to make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Blind users capture a photo of an inaccessible interface with a standard marker for absolute measurements using perspective transformation. Then this image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. These labels are then used to generate 3D models for a layer of tactile and pressable buttons that fits over the original controls. Users can customize the shape and labels of the buttons using a web interface. Finally, a consumer-grade 3D printer fabricates the layer, which is then attached to the interface using adhesives. Such fabricated overlay is an inexpensive ($10) and more general solution to making physical interfaces accessible.', 'doi': '10.1145/2982142.2982187', 'url': 'https://doi.org/10.1145/2982142.2982187', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Facade: Auto-generating Tactile Interfaces to Appliances', 'author': ""Guo, Anhong and Kim, Jeeeun and Chen, Xiang 'Anthony' and Yeh, Tom and Hudson, Scott E. and Mankoff, Jennifer and Bigham, Jeffrey P."", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982187'}"
An Accessible Blocks Language: Work in Progress,10.1145/2982142.2982150,"Block languages are extensively used to introduce programming to children. They replace the complex and error prone syntax of textual languages with simple shape cues that show how program elements can be combined. In their present form, blind learners cannot use them, because they rely on graphical presentation of code, and mouse interactions. We are working on a nonvisual blocks language called Pseudospatial Blocks (PB), that supports program creation using keyboard commands with synthetic speech output. It replaces visual shape cues for language syntax, the key feature of block languages, with filtering of program elements by syntactic category.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'learning to program, barriers to programming, accessible interfaces', 'numpages': '2', 'pages': '317–318', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Block languages are extensively used to introduce programming to children. They replace the complex and error prone syntax of textual languages with simple shape cues that show how program elements can be combined. In their present form, blind learners cannot use them, because they rely on graphical presentation of code, and mouse interactions. We are working on a nonvisual blocks language called Pseudospatial Blocks (PB), that supports program creation using keyboard commands with synthetic speech output. It replaces visual shape cues for language syntax, the key feature of block languages, with filtering of program elements by syntactic category.', 'doi': '10.1145/2982142.2982150', 'url': 'https://doi.org/10.1145/2982142.2982150', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'An Accessible Blocks Language: Work in Progress', 'author': 'Koushik, Varsha and Lewis, Clayton', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982150'}"
Demonstration: Screen Reader Support for a Complex Interactive Science Simulation,10.1145/2982142.2982154,"Interactive simulations are increasingly important in science education, yet most are inaccessible to blind learners. We demonstrate an accessible version of a simulation, Balloons and Static Electricity, that illustrates responses to key challenges in providing screen reader support: the need to describe unpredictable sequences of events, the manipulation of objects that act as both controls and displays, and the management of descriptions of changes in the state of the simulation as well as of the state of the interactive object, itself. Meeting these challenges requires extending current practices for verbal description of visual interactive content.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairment, usability study, stem education, phet simulation, interactive science simulation, description, accessibility', 'numpages': '2', 'pages': '319–320', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Interactive simulations are increasingly important in science education, yet most are inaccessible to blind learners. We demonstrate an accessible version of a simulation, Balloons and Static Electricity, that illustrates responses to key challenges in providing screen reader support: the need to describe unpredictable sequences of events, the manipulation of objects that act as both controls and displays, and the management of descriptions of changes in the state of the simulation as well as of the state of the interactive object, itself. Meeting these challenges requires extending current practices for verbal description of visual interactive content.', 'doi': '10.1145/2982142.2982154', 'url': 'https://doi.org/10.1145/2982142.2982154', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Demonstration: Screen Reader Support for a Complex Interactive Science Simulation', 'author': 'Smith, Taliesin L. and Lewis, Clayton and Moore, Emily B.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982154'}"
TranslatAble: Giving Individuals with Complex Communication Needs a Voice through Speech and Gesture Recognition,10.1145/2982142.2982197,"This paper presents the design of TranslatAble, a new Augmentative and Alternative Communication system. Taking advantage of the convenience and mobility of modern smartphones, TranslatAble allows individuals with complex communication needs-specifically individuals with severe dysarthria or individuals who primarily use non-sign language gestures---to build their own system of communication through speech or gesture input. This system uses a machine learning model---specifically dynamic time warping---to match the user's input to their unique dictionary to help them be understood by their communication partner. TranslatAble is highly flexible and person-centered, which allows it to adapt to fit the unique needs of each user's unique communication needs. We expect this novel device to enable individuals with complex communication needs to interact with a larger social circle. This may help decrease feelings of loneliness and increase self-confidence, self-esteem, and independence, as well as help maintain strong relationships outside of the user's support network.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'speech recognition, gesture recognition, complex communication needs, augmentative and alternative communication, aac device', 'numpages': '2', 'pages': '321–322', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""This paper presents the design of TranslatAble, a new Augmentative and Alternative Communication system. Taking advantage of the convenience and mobility of modern smartphones, TranslatAble allows individuals with complex communication needs-specifically individuals with severe dysarthria or individuals who primarily use non-sign language gestures---to build their own system of communication through speech or gesture input. This system uses a machine learning model---specifically dynamic time warping---to match the user's input to their unique dictionary to help them be understood by their communication partner. TranslatAble is highly flexible and person-centered, which allows it to adapt to fit the unique needs of each user's unique communication needs. We expect this novel device to enable individuals with complex communication needs to interact with a larger social circle. This may help decrease feelings of loneliness and increase self-confidence, self-esteem, and independence, as well as help maintain strong relationships outside of the user's support network."", 'doi': '10.1145/2982142.2982197', 'url': 'https://doi.org/10.1145/2982142.2982197', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'TranslatAble: Giving Individuals with Complex Communication Needs a Voice through Speech and Gesture Recognition', 'author': 'Moore, Meredith and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982197'}"
Supporting Visual Impaired Learners in Editing Mathematics,10.1145/2982142.2982212,"We present an extension to the Emacspeak audio desktop that provides support for editing mathematics in LaTeX. It integrates MathJax and the Speech Rule Engine to support users in reading LaTeX sources, manipulating mathematical formulas and verifying correctness of the rendered output.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'stem accessibility, mathjax, mathematics', 'numpages': '2', 'pages': '323–324', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present an extension to the Emacspeak audio desktop that provides support for editing mathematics in LaTeX. It integrates MathJax and the Speech Rule Engine to support users in reading LaTeX sources, manipulating mathematical formulas and verifying correctness of the rendered output.', 'doi': '10.1145/2982142.2982212', 'url': 'https://doi.org/10.1145/2982142.2982212', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Supporting Visual Impaired Learners in Editing Mathematics', 'author': 'Sorge, Volker', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982212'}"
Motivating Individuals with Spastic Cerebral Palsy to Speak Using Mobile Speech Recognition,10.1145/2982142.2982203,"Individuals with cerebral palsy (CP) struggle with conditions such as dysarthria, dysphagia, and dyspraxia as they speak. While speech therapy is successful in practice, outside practice requires increased commitment and effort from caregivers. Researchers developed a speech recognition game designed to encourage out-of-office exercises and motivate users to practice. Next they recruited a participant with cerebral palsy to investigate the performance of the system in a live environment. The participant joined the game after demonstration from the caregiver and temporarily increased speech loudness and clarity during play. The participant found sound effects more rewarding than animations. The total number of sentences spoken during the session was found to be less than half that of a speaker without any impairment. Researchers also observed two instances of cheating. This work provides insight into the automated motivation of motivating speech production with individuals with cerebral palsy.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'user study, speech therapy, speech recognition interface, cerebral palsy', 'numpages': '2', 'pages': '325–326', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Individuals with cerebral palsy (CP) struggle with conditions such as dysarthria, dysphagia, and dyspraxia as they speak. While speech therapy is successful in practice, outside practice requires increased commitment and effort from caregivers. Researchers developed a speech recognition game designed to encourage out-of-office exercises and motivate users to practice. Next they recruited a participant with cerebral palsy to investigate the performance of the system in a live environment. The participant joined the game after demonstration from the caregiver and temporarily increased speech loudness and clarity during play. The participant found sound effects more rewarding than animations. The total number of sentences spoken during the session was found to be less than half that of a speaker without any impairment. Researchers also observed two instances of cheating. This work provides insight into the automated motivation of motivating speech production with individuals with cerebral palsy.', 'doi': '10.1145/2982142.2982203', 'url': 'https://doi.org/10.1145/2982142.2982203', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Motivating Individuals with Spastic Cerebral Palsy to Speak Using Mobile Speech Recognition', 'author': 'Rubin, Zak and Kurniawan, Sri and Gotfrid, Taylor and Pugliese, Annie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982203'}"
A Virtual Self-care Coach for Individuals with Spinal Cord Injury,10.1145/2982142.2982199,"Most persons with spinal cord injury (SCI) require training and support for self-care management to help prevent the development of serious secondary conditions after hospital discharge. We have designed a virtual coach system, in which an animated character engages users in simulated face-to-face conversation to provide health education and motivate healthy behavior. We conducted an exploratory study with nine participants who have SCI to examine the acceptance and attitudes towards our system. Results of the study show that participants are highly receptive of the virtual coach technology and recognize it as an effective medium to promote self-care.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'spinal cord injury, healthcare, embodied conversational agent', 'numpages': '2', 'pages': '327–328', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most persons with spinal cord injury (SCI) require training and support for self-care management to help prevent the development of serious secondary conditions after hospital discharge. We have designed a virtual coach system, in which an animated character engages users in simulated face-to-face conversation to provide health education and motivate healthy behavior. We conducted an exploratory study with nine participants who have SCI to examine the acceptance and attitudes towards our system. Results of the study show that participants are highly receptive of the virtual coach technology and recognize it as an effective medium to promote self-care.', 'doi': '10.1145/2982142.2982199', 'url': 'https://doi.org/10.1145/2982142.2982199', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'A Virtual Self-care Coach for Individuals with Spinal Cord Injury', 'author': 'Shamekhi, Ameneh and Trinh, Ha and Bickmore, Timothy W. and DeAngelis, Tamara R. and Ellis, Theresa and Houlihan, Bethlyn V. and Latham, Nancy K.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982199'}"
Magic Touch: Interacting with 3D Printed Graphics,10.1145/2982142.2982153,"Graphics like maps and models are important learning materials. With recently developed projects, we can use 3D printers to make tactile graphics that are more accessible to blind people. However, current 3D printed graphics can only convey limited information through their shapes and textures. We present Magic Touch, a computer vision-based system that augments printed graphics with audio files associated with specific locations, or hotspots, on the model. A user can access an audio file associated with a hotspot by touching it with a pointing gesture. The system detects the user's gesture and determines the hotspot location with computer vision algorithms by comparing a video feed of the user's interaction with the digital representation of the model and its hotspots. To enable MT, a model designer must add a single tracker with fiducial tags to a model. After the tracker is added, MT only requires an RGB camera, so it can be easily deployed on many devices such as mobile phones, laptops and smart glasses.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'visual impairments, computer vision, 3d printing', 'numpages': '2', 'pages': '329–330', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Graphics like maps and models are important learning materials. With recently developed projects, we can use 3D printers to make tactile graphics that are more accessible to blind people. However, current 3D printed graphics can only convey limited information through their shapes and textures. We present Magic Touch, a computer vision-based system that augments printed graphics with audio files associated with specific locations, or hotspots, on the model. A user can access an audio file associated with a hotspot by touching it with a pointing gesture. The system detects the user's gesture and determines the hotspot location with computer vision algorithms by comparing a video feed of the user's interaction with the digital representation of the model and its hotspots. To enable MT, a model designer must add a single tracker with fiducial tags to a model. After the tracker is added, MT only requires an RGB camera, so it can be easily deployed on many devices such as mobile phones, laptops and smart glasses."", 'doi': '10.1145/2982142.2982153', 'url': 'https://doi.org/10.1145/2982142.2982153', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Magic Touch: Interacting with 3D Printed Graphics', 'author': 'Shi, Lei and McLachlan, Ross and Zhao, Yuhang and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982153'}"
Evaluation of Automatic Caption Segmentation,10.1145/2982142.2982205,"Captions are typically segmented in a way that respects grammatical boundaries and makes them more readable. However, the growth of online video content with captions generated from transcripts means that this segmentation process is often ignored. This study evaluates the effects of text segmentation on caption readability, and proposes a program to automatically segment captions using a parser. The parser-segmented captions readability is also evaluated and compared to human-segmented captions and arbitrarily- segmented captions. Results indicate segmentation influences sentence recall, though other wise little difference is found between the different kinds of captioning.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'caption segmentation', 'numpages': '2', 'pages': '331–332', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Captions are typically segmented in a way that respects grammatical boundaries and makes them more readable. However, the growth of online video content with captions generated from transcripts means that this segmentation process is often ignored. This study evaluates the effects of text segmentation on caption readability, and proposes a program to automatically segment captions using a parser. The parser-segmented captions readability is also evaluated and compared to human-segmented captions and arbitrarily- segmented captions. Results indicate segmentation influences sentence recall, though other wise little difference is found between the different kinds of captioning.', 'doi': '10.1145/2982142.2982205', 'url': 'https://doi.org/10.1145/2982142.2982205', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Evaluation of Automatic Caption Segmentation', 'author': 'Waller, James M. and Kushalnagar, Raja S.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982205'}"
Utilizing Neural Networks to Predict Freezing of Gait in Parkinson's Patients,10.1145/2982142.2982194,"With the appropriate mathematical models, data from wearable devices can be used to help Parkinson's patients live safer and more independent lives. Inspired by this idea, the purpose of this study was to determine the viability of neural networks in predicting Freezing of Gait (FoG), a symptom of Parkinson's disease in which the patient's legs are suddenly rendered unable to move. A class of neural networks known as layered recurrent networks (LRNs) was applied to an open-source FoG experimental dataset donated to the Machine Learning Repository of the University of California at Irvine. The independent variables in this experiment -- the subject being tested, neural network architecture, and down sampling of the majority classes -- were each varied and compared against the performance of the neural network in predicting impending FoG events. It was determined that single-layered recurrent networks are a viable method of predicting FoG events given the volume of the training data available, though results varied between patients.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': ""wearable devices., parkinson's disease, machine learning, freezing of gait"", 'numpages': '2', 'pages': '333–334', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""With the appropriate mathematical models, data from wearable devices can be used to help Parkinson's patients live safer and more independent lives. Inspired by this idea, the purpose of this study was to determine the viability of neural networks in predicting Freezing of Gait (FoG), a symptom of Parkinson's disease in which the patient's legs are suddenly rendered unable to move. A class of neural networks known as layered recurrent networks (LRNs) was applied to an open-source FoG experimental dataset donated to the Machine Learning Repository of the University of California at Irvine. The independent variables in this experiment -- the subject being tested, neural network architecture, and down sampling of the majority classes -- were each varied and compared against the performance of the neural network in predicting impending FoG events. It was determined that single-layered recurrent networks are a viable method of predicting FoG events given the volume of the training data available, though results varied between patients."", 'doi': '10.1145/2982142.2982194', 'url': 'https://doi.org/10.1145/2982142.2982194', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': ""Utilizing Neural Networks to Predict Freezing of Gait in Parkinson's Patients"", 'author': 'Zia, Jonathan and Tadayon, Arash and McDaniel, Troy and Panchanathan, Sethuraman', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982194'}"
Games for People with Developmental Disabilities,10.1145/2982142.2982148,"This study presents the work on the development and evaluation of web based applications for people with developmental disabilities (DD) in collaboration with Hope Services, a California based non-profit organization that provides services to improve the quality of life for individuals with DD. The system includes two games that aim to teach basic skills such as relationship concepts, causality, and or improve upon cognitive skills. User evaluation suggests that these games provide a good platform for people with DD to increase their independence, provide an additional or alternative learning system, as well as improve their life satisfaction.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'tablet devices, game, developmental disability, accessibility', 'numpages': '2', 'pages': '335–336', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This study presents the work on the development and evaluation of web based applications for people with developmental disabilities (DD) in collaboration with Hope Services, a California based non-profit organization that provides services to improve the quality of life for individuals with DD. The system includes two games that aim to teach basic skills such as relationship concepts, causality, and or improve upon cognitive skills. User evaluation suggests that these games provide a good platform for people with DD to increase their independence, provide an additional or alternative learning system, as well as improve their life satisfaction.', 'doi': '10.1145/2982142.2982148', 'url': 'https://doi.org/10.1145/2982142.2982148', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Games for People with Developmental Disabilities', 'author': 'Gotfrid, Taylor', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982148'}"
Closed ASL Interpreting for Online Videos,10.1145/2982142.2982147,"This paper focuses on accessibility for deaf and hard of hearing people, specifically those who rely on American Sign Language (ASL) for communication, with regards to online videos. In this paper, we propose the idea of ""closed interpreting"" which allows the interpreter to be toggled on and appear alongside the main video, similiar to closed captioning. While the idea is similar to closed captioning, closed interpreting as described in this paper is more dynamic, allowing viewers to adjust the interpreter as they please. A major factor in differentiating closed captioning from closed interpreting is that many deaf and hard of hearing signers rely on ASL as their primary means of communication and thus English captioning is not satisfactory. The goal of the research presented in this paper is to assess what features and qualities of closed interpreting appeals to deaf viewers.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'deaf and hard of hearing, closed interpreting, american sign language, accessible technology', 'numpages': '2', 'pages': '337–338', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper focuses on accessibility for deaf and hard of hearing people, specifically those who rely on American Sign Language (ASL) for communication, with regards to online videos. In this paper, we propose the idea of ""closed interpreting"" which allows the interpreter to be toggled on and appear alongside the main video, similiar to closed captioning. While the idea is similar to closed captioning, closed interpreting as described in this paper is more dynamic, allowing viewers to adjust the interpreter as they please. A major factor in differentiating closed captioning from closed interpreting is that many deaf and hard of hearing signers rely on ASL as their primary means of communication and thus English captioning is not satisfactory. The goal of the research presented in this paper is to assess what features and qualities of closed interpreting appeals to deaf viewers.', 'doi': '10.1145/2982142.2982147', 'url': 'https://doi.org/10.1145/2982142.2982147', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Closed ASL Interpreting for Online Videos', 'author': 'Seita, Matthew', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982147'}"
Playing Music with the Head,10.1145/2982142.2982146,"In this paper, we describe the co-design process leading to the implementation of an open source software enabling M., a person living severe motor, dexterity and speech impairments, to play music, either alone or with others. We first conducted participant observations in the nursing home she lives in. We then used regular iterations to facilitate communication and to enable her to participate to the design process. We outline how such design process can reinforce participation in different areas and contribute to the research on empowering adapted technologies.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'pure data, infrared tracking, computer music', 'numpages': '2', 'pages': '339–340', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we describe the co-design process leading to the implementation of an open source software enabling M., a person living severe motor, dexterity and speech impairments, to play music, either alone or with others. We first conducted participant observations in the nursing home she lives in. We then used regular iterations to facilitate communication and to enable her to participate to the design process. We outline how such design process can reinforce participation in different areas and contribute to the research on empowering adapted technologies.', 'doi': '10.1145/2982142.2982146', 'url': 'https://doi.org/10.1145/2982142.2982146', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Playing Music with the Head', 'author': ""Brul\\'{e}, Emeline"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982146'}"
Designing Wearable Mobile Device Controllers for Blind People: A Co-Design Approach,10.1145/2982142.2982144,"Blind people get critical information from their mobile phones while traveling. Accessing their phones while on the go, however, can be a cumbersome process as they have to listen to their environment, while holding a cane or a dog harness. We explore the design space and feasibility of using wearable mobile device controllers to make it easier and faster for blind people to access their phones on the go by considering various form factors and on-body placements. We conducted a study with eight blind participants, where the researchers and participants interacted with design probes to design mobile device controllers that operate the screen reader on a smartphone for the following on-body placements: hip, head, hand, and wrist. Most participants preferred wrist- and hand-mounted systems as they were considered to allow for more natural and discreet interfaces. Based on our findings, we designed a smart ring controller, which allows for a small and compact form factor, and only requires one-handed interactions.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wearable controls, mobile devices, blind, accessibility', 'numpages': '2', 'pages': '341–342', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind people get critical information from their mobile phones while traveling. Accessing their phones while on the go, however, can be a cumbersome process as they have to listen to their environment, while holding a cane or a dog harness. We explore the design space and feasibility of using wearable mobile device controllers to make it easier and faster for blind people to access their phones on the go by considering various form factors and on-body placements. We conducted a study with eight blind participants, where the researchers and participants interacted with design probes to design mobile device controllers that operate the screen reader on a smartphone for the following on-body placements: hip, head, hand, and wrist. Most participants preferred wrist- and hand-mounted systems as they were considered to allow for more natural and discreet interfaces. Based on our findings, we designed a smart ring controller, which allows for a small and compact form factor, and only requires one-handed interactions.', 'doi': '10.1145/2982142.2982144', 'url': 'https://doi.org/10.1145/2982142.2982144', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Designing Wearable Mobile Device Controllers for Blind People: A Co-Design Approach', 'author': 'Feng, Catherine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982144'}"
An Affordable Virtual Reality Learning Framework for Children with Neuro-Developmental Disorder,10.1145/2982142.2982143,"Our research explores wearable Immersive Virtual Reality (IVR) to support new forms of intervention for children with Neuro-Developmental Disorder (NDD). In cooperation with therapists at a local rehabilitation center, we developed and evaluated Wildcard, a system that exploits a low cost VR visor and enables the child to ""feel immersed"" in 3D worlds, using eye focus and head/body movements to interact with the virtual items. Wildcard includes a set of functionalities for the therapists to monitor children's interaction, to customize the virtual space for the specific needs of each subject, and to automatically collect data.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'virtual reality, neuro-developmental disorder, accessibility', 'numpages': '2', 'pages': '343–344', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Our research explores wearable Immersive Virtual Reality (IVR) to support new forms of intervention for children with Neuro-Developmental Disorder (NDD). In cooperation with therapists at a local rehabilitation center, we developed and evaluated Wildcard, a system that exploits a low cost VR visor and enables the child to ""feel immersed"" in 3D worlds, using eye focus and head/body movements to interact with the virtual items. Wildcard includes a set of functionalities for the therapists to monitor children\'s interaction, to customize the virtual space for the specific needs of each subject, and to automatically collect data.', 'doi': '10.1145/2982142.2982143', 'url': 'https://doi.org/10.1145/2982142.2982143', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'An Affordable Virtual Reality Learning Framework for Children with Neuro-Developmental Disorder', 'author': 'Gelsomini, Mirko', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982143'}"
Gaze Typing Through Foot-Operated Wearable Device,10.1145/2982142.2982145,"Gaze Typing, a gaze-assisted text entry method, allows individuals with motor (arm, spine) impairments to enter text on a computer using a virtual keyboard and their gaze. Though gaze typing is widely accepted, this method is limited by its lower typing speed, higher error rate, and the resulting visual fatigue, since dwell-based key selection is used. In this research, we present a gaze-assisted, wearable-supplemented, foot interaction framework for dwell-free gaze typing. The framework consists of a custom-built virtual keyboard, an eye tracker, and a wearable device attached to the user's foot. To enter a character, the user looks at the character and selects it by pressing the pressure pad, attached to the wearable device, with the foot. Results from a preliminary user study involving two participants with motor impairments show that the participants achieved a mean gaze typing speed of 6.23 Words Per Minute (WPM). In addition, the mean value of Key Strokes Per Character (KPSC) was 1.07 (ideal 1.0), and the mean value of Rate of Backspace Activation (RBA) was 0.07 (ideal 0.0). Furthermore, we present our findings from multiple usability studies and design iterations, through which we created appropriate affordances and experience design of our gaze typing system.","{'series': ""ASSETS '16"", 'location': 'Reno, Nevada, USA', 'keywords': 'wearable devices, gaze typing, foot-operated devices', 'numpages': '2', 'pages': '345–346', 'booktitle': 'Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Gaze Typing, a gaze-assisted text entry method, allows individuals with motor (arm, spine) impairments to enter text on a computer using a virtual keyboard and their gaze. Though gaze typing is widely accepted, this method is limited by its lower typing speed, higher error rate, and the resulting visual fatigue, since dwell-based key selection is used. In this research, we present a gaze-assisted, wearable-supplemented, foot interaction framework for dwell-free gaze typing. The framework consists of a custom-built virtual keyboard, an eye tracker, and a wearable device attached to the user's foot. To enter a character, the user looks at the character and selects it by pressing the pressure pad, attached to the wearable device, with the foot. Results from a preliminary user study involving two participants with motor impairments show that the participants achieved a mean gaze typing speed of 6.23 Words Per Minute (WPM). In addition, the mean value of Key Strokes Per Character (KPSC) was 1.07 (ideal 1.0), and the mean value of Rate of Backspace Activation (RBA) was 0.07 (ideal 0.0). Furthermore, we present our findings from multiple usability studies and design iterations, through which we created appropriate affordances and experience design of our gaze typing system."", 'doi': '10.1145/2982142.2982145', 'url': 'https://doi.org/10.1145/2982142.2982145', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450341240', 'year': '2016', 'title': 'Gaze Typing Through Foot-Operated Wearable Device', 'author': 'Rajanna, Vijay', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2982142.2982145'}"