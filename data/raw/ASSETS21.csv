Title,DOI,Abstract,BibTeX
The DARE Index - Monitoring the Progress of Digital Accessibility around the World - A Research Conducted by Advocates for Advocates,10.1145/3441852.3487959,"It is not sufficient to simply express the goal of improved digital access for people with disabilities, without properly monitoring the progress towards those goals. This keynote speech describes the Digital Accessibility Rights Evaluation (DARE) index, which is coordinated by the Global Initiative for Inclusive ICTs (G3ICT). The DARE index is a benchmarking tool, for disability advocates, governments, civil society, international organizations and policy makers to trace country progress in making Information and Communication Technologies (ICT) accessible for all, in compliance with Article 9 of the Convention on the Rights of Persons with Disabilities (CRPD). The DARE Index measures three categories of variables in each country: country commitments (legal, regulatory, policies and programs), country capacity to implement (organization, processes, resources) and actual digital accessibility outcomes for persons with disabilities in 10 areas of products and services. Data is collected in close cooperation with Disabled People's International (DPI) and persons with disabilities worldwide, considering their best position to assess and report on digital accessibility matters in their respective countries. This keynote speech for ASSETS 2021 describes the DARE index and the most recent data collected in the DARE index in 2020, and highlights how the DARE index can be used to support digital accessibility research.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '1', 'articleno': '1', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""It is not sufficient to simply express the goal of improved digital access for people with disabilities, without properly monitoring the progress towards those goals. This keynote speech describes the Digital Accessibility Rights Evaluation (DARE) index, which is coordinated by the Global Initiative for Inclusive ICTs (G3ICT). The DARE index is a benchmarking tool, for disability advocates, governments, civil society, international organizations and policy makers to trace country progress in making Information and Communication Technologies (ICT) accessible for all, in compliance with Article 9 of the Convention on the Rights of Persons with Disabilities (CRPD). The DARE Index measures three categories of variables in each country: country commitments (legal, regulatory, policies and programs), country capacity to implement (organization, processes, resources) and actual digital accessibility outcomes for persons with disabilities in 10 areas of products and services. Data is collected in close cooperation with Disabled People's International (DPI) and persons with disabilities worldwide, considering their best position to assess and report on digital accessibility matters in their respective countries. This keynote speech for ASSETS 2021 describes the DARE index and the most recent data collected in the DARE index in 2020, and highlights how the DARE index can be used to support digital accessibility research."", 'doi': '10.1145/3441852.3487959', 'url': 'https://doi.org/10.1145/3441852.3487959', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'The DARE Index - Monitoring the Progress of Digital Accessibility around the World - A Research Conducted by Advocates for Advocates', 'author': 'Leblois, Axel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3487959'}"
Enabling meaningful use of AI-infused educational technologies for children with blindness: Learnings from the development and piloting of the PeopleLens curriculum,10.1145/3441852.3471210,"Novel AI-infused educational technologies can give children with blindness the opportunity to explore concepts learned incidentally through vision by using alternative perceptual modalities. However, more effort is needed to support the meaningful use of such technological innovations for evaluations at scale and later wide-spread adoption. This paper presents the development and pilot evaluation of a curriculum to enable educators to support blind learners’ self-exploration of social attention using the PeopleLens technology. We reflect on these learnings to present four design guidelines for creating curricula aimed to enable meaningful use. We then consider how formulations of “success” by our participants can help us think about ways of assessing efficacy in low-incidence disability groups. We conclude by arguing for our community to widen the scope of discourse around assistive technologies from design and engineering to include supporting their meaningful use.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Human-centred AI, accessibility, blindness, children, disability, user evaluation, visual impairment', 'numpages': '13', 'articleno': '2', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Novel AI-infused educational technologies can give children with blindness the opportunity to explore concepts learned incidentally through vision by using alternative perceptual modalities. However, more effort is needed to support the meaningful use of such technological innovations for evaluations at scale and later wide-spread adoption. This paper presents the development and pilot evaluation of a curriculum to enable educators to support blind learners’ self-exploration of social attention using the PeopleLens technology. We reflect on these learnings to present four design guidelines for creating curricula aimed to enable meaningful use. We then consider how formulations of “success” by our participants can help us think about ways of assessing efficacy in low-incidence disability groups. We conclude by arguing for our community to widen the scope of discourse around assistive technologies from design and engineering to include supporting their meaningful use.', 'doi': '10.1145/3441852.3471210', 'url': 'https://doi.org/10.1145/3441852.3471210', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Enabling meaningful use of AI-infused educational technologies for children with blindness: Learnings from the development and piloting of the PeopleLens curriculum', 'author': 'Morrison, Cecily and Cutrell, Edward and Grayson, Martin and Becker, Elisabeth RB and Kladouchou, Vasiliki and Pring, Linda and Jones, Katherine and Faia Marques, Rita and Longden, Camilla and Sellen, Abigail', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471210'}"
Understanding Disability Services Toward Improving Graduate Student Support,10.1145/3441852.3471231,"Few students with disabilities transition from undergraduate to graduate programs. Graduate students often receive ineffective and insufficient accommodations, including lack of support specific to graduate students, because disability services policies are shaped by undergraduate experiences. To understand how disability services offices accommodate graduate students: we (1) critically analyzed disability services websites of 18 U.S. institutions, and (2) interviewed 17 disability services staff. Disability services websites publicly present institutional accommodation policies and guidelines, and staff are responsible for identifying, providing, and implementing reasonable accommodations. We found that policies may be interpreted differently depending on specific student circumstances. We discuss our findings in two main themes: (a) Policies and attitudes ascribed to disability, technology, and faculty, and (b) Impacts of policies and perspectives on accommodation decisions for graduate students. The contributions of this work include an empirical investigation of institutional support for disabled graduate students and suggestions for how to improve support from disability services offices to empower students.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Ableism, Accessibility, Computing Education Research, Higher Education', 'numpages': '14', 'articleno': '3', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Few students with disabilities transition from undergraduate to graduate programs. Graduate students often receive ineffective and insufficient accommodations, including lack of support specific to graduate students, because disability services policies are shaped by undergraduate experiences. To understand how disability services offices accommodate graduate students: we (1) critically analyzed disability services websites of 18 U.S. institutions, and (2) interviewed 17 disability services staff. Disability services websites publicly present institutional accommodation policies and guidelines, and staff are responsible for identifying, providing, and implementing reasonable accommodations. We found that policies may be interpreted differently depending on specific student circumstances. We discuss our findings in two main themes: (a) Policies and attitudes ascribed to disability, technology, and faculty, and (b) Impacts of policies and perspectives on accommodation decisions for graduate students. The contributions of this work include an empirical investigation of institutional support for disabled graduate students and suggestions for how to improve support from disability services offices to empower students.', 'doi': '10.1145/3441852.3471231', 'url': 'https://doi.org/10.1145/3441852.3471231', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Understanding Disability Services Toward Improving Graduate Student Support', 'author': 'Tamjeed, Murtaza and Tibdewal, Vinita and Russell, Madison and McQuaid, Michael and Oh, Tae and Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471231'}"
How Teachers of the Visually Impaired Compensate with the Absence of Accessible Block-Based Languages,10.1145/3441852.3471221,"The past five years have witnessed an increase in research to improve the accessibility of block-based programming environments to people with visual impairments. This has led to the creation of a few accessible block-based programming environments with some researchers considering tangible alternatives or hybrid environments. However, the literature says little about the learning experiences of K-12 students with visual impairments on these systems in educational settings. We try to fill this gap of knowledge with a report on an interview study with twelve teachers of K-12 students with visual impairments. Through the lens of the teachers, we discovered that factors such as the students background, the teacher's CS background and the design of existing curricula influence the learning process of students with visual impairments learning how to code. In addition to discussing how they go about to mitigate the challenges that stem from these factors, teachers also reported on how they compensate for the lack of accessible block-based languages. Through this work, we offer insights into how the research community can improve the learning experiences of students with visual impairments including training teachers, ensuring students have basic computing skills, improving the curriculum and designing accessible on-screen block-based programming environments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessible Computing, Block-based programming, K-12 computing, Programming, Visually impaired', 'numpages': '10', 'articleno': '4', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""The past five years have witnessed an increase in research to improve the accessibility of block-based programming environments to people with visual impairments. This has led to the creation of a few accessible block-based programming environments with some researchers considering tangible alternatives or hybrid environments. However, the literature says little about the learning experiences of K-12 students with visual impairments on these systems in educational settings. We try to fill this gap of knowledge with a report on an interview study with twelve teachers of K-12 students with visual impairments. Through the lens of the teachers, we discovered that factors such as the students background, the teacher's CS background and the design of existing curricula influence the learning process of students with visual impairments learning how to code. In addition to discussing how they go about to mitigate the challenges that stem from these factors, teachers also reported on how they compensate for the lack of accessible block-based languages. Through this work, we offer insights into how the research community can improve the learning experiences of students with visual impairments including training teachers, ensuring students have basic computing skills, improving the curriculum and designing accessible on-screen block-based programming environments."", 'doi': '10.1145/3441852.3471221', 'url': 'https://doi.org/10.1145/3441852.3471221', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'How Teachers of the Visually Impaired Compensate with the Absence of Accessible Block-Based Languages', 'author': 'Mountapmbeme, Aboubakar and Ludi, Stephanie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471221'}"
Nearmi: A Framework for Designing Point of Interest Techniques for VR Users with Limited Mobility,10.1145/3441852.3471230,"We propose Nearmi, a framework that enables designers to create customizable and accessible point-of-interest (POI) techniques in virtual reality (VR) for people with limited mobility. Designers can use Nearmi by creating and combining instances of its four components—representation, display, selection, and transition. These components enable users to gain awareness of POIs in virtual environments, and automatically re-orient the virtual camera toward a selected POI. We conducted a video elicitation study where 17 participants with limited mobility provided feedback on different Nearmi implementations. Although participants generally weighed the same design considerations when discussing their preferences, their choices reflected tradeoffs in accessibility, realism, spatial awareness, comfort, and familiarity with the interaction. Our findings highlight the need for accessible and customizable VR interaction techniques, as well as design considerations for building and evaluating these techniques.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Design framework, Limited mobility, Out-of-view, Point of interest, Virtual reality', 'numpages': '14', 'articleno': '5', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We propose Nearmi, a framework that enables designers to create customizable and accessible point-of-interest (POI) techniques in virtual reality (VR) for people with limited mobility. Designers can use Nearmi by creating and combining instances of its four components—representation, display, selection, and transition. These components enable users to gain awareness of POIs in virtual environments, and automatically re-orient the virtual camera toward a selected POI. We conducted a video elicitation study where 17 participants with limited mobility provided feedback on different Nearmi implementations. Although participants generally weighed the same design considerations when discussing their preferences, their choices reflected tradeoffs in accessibility, realism, spatial awareness, comfort, and familiarity with the interaction. Our findings highlight the need for accessible and customizable VR interaction techniques, as well as design considerations for building and evaluating these techniques.', 'doi': '10.1145/3441852.3471230', 'url': 'https://doi.org/10.1145/3441852.3471230', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Nearmi: A Framework for Designing Point of Interest Techniques for VR Users with Limited Mobility', 'author': 'L. Franz, Rachel and Junuzovic, Sasa and Mott, Martez', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471230'}"
Beyond Adaptive Sports: Challenges \&amp; Opportunities to Improve Accessibility and Analytics,10.1145/3441852.3471223,"A recent surge in sensing platforms for sports has been accompanied by drastic improvements in the quality of data analytics. This improved quality has catalyzed notable progress in training techniques, athletic performance tracking, real-time strategy management, and even better refereeing. However, despite a sustained growth in the number of para-athletes, there has been little exploration into the accessibility and data analytics needs for adaptive sports. We interviewed 18 participants in different roles (athletes, coaches, and high-performance managers) across six adaptive sports. We probed them on their current practices, existing challenges, and analytical needs. We uncovered common themes prevalent across all six sports and further examined findings in three groups: (1) blind sports; (2) wheelchair sports; and (3) adaptive sports with high equipment. Our study highlights the challenges faced by different adaptive sports and unearths opportunities for future research to improve accessibility and address specific needs for each sport.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, adaptive sports, analytics', 'numpages': '11', 'articleno': '6', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'A recent surge in sensing platforms for sports has been accompanied by drastic improvements in the quality of data analytics. This improved quality has catalyzed notable progress in training techniques, athletic performance tracking, real-time strategy management, and even better refereeing. However, despite a sustained growth in the number of para-athletes, there has been little exploration into the accessibility and data analytics needs for adaptive sports. We interviewed 18 participants in different roles (athletes, coaches, and high-performance managers) across six adaptive sports. We probed them on their current practices, existing challenges, and analytical needs. We uncovered common themes prevalent across all six sports and further examined findings in three groups: (1) blind sports; (2) wheelchair sports; and (3) adaptive sports with high equipment. Our study highlights the challenges faced by different adaptive sports and unearths opportunities for future research to improve accessibility and address specific needs for each sport.', 'doi': '10.1145/3441852.3471223', 'url': 'https://doi.org/10.1145/3441852.3471223', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Beyond Adaptive Sports: Challenges \\&amp; Opportunities to Improve Accessibility and Analytics', 'author': 'Khurana, Rushil and Wang, Ashley and Carrington, Patrick', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471223'}"
"Wearable Interactions for Users with Motor Impairments: Systematic Review, Inventory, and Research Implications",10.1145/3441852.3471212,"We conduct a systematic literature review on wearable interactions for users with motor impairments and report results from a meta-analysis of 57 scientific articles identified in the ACM DL and IEEE Xplore databases. Our findings show limited research conducted on accessible wearable interactions (e.g., just four papers addressing smartwatch input), a disproportionate interest for hand gestures compared to other input modalities for wearable devices, and low numbers of participants with motor impairments involved in user studies about wearable interactions (a median of 6.0 and average of 8.2 participants per study). We compile an inventory of 92 finger, hand, head, shoulder, eye gaze, and foot gesture commands for smartwatches, smartglasses, headsets, earsets, fitness trackers, data gloves, and armband wearable devices extracted from the scientific literature that we surveyed. Based on our findings, we propose four directions for future research on accessible wearable interactions for users with motor impairments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'HMDs, Motor impairments, accessible input, fitness trackers., headsets, review, rings, smartglasses, smartwatches, survey, wearables', 'numpages': '15', 'articleno': '7', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We conduct a systematic literature review on wearable interactions for users with motor impairments and report results from a meta-analysis of 57 scientific articles identified in the ACM DL and IEEE Xplore databases. Our findings show limited research conducted on accessible wearable interactions (e.g., just four papers addressing smartwatch input), a disproportionate interest for hand gestures compared to other input modalities for wearable devices, and low numbers of participants with motor impairments involved in user studies about wearable interactions (a median of 6.0 and average of 8.2 participants per study). We compile an inventory of 92 finger, hand, head, shoulder, eye gaze, and foot gesture commands for smartwatches, smartglasses, headsets, earsets, fitness trackers, data gloves, and armband wearable devices extracted from the scientific literature that we surveyed. Based on our findings, we propose four directions for future research on accessible wearable interactions for users with motor impairments.', 'doi': '10.1145/3441852.3471212', 'url': 'https://doi.org/10.1145/3441852.3471212', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Wearable Interactions for Users with Motor Impairments: Systematic Review, Inventory, and Research Implications', 'author': 'Siean, Alexandru-Ionut and Vatavu, Radu-Daniel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471212'}"
Accessing Passersby Proxemic Signals through a Head-Worn Camera: Opportunities and Limitations for the Blind,10.1145/3441852.3471232,"The spatial behavior of passersby can be critical to blind individuals to initiate interactions, preserve personal space, or practice social distancing during a pandemic. Among other use cases, wearable cameras employing computer vision can be used to extract proxemic signals of others and thus increase access to the spatial behavior of passersby for blind people. Analyzing data collected in a study with blind (N=10) and sighted (N=40) participants, we explore: (i) visual information on approaching passersby captured by a head-worn camera; (ii) pedestrian detection algorithms for extracting proxemic signals such as passerby presence, relative position, distance, and head pose; and (iii) opportunities and limitations of using wearable cameras for helping blind people access proxemics related to nearby people. Our observations and findings provide insights into dyadic behaviors for assistive pedestrian detection and lead to implications for the design of future head-worn cameras and interactions.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'blind people, machine learning, pedestrian detection, proxemics, spatial proximity, wearable camera', 'numpages': '15', 'articleno': '8', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The spatial behavior of passersby can be critical to blind individuals to initiate interactions, preserve personal space, or practice social distancing during a pandemic. Among other use cases, wearable cameras employing computer vision can be used to extract proxemic signals of others and thus increase access to the spatial behavior of passersby for blind people. Analyzing data collected in a study with blind (N=10) and sighted (N=40) participants, we explore: (i) visual information on approaching passersby captured by a head-worn camera; (ii) pedestrian detection algorithms for extracting proxemic signals such as passerby presence, relative position, distance, and head pose; and (iii) opportunities and limitations of using wearable cameras for helping blind people access proxemics related to nearby people. Our observations and findings provide insights into dyadic behaviors for assistive pedestrian detection and lead to implications for the design of future head-worn cameras and interactions.', 'doi': '10.1145/3441852.3471232', 'url': 'https://doi.org/10.1145/3441852.3471232', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Accessing Passersby Proxemic Signals through a Head-Worn Camera: Opportunities and Limitations for the Blind', 'author': 'Lee, Kyungjun and Sato, Daisuke and Asakawa, Saki and Asakawa, Chieko and Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471232'}"
Understanding Barriers and Design Opportunities to Improve Healthcare and QOL for Older Adults through Voice Assistants,10.1145/3441852.3471218,"Voice-based Intelligent Virtual Assistants&nbsp;(IVAs) promise to improve healthcare management and Quality of Life&nbsp;(QOL) by introducing the paradigm of hands-free and eye-free interactions. However, there has been little understanding regarding the challenges for designing such systems for older adults, especially when it comes to healthcare related tasks. To tackle this, we consider the processes of care delivery and QOL enhancements for older adults as a collaborative task between patients and providers. By interviewing 16 older adults living independently or semi–independently and 5 providers, we identified 12&nbsp;barriers that older adults might encounter during daily routine and while managing health. We ultimately highlighted key design challenges and opportunities that might be introduced when integrating voice-based IVAs into the life of older adults. Our work will benefit practitioners who study and attempt to create full-fledged IVA-powered smart devices to deliver better care and support an increased QOL for aging populations.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Gerontechnology, Health – Well-being, Older Adults, Semi-Structured Interview, User Experience Design', 'numpages': '16', 'articleno': '9', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Voice-based Intelligent Virtual Assistants&nbsp;(IVAs) promise to improve healthcare management and Quality of Life&nbsp;(QOL) by introducing the paradigm of hands-free and eye-free interactions. However, there has been little understanding regarding the challenges for designing such systems for older adults, especially when it comes to healthcare related tasks. To tackle this, we consider the processes of care delivery and QOL enhancements for older adults as a collaborative task between patients and providers. By interviewing 16 older adults living independently or semi–independently and 5 providers, we identified 12&nbsp;barriers that older adults might encounter during daily routine and while managing health. We ultimately highlighted key design challenges and opportunities that might be introduced when integrating voice-based IVAs into the life of older adults. Our work will benefit practitioners who study and attempt to create full-fledged IVA-powered smart devices to deliver better care and support an increased QOL for aging populations.', 'doi': '10.1145/3441852.3471218', 'url': 'https://doi.org/10.1145/3441852.3471218', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Understanding Barriers and Design Opportunities to Improve Healthcare and QOL for Older Adults through Voice Assistants', 'author': 'Chen, Chen and Johnson, Janet G and Charles, Kemeberly and Lee, Alice and Lifset, Ella T and Hogarth, Michael and Moore, Alison A and Farcas, Emilia and Weibel, Nadir', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471218'}"
How Online Tests Contribute to the Support System for People With Cognitive and Mental Disabilities,10.1145/3441852.3471229,"Roughly 1 in 3 people around the world are affected by cognitive or mental disabilities at some point in their lives, yet people often face a variety of barriers when seeking support and receiving diagnosis from healthcare professionals. While prior work found that people with such disabilities assess themselves using online tests and assessments, it remains unknown whether and how effectively these tests fill gaps in healthcare and general support systems. To find out, we interviewed 17 adults with cognitive or mental disabilities about their motivation for and experience using online tests. We learned that online tests act as an important resource that address the shortcomings in support systems for people with professionally diagnosed or suspected cognitive or mental disabilities. In particular, online tests can lower barriers to a professional diagnosis, provide valuable information about the nuances of a disability, and support people in forming a disability identity – an invaluable step towards a positive acceptance of oneself. Our results also uncovered challenges and risks that prevent people with known or suspected health conditions from fully taking advantage of online tests. Based on these findings, we discuss how online tests can be better leveraged to support people with cognitive or mental disabilities before and after professional diagnosis.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'cognitive disability, disability, health support, mental health, online tests, psychiatric disorder', 'numpages': '15', 'articleno': '10', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Roughly 1 in 3 people around the world are affected by cognitive or mental disabilities at some point in their lives, yet people often face a variety of barriers when seeking support and receiving diagnosis from healthcare professionals. While prior work found that people with such disabilities assess themselves using online tests and assessments, it remains unknown whether and how effectively these tests fill gaps in healthcare and general support systems. To find out, we interviewed 17 adults with cognitive or mental disabilities about their motivation for and experience using online tests. We learned that online tests act as an important resource that address the shortcomings in support systems for people with professionally diagnosed or suspected cognitive or mental disabilities. In particular, online tests can lower barriers to a professional diagnosis, provide valuable information about the nuances of a disability, and support people in forming a disability identity – an invaluable step towards a positive acceptance of oneself. Our results also uncovered challenges and risks that prevent people with known or suspected health conditions from fully taking advantage of online tests. Based on these findings, we discuss how online tests can be better leveraged to support people with cognitive or mental disabilities before and after professional diagnosis.', 'doi': '10.1145/3441852.3471229', 'url': 'https://doi.org/10.1145/3441852.3471229', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'How Online Tests Contribute to the Support System for People With Cognitive and Mental Disabilities', 'author': 'Li, Qisheng and Lee, Josephine and Zhang, Christina and Reinecke, Katharina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471229'}"
Designing an App to Help Individuals with Intellectual and Developmental Disabilities to Recognize Abuse,10.1145/3441852.3471217,"In the US, the abuse of individuals with intellectual and developmental disabilities (I/DD) is at epidemic proportions; however, the reporting of such abuse has been severely lacking. It has been found that individuals with I/DD are more aware of when and how to report abuse if they have received abuse prevention training. Consequently, in this paper we present the design of a mobile-computing app called Recognize to teach individuals with I/DD about abuse. Our research team is diverse, with both individuals with I/DD and neurotypical individuals. We leveraged this diversity by utilizing a co-design process with our team members who live with I/DD. Our team developed three initial prototypes of the app and performed a qualitative, within-group user study with six separate individuals with I/DD who are themselves experienced teachers to other individuals with I/DD. We found that, overall, the app would be viable for use by individuals with I/DD. We end the paper with a brief discussion of the implications of our findings toward building a full prototype of the app.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'abuse, co-design, education, empowerment, intellectual and developmental disabilities', 'numpages': '14', 'articleno': '11', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In the US, the abuse of individuals with intellectual and developmental disabilities (I/DD) is at epidemic proportions; however, the reporting of such abuse has been severely lacking. It has been found that individuals with I/DD are more aware of when and how to report abuse if they have received abuse prevention training. Consequently, in this paper we present the design of a mobile-computing app called Recognize to teach individuals with I/DD about abuse. Our research team is diverse, with both individuals with I/DD and neurotypical individuals. We leveraged this diversity by utilizing a co-design process with our team members who live with I/DD. Our team developed three initial prototypes of the app and performed a qualitative, within-group user study with six separate individuals with I/DD who are themselves experienced teachers to other individuals with I/DD. We found that, overall, the app would be viable for use by individuals with I/DD. We end the paper with a brief discussion of the implications of our findings toward building a full prototype of the app.', 'doi': '10.1145/3441852.3471217', 'url': 'https://doi.org/10.1145/3441852.3471217', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing an App to Help Individuals with Intellectual and Developmental Disabilities to Recognize Abuse', 'author': 'Howard, Thomas and Venkatasubramanian, Krishna and Skorinko, Jeanine L M and Bosma, Pauline and Mullaly, John and Kelly, Brian and Lloyd, Deborah and Wishart, Mary and Alves, Emiton and Jutras, Nicole and Freark, Mariah and Alterio, Nancy A.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471217'}"
Beyond Fun: Players’ Experiences of Accessible Rehabilitation Gaming for Spinal Cord Injury,10.1145/3441852.3471227,"Rehabilitation gaming—play of digital games that incorporate rehabilitation exercises—is a well-known and broadly applicable way to make physical rehabilitation more fun. It can motivate patients with spinal cord injury to engage in exercises that they find boring and can be as effective as traditional physiotherapy. However, patients’ needs are not only physical. Rehabilitation also needs to help patients overcome the psychological trauma of spinal cord injury. For patients coping with disability, hopelessness, depression, anxiety, or a loss of identity, rehabilitation gaming may provide benefits beyond making exercise more fun. We asked six participants with spinal cord injury to play three cycling-based rehabilitation games to determine how play might change their experiences of rehabilitation. They said that rehabilitation games may be able to help patients to actively participate in their rehabilitation, help them to rediscover who they are, and show them a better future living with spinal cord injury.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Digital games, Rehabilitation, Spinal cord injury', 'numpages': '13', 'articleno': '12', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Rehabilitation gaming—play of digital games that incorporate rehabilitation exercises—is a well-known and broadly applicable way to make physical rehabilitation more fun. It can motivate patients with spinal cord injury to engage in exercises that they find boring and can be as effective as traditional physiotherapy. However, patients’ needs are not only physical. Rehabilitation also needs to help patients overcome the psychological trauma of spinal cord injury. For patients coping with disability, hopelessness, depression, anxiety, or a loss of identity, rehabilitation gaming may provide benefits beyond making exercise more fun. We asked six participants with spinal cord injury to play three cycling-based rehabilitation games to determine how play might change their experiences of rehabilitation. They said that rehabilitation games may be able to help patients to actively participate in their rehabilitation, help them to rediscover who they are, and show them a better future living with spinal cord injury.', 'doi': '10.1145/3441852.3471227', 'url': 'https://doi.org/10.1145/3441852.3471227', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Beyond Fun: Players’ Experiences of Accessible Rehabilitation Gaming for Spinal Cord Injury', 'author': 'Cimolino, Gabriele and Askari, Sussan and Graham, T.C. Nicholas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471227'}"
VIDDE: Visualizations for Helping People with COPD Interpret Dyspnea During Exercise,10.1145/3441852.3471204,"People with chronic obstructive pulmonary disease (COPD) experience dyspnea and dyspnea-related distress and anxiety (DDA) upon physical exertion. When performing supervised exercise, measurement of physiological data, such as heart rate (HR) and blood oxygen saturation (O2sat), are commonly used for safety, but the impacts of such monitoring on their perceptions and behaviour have not previously been studied. This paper investigates the effect of presenting live physiological data to people with COPD during exercise with a focus on its impact on perceptions of dyspnea intensity (DI) and DDA. Informed by formative interviews with 15 people with COPD, we design VIDDE, an exercise companion tool visualizing live data from a pulse oximeter, and evaluate its effect on DI and DDA through case studies involving 3 participants with COPD exercising at their homes. We also conducted design probe interviews with 6 more participants with COPD to investigate their needs and design requirements for an exercise-companion application that featured physiological data monitoring. Our results suggest that presenting live physiological data during exercise is of value, and can contribute to reduced DDA, better understanding of breathlessness sensations, while providing sufficient reassurance to encourage physical activity.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'COPD, biofeedback, dyspnea, dyspnea-related anxiety, physiological data, visualization', 'numpages': '14', 'articleno': '13', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with chronic obstructive pulmonary disease (COPD) experience dyspnea and dyspnea-related distress and anxiety (DDA) upon physical exertion. When performing supervised exercise, measurement of physiological data, such as heart rate (HR) and blood oxygen saturation (O2sat), are commonly used for safety, but the impacts of such monitoring on their perceptions and behaviour have not previously been studied. This paper investigates the effect of presenting live physiological data to people with COPD during exercise with a focus on its impact on perceptions of dyspnea intensity (DI) and DDA. Informed by formative interviews with 15 people with COPD, we design VIDDE, an exercise companion tool visualizing live data from a pulse oximeter, and evaluate its effect on DI and DDA through case studies involving 3 participants with COPD exercising at their homes. We also conducted design probe interviews with 6 more participants with COPD to investigate their needs and design requirements for an exercise-companion application that featured physiological data monitoring. Our results suggest that presenting live physiological data during exercise is of value, and can contribute to reduced DDA, better understanding of breathlessness sensations, while providing sufficient reassurance to encourage physical activity.', 'doi': '10.1145/3441852.3471204', 'url': 'https://doi.org/10.1145/3441852.3471204', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'VIDDE: Visualizations for Helping People with COPD Interpret Dyspnea During Exercise', 'author': 'Chen, Claudia and Wu, Robert and Khan, Hashim and Truong, Khai and Chevalier, Fanny', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471204'}"
Understanding Screen-Reader Users’ Experiences with Online Data Visualizations,10.1145/3441852.3471202,"Online data visualizations are widely used to communicate information from simple statistics to complex phenomena, supporting people in gaining important insights from data. However, due to the defining visual nature of data visualizations, extracting information from visualizations can be difficult or impossible for screen-reader users. To assess screen-reader users’ challenges with online data visualizations, we conducted two empirical studies: (1) A qualitative study with nine screen-reader users, and (2) a quantitative study with 36 screen-reader and 36 non-screen-reader users. Our results show that due to the inaccessibility of online data visualizations, screen-reader users extract information 61.48\% less accurately and spend 210.96\% more time interacting with online data visualizations compared to non-screen-reader users. Additionally, our findings show that online data visualizations are commonly indiscoverable to screen readers. In visualizations that are discoverable and comprehensible, screen-reader users suggested tabular and textual representation of data as techniques to improve the accessibility of online visualizations. Taken together, our results provide empirical evidence of the inequalities screen-readers users face in their interaction with online data visualizations.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'challenges, data, screen readers, techniques, visualizations', 'numpages': '16', 'articleno': '14', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Online data visualizations are widely used to communicate information from simple statistics to complex phenomena, supporting people in gaining important insights from data. However, due to the defining visual nature of data visualizations, extracting information from visualizations can be difficult or impossible for screen-reader users. To assess screen-reader users’ challenges with online data visualizations, we conducted two empirical studies: (1) A qualitative study with nine screen-reader users, and (2) a quantitative study with 36 screen-reader and 36 non-screen-reader users. Our results show that due to the inaccessibility of online data visualizations, screen-reader users extract information 61.48\\% less accurately and spend 210.96\\% more time interacting with online data visualizations compared to non-screen-reader users. Additionally, our findings show that online data visualizations are commonly indiscoverable to screen readers. In visualizations that are discoverable and comprehensible, screen-reader users suggested tabular and textual representation of data as techniques to improve the accessibility of online visualizations. Taken together, our results provide empirical evidence of the inequalities screen-readers users face in their interaction with online data visualizations.', 'doi': '10.1145/3441852.3471202', 'url': 'https://doi.org/10.1145/3441852.3471202', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Understanding Screen-Reader Users’ Experiences with Online Data Visualizations', 'author': 'Sharif, Ather and Chintalapati, Sanjana Shivani and Wobbrock, Jacob O. and Reinecke, Katharina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471202'}"
Understanding Screen Readers’ Plugins,10.1145/3441852.3471205,"Screen reader plugins are small pieces of code that blind users can download and install to enhance the capabilities of their screen readers. In this paper, we aim to understand the user experience of screen readers’ plugins, as well as their developers, distribution model, and maintenance. To this end, we conducted a study with 14 blind screen reader users. Our study revealed that screen reader users rely on plugins for various reasons, e.g., to improve the usability of both screen readers and application software, to make partially accessible applications accessible, and to enable custom shortcuts and commands. Furthermore, installing plugins is easy; uninstalling them is unlikely; and finding them online is ad hoc, challenging, and poses security threats. In addition, developing screen reader plugins is technically demanding; only a handful of people develop plugins, and they are well-recognized in the community. Finally, there is no central repository for plugins for most screen readers, and most plugins do not receive updates from their developers and become obsolete. The lack of financial incentives plays in the slow growth of the plugin ecosystem. Based on our findings, we recommend creating a central repository for all plugins, engaging third-party developers, and raising general awareness about the benefits and dangers of plugins. We believe our findings will inspire researchers to embrace the plugin-based distribution model as an effective way to combat application-level accessibility issues.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, add-ons, blind, extensions, plugins, screen readers, scripts, user study.', 'numpages': '10', 'articleno': '15', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Screen reader plugins are small pieces of code that blind users can download and install to enhance the capabilities of their screen readers. In this paper, we aim to understand the user experience of screen readers’ plugins, as well as their developers, distribution model, and maintenance. To this end, we conducted a study with 14 blind screen reader users. Our study revealed that screen reader users rely on plugins for various reasons, e.g., to improve the usability of both screen readers and application software, to make partially accessible applications accessible, and to enable custom shortcuts and commands. Furthermore, installing plugins is easy; uninstalling them is unlikely; and finding them online is ad hoc, challenging, and poses security threats. In addition, developing screen reader plugins is technically demanding; only a handful of people develop plugins, and they are well-recognized in the community. Finally, there is no central repository for plugins for most screen readers, and most plugins do not receive updates from their developers and become obsolete. The lack of financial incentives plays in the slow growth of the plugin ecosystem. Based on our findings, we recommend creating a central repository for all plugins, engaging third-party developers, and raising general awareness about the benefits and dangers of plugins. We believe our findings will inspire researchers to embrace the plugin-based distribution model as an effective way to combat application-level accessibility issues.', 'doi': '10.1145/3441852.3471205', 'url': 'https://doi.org/10.1145/3441852.3471205', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Understanding Screen Readers’ Plugins', 'author': 'Momotaz, Farhani and Islam, Md Touhidul and Ehtesham-Ul-Haque, Md and Billah, Syed Masum', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471205'}"
Going Beyond One-Size-Fits-All Image Descriptions to Satisfy the Information Wants of People Who are Blind or Have Low Vision,10.1145/3441852.3471233,"Image descriptions are how people who are blind or have low vision (BLV) access information depicted within images. To our knowledge, no prior work has examined how a description for an image should be designed for different scenarios in which users encounter images. Scenarios consist of the information goal the person has when seeking information from or about an image, paired with the source where the image is found. To address this gap, we interviewed 28 people who are BLV to learn how the scenario impacts what image content (information) should go into an image description. We offer our findings as a foundation for considering how to design next-generation image description technologies that can both (A) support a departure from one-size-fits-all image descriptions to context-aware descriptions, and (B) reveal what content to include in minimum viable descriptions for a large range of scenarios.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'alt text, blind, context aware, image caption, image description, low vision, minimum viable description, scenarios, visual impairment', 'numpages': '15', 'articleno': '16', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Image descriptions are how people who are blind or have low vision (BLV) access information depicted within images. To our knowledge, no prior work has examined how a description for an image should be designed for different scenarios in which users encounter images. Scenarios consist of the information goal the person has when seeking information from or about an image, paired with the source where the image is found. To address this gap, we interviewed 28 people who are BLV to learn how the scenario impacts what image content (information) should go into an image description. We offer our findings as a foundation for considering how to design next-generation image description technologies that can both (A) support a departure from one-size-fits-all image descriptions to context-aware descriptions, and (B) reveal what content to include in minimum viable descriptions for a large range of scenarios.', 'doi': '10.1145/3441852.3471233', 'url': 'https://doi.org/10.1145/3441852.3471233', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Going Beyond One-Size-Fits-All Image Descriptions to Satisfy the Information Wants of People Who are Blind or Have Low Vision', 'author': 'Stangl, Abigale and Verma, Nitin and Fleischmann, Kenneth R. and Morris, Meredith Ringel and Gurari, Danna', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471233'}"
The Efficacy of Collaborative Authoring of Video Scene Descriptions,10.1145/3441852.3471201,"The majority of online video contents remain inaccessible to people with visual impairments due to the lack of audio descriptions to depict the video scenes. Content creators have traditionally relied on professionals to author audio descriptions, but their service is costly and not readily-available. We investigate the feasibility of creating more cost-effective audio descriptions that are also of high quality by involving novices. Specifically, we designed, developed, and evaluated ViScene, a web-based collaborative audio description authoring tool that enables a sighted novice author and a reviewer either sighted or blind to interact and contribute to scene descriptions (SDs)—text that can be transformed into audio through text-to-speech. Through a mixed-design study with N = 60 participants, we assessed the quality of SDs created by sighted novices with feedback from both sighted and blind reviewers. Our results showed that with ViScene novices could produce content that is Descriptive, Objective, Referable, and Clear at a cost of i.e., US$2.81pvm to US$5.48pvm, which is 54\% to 96\% lower than the professional service. However, the descriptions lacked in other quality dimensions (e.g., learning, a measure of how well an SD conveys the video’s intended message). While professional audio describers remain the gold standard, for content creators who cannot afford it, ViScene offers a cost-effective alternative, ultimately leading to a more accessible medium.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Scene description, video accessibility, visual impairment', 'numpages': '15', 'articleno': '17', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The majority of online video contents remain inaccessible to people with visual impairments due to the lack of audio descriptions to depict the video scenes. Content creators have traditionally relied on professionals to author audio descriptions, but their service is costly and not readily-available. We investigate the feasibility of creating more cost-effective audio descriptions that are also of high quality by involving novices. Specifically, we designed, developed, and evaluated ViScene, a web-based collaborative audio description authoring tool that enables a sighted novice author and a reviewer either sighted or blind to interact and contribute to scene descriptions (SDs)—text that can be transformed into audio through text-to-speech. Through a mixed-design study with N = 60 participants, we assessed the quality of SDs created by sighted novices with feedback from both sighted and blind reviewers. Our results showed that with ViScene novices could produce content that is Descriptive, Objective, Referable, and Clear at a cost of i.e., US$2.81pvm to US$5.48pvm, which is 54\\% to 96\\% lower than the professional service. However, the descriptions lacked in other quality dimensions (e.g., learning, a measure of how well an SD conveys the video’s intended message). While professional audio describers remain the gold standard, for content creators who cannot afford it, ViScene offers a cost-effective alternative, ultimately leading to a more accessible medium.', 'doi': '10.1145/3441852.3471201', 'url': 'https://doi.org/10.1145/3441852.3471201', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'The Efficacy of Collaborative Authoring of Video Scene Descriptions', 'author': 'Natalie, Rosiana and Loh, Jolene and Tan, Huei Suen and Tseng, Joshua and Chan, Ian Luke Yi-Ren and Jarjue, Ebrima H and Kacorri, Hernisa and Hara, Kotaro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471201'}"
What difference does tech make? Conceptualizations of Disability and Assistive Technology among Kenyan Youth: Conceptualizations of Disability and AT,10.1145/3441852.3471226,"Most research which investigates stigma towards with people with disabilities and the use of Assistive Technology (AT) are based in the Global North and focus on the experiences of people with disabilities and the consequences that stigma has on choices surrounding AT. However, stigma is a societal construct rooted in the attitude and beliefs that people without disabilities hold on disability and AT. Furthermore, the portrayal of people with disabilities and AT is dependent on the social context. In this paper, we examine how young Kenyans without disabilities view people with disabilities and AT users. Findings show that while the portrayal of disability is often shaped by negative emotion, participants felt that many of the barriers affecting people with disabilities were created by society. Perceptions of AT differed –devices were not only seen as a mark of disability but also as a sign of access to resources. Therefore, what we see is an emergent picture where social barriers can be reinforced by poverty, and where poverty reinforces social barriers faced by people with disabilities. We conclude that access to appropriate technology alongside societal interventions tackling incorrect beliefs about disability can help to overcome the stigma faced by people with disabilities.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Assistive technology, Disability, Global South, Stigma', 'numpages': '13', 'articleno': '18', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most research which investigates stigma towards with people with disabilities and the use of Assistive Technology (AT) are based in the Global North and focus on the experiences of people with disabilities and the consequences that stigma has on choices surrounding AT. However, stigma is a societal construct rooted in the attitude and beliefs that people without disabilities hold on disability and AT. Furthermore, the portrayal of people with disabilities and AT is dependent on the social context. In this paper, we examine how young Kenyans without disabilities view people with disabilities and AT users. Findings show that while the portrayal of disability is often shaped by negative emotion, participants felt that many of the barriers affecting people with disabilities were created by society. Perceptions of AT differed –devices were not only seen as a mark of disability but also as a sign of access to resources. Therefore, what we see is an emergent picture where social barriers can be reinforced by poverty, and where poverty reinforces social barriers faced by people with disabilities. We conclude that access to appropriate technology alongside societal interventions tackling incorrect beliefs about disability can help to overcome the stigma faced by people with disabilities.', 'doi': '10.1145/3441852.3471226', 'url': 'https://doi.org/10.1145/3441852.3471226', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'What difference does tech make? Conceptualizations of Disability and Assistive Technology among Kenyan Youth: Conceptualizations of Disability and AT', 'author': 'Barbareschi, Giulia and Shitawa Kopi, Norah and Oldfrey, Ben and Holloway, Catherine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471226'}"
"""That's in the eye of the beholder"": Layers of Interpretation in Image Descriptions for Fictional Representations of People with Disabilities",10.1145/3441852.3471222,"Image accessibility is an established research area in Accessible Computing and a key area of digital accessibility for blind and low vision (BLV) people worldwide. Recent work has delved deeper into the question of how image descriptions should properly reflect the complexities of marginalized identity. However, when real subjects are not available to consult on their preferred identity terminology, as is the case with fictional representations of disability, the issue arises again of how to create accurate and sensitive image descriptions. We worked with 25 participants to assess and iteratively co-design image descriptions for nine fictional representations of people with disabilities. Through nine focus groups and nineteen interviews, we discovered five key themes which we present here along with an analysis of the layers of interpretation at work in the production and consumption of image descriptions for fictional representations.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Alt text, design system, fictional users, image description, representations of disability', 'numpages': '14', 'articleno': '19', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Image accessibility is an established research area in Accessible Computing and a key area of digital accessibility for blind and low vision (BLV) people worldwide. Recent work has delved deeper into the question of how image descriptions should properly reflect the complexities of marginalized identity. However, when real subjects are not available to consult on their preferred identity terminology, as is the case with fictional representations of disability, the issue arises again of how to create accurate and sensitive image descriptions. We worked with 25 participants to assess and iteratively co-design image descriptions for nine fictional representations of people with disabilities. Through nine focus groups and nineteen interviews, we discovered five key themes which we present here along with an analysis of the layers of interpretation at work in the production and consumption of image descriptions for fictional representations.', 'doi': '10.1145/3441852.3471222', 'url': 'https://doi.org/10.1145/3441852.3471222', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': '""That\'s in the eye of the beholder"": Layers of Interpretation in Image Descriptions for Fictional Representations of People with Disabilities', 'author': 'James Edwards, Emory and Lewis Polster, Kyle and Tuason, Isabel and Blank, Emily and Gilbert, Michael and Branham, Stacy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471222'}"
Accept or Address? Researchers’ Perspectives on Response Bias in Accessibility Research,10.1145/3441852.3471216,"Response bias has been framed as the tendency of a participant's response to be skewed by a variety of factors, including study design and participant-researcher dynamics. Response bias is a concern for all researchers who conduct studies with people — especially those working with participants with disabilities. This is because these participants’ diverse needs require methodological adjustments and differences in disability identity between the researcher and participant influence power dynamics. Despite its relevance, there is little literature that connects response bias to accessibility. We conducted semi-structured interviews with 27 accessibility researchers on how response bias manifested in their research and how they mitigated it. We present unique instances of response bias and how it is handled in accessibility research; insights into how response bias interacts with other biases like researcher or sampling bias; and philosophies and tensions around response bias such as whether to accept or address it. We conclude with guidelines on thinking about response bias in accessibility research.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Response bias, accessibility dongle, charity model of disability, participant-researcher power dynamics', 'numpages': '13', 'articleno': '20', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Response bias has been framed as the tendency of a participant's response to be skewed by a variety of factors, including study design and participant-researcher dynamics. Response bias is a concern for all researchers who conduct studies with people — especially those working with participants with disabilities. This is because these participants’ diverse needs require methodological adjustments and differences in disability identity between the researcher and participant influence power dynamics. Despite its relevance, there is little literature that connects response bias to accessibility. We conducted semi-structured interviews with 27 accessibility researchers on how response bias manifested in their research and how they mitigated it. We present unique instances of response bias and how it is handled in accessibility research; insights into how response bias interacts with other biases like researcher or sampling bias; and philosophies and tensions around response bias such as whether to accept or address it. We conclude with guidelines on thinking about response bias in accessibility research."", 'doi': '10.1145/3441852.3471216', 'url': 'https://doi.org/10.1145/3441852.3471216', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Accept or Address? Researchers’ Perspectives on Response Bias in Accessibility Research', 'author': 'Ming, Joy and Heung, Sharon and Azenkot, Shiri and Vashistha, Aditya', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471216'}"
Mixed Abilities and Varied Experiences: a group autoethnography of a virtual summer internship,10.1145/3441852.3471199,"The COVID-19 pandemic forced many people to convert their daily work lives to a “virtual” format where everyone connected remotely from their home. In this new, virtual environment, accessibility barriers changed, in some respects for the better (e.g., more flexibility) and in other aspects, for the worse (e.g., problems including American Sign Language interpreters over video calls). Microsoft&nbsp;Research held its first cohort of all virtual interns in 2020. We the authors, full time and intern members and affiliates of the Ability Team, a research team focused on accessibility, reflect on our virtual work experiences as a team consisting of members with a variety of abilities, positions, and seniority during the summer intern season. Through our autoethnographic method, we provide a nuanced view into the experiences of a mixed-ability, virtual team, and how the virtual setting affected the team’s accessibility. We then reflect on these experiences, noting the successful strategies we used to promote access and the areas in which we could have further improved access. Finally, we present guidelines for future virtual mixed-ability teams looking to improve access.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, autoethnography, disability, virtual', 'numpages': '13', 'articleno': '21', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The COVID-19 pandemic forced many people to convert their daily work lives to a “virtual” format where everyone connected remotely from their home. In this new, virtual environment, accessibility barriers changed, in some respects for the better (e.g., more flexibility) and in other aspects, for the worse (e.g., problems including American Sign Language interpreters over video calls). Microsoft&nbsp;Research held its first cohort of all virtual interns in 2020. We the authors, full time and intern members and affiliates of the Ability Team, a research team focused on accessibility, reflect on our virtual work experiences as a team consisting of members with a variety of abilities, positions, and seniority during the summer intern season. Through our autoethnographic method, we provide a nuanced view into the experiences of a mixed-ability, virtual team, and how the virtual setting affected the team’s accessibility. We then reflect on these experiences, noting the successful strategies we used to promote access and the areas in which we could have further improved access. Finally, we present guidelines for future virtual mixed-ability teams looking to improve access.', 'doi': '10.1145/3441852.3471199', 'url': 'https://doi.org/10.1145/3441852.3471199', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Mixed Abilities and Varied Experiences: a group autoethnography of a virtual summer internship', 'author': 'Mack, Kelly and Das, Maitraye and Jain, Dhruv and Bragg, Danielle and Tang, John and Begel, Andrew and Beneteau, Erin and Davis, Josh Urban and Glasser, Abraham and Park, Joon Sung and Potluri, Venkatesh', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471199'}"
American Sign Language Video Anonymization to Support Online Participation of Deaf and Hard of Hearing Users,10.1145/3441852.3471200,"Without a commonly accepted writing system for American Sign Language (ASL), Deaf or Hard of Hearing (DHH) ASL signers who wish to express opinions or ask questions online must post a video of their signing, if they prefer not to use written English, a language in which they may feel less proficient. Since the face conveys essential linguistic meaning, the face cannot simply be removed from the video in order to preserve anonymity. Thus, DHH ASL signers cannot easily discuss sensitive, personal, or controversial topics in their primary language, limiting engagement in online debate or inquiries about health or legal issues. We explored several recent attempts to address this problem through development of “face swap” technologies to automatically disguise the face in videos while preserving essential facial expressions and natural human appearance. We presented several prototypes to DHH ASL signers (N=16) and examined their interests in and requirements for such technology. After viewing transformed videos of other signers and of themselves, participants evaluated the understandability, naturalness of appearance, and degree of anonymity protection of these technologies. Our study revealed users’ perception of key trade-offs among these three dimensions, factors that contribute to each, and their views on transformation options enabled by this technology, for use in various contexts. Our findings guide future designers of this technology and inform selection of applications and design features.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Anonymization, Deaf and Hard of Hearing', 'numpages': '13', 'articleno': '22', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Without a commonly accepted writing system for American Sign Language (ASL), Deaf or Hard of Hearing (DHH) ASL signers who wish to express opinions or ask questions online must post a video of their signing, if they prefer not to use written English, a language in which they may feel less proficient. Since the face conveys essential linguistic meaning, the face cannot simply be removed from the video in order to preserve anonymity. Thus, DHH ASL signers cannot easily discuss sensitive, personal, or controversial topics in their primary language, limiting engagement in online debate or inquiries about health or legal issues. We explored several recent attempts to address this problem through development of “face swap” technologies to automatically disguise the face in videos while preserving essential facial expressions and natural human appearance. We presented several prototypes to DHH ASL signers (N=16) and examined their interests in and requirements for such technology. After viewing transformed videos of other signers and of themselves, participants evaluated the understandability, naturalness of appearance, and degree of anonymity protection of these technologies. Our study revealed users’ perception of key trade-offs among these three dimensions, factors that contribute to each, and their views on transformation options enabled by this technology, for use in various contexts. Our findings guide future designers of this technology and inform selection of applications and design features.', 'doi': '10.1145/3441852.3471200', 'url': 'https://doi.org/10.1145/3441852.3471200', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'American Sign Language Video Anonymization to Support Online Participation of Deaf and Hard of Hearing Users', 'author': 'Lee, Sooyeon and Glasser, Abraham and Dingman, Becca and Xia, Zhaoyang and Metaxas, Dimitris and Neidle, Carol and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471200'}"
Designing Tools for High-Quality Alt Text Authoring,10.1145/3441852.3471207,"Alternative (alt) text provides access to descriptions of digital images for people who use screen readers. While prior work studied screen reader users’ (SRUs’) preferences about alt text and automatic alt text (i.e., alt text generated by artificial intelligence), little work examined the alt text author’s experience composing or editing these descriptions. We built two types of prototype interfaces for two tasks: authoring alt text and providing feedback on automatic alt text. Through combined interview-usability testing sessions with alt text authors and interviews with SRUs, we tested the effectiveness of our prototypes in the context of Microsoft PowerPoint. Our results suggest that authoring interfaces that support authors in choosing what to include in their descriptions result in higher quality alt text. The feedback interfaces highlighted considerable differences in the perceptions of authors and SRUs regarding “high-quality” alt text. Finally, authors crafted significantly lower quality alt text when starting from the automatic alt text compared to starting from a blank box. We discuss the implications of these results on applications that support alt text.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'alt text, alt text authoring, feedback on automatic alt text, high-quality alt text, screen reader users', 'numpages': '14', 'articleno': '23', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Alternative (alt) text provides access to descriptions of digital images for people who use screen readers. While prior work studied screen reader users’ (SRUs’) preferences about alt text and automatic alt text (i.e., alt text generated by artificial intelligence), little work examined the alt text author’s experience composing or editing these descriptions. We built two types of prototype interfaces for two tasks: authoring alt text and providing feedback on automatic alt text. Through combined interview-usability testing sessions with alt text authors and interviews with SRUs, we tested the effectiveness of our prototypes in the context of Microsoft PowerPoint. Our results suggest that authoring interfaces that support authors in choosing what to include in their descriptions result in higher quality alt text. The feedback interfaces highlighted considerable differences in the perceptions of authors and SRUs regarding “high-quality” alt text. Finally, authors crafted significantly lower quality alt text when starting from the automatic alt text compared to starting from a blank box. We discuss the implications of these results on applications that support alt text.', 'doi': '10.1145/3441852.3471207', 'url': 'https://doi.org/10.1145/3441852.3471207', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing Tools for High-Quality Alt Text Authoring', 'author': 'Mack, Kelly and Cutrell, Edward and Lee, Bongshin and Morris, Meredith Ringel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471207'}"
Slidecho: Flexible Non-Visual Exploration of Presentation Videos,10.1145/3441852.3471234,"We present Slidecho, a system that enables non-visual access of the slide content in a presentation video on-demand. Slidecho automatically extracts slides and their text and image elements from the presentation video and aligns these elements to the presenter’s speech. When listening to the video, Slidecho provides learners with audio notifications about slide changes and slide elements that are not described by the presenter. The learner can pause the video and browse the entire slide, or only the undescribed slide elements, to gain information. A technical evaluation with presentation videos in-the-wild shows that compared to the presenter’s speech alone, Slidecho provides access to an additional 20\% of total text elements and 30\% of total image elements that were previously not described. Blind and visually impaired participants in our user study reported that it was easier to locate undescribed slide elements with Slidecho’s synchronized interface than when browsing the video and extracted slides separately, and using Slidecho they read fewer slides that were fully redundant with the speech.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Audio description, Multimedia consumption, Presentation, Slides, Video', 'numpages': '12', 'articleno': '24', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present Slidecho, a system that enables non-visual access of the slide content in a presentation video on-demand. Slidecho automatically extracts slides and their text and image elements from the presentation video and aligns these elements to the presenter’s speech. When listening to the video, Slidecho provides learners with audio notifications about slide changes and slide elements that are not described by the presenter. The learner can pause the video and browse the entire slide, or only the undescribed slide elements, to gain information. A technical evaluation with presentation videos in-the-wild shows that compared to the presenter’s speech alone, Slidecho provides access to an additional 20\\% of total text elements and 30\\% of total image elements that were previously not described. Blind and visually impaired participants in our user study reported that it was easier to locate undescribed slide elements with Slidecho’s synchronized interface than when browsing the video and extracted slides separately, and using Slidecho they read fewer slides that were fully redundant with the speech.', 'doi': '10.1145/3441852.3471234', 'url': 'https://doi.org/10.1145/3441852.3471234', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Slidecho: Flexible Non-Visual Exploration of Presentation Videos', 'author': 'Peng, Yi-Hao and Bigham, Jeffrey P and Pavel, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471234'}"
VStroll: An Audio-based Virtual Exploration to Encourage Walking among People with Vision Impairments,10.1145/3441852.3471206,"Current infrastructure design, discouragement by parents, and lack of internal motivation act as barriers for people with visual impairments (PVIs) to perform physical activities at par with sighted individuals. This has triggered accessible exercise technologies to be an emerging area of research. However, most current solutions have either safety concerns and/or are expensive, hence limiting their mass adoption. In our work, we propose VStroll, a smartphone app to promote walking among PVIs, by enabling them to virtually explore real-world locations, while physically walking in the safety and comfort of their homes. Walking is a cheap, accessible, and a common physical activity for people with blindness. VStroll has several added features, such as places-of-interest (POI) announcement using spatial audio and voice input for route selection at every intersection, which helps the user to gain spatial awareness while walking. To understand the usability of VStroll, 16 participants used our app for five days, followed by a semi-structured interview. Overall, our participants took 253 trips, walked for 50.8 hours covering 121.6 kms. We uncovered novel insights, such as discovering new POIs and fitness-related updates acted as key motivators, route selection boosted their confidence in navigation, and spatial audio resulted in an immersive experience. We conclude the paper with key lessons learned to promote accessible exercise technologies.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, blind, exercise, maps, navigation, point of interest, smartphone, spatial audio, walk', 'numpages': '13', 'articleno': '25', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Current infrastructure design, discouragement by parents, and lack of internal motivation act as barriers for people with visual impairments (PVIs) to perform physical activities at par with sighted individuals. This has triggered accessible exercise technologies to be an emerging area of research. However, most current solutions have either safety concerns and/or are expensive, hence limiting their mass adoption. In our work, we propose VStroll, a smartphone app to promote walking among PVIs, by enabling them to virtually explore real-world locations, while physically walking in the safety and comfort of their homes. Walking is a cheap, accessible, and a common physical activity for people with blindness. VStroll has several added features, such as places-of-interest (POI) announcement using spatial audio and voice input for route selection at every intersection, which helps the user to gain spatial awareness while walking. To understand the usability of VStroll, 16 participants used our app for five days, followed by a semi-structured interview. Overall, our participants took 253 trips, walked for 50.8 hours covering 121.6 kms. We uncovered novel insights, such as discovering new POIs and fitness-related updates acted as key motivators, route selection boosted their confidence in navigation, and spatial audio resulted in an immersive experience. We conclude the paper with key lessons learned to promote accessible exercise technologies.', 'doi': '10.1145/3441852.3471206', 'url': 'https://doi.org/10.1145/3441852.3471206', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'VStroll: An Audio-based Virtual Exploration to Encourage Walking among People with Vision Impairments', 'author': 'India, Gesu and Jain, Mohit and Karya, Pallav and Diwakar, Nirmalendu and Swaminathan, Manohar', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471206'}"
Fluent: An AI Augmented Writing Tool for People who Stutter,10.1145/3441852.3471211,"Stuttering is a speech disorder which impacts the personal and professional lives of millions of people worldwide. To save themselves from stigma and discrimination, people who stutter (PWS) may adopt different strategies to conceal their stuttering. One of the common strategies is word substitution where an individual avoids saying a word they might stutter on and use an alternative instead. This process itself can cause stress and add more burden. In this work, we present Fluent, an AI augmented writing tool which assists PWS in writing scripts which they can speak more fluently. Fluent embodies a novel active learning based method of identifying words an individual might struggle pronouncing. Such words are highlighted in the interface. On hovering over any such word, Fluent presents a set of alternative words which have similar meaning but are easier to speak. The user is free to accept or ignore these suggestions. Based on such user interaction (feedback), Fluent continuously evolves its classifier to better suit the personalized needs of each user. We evaluated our tool by measuring its ability to identify difficult words for 10 simulated users. We found that our tool can identify difficult words with a mean accuracy of over 80\% in under 20 interactions and it keeps improving with more feedback. Our tool can be beneficial for certain important life situations like giving a talk, presentation, etc. The source code for this tool has been made publicly accessible at github.com/bhavyaghai/Fluent.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessible computing, Active learning, Stammering, Stuttering', 'numpages': '8', 'articleno': '26', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Stuttering is a speech disorder which impacts the personal and professional lives of millions of people worldwide. To save themselves from stigma and discrimination, people who stutter (PWS) may adopt different strategies to conceal their stuttering. One of the common strategies is word substitution where an individual avoids saying a word they might stutter on and use an alternative instead. This process itself can cause stress and add more burden. In this work, we present Fluent, an AI augmented writing tool which assists PWS in writing scripts which they can speak more fluently. Fluent embodies a novel active learning based method of identifying words an individual might struggle pronouncing. Such words are highlighted in the interface. On hovering over any such word, Fluent presents a set of alternative words which have similar meaning but are easier to speak. The user is free to accept or ignore these suggestions. Based on such user interaction (feedback), Fluent continuously evolves its classifier to better suit the personalized needs of each user. We evaluated our tool by measuring its ability to identify difficult words for 10 simulated users. We found that our tool can identify difficult words with a mean accuracy of over 80\\% in under 20 interactions and it keeps improving with more feedback. Our tool can be beneficial for certain important life situations like giving a talk, presentation, etc. The source code for this tool has been made publicly accessible at github.com/bhavyaghai/Fluent.', 'doi': '10.1145/3441852.3471211', 'url': 'https://doi.org/10.1145/3441852.3471211', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Fluent: An AI Augmented Writing Tool for People who Stutter', 'author': 'Ghai, Bhavya and Mueller, Klaus', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471211'}"
Disability-first Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors,10.1145/3441852.3471225,"Artificial Intelligence (AI) for accessibility is a rapidly growing area, requiring datasets that are inclusive of the disabled users that assistive technology aims to serve. We offer insights from a multi-disciplinary project that constructed a dataset for teachable object recognition with people who are blind or low vision. Teachable object recognition enables users to teach a model objects that are of interest to them, e.g., their white cane or own sunglasses, by providing example images or videos of objects. In this paper, we make the following contributions: 1) a disability-first procedure to support blind and low vision data collectors to produce good quality data, using video rather than images; 2) a validation and evolution of this procedure through a series of data collection phases and 3) a set of questions to orient researchers involved in creating datasets toward reflecting on the needs of their participant community.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'AI, accessibility, blind and low vision users, datasets, teachable object recognition', 'numpages': '12', 'articleno': '27', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Artificial Intelligence (AI) for accessibility is a rapidly growing area, requiring datasets that are inclusive of the disabled users that assistive technology aims to serve. We offer insights from a multi-disciplinary project that constructed a dataset for teachable object recognition with people who are blind or low vision. Teachable object recognition enables users to teach a model objects that are of interest to them, e.g., their white cane or own sunglasses, by providing example images or videos of objects. In this paper, we make the following contributions: 1) a disability-first procedure to support blind and low vision data collectors to produce good quality data, using video rather than images; 2) a validation and evolution of this procedure through a series of data collection phases and 3) a set of questions to orient researchers involved in creating datasets toward reflecting on the needs of their participant community.', 'doi': '10.1145/3441852.3471225', 'url': 'https://doi.org/10.1145/3441852.3471225', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Disability-first Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors', 'author': 'Theodorou, Lida and Massiceti, Daniela and Zintgraf, Luisa and Stumpf, Simone and Morrison, Cecily and Cutrell, Edward and Harris, Matthew Tobias and Hofmann, Katja', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471225'}"
Sharing Practices for Datasets Related to Accessibility and Aging,10.1145/3441852.3471208,"Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive AI-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our analysis highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, legal, and institutional privacy frameworks that are more attuned to concerns from these communities.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'dataset, disability, machine learning., repository, sharing practices', 'numpages': '16', 'articleno': '28', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive AI-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our analysis highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, legal, and institutional privacy frameworks that are more attuned to concerns from these communities.', 'doi': '10.1145/3441852.3471208', 'url': 'https://doi.org/10.1145/3441852.3471208', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Sharing Practices for Datasets Related to Accessibility and Aging', 'author': 'Kamikubo, Rie and Dwivedi, Utkarsh and Kacorri, Hernisa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471208'}"
WLA4ND: a Wearable Dataset of Learning Activities for Young Adults with Neurodiversity to Provide Support in Education,10.1145/3441852.3471220,"Data-driven assistive wearable technologies are promising to support young adults with neurodiversity in inclusive education. Existing datasets focus on wearable sensor data of various activities from neurotypical people. However, no dataset exists including learning-related activity data from individuals with neurodiversity. The contributions of this paper include (1) WLA4ND, a dataset of learning activities performed by eight young adults with neurodiversity collected from smartwatch sensors. The activities are common learning tasks, including reading, writing, typing, answering follow-up questions, and off-task. (2) Evaluation of classification on WLA4ND with five activity recognition models, including conventional and deep learning methods. The Convolutional Recurrent Neural Network (CRNN) model achieved a balanced accuracy of 92.2\% for user-dependent evaluations, while Federated Multi-Task Hierarchical Attention Model (FATHOM) achieved 91.8\% for user-independent evaluations. This evaluation demonstrates that existing activity recognition technologies can be applied to neurodiverse populations. Also, WLA4ND can be used by researchers as a complement for activity recognition, automatic labeling, and next-generation assistive wearable applications.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Classification, Datasets, Inclusive Education, Neurodiversity, Smartwatches, Ubiquitous Computing, Wearable Sensors', 'numpages': '15', 'articleno': '29', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Data-driven assistive wearable technologies are promising to support young adults with neurodiversity in inclusive education. Existing datasets focus on wearable sensor data of various activities from neurotypical people. However, no dataset exists including learning-related activity data from individuals with neurodiversity. The contributions of this paper include (1) WLA4ND, a dataset of learning activities performed by eight young adults with neurodiversity collected from smartwatch sensors. The activities are common learning tasks, including reading, writing, typing, answering follow-up questions, and off-task. (2) Evaluation of classification on WLA4ND with five activity recognition models, including conventional and deep learning methods. The Convolutional Recurrent Neural Network (CRNN) model achieved a balanced accuracy of 92.2\\% for user-dependent evaluations, while Federated Multi-Task Hierarchical Attention Model (FATHOM) achieved 91.8\\% for user-independent evaluations. This evaluation demonstrates that existing activity recognition technologies can be applied to neurodiverse populations. Also, WLA4ND can be used by researchers as a complement for activity recognition, automatic labeling, and next-generation assistive wearable applications.', 'doi': '10.1145/3441852.3471220', 'url': 'https://doi.org/10.1145/3441852.3471220', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'WLA4ND: a Wearable Dataset of Learning Activities for Young Adults with Neurodiversity to Provide Support in Education', 'author': 'Zheng, Hui and Mahapasuthanon, Pattiya and Chen, Yujing and Rangwala, Huzefa and Evmenova, Anya S and Genaro Motti, Vivian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471220'}"
Non-Visual Cooking: Exploring Practices and Challenges of Meal Preparation by People with Visual Impairments,10.1145/3441852.3471215,"The reliance on vision for tasks related to cooking and eating healthy can present barriers to cooking for oneself and achieving proper nutrition. There has been little research exploring cooking practices and challenges faced by people with visual impairments. We present a content analysis of 122 YouTube videos to highlight the cooking practices of visually impaired people, and we describe detailed practices for 12 different cooking activities (e.g., cutting and chopping, measuring, testing food for doneness). Based on the cooking practices, we also conducted semi-structured interviews with 12 visually impaired people who have cooking experience and show existing challenges, concerns, and risks in cooking (e.g., tracking the status of tasks in progress, verifying whether things are peeled or cleaned thoroughly). We further discuss opportunities to support the current practices and improve the independence of people with visual impairments in cooking (e.g., zero-touch interactions for cooking). Overall, our findings provide guidance for future research exploring various assistive technologies to help people cook without relying on vision.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, activity of daily living, assistive technology, blind, cooking, people with visual impairments', 'numpages': '11', 'articleno': '30', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The reliance on vision for tasks related to cooking and eating healthy can present barriers to cooking for oneself and achieving proper nutrition. There has been little research exploring cooking practices and challenges faced by people with visual impairments. We present a content analysis of 122 YouTube videos to highlight the cooking practices of visually impaired people, and we describe detailed practices for 12 different cooking activities (e.g., cutting and chopping, measuring, testing food for doneness). Based on the cooking practices, we also conducted semi-structured interviews with 12 visually impaired people who have cooking experience and show existing challenges, concerns, and risks in cooking (e.g., tracking the status of tasks in progress, verifying whether things are peeled or cleaned thoroughly). We further discuss opportunities to support the current practices and improve the independence of people with visual impairments in cooking (e.g., zero-touch interactions for cooking). Overall, our findings provide guidance for future research exploring various assistive technologies to help people cook without relying on vision.', 'doi': '10.1145/3441852.3471215', 'url': 'https://doi.org/10.1145/3441852.3471215', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Non-Visual Cooking: Exploring Practices and Challenges of Meal Preparation by People with Visual Impairments', 'author': 'Li, Franklin Mingzhe and Dorst, Jamie and Cederberg, Peter and Carrington, Patrick', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471215'}"
Deinstitutionalizing Independence: Discourses of Disability and Housing in Accessible Computing,10.1145/3441852.3471213,"The meaning of “homes” is complicated for disabled people because of the historical link between (de)institutionalization, housing, and civil rights. But, it is unclear whether and how this history impacts Accessible Computing (AC) research in domestic spaces. We performed Critical Discourse Analysis on 101 AC articles to explore how (de)institutionalization affects domestic AC research. We found (de)institutionalization motivates goals of “independence” for disabled people. Yet, discourses of housing reflected institutional logics which are in tension with “independence”—complicating how goals were set, housing was understood, and design was approached. We outline three discourses of housing in AC and identify parallels to those used to justify institutionalization in the USA. We reflect upon their consequences for AC research. We offer principles derived from the Independent Living Movement as frameworks for challenging institutional conceptions of housing, to open new avenues for more holistic and anti-ableist domestic AC research.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Critical Discourse Analysis, Disability, Homes, Housing, Institutionalization', 'numpages': '14', 'articleno': '31', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The meaning of “homes” is complicated for disabled people because of the historical link between (de)institutionalization, housing, and civil rights. But, it is unclear whether and how this history impacts Accessible Computing (AC) research in domestic spaces. We performed Critical Discourse Analysis on 101 AC articles to explore how (de)institutionalization affects domestic AC research. We found (de)institutionalization motivates goals of “independence” for disabled people. Yet, discourses of housing reflected institutional logics which are in tension with “independence”—complicating how goals were set, housing was understood, and design was approached. We outline three discourses of housing in AC and identify parallels to those used to justify institutionalization in the USA. We reflect upon their consequences for AC research. We offer principles derived from the Independent Living Movement as frameworks for challenging institutional conceptions of housing, to open new avenues for more holistic and anti-ableist domestic AC research.', 'doi': '10.1145/3441852.3471213', 'url': 'https://doi.org/10.1145/3441852.3471213', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Deinstitutionalizing Independence: Discourses of Disability and Housing in Accessible Computing', 'author': 'M. Storer, Kevin and M. Branham, Stacy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471213'}"
Opportunities for Supporting Self-efficacy Through Orientation \&amp; Mobility Training Technologies for Blind and Partially Sighted People,10.1145/3441852.3471224,"Orientation and mobility (O&amp;M) training provides essential skills and techniques for safe and independent mobility for blind and partially sighted (BPS) people. The demand for O&amp;M training is increasing as the number of people living with vision impairment increases. Despite the growing portfolio of HCI research on assistive technologies (AT), few studies have examined the experiences of BPS people during O&amp;M training, including the use of technology to aid O&amp;M training. To address this gap, we conducted semi-structured interviews with 20 BPS people and 8 Mobility and Orientation Trainers (MOT). The interviews were thematically analysed and organised into four overarching themes discussing factors influencing the self-efficacy belief of BPS people: Tools and Strategies for O&amp;M training, Technology Use in O&amp;M Training, Changing Personal and Social Circumstances, and Social Influences. We further highlight opportunities for combinations of multimodal technologies to increase access to and effectiveness of O&amp;M training.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Orientation and mobility training, blind and partially sighted people, self-efficacy', 'numpages': '13', 'articleno': '32', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Orientation and mobility (O&amp;M) training provides essential skills and techniques for safe and independent mobility for blind and partially sighted (BPS) people. The demand for O&amp;M training is increasing as the number of people living with vision impairment increases. Despite the growing portfolio of HCI research on assistive technologies (AT), few studies have examined the experiences of BPS people during O&amp;M training, including the use of technology to aid O&amp;M training. To address this gap, we conducted semi-structured interviews with 20 BPS people and 8 Mobility and Orientation Trainers (MOT). The interviews were thematically analysed and organised into four overarching themes discussing factors influencing the self-efficacy belief of BPS people: Tools and Strategies for O&amp;M training, Technology Use in O&amp;M Training, Changing Personal and Social Circumstances, and Social Influences. We further highlight opportunities for combinations of multimodal technologies to increase access to and effectiveness of O&amp;M training.', 'doi': '10.1145/3441852.3471224', 'url': 'https://doi.org/10.1145/3441852.3471224', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Opportunities for Supporting Self-efficacy Through Orientation \\&amp; Mobility Training Technologies for Blind and Partially Sighted People', 'author': 'Bandukda, Maryam and Holloway, Catherine and Singh, Aneesha and Barbareschi, Giulia and Berthouze, Nadia', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471224'}"
Investigating the Navigational Habits of People who are Blind in India,10.1145/3441852.3471203,"Assistive navigational technologies offer considerable promise to people who are blind. However, uptake of these technologies has traditionally been lower in low and middle income countries (LMICs), where levels of investment and maintenance in infrastructure differ from upper middle (UMICs) and high income countries (HICs). In this paper, we describe a qualitative study undertaken with 14 people who identify as legally-blind in an LMIC (India) to understand their experiences and strategies used when navigating within a metropolitan area. We highlight a set of scenarios impacting people who are blind within the context studied. These include crossing busy highways, navigating in the rainy season, collaborating with others to navigate at night, and using older public transportation. Our work brings attention to areas where the latest successful and well-publicized innovations in blind navigation may fall short when used in an Indian metropolitan area. We suggest that designers should be cognizant of the role that infrastructure (particularly its shortcomings) and environmental factors may play when navigating in LMICs such as India, with a view to designing assistive navigational technologies to better match the needs of users within these contexts.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Assistive technologies, Blind, India, Navigation, Visual Impairment', 'numpages': '10', 'articleno': '33', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Assistive navigational technologies offer considerable promise to people who are blind. However, uptake of these technologies has traditionally been lower in low and middle income countries (LMICs), where levels of investment and maintenance in infrastructure differ from upper middle (UMICs) and high income countries (HICs). In this paper, we describe a qualitative study undertaken with 14 people who identify as legally-blind in an LMIC (India) to understand their experiences and strategies used when navigating within a metropolitan area. We highlight a set of scenarios impacting people who are blind within the context studied. These include crossing busy highways, navigating in the rainy season, collaborating with others to navigate at night, and using older public transportation. Our work brings attention to areas where the latest successful and well-publicized innovations in blind navigation may fall short when used in an Indian metropolitan area. We suggest that designers should be cognizant of the role that infrastructure (particularly its shortcomings) and environmental factors may play when navigating in LMICs such as India, with a view to designing assistive navigational technologies to better match the needs of users within these contexts.', 'doi': '10.1145/3441852.3471203', 'url': 'https://doi.org/10.1145/3441852.3471203', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Investigating the Navigational Habits of People who are Blind in India', 'author': 'Nagraj, Anirudh and Kuber, Ravi and Hamidi, Foad and SG Prasad, Raghavendra', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471203'}"
A Case for Making Web Accessibility Guidelines Accessible: Older Adult Content Creators and Web Accessibility Planning,10.1145/3441852.3476472,This paper presents our experiences supporting web accessibility planning among a group of older adult online content creators. We highlight challenges we encountered meeting the web accessibility informational needs of our partners and helping this group of creators become aware and put in place measures to address accessibility issues. Our reflections highlight opportunities for future efforts to improve web accessibility support for everyday content creators and support for helping those less familiar with web accessibility options.,"{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'content creators, lay web users, older adults, participatory research, web accessibility', 'numpages': '6', 'articleno': '34', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents our experiences supporting web accessibility planning among a group of older adult online content creators. We highlight challenges we encountered meeting the web accessibility informational needs of our partners and helping this group of creators become aware and put in place measures to address accessibility issues. Our reflections highlight opportunities for future efforts to improve web accessibility support for everyday content creators and support for helping those less familiar with web accessibility options.', 'doi': '10.1145/3441852.3476472', 'url': 'https://doi.org/10.1145/3441852.3476472', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'A Case for Making Web Accessibility Guidelines Accessible: Older Adult Content Creators and Web Accessibility Planning', 'author': 'Martin-Hammond, Aqueasha and Patil, Ulka and Tandukar, Barsa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476472'}"
Developing Accessible Mobile Applications with Cross-Platform Development Frameworks,10.1145/3441852.3476469,"We illustrate our experience, gained over years of involvement in multiple research and commercial projects, in developing accessible mobile apps with cross-platform development frameworks (CPDF). These frameworks allow the developers to write the app code only once and run it on both iOS and Android. However, they have limited support for accessibility features, in particular for what concerns the interaction with the system screen reader. To study the coverage of accessibility features in CPDFs, we first systematically analyze screen reader APIs available in native iOS and Android, and we examine whether and at what level the same functionalities are available in two popular CPDF: Xamarin and React Native. This analysis unveils that there are many functionalities shared between native iOS and Android APIs, but most of them are not available neither in React Native nor in Xamarin. In particular, not even all basic APIs are exposed by the examined CPDF. Accessing the unavailable APIs is still possible, but it requires additional effort by the developers who need to write platform-specific code in native APIs, hence partially negating the advantages of CPDF. To address this problem, we consider a representative set of native APIs that cannot be directly accessed from React Native and Xamarin and we report challenges encountered in accessing them.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Cross platform development, accessibility, mobile applications.', 'numpages': '5', 'articleno': '35', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We illustrate our experience, gained over years of involvement in multiple research and commercial projects, in developing accessible mobile apps with cross-platform development frameworks (CPDF). These frameworks allow the developers to write the app code only once and run it on both iOS and Android. However, they have limited support for accessibility features, in particular for what concerns the interaction with the system screen reader. To study the coverage of accessibility features in CPDFs, we first systematically analyze screen reader APIs available in native iOS and Android, and we examine whether and at what level the same functionalities are available in two popular CPDF: Xamarin and React Native. This analysis unveils that there are many functionalities shared between native iOS and Android APIs, but most of them are not available neither in React Native nor in Xamarin. In particular, not even all basic APIs are exposed by the examined CPDF. Accessing the unavailable APIs is still possible, but it requires additional effort by the developers who need to write platform-specific code in native APIs, hence partially negating the advantages of CPDF. To address this problem, we consider a representative set of native APIs that cannot be directly accessed from React Native and Xamarin and we report challenges encountered in accessing them.', 'doi': '10.1145/3441852.3476469', 'url': 'https://doi.org/10.1145/3441852.3476469', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Developing Accessible Mobile Applications with Cross-Platform Development Frameworks', 'author': 'Mascetti, Sergio and Ducci, Mattia and Cant\\`{u}, Niccol\\`{o} and Pecis, Paolo and Ahmetovic, Dragan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476469'}"
Interdependent Variables: Remotely Designing Tactile Graphics for an Accessible Workflow,10.1145/3441852.3476468,"In this experience report, we offer a case study of blind and sighted colleagues creating an accessible workflow to collaborate on a data visualization-focused project. We outline our process for making the project's shared data representations accessible through incorporating both handmade and machine-embossed tactile graphics. We also share lessons and strategies for considering team needs and addressing contextual constraints like remote collaboration during the COVID-19 pandemic. More broadly, this report contributes to ongoing research into the ways accessibility is interdependent by arguing that access work must be a collective responsibility and properly supported with recognition, resources, and infrastructure.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Blind, Collaboration, Low Vision, Tactile Graphics', 'numpages': '6', 'articleno': '36', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""In this experience report, we offer a case study of blind and sighted colleagues creating an accessible workflow to collaborate on a data visualization-focused project. We outline our process for making the project's shared data representations accessible through incorporating both handmade and machine-embossed tactile graphics. We also share lessons and strategies for considering team needs and addressing contextual constraints like remote collaboration during the COVID-19 pandemic. More broadly, this report contributes to ongoing research into the ways accessibility is interdependent by arguing that access work must be a collective responsibility and properly supported with recognition, resources, and infrastructure."", 'doi': '10.1145/3441852.3476468', 'url': 'https://doi.org/10.1145/3441852.3476468', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Interdependent Variables: Remotely Designing Tactile Graphics for an Accessible Workflow', 'author': 'de Greef, Lilian and Moritz, Dominik and Bennett, Cynthia', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476468'}"
Lost in Translation: Challenges and Barriers to Sign Language-Accessible User Research,10.1145/3441852.3476473,"In this experience report, we describe an approach to ability-based focus groups with sign language users in a remote environment. We discuss our main lessons learned in terms of requirements for sign language-accessibility within research, calling out issues such as the need to address users in their natural language, ensuring translation for all parts of research processes, and including users not only within the conducted method but already within preparation phases. Based on requirements such as these, we argue that HCI research currently faces a dilemma when it comes to hearing researchers working with the sign language user population—having to handle the increasingly emphasized demand for conducting user research with this specific target group while lacking accessible tools and procedures to do so. Concluding our experience report, we address this dilemma by discussing the two sides of its fundamental challenge: Inadequate communication with and insufficient representation of sign language users within research.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Deaf, Focus Groups, Hard of Hearing, Language-Accessibility, Sign Language', 'numpages': '5', 'articleno': '37', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this experience report, we describe an approach to ability-based focus groups with sign language users in a remote environment. We discuss our main lessons learned in terms of requirements for sign language-accessibility within research, calling out issues such as the need to address users in their natural language, ensuring translation for all parts of research processes, and including users not only within the conducted method but already within preparation phases. Based on requirements such as these, we argue that HCI research currently faces a dilemma when it comes to hearing researchers working with the sign language user population—having to handle the increasingly emphasized demand for conducting user research with this specific target group while lacking accessible tools and procedures to do so. Concluding our experience report, we address this dilemma by discussing the two sides of its fundamental challenge: Inadequate communication with and insufficient representation of sign language users within research.', 'doi': '10.1145/3441852.3476473', 'url': 'https://doi.org/10.1145/3441852.3476473', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Lost in Translation: Challenges and Barriers to Sign Language-Accessible User Research', 'author': 'Unger, Amelie and Wallach, Dieter P. and Jochems, Nicole', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476473'}"
"Providing and Accessing Support During the COVID-19 Pandemic: Experiences of Mental Health Professionals, Community and Vocational Support Providers, and Adults with ASD",10.1145/3441852.3476470,"Due to the COVID-19 pandemic, essential services and support for individuals with ASD have had to transition to telehealth and virtual technologies. While these technologies have been recommended for use to continue provision of essential services to this population, it has yet to be understood what impact it has had on essential service providers and adults with ASD. This experience report provides insight from essential service providers and adults with ASD from a community center for adults with developmental disabilities to understand their experiences in providing and accessing mental health, and community and vocational support during the COVID-19 pandemic through telehealth and virtual technologies.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'ASD, COVID-19, autism spectrum disorders, community centers, essential services, mental health, telehealth, virtual conferencing', 'numpages': '6', 'articleno': '38', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Due to the COVID-19 pandemic, essential services and support for individuals with ASD have had to transition to telehealth and virtual technologies. While these technologies have been recommended for use to continue provision of essential services to this population, it has yet to be understood what impact it has had on essential service providers and adults with ASD. This experience report provides insight from essential service providers and adults with ASD from a community center for adults with developmental disabilities to understand their experiences in providing and accessing mental health, and community and vocational support during the COVID-19 pandemic through telehealth and virtual technologies.', 'doi': '10.1145/3441852.3476470', 'url': 'https://doi.org/10.1145/3441852.3476470', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Providing and Accessing Support During the COVID-19 Pandemic: Experiences of Mental Health Professionals, Community and Vocational Support Providers, and Adults with ASD', 'author': 'Thang, Tiffany and Liang, Alice and Choi, Yechan and Parrales, Adrian and Kuang, Sara H. and Kurniawan, Sri and Perez, Heather', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476470'}"
Regulating Personal Cameras for Disabled People and People with Deafblindness: Implications for HCI and Accessible Computing,10.1145/3441852.3476471,"In this experience paper we consider the relevance of social policy to the design of personal cameras for accessibility. As researchers with different backgrounds, in disability studies, accessible computing, AI-based systems, HCI and disability policy, we reflect broadly on our experiences of developing assistive technology for and with people with deafblindness. For designers of assistive technology there are usually few restrictions placed on what may be investigated, provided certain ethical and legal standards are met. However, deafblind and disabled people experience many more barriers in how the products of design may be accessed and how they may be used. Social policy is one of the mediators that governs the allocation of resources and benefits, especially for disabled people. We discuss these issues for researchers in the field, using the example of personal cameras: an area of high policy intervention. Awareness of policy is limited in HCI research, and we argue that it has the potential to add focus to work on design and assistive devices for disabled people. Designers have an important role to play in this process.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'AI Fairness, Accessibility, Assistive Technology, Data Privacy, Deafblindness, Ethical AI, Face Recognition, Mass Surveillance, Regulation of New Technologies, Wearable Cameras', 'numpages': '6', 'articleno': '39', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this experience paper we consider the relevance of social policy to the design of personal cameras for accessibility. As researchers with different backgrounds, in disability studies, accessible computing, AI-based systems, HCI and disability policy, we reflect broadly on our experiences of developing assistive technology for and with people with deafblindness. For designers of assistive technology there are usually few restrictions placed on what may be investigated, provided certain ethical and legal standards are met. However, deafblind and disabled people experience many more barriers in how the products of design may be accessed and how they may be used. Social policy is one of the mediators that governs the allocation of resources and benefits, especially for disabled people. We discuss these issues for researchers in the field, using the example of personal cameras: an area of high policy intervention. Awareness of policy is limited in HCI research, and we argue that it has the potential to add focus to work on design and assistive devices for disabled people. Designers have an important role to play in this process.', 'doi': '10.1145/3441852.3476471', 'url': 'https://doi.org/10.1145/3441852.3476471', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Regulating Personal Cameras for Disabled People and People with Deafblindness: Implications for HCI and Accessible Computing', 'author': 'L. Woodin, Sarah and Theil, Arthur', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476471'}"
At a Different Pace: Evaluating Whether Users Prefer Timing Parameters in American Sign Language Animations to Differ from Human Signers’ Timing,10.1145/3441852.3471214,"Adding American Sign Language (ASL) versions of information content to websites can improve information accessibility for many people who are Deaf or Hard of Hearing (DHH) who may have lower levels of English literacy. Generating animations from a script representation would enable this content to be easily updated, yet software is needed that can set detailed speed and timing parameters for such animations, which prior work has revealed to be critical for their understandability and acceptance among DHH users. Despite recent work on predicting these parameters using AI models trained on recordings of human signers, no prior work had examined whether DHH users actually prefer for these speed and timing properties to be similar to humans, or to be exaggerated, e.g. for additional clarity. We conducted two empirical studies to investigate preferences of ASL signers for speed and timing parameters of ASL animations, including: sign duration, transition time, differential signing rate, pause length, and pausing frequency. Our first study (N=20) identified two preferred values from among five options for each parameter, one of which included a typical human value for this parameter, and a second study (N=20) identified the most preferred value. We found that while ASL signers preferred pause length and frequency to be similar to those of humans, they actually preferred animations to have faster signs, slower transitions, and less dynamic variation in differential signing speed, as compared to the timing of human signers. This study provides specific empirical guidance for creators of future ASL animation technologies, and more broadly, it demonstrates that it is not safe to assume that ASL signers will simply prefer for properties of ASL animations to be as similar as possible to human signers.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'ASL, American Sign Language, Animation, Modeling., Prosodic Breaks, Speed, Timing', 'numpages': '12', 'articleno': '40', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Adding American Sign Language (ASL) versions of information content to websites can improve information accessibility for many people who are Deaf or Hard of Hearing (DHH) who may have lower levels of English literacy. Generating animations from a script representation would enable this content to be easily updated, yet software is needed that can set detailed speed and timing parameters for such animations, which prior work has revealed to be critical for their understandability and acceptance among DHH users. Despite recent work on predicting these parameters using AI models trained on recordings of human signers, no prior work had examined whether DHH users actually prefer for these speed and timing properties to be similar to humans, or to be exaggerated, e.g. for additional clarity. We conducted two empirical studies to investigate preferences of ASL signers for speed and timing parameters of ASL animations, including: sign duration, transition time, differential signing rate, pause length, and pausing frequency. Our first study (N=20) identified two preferred values from among five options for each parameter, one of which included a typical human value for this parameter, and a second study (N=20) identified the most preferred value. We found that while ASL signers preferred pause length and frequency to be similar to those of humans, they actually preferred animations to have faster signs, slower transitions, and less dynamic variation in differential signing speed, as compared to the timing of human signers. This study provides specific empirical guidance for creators of future ASL animation technologies, and more broadly, it demonstrates that it is not safe to assume that ASL signers will simply prefer for properties of ASL animations to be as similar as possible to human signers.', 'doi': '10.1145/3441852.3471214', 'url': 'https://doi.org/10.1145/3441852.3471214', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'At a Different Pace: Evaluating Whether Users Prefer Timing Parameters in American Sign Language Animations to Differ from Human Signers’ Timing', 'author': 'Al-khazraji, Sedeeq and Dingman, Becca and Lee, Sooyeon and Huenerfauth, Matt', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471214'}"
I See What You’re Saying: A Literature Review of Eye Tracking Research in Communication of Deaf or Hard of Hearing Users,10.1145/3441852.3471209,"Deaf or hard-of-hearing (DHH) individuals heavily rely on their visual senses to be aware about their environment, giving them heightened visual cognition and improved attention management strategies. Thus, the eyes have shown to play a significant role in these visual communication practices and, therefore, many various researches have adopted methodologies, specifically eye-tracking, to understand the gaze patterns and analyze the behavior of DHH individuals. In this paper, we provide a literature review from 55 papers and data analysis from eye-tracking studies concerning hearing impairment, attention management strategies, and their mode of communication such as Visual and Textual based communication. Through this survey, we summarize the findings and provide future research directions.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Deaf or Hard of Hearing, attention, communication, eye gaze, eye tracking', 'numpages': '13', 'articleno': '41', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Deaf or hard-of-hearing (DHH) individuals heavily rely on their visual senses to be aware about their environment, giving them heightened visual cognition and improved attention management strategies. Thus, the eyes have shown to play a significant role in these visual communication practices and, therefore, many various researches have adopted methodologies, specifically eye-tracking, to understand the gaze patterns and analyze the behavior of DHH individuals. In this paper, we provide a literature review from 55 papers and data analysis from eye-tracking studies concerning hearing impairment, attention management strategies, and their mode of communication such as Visual and Textual based communication. Through this survey, we summarize the findings and provide future research directions.', 'doi': '10.1145/3441852.3471209', 'url': 'https://doi.org/10.1145/3441852.3471209', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'I See What You’re Saying: A Literature Review of Eye Tracking Research in Communication of Deaf or Hard of Hearing Users', 'author': 'Agrawal, Chanchal and Peiris, Roshan L', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471209'}"
“It is fascinating to make these beasts fly”: Understanding Visually Impaired People's Motivations and Needs for Drone Piloting,10.1145/3441852.3471219,"Drones have become fixtures in commerce, safety efforts, and in homes as a leisure activity. Researchers have started to explore how drones can support people with disabilities in piloting and serve as assistive devices. Our work focuses on people with vision impairment and investigates what motivates them to fly drones. We administered a survey to visually impaired adults that gauged general interest in drone piloting and previous experience with drones. From the 59 survey responses, we interviewed 13 participants to elaborate on how they envision using drones and how different feedback and modes of piloting can make the flying experience more accessible. We found that our participants had overarching interests in aviation, trying new technology, environment exploration, and finding collaborative activities to do with their sighted family members, which extended to an interest in piloting drones. This research helps lay groundwork for design scenarios and accessible features for future drones.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Drones, interviews, personas, vision impairment', 'numpages': '12', 'articleno': '42', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Drones have become fixtures in commerce, safety efforts, and in homes as a leisure activity. Researchers have started to explore how drones can support people with disabilities in piloting and serve as assistive devices. Our work focuses on people with vision impairment and investigates what motivates them to fly drones. We administered a survey to visually impaired adults that gauged general interest in drone piloting and previous experience with drones. From the 59 survey responses, we interviewed 13 participants to elaborate on how they envision using drones and how different feedback and modes of piloting can make the flying experience more accessible. We found that our participants had overarching interests in aviation, trying new technology, environment exploration, and finding collaborative activities to do with their sighted family members, which extended to an interest in piloting drones. This research helps lay groundwork for design scenarios and accessible features for future drones.', 'doi': '10.1145/3441852.3471219', 'url': 'https://doi.org/10.1145/3441852.3471219', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': ""“It is fascinating to make these beasts fly”: Understanding Visually Impaired People's Motivations and Needs for Drone Piloting"", 'author': ""Gadiraju, Vinitha and Garcia, J\\'{e}r\\'{e}mie and Kane, Shaun and M. Brock, Anke"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471219'}"
Aided Nonverbal Communication through Physical Expressive Objects,10.1145/3441852.3471228,"Augmentative and alternative communication (AAC) devices enable speech-based communication, but generating speech is not the only resource needed to have a successful conversation. Being able to signal one wishes to take a turn by raising a hand or providing some other cue is critical in securing a turn to speak. Experienced conversation partners know how to recognize the nonverbal communication an augmented communicator (AC) displays, but these same nonverbal gestures can be hard to interpret by people who meet an AC for the first time. Prior work has identified motion-based AAC as a viable and underexplored modality for increasing ACs’ agency in conversation. We build on this prior work to dig deeper into a particular case study on motion-based AAC by co-designing a physical expressive object to support ACs during conversations. We found that our physical expressive object could support communication with unfamiliar partners. As such, we present our process and resulting lessons on the designed object itself and the co-design process.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Access technologies, Communication, Disability, Tangible interfaces', 'numpages': '11', 'articleno': '43', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Augmentative and alternative communication (AAC) devices enable speech-based communication, but generating speech is not the only resource needed to have a successful conversation. Being able to signal one wishes to take a turn by raising a hand or providing some other cue is critical in securing a turn to speak. Experienced conversation partners know how to recognize the nonverbal communication an augmented communicator (AC) displays, but these same nonverbal gestures can be hard to interpret by people who meet an AC for the first time. Prior work has identified motion-based AAC as a viable and underexplored modality for increasing ACs’ agency in conversation. We build on this prior work to dig deeper into a particular case study on motion-based AAC by co-designing a physical expressive object to support ACs during conversations. We found that our physical expressive object could support communication with unfamiliar partners. As such, we present our process and resulting lessons on the designed object itself and the co-design process.', 'doi': '10.1145/3441852.3471228', 'url': 'https://doi.org/10.1145/3441852.3471228', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Aided Nonverbal Communication through Physical Expressive Objects', 'author': 'Valencia, Stephanie and Steidl, Mark and Rivera, Michael and Bennett, Cynthia and Bigham, Jeffrey and Admoni, Henny', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3471228'}"
Participatory Design and Research: Challenges for Augmentative and Alternative Communication Technologies,10.1145/3441852.3487958,"User-Centred Design (UCD) and Participatory Action Research (PAR) have laid the foundations for Universal Accessibility. The inclusion of disabled end users in the design of digital Assistive Technology (dAT) is now an expectation within the accessibility field. However, some areas of dAT research fall short of this gold standard, especially when end users have speech, language and/or cognitive impairments. This is a particular challenge when developing technology for individuals who use Augmentative and Alternative Communication (AAC). In her ASSETS 2021 keynote talk, Prof. Waller provides a brief history of the development of AAC technologies since the early 1970s with a focus on users with severe speech and physical disabilities, illustrating that, despite significant advances in technology, the underlying design of AAC has not changed. This is in part due to challenges associated with the inclusion of a diverse user group in all stages of research from project ideation to product evaluation. She will demonstrate how a more inclusive approach might be achieved and will challenge the research community to consider the nature of interdisciplinary research teams and their role in setting the research agenda.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '1', 'articleno': '44', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'User-Centred Design (UCD) and Participatory Action Research (PAR) have laid the foundations for Universal Accessibility. The inclusion of disabled end users in the design of digital Assistive Technology (dAT) is now an expectation within the accessibility field. However, some areas of dAT research fall short of this gold standard, especially when end users have speech, language and/or cognitive impairments. This is a particular challenge when developing technology for individuals who use Augmentative and Alternative Communication (AAC). In her ASSETS 2021 keynote talk, Prof. Waller provides a brief history of the development of AAC technologies since the early 1970s with a focus on users with severe speech and physical disabilities, illustrating that, despite significant advances in technology, the underlying design of AAC has not changed. This is in part due to challenges associated with the inclusion of a diverse user group in all stages of research from project ideation to product evaluation. She will demonstrate how a more inclusive approach might be achieved and will challenge the research community to consider the nature of interdisciplinary research teams and their role in setting the research agenda.', 'doi': '10.1145/3441852.3487958', 'url': 'https://doi.org/10.1145/3441852.3487958', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Participatory Design and Research: Challenges for Augmentative and Alternative Communication Technologies', 'author': 'Waller, Annalu', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3487958'}"
A Preliminary Analysis of Android Educational Game Accessibility,10.1145/3441852.3476532,"Android educational games are powerful learning tools but small, moving targets and game implementations pose accessibility challenges to people with upper-body motor impairments. In this poster, we present findings from a qualitative accessibility evaluation of 30 popular Android educational games, identify and reflect on accessibility barriers, and provide preliminary design recommendations.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Android, accessibility, educational games', 'numpages': '4', 'articleno': '45', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Android educational games are powerful learning tools but small, moving targets and game implementations pose accessibility challenges to people with upper-body motor impairments. In this poster, we present findings from a qualitative accessibility evaluation of 30 popular Android educational games, identify and reflect on accessibility barriers, and provide preliminary design recommendations.', 'doi': '10.1145/3441852.3476532', 'url': 'https://doi.org/10.1145/3441852.3476532', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'A Preliminary Analysis of Android Educational Game Accessibility', 'author': 'Martinez, Jesse J and Fogarty, James and Froehlich, Jon E.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476532'}"
A review of how older adults’ computer skills and proficiency are reported in the literature,10.1145/3441852.3476522,"Participants’ technology knowledge and proficiency can directly impact their experiences with new technologies and affect study outcomes. This paper presents a review of studies from the ACM Digital Library published between 2010-2020, with the aim of synthesising existing practice in reporting older adults’ computer skills, proficiency and related concepts. The results highlight that there is no standard practice for reporting these characteristics, and that papers assess a range of metrics including technology use, frequency, experience, familiarity, purpose, attitude, and confidence.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'aging, confidence, familiarity, seniors, technology use', 'numpages': '3', 'articleno': '46', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Participants’ technology knowledge and proficiency can directly impact their experiences with new technologies and affect study outcomes. This paper presents a review of studies from the ACM Digital Library published between 2010-2020, with the aim of synthesising existing practice in reporting older adults’ computer skills, proficiency and related concepts. The results highlight that there is no standard practice for reporting these characteristics, and that papers assess a range of metrics including technology use, frequency, experience, familiarity, purpose, attitude, and confidence.', 'doi': '10.1145/3441852.3476522', 'url': 'https://doi.org/10.1145/3441852.3476522', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'A review of how older adults’ computer skills and proficiency are reported in the literature', 'author': 'Colbourne, Emma and Khan, Alishbah and Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476522'}"
Accessibility Support in Web Frameworks,10.1145/3441852.3476531,"Despite the existence of accessibility testing tools, software still largely inaccessible mainly due to lack of awareness among developers and issues with existing tools [14, 18]. This motivated us to evaluate the accessibility support of development tools that do not require specific accessibility knowledge such as web frameworks. We tested the accessibility support of three JavaScript web frameworks; Angular, React, and Vue. For each of the three frameworks, we built a web application with 32 pages, each of which violated a single accessibility guideline. We found that only React generated a warning for one of the accessibility violations that is lack of label for non-text content. The rest of the accessibility violations went unnoticed by the three frameworks.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility guidelines, web frameworks', 'numpages': '4', 'articleno': '47', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Despite the existence of accessibility testing tools, software still largely inaccessible mainly due to lack of awareness among developers and issues with existing tools [14, 18]. This motivated us to evaluate the accessibility support of development tools that do not require specific accessibility knowledge such as web frameworks. We tested the accessibility support of three JavaScript web frameworks; Angular, React, and Vue. For each of the three frameworks, we built a web application with 32 pages, each of which violated a single accessibility guideline. We found that only React generated a warning for one of the accessibility violations that is lack of label for non-text content. The rest of the accessibility violations went unnoticed by the three frameworks.', 'doi': '10.1145/3441852.3476531', 'url': 'https://doi.org/10.1145/3441852.3476531', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Accessibility Support in Web Frameworks', 'author': 'Longley, Michael and Elglaly, Yasmine N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476531'}"
"Accessible Citizen Science, by people with intellectual disability",10.1145/3441852.3476558,"This research explores the conditions and opportunities for citizen science applications to enhance their accessibility to people with intellectual disability (ID). In this paper, we present how the knowledge gathered by co-designing with a group of 3 participants with ID led to a design judged accessible and engaging by another group of 4 participants with ID. We contribute the key elements of that design: static subject, visual engagement, embodiment and social connectedness.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility., Citizen Science, Intellectual Disability', 'numpages': '3', 'articleno': '48', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This research explores the conditions and opportunities for citizen science applications to enhance their accessibility to people with intellectual disability (ID). In this paper, we present how the knowledge gathered by co-designing with a group of 3 participants with ID led to a design judged accessible and engaging by another group of 4 participants with ID. We contribute the key elements of that design: static subject, visual engagement, embodiment and social connectedness.', 'doi': '10.1145/3441852.3476558', 'url': 'https://doi.org/10.1145/3441852.3476558', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Accessible Citizen Science, by people with intellectual disability', 'author': 'Howlett, Robin and Sitbon, Laurianne and Hoogstrate, Maria and Balasuriya, Saminda Sundeepa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476558'}"
Active Math Learning for Students with Writing Disabilities,10.1145/3441852.3476536,"In a typical elementary mathematics(math) class, Students with Writing Disabilities (SWD) operate at a disadvantage. Math lessons and techniques are geared towards students who are able to actively ‘work out’ math problems with pencil and paper. We conducted interviews with special educators in elementary schools to learn about the pros and cons of current writing assistive technologies that are used in classrooms for math. Informed by the interviews findings, we designed a prototype called SMPL that enables SWD to work out math problems digitally. We ran a user study with 8 SWD to obtain feedback on SMPL. We present the interviews and user study findings. We found that: 1) There is a lack of writing assistive technologies that are designed specifically for elementary math learning; 2) It is feasible to provide SWD with a math learning experience similar to their peers; and 3) The writing assistive technology should be adaptive to students’ skills and backgrounds.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Mathematics, dysgraphia, middle school, writing disabilities', 'numpages': '3', 'articleno': '49', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In a typical elementary mathematics(math) class, Students with Writing Disabilities (SWD) operate at a disadvantage. Math lessons and techniques are geared towards students who are able to actively ‘work out’ math problems with pencil and paper. We conducted interviews with special educators in elementary schools to learn about the pros and cons of current writing assistive technologies that are used in classrooms for math. Informed by the interviews findings, we designed a prototype called SMPL that enables SWD to work out math problems digitally. We ran a user study with 8 SWD to obtain feedback on SMPL. We present the interviews and user study findings. We found that: 1) There is a lack of writing assistive technologies that are designed specifically for elementary math learning; 2) It is feasible to provide SWD with a math learning experience similar to their peers; and 3) The writing assistive technology should be adaptive to students’ skills and backgrounds.', 'doi': '10.1145/3441852.3476536', 'url': 'https://doi.org/10.1145/3441852.3476536', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Active Math Learning for Students with Writing Disabilities', 'author': 'Marone, Andrew and Gotfrid, Taylor and Kurtzhall, Kale and Elglaly, Yasmine N.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476536'}"
An automated AR-based annotation tool for indoor navigation for visually impaired people,10.1145/3441852.3476561,"Low vision people face many daily encumbrances. Traditional visual enhancements do not suffice to navigate indoor environments, or recognize objects efficiently. In this paper, we explore how Augmented Reality (AR) can be leveraged to design mobile applications to improve visual experience and unburden low vision persons. Specifically, we propose a novel automated AR-based annotation tool for detecting and labeling salient objects for assisted indoor navigation applications like NearbyExplorer. NearbyExplorer, which issues audio descriptions of nearby objects to the users, relies on a database populated by large teams of volunteers and map-a-thons to manually annotate salient objects in the environment like desks, chairs, low overhead ceilings. This has limited widespread and rapid deployment. Our tool builds on advances in automated object detection, AR labeling and accurate indoor positioning to provide an automated way to upload object labels and user position to a database, requiring just one volunteer. Moreover, it enables low vision people to detect and notice surrounding objects quickly using smartphones in various indoor environments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'augmented reality, database, indoor navigation, object detection', 'numpages': '4', 'articleno': '50', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Low vision people face many daily encumbrances. Traditional visual enhancements do not suffice to navigate indoor environments, or recognize objects efficiently. In this paper, we explore how Augmented Reality (AR) can be leveraged to design mobile applications to improve visual experience and unburden low vision persons. Specifically, we propose a novel automated AR-based annotation tool for detecting and labeling salient objects for assisted indoor navigation applications like NearbyExplorer. NearbyExplorer, which issues audio descriptions of nearby objects to the users, relies on a database populated by large teams of volunteers and map-a-thons to manually annotate salient objects in the environment like desks, chairs, low overhead ceilings. This has limited widespread and rapid deployment. Our tool builds on advances in automated object detection, AR labeling and accurate indoor positioning to provide an automated way to upload object labels and user position to a database, requiring just one volunteer. Moreover, it enables low vision people to detect and notice surrounding objects quickly using smartphones in various indoor environments.', 'doi': '10.1145/3441852.3476561', 'url': 'https://doi.org/10.1145/3441852.3476561', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'An automated AR-based annotation tool for indoor navigation for visually impaired people', 'author': 'Du, Pei and Bulusu, Nirupama', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476561'}"
An Intelligent Math E-Tutoring System for Students with Specific Learning Disabilities,10.1145/3441852.3476568,"Students with specific learning disabilities (SLDs) often experience negative emotions when solving math problems, which they have difficulty managing. This is one reason that current math e-learning tools, which elicit these negative emotions, are not effective for these students. We designed an intelligent math e-tutoring system that aims to reduce students’ negative emotional behaviors. The system automatically detects possible negative emotional behaviors by analyzing gaze, inputs on the touchscreen, and response time. It then uses one of four intervention methods (e.g., hints or brain breaks) to prevent students from being upset. To form this design, we conducted a formative study with five teachers for students with SLDs. The teachers thought that the design of four intervention methods would help students with SLDs. Among the four intervention methods, providing brain breaks is new and particularly useful for the students. The teachers also suggested that the system should personalize the detection of negative emotional behaviors to help students who have more severe learning disabilities.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Intelligent Tutoring System, K-12 Education, Special Education', 'numpages': '4', 'articleno': '51', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Students with specific learning disabilities (SLDs) often experience negative emotions when solving math problems, which they have difficulty managing. This is one reason that current math e-learning tools, which elicit these negative emotions, are not effective for these students. We designed an intelligent math e-tutoring system that aims to reduce students’ negative emotional behaviors. The system automatically detects possible negative emotional behaviors by analyzing gaze, inputs on the touchscreen, and response time. It then uses one of four intervention methods (e.g., hints or brain breaks) to prevent students from being upset. To form this design, we conducted a formative study with five teachers for students with SLDs. The teachers thought that the design of four intervention methods would help students with SLDs. Among the four intervention methods, providing brain breaks is new and particularly useful for the students. The teachers also suggested that the system should personalize the detection of negative emotional behaviors to help students who have more severe learning disabilities.', 'doi': '10.1145/3441852.3476568', 'url': 'https://doi.org/10.1145/3441852.3476568', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'An Intelligent Math E-Tutoring System for Students with Specific Learning Disabilities', 'author': 'Wen, Zikai Alex and Zhao, Yuhang and Silverstein, Erica and Azenkot, Shiri', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476568'}"
An Open-source Tool for Simplifying Computer and Assistive Technology Use: Tool for simplification and auto-personalization of computers and assistive technologies,10.1145/3441852.3476554,"Computer access is increasingly critical for all aspects of life from education to employment to daily living, health and almost all types of participation. The pandemic has highlighted our dependence on technology, but the dependence existed before and is continuing after. Yet many face barriers due to disability, literacy, or digital literacy. Although the problems faced by individuals with disabilities have received focus for some time, the problems faced by people who just have difficulty in using technologies has not, but is a second large, yet less understood problem. Solutions exist but are often not installed, buried, hard to find, and difficult to understand and use. To address these problems, an open-source extension to the Windows and macOS operating systems has been under exploration and development by an international consortium of organizations, companies, and individuals. It combines auto-personalization, layering, and enhanced discovery, with the ability to Install on Demand (IoD) any assistive technologies a user needs. The software, called Morphic, is now installed on all of the computers across campus at several major universities and libraries in the US and Canada. It makes computers simpler to use, and allows whichever features or assistive technologies a person needs to appear on any computer they encounter (that has Morphic on it) and want to use at school, work, library, community center, etc. This demonstration will cover both the basic and advanced features as well as how to get free copies of the open-source software and configure it for school, work or personal use. It will also highlight lessons learned from the placements.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Assistive Technologies, Auto-personalization, Inclusive Design, Layering', 'numpages': '3', 'articleno': '52', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Computer access is increasingly critical for all aspects of life from education to employment to daily living, health and almost all types of participation. The pandemic has highlighted our dependence on technology, but the dependence existed before and is continuing after. Yet many face barriers due to disability, literacy, or digital literacy. Although the problems faced by individuals with disabilities have received focus for some time, the problems faced by people who just have difficulty in using technologies has not, but is a second large, yet less understood problem. Solutions exist but are often not installed, buried, hard to find, and difficult to understand and use. To address these problems, an open-source extension to the Windows and macOS operating systems has been under exploration and development by an international consortium of organizations, companies, and individuals. It combines auto-personalization, layering, and enhanced discovery, with the ability to Install on Demand (IoD) any assistive technologies a user needs. The software, called Morphic, is now installed on all of the computers across campus at several major universities and libraries in the US and Canada. It makes computers simpler to use, and allows whichever features or assistive technologies a person needs to appear on any computer they encounter (that has Morphic on it) and want to use at school, work, library, community center, etc. This demonstration will cover both the basic and advanced features as well as how to get free copies of the open-source software and configure it for school, work or personal use. It will also highlight lessons learned from the placements.', 'doi': '10.1145/3441852.3476554', 'url': 'https://doi.org/10.1145/3441852.3476554', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'An Open-source Tool for Simplifying Computer and Assistive Technology Use: Tool for simplification and auto-personalization of computers and assistive technologies', 'author': 'Vanderheiden, Gregg and Jordan, J. Bern', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476554'}"
Augmenta11y: A Reading Assistant Application for Children with Dyslexia,10.1145/3441852.3476530,"We designed Augmenta11y, a cross-platform application that aims to provide ubiquitous reading and learning companionship to children with dyslexia. This paper presents the iterative user-centered design process and implementation details of the application and offers suggestions and guidelines for designing future assisted reading applications. We foresee the opportunity for Augmenta11y to be an accessible, low-cost assistive reading solution for dyslexic children with little to no access to educational specialists or after-school practices. The Augmenta11y application is available on iOS and Android.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Assistive Technology, Children, Dyslexia, Learning Disability', 'numpages': '3', 'articleno': '53', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We designed Augmenta11y, a cross-platform application that aims to provide ubiquitous reading and learning companionship to children with dyslexia. This paper presents the iterative user-centered design process and implementation details of the application and offers suggestions and guidelines for designing future assisted reading applications. We foresee the opportunity for Augmenta11y to be an accessible, low-cost assistive reading solution for dyslexic children with little to no access to educational specialists or after-school practices. The Augmenta11y application is available on iOS and Android.', 'doi': '10.1145/3441852.3476530', 'url': 'https://doi.org/10.1145/3441852.3476530', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Augmenta11y: A Reading Assistant Application for Children with Dyslexia', 'author': 'Gupta, Tushar and Aflatoony, Leila and Leonard, Lynette', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476530'}"
Clew3D: Automated Generation of O&amp;M Instructions Using LIDAR-Equipped Smartphones,10.1145/3441852.3476564,"Certified orientation and mobility specialists (COMS) work with clients who are blind or visually impaired (BVI) to help them travel independently with confidence. Part of this process involves creating a narrative description of a route and using specific techniques to help the client internalize it. We focus on the problem of automatically generating a narrative description of an indoor route based on a recording from a smartphone. These automatically generated narrations could be used in cases where a COMS is not available or to enable clients to independently practice routes that were originally learned with the help of a COMS. Specifically, we introduce Clew3D, a mobile app that leverages LIDAR-equipped iOS devices to identify orientation and mobility (O&amp;M) landmarks and their relative location along a recorded route. The identified landmarks are then used to provide a spoken narration modeled after traditional O&amp;M techniques. Our solution is co-designed with COMS and uses methods and language that they employ when creating route narrations for their clients. In addition to presenting Clew3D, we report the results of an analysis conducted with COMS regarding techniques and terminology used in traditional, in-person O&amp;M instruction. We also discuss challenges posed by vision-based systems to achieve automatic narrations that are reliable. Finally, we provide an example of an automatically generated route description and compare it with the same route provided by a COMS.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'computer vision, guided navigation, object classification, orientation and mobility', 'numpages': '3', 'articleno': '54', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Certified orientation and mobility specialists (COMS) work with clients who are blind or visually impaired (BVI) to help them travel independently with confidence. Part of this process involves creating a narrative description of a route and using specific techniques to help the client internalize it. We focus on the problem of automatically generating a narrative description of an indoor route based on a recording from a smartphone. These automatically generated narrations could be used in cases where a COMS is not available or to enable clients to independently practice routes that were originally learned with the help of a COMS. Specifically, we introduce Clew3D, a mobile app that leverages LIDAR-equipped iOS devices to identify orientation and mobility (O&amp;M) landmarks and their relative location along a recorded route. The identified landmarks are then used to provide a spoken narration modeled after traditional O&amp;M techniques. Our solution is co-designed with COMS and uses methods and language that they employ when creating route narrations for their clients. In addition to presenting Clew3D, we report the results of an analysis conducted with COMS regarding techniques and terminology used in traditional, in-person O&amp;M instruction. We also discuss challenges posed by vision-based systems to achieve automatic narrations that are reliable. Finally, we provide an example of an automatically generated route description and compare it with the same route provided by a COMS.', 'doi': '10.1145/3441852.3476564', 'url': 'https://doi.org/10.1145/3441852.3476564', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Clew3D: Automated Generation of O&amp;M Instructions Using LIDAR-Equipped Smartphones', 'author': 'Harriman, Hwei-Shin and Ahmetovic, Dragan and Mascetti, Sergio and Moyle, Darren and Evans, Michael and Ruvolo, Paul', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476564'}"
CollabAlly: Accessible Collaboration Awareness in Document Editing,10.1145/3441852.3476562,"Collaborative document editing tools are widely used in both professional and academic workplaces. While these tools provide some accessibility features, it is still challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who edited or commented where and what in the document). To address this gap, we present CollabAlly, a browser extension that makes extractable collaborative and contextual information in document editing accessible for blind users. With CollabAlly, blind users can easily access collaborators’ information, track real-time or asynchronous content and comment changes, and navigate through these elements. In order to convey this complex information through audio, CollabAlly uses voice fonts and spatial audio to enhance users’ collaboration awareness in shared documents. Through a series of pilot studies with a coauthor who is blind, CollabAlly’s design was refined to include more information and to be more compatible with existing screen readers.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '4', 'articleno': '55', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Collaborative document editing tools are widely used in both professional and academic workplaces. While these tools provide some accessibility features, it is still challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who edited or commented where and what in the document). To address this gap, we present CollabAlly, a browser extension that makes extractable collaborative and contextual information in document editing accessible for blind users. With CollabAlly, blind users can easily access collaborators’ information, track real-time or asynchronous content and comment changes, and navigate through these elements. In order to convey this complex information through audio, CollabAlly uses voice fonts and spatial audio to enhance users’ collaboration awareness in shared documents. Through a series of pilot studies with a coauthor who is blind, CollabAlly’s design was refined to include more information and to be more compatible with existing screen readers.', 'doi': '10.1145/3441852.3476562', 'url': 'https://doi.org/10.1145/3441852.3476562', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'CollabAlly: Accessible Collaboration Awareness in Document Editing', 'author': 'Lee, Cheuk Yin Phipson and Zhang, Zhuohao and Herskovitz, Jaylin and Seo, JooYoung and Guo, Anhong', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476562'}"
Collecting Sidewalk Network Data at Scale for Accessible Pedestrian Travel,10.1145/3441852.3476560,"Sidewalks are central to an accessible transportation network, as they connect all other transportation modes. The street-side environment, especially the location and connectivity of the sidewalks, has not been widely integrated into information systems used to report accessibility and walkability in wayfinding applications. Typical sidewalk mapping methods rely on surveyor collections, which are non-standardized, laborious, costly, difficult to maintain, and do not scale well. In this work, we introduce a working proof-of-concept system for automated mapping of sidewalk networks on portable computing devices. Our system utilizes efficient neural networks, image sensing, GPS, and compact hardware to perform sidewalk mapping on portable devices. We discuss future opportunities for cities and transportation agencies to advance their knowledge of the transportation network they own and manage in order to improve accessibility for all travelers.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Depth sensing, First-last-mile, Image processing, Pedestrian mapping, Semantic segmentation', 'numpages': '4', 'articleno': '56', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sidewalks are central to an accessible transportation network, as they connect all other transportation modes. The street-side environment, especially the location and connectivity of the sidewalks, has not been widely integrated into information systems used to report accessibility and walkability in wayfinding applications. Typical sidewalk mapping methods rely on surveyor collections, which are non-standardized, laborious, costly, difficult to maintain, and do not scale well. In this work, we introduce a working proof-of-concept system for automated mapping of sidewalk networks on portable computing devices. Our system utilizes efficient neural networks, image sensing, GPS, and compact hardware to perform sidewalk mapping on portable devices. We discuss future opportunities for cities and transportation agencies to advance their knowledge of the transportation network they own and manage in order to improve accessibility for all travelers.', 'doi': '10.1145/3441852.3476560', 'url': 'https://doi.org/10.1145/3441852.3476560', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Collecting Sidewalk Network Data at Scale for Accessible Pedestrian Travel', 'author': 'Zhang, Yuxiang and Mehta, Sachin and Caspi, Anat', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476560'}"
Colorable Band: A Wearable Device to Encourage Daily Decision Making Based on Behavior of Users with Color Vision Deficiency,10.1145/3441852.3476570,"People with color vision deficiency (CVD) face several difficulties in performing daily tasks because they often fall outside of the culturally, linguistically, and educationally modulated majority opinion. This study aims to develop a device that can seamlessly input/output information based on the user's handling actions and to verify the validity of the support for daily decision-making of people with CVD. In this study, the use case is set as selecting clothes in a shop; online behavior observation is then conducted to design an assistive method and a watch-type device that shows useful information, such as the adjusted color and/or text for people with CVD on a display at the wrist is developed. An online user interview is conducted using a first-person perspective and bird's-eye perspective video with three CVD participants to verify the validity of the developed device for daily support. Consequently, the accuracy and effectiveness of the watch-type devices were determined. This study presents a prototyped proof-of-concept device in a remote environment, considering the coronavirus pandemic, and discusses the daily support for people with CVD.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Color Vision Deficiency, Natural User Interface, Wearable Device', 'numpages': '4', 'articleno': '57', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""People with color vision deficiency (CVD) face several difficulties in performing daily tasks because they often fall outside of the culturally, linguistically, and educationally modulated majority opinion. This study aims to develop a device that can seamlessly input/output information based on the user's handling actions and to verify the validity of the support for daily decision-making of people with CVD. In this study, the use case is set as selecting clothes in a shop; online behavior observation is then conducted to design an assistive method and a watch-type device that shows useful information, such as the adjusted color and/or text for people with CVD on a display at the wrist is developed. An online user interview is conducted using a first-person perspective and bird's-eye perspective video with three CVD participants to verify the validity of the developed device for daily support. Consequently, the accuracy and effectiveness of the watch-type devices were determined. This study presents a prototyped proof-of-concept device in a remote environment, considering the coronavirus pandemic, and discusses the daily support for people with CVD."", 'doi': '10.1145/3441852.3476570', 'url': 'https://doi.org/10.1145/3441852.3476570', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Colorable Band: A Wearable Device to Encourage Daily Decision Making Based on Behavior of Users with Color Vision Deficiency', 'author': 'Uehara, Akira', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476570'}"
Designing a Pictorial Communication Web Application With People With Intellectual Disability,10.1145/3441852.3476527,This paper presents the first iteration of the design of a web application which supports its users to access and arrange pictures as a non-linguistic way of supporting communication. We motivate our initial design by examining related work on Augmentative Alternative Communication (AAC). We present our reflections on the use of a working prototype by two minimally-verbal users with intellectual disability and how this can inform future work.,"{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'AAC, communication, intellectual disability', 'numpages': '4', 'articleno': '58', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper presents the first iteration of the design of a web application which supports its users to access and arrange pictures as a non-linguistic way of supporting communication. We motivate our initial design by examining related work on Augmentative Alternative Communication (AAC). We present our reflections on the use of a working prototype by two minimally-verbal users with intellectual disability and how this can inform future work.', 'doi': '10.1145/3441852.3476527', 'url': 'https://doi.org/10.1145/3441852.3476527', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing a Pictorial Communication Web Application With People With Intellectual Disability', 'author': 'Robertson, Nicholas L and Bircanin, Filip and Sitbon, Laurianne', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476527'}"
Designing a Podcast Platform for Deaf and Hard of Hearing Users,10.1145/3441852.3476523,"Listening to podcasts is a popular way for people to spend their time. However, little focus has been given to how accessible podcast platforms are for Deaf and Hard-of-Hearing (DHH) people. We present a DHH-centered accessible podcast platform prototype developed with user-centered design. Our proposed design was constructed through semi-structured interviews (n=7) and prototype design feedback sessions (n=8) with DHH users. We encourage podcast platform designers to adopt our design recommendations to make podcasts more inclusive for DHH people and recommend how podcast hosts can make their shows more accessible.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Deaf and Hard-of-Hearing, Design, Podcasts', 'numpages': '4', 'articleno': '59', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Listening to podcasts is a popular way for people to spend their time. However, little focus has been given to how accessible podcast platforms are for Deaf and Hard-of-Hearing (DHH) people. We present a DHH-centered accessible podcast platform prototype developed with user-centered design. Our proposed design was constructed through semi-structured interviews (n=7) and prototype design feedback sessions (n=8) with DHH users. We encourage podcast platform designers to adopt our design recommendations to make podcasts more inclusive for DHH people and recommend how podcast hosts can make their shows more accessible.', 'doi': '10.1145/3441852.3476523', 'url': 'https://doi.org/10.1145/3441852.3476523', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing a Podcast Platform for Deaf and Hard of Hearing Users', 'author': 'Dingman, Becca and Tigwell, Garreth W. and Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476523'}"
Designing Apps to Support Engagement by Older Adults: A think-aloud study of the eNutri dietary-intake assessment web app,10.1145/3441852.3476537,"Evidence suggests that, compared with younger users, older adults benefit from additional support when engaging with new apps. This paper presents a remote observation study of 15 UK older adults (aged &gt;65 years) using eNutri, a web-based dietary assessment app. The results highlight the importance placed by older adults on having good instructions and support when learning and using apps, and suggest that including features such as instructional videos, “contact us” information, and explicit guidance on “commonly-known” features may be important for this population. The study also found heterogeneity within the group in terms of app delivery preferences (smartphone vs web-based), which serves as a reminder that when designing apps for older adults, it may be helpful to bear in mind the variation in people's use of and comfort with types of devices.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '3', 'articleno': '60', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Evidence suggests that, compared with younger users, older adults benefit from additional support when engaging with new apps. This paper presents a remote observation study of 15 UK older adults (aged &gt;65 years) using eNutri, a web-based dietary assessment app. The results highlight the importance placed by older adults on having good instructions and support when learning and using apps, and suggest that including features such as instructional videos, “contact us” information, and explicit guidance on “commonly-known” features may be important for this population. The study also found heterogeneity within the group in terms of app delivery preferences (smartphone vs web-based), which serves as a reminder that when designing apps for older adults, it may be helpful to bear in mind the variation in people's use of and comfort with types of devices."", 'doi': '10.1145/3441852.3476537', 'url': 'https://doi.org/10.1145/3441852.3476537', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing Apps to Support Engagement by Older Adults: A think-aloud study of the eNutri dietary-intake assessment web app', 'author': 'Kelly, Eve and Weech, Michelle and Fallaize, Rosalind and Zenun Franco, Rodrigo and Hwang, Faustina and Lovegrove, Julie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476537'}"
Designing Sensory and Social Tools for Neurodivergent Individuals in Social Media Environments,10.1145/3441852.3476546,"Sensory guides and social narratives are learning tools that provide sensory and social support to neurodivergent individuals. These tools—and their design guidelines—have historically been developed for physical environments, such as museums and classrooms. They lack support for social media environments, where sensory stimuli and social contexts can be complex and uncertain. We address these challenges by designing a novel social media sensory guide and social narrative, specifically adapted for social media interaction. We leverage our use case, Twitter Spaces—an audio-only conversation feature in beta. The goal of this pilot study is to determine whether neurodivergent users want sensory guides and social narratives adapted for social media, and if users find them helpful in setting expectations for social media interaction. We evaluate these tools with eight neurodivergent Twitter users, using tasks and thinking aloud. Results indicate a strong potential for adoption of both tools among neurodivergent individuals to reduce overstimulation in social media environments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Cognitive Disability, Design, Neurodiversity, Social Media', 'numpages': '5', 'articleno': '61', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sensory guides and social narratives are learning tools that provide sensory and social support to neurodivergent individuals. These tools—and their design guidelines—have historically been developed for physical environments, such as museums and classrooms. They lack support for social media environments, where sensory stimuli and social contexts can be complex and uncertain. We address these challenges by designing a novel social media sensory guide and social narrative, specifically adapted for social media interaction. We leverage our use case, Twitter Spaces—an audio-only conversation feature in beta. The goal of this pilot study is to determine whether neurodivergent users want sensory guides and social narratives adapted for social media, and if users find them helpful in setting expectations for social media interaction. We evaluate these tools with eight neurodivergent Twitter users, using tasks and thinking aloud. Results indicate a strong potential for adoption of both tools among neurodivergent individuals to reduce overstimulation in social media environments.', 'doi': '10.1145/3441852.3476546', 'url': 'https://doi.org/10.1145/3441852.3476546', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Designing Sensory and Social Tools for Neurodivergent Individuals in Social Media Environments', 'author': 'Race, Lauren and James, Amber and Hayward, Andrew and El-Amin, Kia and Patterson, Maya Gold and Mershon, Theresa', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476546'}"
Determining a Taxonomy of Accessible Phrases During Exercise Instruction for People with Visual Impairments for Text Analysis,10.1145/3441852.3476567,"Physical activity is an important part of quality life, however people with visual impairments (PVIs) are less likely to participate in physical activity than their sighted peers. One barrier is that exercise instructors may not give accessible verbal instructions. There is a potential for text analysis to determine these phrases, and in response provide more accessible instructions. First, a taxonomy of accessible phrases needs to be developed. To address this problem, we conducted user studies with 10 PVIs exercising along with audio and video aerobic workouts. We analyzed video footage of their exercise along with interviews to determine a preliminary set of phrases that are helpful or confusing. We then conducted an iterative qualitative analysis of six other exercise videos and sought expert feedback to derive our taxonomy. We hope these findings inform systems that analyze instructional phrases for accessibility to PVIs.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Blind, Exercise, Physical Activity, Verbal Instructions, Visual impairment', 'numpages': '3', 'articleno': '62', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Physical activity is an important part of quality life, however people with visual impairments (PVIs) are less likely to participate in physical activity than their sighted peers. One barrier is that exercise instructors may not give accessible verbal instructions. There is a potential for text analysis to determine these phrases, and in response provide more accessible instructions. First, a taxonomy of accessible phrases needs to be developed. To address this problem, we conducted user studies with 10 PVIs exercising along with audio and video aerobic workouts. We analyzed video footage of their exercise along with interviews to determine a preliminary set of phrases that are helpful or confusing. We then conducted an iterative qualitative analysis of six other exercise videos and sought expert feedback to derive our taxonomy. We hope these findings inform systems that analyze instructional phrases for accessibility to PVIs.', 'doi': '10.1145/3441852.3476567', 'url': 'https://doi.org/10.1145/3441852.3476567', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Determining a Taxonomy of Accessible Phrases During Exercise Instruction for People with Visual Impairments for Text Analysis', 'author': 'Malik, Jeehan and Rumi, Masuma Akter and DeNeve, Morgan and Skalla, Calvin and Ball, Lindsay and Lieberman, Lauren and Rector, Kyle', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476567'}"
Equivalent Telecommunications Access on Mobile Devices,10.1145/3441852.3476535,"Currently, Deaf and hard of hearing (D/HH) callers using mobile phones cannot place a video or captioned based call to a Telecommunication Relay Services (TRS) Communication Assistant (CA) using the carrier assigned mobile phone number. D/HH callers need to use accessible hardware (video phones, captioned telephones, Teletypewriter, TTY) or download mobile applications to place or receive calls. D/HH callers’ generalized and emergency contact information in captioned/video applications is not linked to the built-in directory. Through our research and development work, we propose a concept to allow D/HH callers to have the option to make captioned and video calls through mobile device native dialer systems without the need to download applications. This proposed concept includes the all-in-one solution of Video Relay Services (VRS), 3-Party Video Calls, Voice-to-Text Captioning, and NextGen 911 built into the dialer systems. This demonstration introduces a concept that would make placing and receiving calls through TRS more native-like to that of auditory telephone users.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '3', 'articleno': '63', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Currently, Deaf and hard of hearing (D/HH) callers using mobile phones cannot place a video or captioned based call to a Telecommunication Relay Services (TRS) Communication Assistant (CA) using the carrier assigned mobile phone number. D/HH callers need to use accessible hardware (video phones, captioned telephones, Teletypewriter, TTY) or download mobile applications to place or receive calls. D/HH callers’ generalized and emergency contact information in captioned/video applications is not linked to the built-in directory. Through our research and development work, we propose a concept to allow D/HH callers to have the option to make captioned and video calls through mobile device native dialer systems without the need to download applications. This proposed concept includes the all-in-one solution of Video Relay Services (VRS), 3-Party Video Calls, Voice-to-Text Captioning, and NextGen 911 built into the dialer systems. This demonstration introduces a concept that would make placing and receiving calls through TRS more native-like to that of auditory telephone users.', 'doi': '10.1145/3441852.3476535', 'url': 'https://doi.org/10.1145/3441852.3476535', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Equivalent Telecommunications Access on Mobile Devices', 'author': 'Behm, Gary and Sayel Ali, Shareef and Montan, Spencer', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476535'}"
Expanding Designing for One to Invite Others Through Reverse Inclusion,10.1145/3441852.3476517,"This research aims to explore how tangible technology created through co-design can be designed in a way that invites social interaction for people with intellectual disability. We conducted co-design sessions with one participant to create a sensory musical blanket. As the trials were run in a collective environment, their peers were drawn to the developing design. The design method and unique interactions are key contributions of this research.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Co-design, Intellectual Disability, Reverse Inclusion, Social Devices, Tangible Technology', 'numpages': '4', 'articleno': '64', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This research aims to explore how tangible technology created through co-design can be designed in a way that invites social interaction for people with intellectual disability. We conducted co-design sessions with one participant to create a sensory musical blanket. As the trials were run in a collective environment, their peers were drawn to the developing design. The design method and unique interactions are key contributions of this research.', 'doi': '10.1145/3441852.3476517', 'url': 'https://doi.org/10.1145/3441852.3476517', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Expanding Designing for One to Invite Others Through Reverse Inclusion', 'author': 'Andradi, Manesha and Bircanin, Filip and Sitbon, Laurianne and Brereton, Margot', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476517'}"
Experimental Crowd+AI Approaches to Track Accessibility Features in Sidewalk Intersections Over Time,10.1145/3441852.3476549,"How do sidewalks change over time? Are there geographic or socioeconomic patterns to this change? These questions are important but difficult to address with current GIS tools and techniques. In this demo paper, we introduce three preliminary crowd+AI (Artificial Intelligence) prototypes to track changes in street intersection accessibility over time—specifically, curb ramps—and report on results from a pilot usability study.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Mobility, change tracking, crowdsourcing, disability, machine learning, sidewalks', 'numpages': '5', 'articleno': '65', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'How do sidewalks change over time? Are there geographic or socioeconomic patterns to this change? These questions are important but difficult to address with current GIS tools and techniques. In this demo paper, we introduce three preliminary crowd+AI (Artificial Intelligence) prototypes to track changes in street intersection accessibility over time—specifically, curb ramps—and report on results from a pilot usability study.', 'doi': '10.1145/3441852.3476549', 'url': 'https://doi.org/10.1145/3441852.3476549', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Experimental Crowd+AI Approaches to Track Accessibility Features in Sidewalk Intersections Over Time', 'author': 'Sharif, Ather and Gopal, Paari and Saugstad, Michael and Bhatt, Shiven and Fok, Raymond and Weld, Galen and Asher Mankoff Dey, Kavi and E. Froehlich, Jon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476549'}"
Exploring the Requirements of Abuse Reporting for Persons with Intellectual and Developmental Disabilities,10.1145/3441852.3476520,"Incidents of abuse committed against persons with intellectual and developmental disabilities (I/DD) are woefully under-reported. One way of helping change this situation is to empower persons with I/DD with tools to self-report abuse. During abuse reporting the reporter is requested to provide a variety of information about the abuse and its context. In this paper wanted to understand which pieces of information are typically needed to successfully report abuse and whether persons with I/DD can provide them. Consequently, we conducted an exploratory survey of the staff at an adult protective services agency in our region and asked them about their experiences with receiving abuse self-reports by persons with I/DD. Overall, we found that persons with I/DD are typically able to provide enough information to successfully self-report abuse.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Abuse, Abuse reporting, Developmental disability, Intellectual disability, Safety', 'numpages': '4', 'articleno': '66', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Incidents of abuse committed against persons with intellectual and developmental disabilities (I/DD) are woefully under-reported. One way of helping change this situation is to empower persons with I/DD with tools to self-report abuse. During abuse reporting the reporter is requested to provide a variety of information about the abuse and its context. In this paper wanted to understand which pieces of information are typically needed to successfully report abuse and whether persons with I/DD can provide them. Consequently, we conducted an exploratory survey of the staff at an adult protective services agency in our region and asked them about their experiences with receiving abuse self-reports by persons with I/DD. Overall, we found that persons with I/DD are typically able to provide enough information to successfully self-report abuse.', 'doi': '10.1145/3441852.3476520', 'url': 'https://doi.org/10.1145/3441852.3476520', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Exploring the Requirements of Abuse Reporting for Persons with Intellectual and Developmental Disabilities', 'author': 'Venkatasubramanian, Krishna and Skorinko, Jeanine L M and Jutras, Nicole and Carvajal Erker, Natalia and Padir, Lara', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476520'}"
Fostering collaboration with asymmetric roles in accessible programming environments for children with mixed-visual-abilities,10.1145/3441852.3476553,"Introduction of computational thinking training in early childhood potentiates cognitive development and better prepares children to live and prosper in a future heavily computational society. Programming environments are now widely adopted in classrooms to teach programming concepts. However, these tools are often reliant on visual interaction, making them inaccessible to children with visual impairments. Also, programming environments in general are usually designed to promote individual experiences, wasting the potential benefits of group collaborative activities. We propose the design of a programming environment that leverages asymmetric roles to foster collaborative computational thinking activities for children with visual impairments, in particular mixed-visual-ability classes. The multimodal system comprises the use of tangible blocks and auditory feedback, while children have to collaborate to program a robot. We conducted a remote online study, collecting valuable feedback on the limitations and opportunities for future work, aiming to potentiate education and social inclusion.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessible, children, collaboration, robot, tangible, visually impaired', 'numpages': '4', 'articleno': '67', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Introduction of computational thinking training in early childhood potentiates cognitive development and better prepares children to live and prosper in a future heavily computational society. Programming environments are now widely adopted in classrooms to teach programming concepts. However, these tools are often reliant on visual interaction, making them inaccessible to children with visual impairments. Also, programming environments in general are usually designed to promote individual experiences, wasting the potential benefits of group collaborative activities. We propose the design of a programming environment that leverages asymmetric roles to foster collaborative computational thinking activities for children with visual impairments, in particular mixed-visual-ability classes. The multimodal system comprises the use of tangible blocks and auditory feedback, while children have to collaborate to program a robot. We conducted a remote online study, collecting valuable feedback on the limitations and opportunities for future work, aiming to potentiate education and social inclusion.', 'doi': '10.1145/3441852.3476553', 'url': 'https://doi.org/10.1145/3441852.3476553', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Fostering collaboration with asymmetric roles in accessible programming environments for children with mixed-visual-abilities', 'author': ""Rocha, Filipa and Guimar\\~{a}es, Guilherme and Gon\\c{c}alves, David and Pires, Ana Cristina and Abreu, L\\'{u}cia Ver\\'{o}nica and Guerreiro, Tiago"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476553'}"
GazeMetro: A Gaze-Based Interactive System for Metro Map,10.1145/3441852.3476569,"In this paper, we propose a gaze-based interactive system for metro map named GazeMetro, which helps explore and interact with the metro map only by eye movements, providing a new experience of interaction. The objective of GazeMetro is to provide metro map viewers with gaze-based interactions to search the metro map without other manual operations. We implement GazeMetro with 4 gaze-based interaction techniques which are Gaze Fisheye, Gaze Scaling and Panning, Gaze Selection and Gaze Hint. We conducted an experiment to evaluate GazeMetro and the results showed a positive evaluation in pragmatic quality and especially in hedonic quality.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'eye tracking, gaze-based interaction, graph visualization, metro map', 'numpages': '3', 'articleno': '68', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we propose a gaze-based interactive system for metro map named GazeMetro, which helps explore and interact with the metro map only by eye movements, providing a new experience of interaction. The objective of GazeMetro is to provide metro map viewers with gaze-based interactions to search the metro map without other manual operations. We implement GazeMetro with 4 gaze-based interaction techniques which are Gaze Fisheye, Gaze Scaling and Panning, Gaze Selection and Gaze Hint. We conducted an experiment to evaluate GazeMetro and the results showed a positive evaluation in pragmatic quality and especially in hedonic quality.', 'doi': '10.1145/3441852.3476569', 'url': 'https://doi.org/10.1145/3441852.3476569', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'GazeMetro: A Gaze-Based Interactive System for Metro Map', 'author': 'Xie, Yaqi and Wang, Hao and Luo, Chaoquan and YANG, Zhuo and ZHAN, Yinwei', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476569'}"
Image Explorer: Multi-Layered Touch Exploration to Make Images Accessible,10.1145/3441852.3476548,"Blind or visually impaired (BVI) individuals often rely on alternative text (alt-text) in order to understand an image; however, alt-text is often missing or incomplete. Automatically-generated captions are a more scalable alternative, but they are also often missing crucial details, and, sometimes, are completely incorrect, which may still be falsely trusted by BVI users. We hypothesize that additional information could help BVI users better judge the correctness of an auto-generated caption. To achieve this, we present Image Explorer, a touch-based multi-layered image exploration system that enables users to explore the spatial layout and information hierarchies in an image. Image Explorer leverages several off-the-shelf deep learning models to generate segmentation and labeling results for an image, combines and filters the generated information, and presents the resulted information in hierarchical layers. In a pilot study with three BVI users, participants used Image Explorer, Seeing AI, and Facebook to explore images with auto-generated captions of diverging quality, and judge the correctness of the captions. Preliminary results show that participants made more accurate judgements about the correctness of the captions when using Image Explorer, although they were highly confident about their judgement regardless of the tool used. Overall, Image Explorer is a novel touch exploration system that makes images more accessible for BVI users by potentially encouraging skepticism and enabling users to independently validate auto-generated captions.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '4', 'articleno': '69', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Blind or visually impaired (BVI) individuals often rely on alternative text (alt-text) in order to understand an image; however, alt-text is often missing or incomplete. Automatically-generated captions are a more scalable alternative, but they are also often missing crucial details, and, sometimes, are completely incorrect, which may still be falsely trusted by BVI users. We hypothesize that additional information could help BVI users better judge the correctness of an auto-generated caption. To achieve this, we present Image Explorer, a touch-based multi-layered image exploration system that enables users to explore the spatial layout and information hierarchies in an image. Image Explorer leverages several off-the-shelf deep learning models to generate segmentation and labeling results for an image, combines and filters the generated information, and presents the resulted information in hierarchical layers. In a pilot study with three BVI users, participants used Image Explorer, Seeing AI, and Facebook to explore images with auto-generated captions of diverging quality, and judge the correctness of the captions. Preliminary results show that participants made more accurate judgements about the correctness of the captions when using Image Explorer, although they were highly confident about their judgement regardless of the tool used. Overall, Image Explorer is a novel touch exploration system that makes images more accessible for BVI users by potentially encouraging skepticism and enabling users to independently validate auto-generated captions.', 'doi': '10.1145/3441852.3476548', 'url': 'https://doi.org/10.1145/3441852.3476548', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Image Explorer: Multi-Layered Touch Exploration to Make Images Accessible', 'author': 'Lee, Jaewook and Peng, Yi-Hao and Herskovitz, Jaylin and Guo, Anhong', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476548'}"
Increasing Access to Trainer-led Aerobic Exercise for People with Visual Impairments through a Sensor Mat System,10.1145/3441852.3476557,"People with visual impairments (PVIs) are less likely to participate in physical activity than their sighted peers. One barrier is the lack of accessible group-based aerobic exercise classes, often due to instructors not giving accessible verbal instructions. While there is research in exercise tracking, these tools often require vision or familiarity with the exercise. There are accessible solutions that give personalized verbal feedback in slower-paced exercises, not generalizing to aerobics. In response, we have developed an algorithm that detects shoeprints on a sensor mat using computer vision and a CNN. We can infer whether a person is following along with a step aerobics workout and are designing reactive verbal feedback to guide the person to rejoin the class. Future work will include finishing development and conducting a user study to assess the effectiveness of the reactive verbal feedback.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Convolutional neural network, Exercise tracking, People with visual impairments, Sensor mat', 'numpages': '4', 'articleno': '70', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'People with visual impairments (PVIs) are less likely to participate in physical activity than their sighted peers. One barrier is the lack of accessible group-based aerobic exercise classes, often due to instructors not giving accessible verbal instructions. While there is research in exercise tracking, these tools often require vision or familiarity with the exercise. There are accessible solutions that give personalized verbal feedback in slower-paced exercises, not generalizing to aerobics. In response, we have developed an algorithm that detects shoeprints on a sensor mat using computer vision and a CNN. We can infer whether a person is following along with a step aerobics workout and are designing reactive verbal feedback to guide the person to rejoin the class. Future work will include finishing development and conducting a user study to assess the effectiveness of the reactive verbal feedback.', 'doi': '10.1145/3441852.3476557', 'url': 'https://doi.org/10.1145/3441852.3476557', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Increasing Access to Trainer-led Aerobic Exercise for People with Visual Impairments through a Sensor Mat System', 'author': 'Malik, Jeehan and Majure, Mitchell and Rubio Bidon, Hana Gabrielle and Lamoureux, Regan and Rector, Kyle', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476557'}"
Interview and Think Aloud Accessibility for Deaf and Hard of Hearing Participants in Design Research,10.1145/3441852.3476526,"In interaction or user-centered design practices, it is common to employ interviews and think-aloud techniques to gather data about user behavior. These techniques enable researchers to learn about how users think and use technologies during the design and user testing process. However, such techniques involve accessing audio feedback, which may require workarounds if the researcher identifies as deaf or hard of hearing (DHH). We report on a project led by a DHH researcher in which workarounds to audio access resulted in methodological changes. We discuss the implications of these adjustments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, design methods, research methods', 'numpages': '3', 'articleno': '71', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In interaction or user-centered design practices, it is common to employ interviews and think-aloud techniques to gather data about user behavior. These techniques enable researchers to learn about how users think and use technologies during the design and user testing process. However, such techniques involve accessing audio feedback, which may require workarounds if the researcher identifies as deaf or hard of hearing (DHH). We report on a project led by a DHH researcher in which workarounds to audio access resulted in methodological changes. We discuss the implications of these adjustments.', 'doi': '10.1145/3441852.3476526', 'url': 'https://doi.org/10.1145/3441852.3476526', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Interview and Think Aloud Accessibility for Deaf and Hard of Hearing Participants in Design Research', 'author': 'Dingman, Becca and Tigwell, Garreth W. and Shinohara, Kristen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476526'}"
Inverse Color Contrast Checker: Automatically Suggesting Color Adjustments that meet Contrast Requirements on the Web,10.1145/3441852.3476529,"Low contrast between text and background and its effect with low vision is relatively well-understood. Many tools exist for helping web designers check contrast limits. Most of these tools identify contrast problems but give limited advice on how to rectify the problems. Moreover, website accessibility audits reveal that insufficient color contrast still is a recurring issue in practice. A framework was therefore developed that automatically proposes color adjustments to problematic text-background color pairs on web pages. These suggestions adhere to contrast requirements and are aligned with the visual design profile. The framework allows the developers to visually inspect the suggestions and amend color definitions in projects.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'WCAG, color contrast, web accessibility, web framework', 'numpages': '4', 'articleno': '72', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Low contrast between text and background and its effect with low vision is relatively well-understood. Many tools exist for helping web designers check contrast limits. Most of these tools identify contrast problems but give limited advice on how to rectify the problems. Moreover, website accessibility audits reveal that insufficient color contrast still is a recurring issue in practice. A framework was therefore developed that automatically proposes color adjustments to problematic text-background color pairs on web pages. These suggestions adhere to contrast requirements and are aligned with the visual design profile. The framework allows the developers to visually inspect the suggestions and amend color definitions in projects.', 'doi': '10.1145/3441852.3476529', 'url': 'https://doi.org/10.1145/3441852.3476529', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Inverse Color Contrast Checker: Automatically Suggesting Color Adjustments that meet Contrast Requirements on the Web', 'author': 'Sandnes, Frode Eika', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476529'}"
iReadMore: A Reading Therapy App Co-Designed by People with Aphasia and Alexia,10.1145/3441852.3476518,"We present the iReadMore app, a reading therapy for people with acquired reading or language impairments (known as alexia and aphasia respectively). The app was co-designed by people with alexia and aphasia, and has been demonstrated to significantly improve reading speed and accuracy in a randomized controlled trial. It is intended to be used at home without the support of a therapist. Therefore, accessibility and maintaining therapy engagement are key elements in achieving the high therapy doses required for rehabilitation of reading impairments. As such, these elements were developed in a co-design process that included 50 participants over 2 phases. This demonstration will present the flow of the application and detail how we translated a clinically validated prototype into a publicly available therapy app used by hundreds of people with acquired reading impairments since its release in March 2021.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Aphasia, Co-design, Digital health, Reading impairment', 'numpages': '3', 'articleno': '73', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present the iReadMore app, a reading therapy for people with acquired reading or language impairments (known as alexia and aphasia respectively). The app was co-designed by people with alexia and aphasia, and has been demonstrated to significantly improve reading speed and accuracy in a randomized controlled trial. It is intended to be used at home without the support of a therapist. Therefore, accessibility and maintaining therapy engagement are key elements in achieving the high therapy doses required for rehabilitation of reading impairments. As such, these elements were developed in a co-design process that included 50 participants over 2 phases. This demonstration will present the flow of the application and detail how we translated a clinically validated prototype into a publicly available therapy app used by hundreds of people with acquired reading impairments since its release in March 2021.', 'doi': '10.1145/3441852.3476518', 'url': 'https://doi.org/10.1145/3441852.3476518', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'iReadMore: A Reading Therapy App Co-Designed by People with Aphasia and Alexia', 'author': 'Langford, Thomas and Leff, Alex and Romano, Daniela', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476518'}"
Is home-based webcam eye-tracking with older adults living with and without Alzheimer's disease feasible?,10.1145/3441852.3476565,"Home-based eye tracking studies using built-in webcams are typically conducted with younger people and incur long set-up times and a large number of calibration failures. We investigated the set-up time, number of calibration failures and issues faced by twelve older adults living with and without Alzheimer's disease during home-based eye tracking. We found that home-based eye tracking is feasible with set-up support and we provide recommendations for future studies of this nature.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Gorilla, aging, dementia, usability', 'numpages': '3', 'articleno': '74', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': ""Home-based eye tracking studies using built-in webcams are typically conducted with younger people and incur long set-up times and a large number of calibration failures. We investigated the set-up time, number of calibration failures and issues faced by twelve older adults living with and without Alzheimer's disease during home-based eye tracking. We found that home-based eye tracking is feasible with set-up support and we provide recommendations for future studies of this nature."", 'doi': '10.1145/3441852.3476565', 'url': 'https://doi.org/10.1145/3441852.3476565', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': ""Is home-based webcam eye-tracking with older adults living with and without Alzheimer's disease feasible?"", 'author': 'Greenaway, Anne-Marie and Nasuto, Slawomir and Ho, Aileen and Hwang, Faustina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476565'}"
Kavita Project: Voice Programming for People with Motor Disabilities,10.1145/3441852.3476516,"Most computer programs are designed in a way that requires interaction based on finger movements and hand gestures. This type of environment, which assumes the dexterity of human hands, presents limitations for those with motor disabilities. This limitation excludes this population from learning to code and, for those who develop a musculoskeletal disorder in later stages, could jeopardize their programming careers. The objective of this research is to design a Voice User Interface (or VUI for its acronym in English) that allows the use of the user’s voice to program in an Integrated Development Environment (or IDE for its acronym in English). For this, a basic programming structure was defined using Alexa Skills, which allows the user to declare variables, print values, solve basic mathematical expressions, insert conditional expressions, and create loops. An online text editor was created using CodeMirror to run user input using the Python programming language. However, the results could not yet be evaluated since the application does not have a compiler integrated. In future work it is desired to add the compiler, and thus to be able to execute the user’s program in the online editor. The aim is to also add the ability to edit, debug and move the cursor using the Alexa Skill.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, open-source, programming languages, universal design, voice programming', 'numpages': '3', 'articleno': '75', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Most computer programs are designed in a way that requires interaction based on finger movements and hand gestures. This type of environment, which assumes the dexterity of human hands, presents limitations for those with motor disabilities. This limitation excludes this population from learning to code and, for those who develop a musculoskeletal disorder in later stages, could jeopardize their programming careers. The objective of this research is to design a Voice User Interface (or VUI for its acronym in English) that allows the use of the user’s voice to program in an Integrated Development Environment (or IDE for its acronym in English). For this, a basic programming structure was defined using Alexa Skills, which allows the user to declare variables, print values, solve basic mathematical expressions, insert conditional expressions, and create loops. An online text editor was created using CodeMirror to run user input using the Python programming language. However, the results could not yet be evaluated since the application does not have a compiler integrated. In future work it is desired to add the compiler, and thus to be able to execute the user’s program in the online editor. The aim is to also add the ability to edit, debug and move the cursor using the Alexa Skill.', 'doi': '10.1145/3441852.3476516', 'url': 'https://doi.org/10.1145/3441852.3476516', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Kavita Project: Voice Programming for People with Motor Disabilities', 'author': ""De Le\\'{o}n Cordero, Dayanlee and Ayala, Christopher and Ord\\'{o}\\~{n}ez, Patricia"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476516'}"
Landscape Analysis of Commercial Visual Assistance Technologies,10.1145/3441852.3476521,"We present a landscape analysis of commercially available visual assistance technologies (VATs) that provide auditory descriptions of image and video content found online, as well as those taken by people who are blind and have visual questions. Through structured web-based searches, we identified 20 VATs released by 17 companies, and analyzed how these companies communicate to users about their technical innovation and service offerings. Our results can orient new researchers, UX professionals, and developers to trends within commercial VAT development.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'blind, image caption, image description, landscape analysis, visual assistance technology', 'numpages': '4', 'articleno': '76', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present a landscape analysis of commercially available visual assistance technologies (VATs) that provide auditory descriptions of image and video content found online, as well as those taken by people who are blind and have visual questions. Through structured web-based searches, we identified 20 VATs released by 17 companies, and analyzed how these companies communicate to users about their technical innovation and service offerings. Our results can orient new researchers, UX professionals, and developers to trends within commercial VAT development.', 'doi': '10.1145/3441852.3476521', 'url': 'https://doi.org/10.1145/3441852.3476521', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Landscape Analysis of Commercial Visual Assistance Technologies', 'author': 'Sadjo, Emma and Findlater, Leah and Stangl, Abigale', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476521'}"
Making Math Graphs More Accessible in Remote Learning: Using Sonification to Introduce Discontinuity in Calculus,10.1145/3441852.3476533,"Math graphs need to be accessible to People with Visual Impairments (PVI). While tactile graphics are a common way for PVI to access math graphs, their use becomes complicated in remote learning. To make math graphs more accessible in remote education, we focused on sonification, the use of non-speech sound. In this study, we designed techniques of sonification of math graphs to introduce the concept of discontinuity in calculus to PVI. First, we conducted a remote interview with six participants to understand their experiences with math education using graphs. Based on these findings, we developed a series of sonifications of math graphs that we remotely evaluated with three participants from our initial interviews. Our findings reveal that sonification can intuitively convey simple patterns and trends in math graphs with a little practice, be useful to introduce the discontinuities, and be more effective with descriptions of the sound and graphs.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Mathematical graph, Sonification, Visual impairment', 'numpages': '4', 'articleno': '77', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Math graphs need to be accessible to People with Visual Impairments (PVI). While tactile graphics are a common way for PVI to access math graphs, their use becomes complicated in remote learning. To make math graphs more accessible in remote education, we focused on sonification, the use of non-speech sound. In this study, we designed techniques of sonification of math graphs to introduce the concept of discontinuity in calculus to PVI. First, we conducted a remote interview with six participants to understand their experiences with math education using graphs. Based on these findings, we developed a series of sonifications of math graphs that we remotely evaluated with three participants from our initial interviews. Our findings reveal that sonification can intuitively convey simple patterns and trends in math graphs with a little practice, be useful to introduce the discontinuities, and be more effective with descriptions of the sound and graphs.', 'doi': '10.1145/3441852.3476533', 'url': 'https://doi.org/10.1145/3441852.3476533', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Making Math Graphs More Accessible in Remote Learning: Using Sonification to Introduce Discontinuity in Calculus', 'author': 'Ohshiro, Keita and Hurst, Amy and DuBois, Luke', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476533'}"
Meeting Participants with Intellectual Disabilities during COVID-19 Pandemic: Challenges and Improvisation,10.1145/3441852.3476566,"With the COVID-19 pandemic, we all suffered from several restrictions and measures regulating interaction with one another. We had to wear masks, use hand sanitizer, have open-air meetings, feel a combination of excitement and frustration, and eventually depend on online video calls. The combinations of these additional requirements and limitations, while necessary, affected how we could involve users in the different stages of design. It has profoundly hindered our chances of meeting in person with people with temporary or permanent disabilities. In our project, involving people with intellectual disabilities in the museum context, we also had to deal with museums being closed and physical exhibitions being canceled. At the same time, guardians and caregivers often turned to a stricter interpretation of anti-COVID measures to protect people with intellectual disabilities. This paper aims to discuss these challenges and share our lessons about coping with challenging and unpredictable situations by using improvisation.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'COVID-19, Improvisation, Meeting Participants, People with Intellectual Disabilities', 'numpages': '4', 'articleno': '78', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'With the COVID-19 pandemic, we all suffered from several restrictions and measures regulating interaction with one another. We had to wear masks, use hand sanitizer, have open-air meetings, feel a combination of excitement and frustration, and eventually depend on online video calls. The combinations of these additional requirements and limitations, while necessary, affected how we could involve users in the different stages of design. It has profoundly hindered our chances of meeting in person with people with temporary or permanent disabilities. In our project, involving people with intellectual disabilities in the museum context, we also had to deal with museums being closed and physical exhibitions being canceled. At the same time, guardians and caregivers often turned to a stricter interpretation of anti-COVID measures to protect people with intellectual disabilities. This paper aims to discuss these challenges and share our lessons about coping with challenging and unpredictable situations by using improvisation.', 'doi': '10.1145/3441852.3476566', 'url': 'https://doi.org/10.1145/3441852.3476566', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Meeting Participants with Intellectual Disabilities during COVID-19 Pandemic: Challenges and Improvisation', 'author': 'Soares Guedes, Leandro and Landoni, Monica', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476566'}"
myView: End-user Authoring of Virtual Environments for Therapy,10.1145/3441852.3476543,"Virtual environments for therapy are scarce and lack personalization. The creation of these environments is done by specialists, is time-consuming, and expensive. We present a smartphone tool that allows non-specialists to create navigable virtual environments by taking and linking sequences of panoramic photo spheres, analogly to Google Street View. Editing the environments is then possible in a web platform, myView, where text, images, videos, sounds, and pick-up objects can be added. myView allows users to navigate their environments as well as sharing those environments with others. In a preliminary study with two psychologists, where myView was used as an elicitation probe, the approach was found to be useful for creating meaningful activities for reminiscence and cognitive training. The platform showed to be promising in the democratization of the crafting of virtual environments.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'End-user Authoring, Therapy., Virtual Environments', 'numpages': '4', 'articleno': '79', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Virtual environments for therapy are scarce and lack personalization. The creation of these environments is done by specialists, is time-consuming, and expensive. We present a smartphone tool that allows non-specialists to create navigable virtual environments by taking and linking sequences of panoramic photo spheres, analogly to Google Street View. Editing the environments is then possible in a web platform, myView, where text, images, videos, sounds, and pick-up objects can be added. myView allows users to navigate their environments as well as sharing those environments with others. In a preliminary study with two psychologists, where myView was used as an elicitation probe, the approach was found to be useful for creating meaningful activities for reminiscence and cognitive training. The platform showed to be promising in the democratization of the crafting of virtual environments.', 'doi': '10.1145/3441852.3476543', 'url': 'https://doi.org/10.1145/3441852.3476543', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'myView: End-user Authoring of Virtual Environments for Therapy', 'author': ""Alves, S\\'{e}rgio and Caldeira, Pedro and Ferreira-Brito, Filipa and Carri\\c{c}o, Lu\\'{\\i}s and Guerreiro, Tiago"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476543'}"
New Metrics for Understanding Touch by People with and without Limited Fine Motor Function,10.1145/3441852.3476559,"Current performance measures with touch-based systems usually focus on overall performance, such as touch accuracy and target acquisition speed. But a touch is not an atomic event; it is a process that unfolds over time, and this process can be characterized to gain insight into users’ touch behaviors. To this end, our work proposes 13 target-agnostic touch performance metrics to characterize what happens during a touch. These metrics are: touch direction, variability, drift, duration, extent, absolute/signed area change, area variability, area deviation, absolute/signed angle change, angle variability, and angle deviation. Unlike traditional touch performance measures that treat a touch as a single (x, y) coordinate, we regard a touch as a time series of ovals that occur from finger-down to finger-up. We provide a mathematical formula and intuitive description for each metric we propose. To evaluate our metrics, we run an analysis on a publicly available dataset containing touch inputs by people with and without limited fine motor function, finding our metrics helpful in characterizing different fine motor control challenges. Our metrics can be useful to designers and evaluators of touch-based systems, particularly when making touch screens accessible to all forms of touch.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Understanding touch, limited fine motor function', 'numpages': '4', 'articleno': '80', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Current performance measures with touch-based systems usually focus on overall performance, such as touch accuracy and target acquisition speed. But a touch is not an atomic event; it is a process that unfolds over time, and this process can be characterized to gain insight into users’ touch behaviors. To this end, our work proposes 13 target-agnostic touch performance metrics to characterize what happens during a touch. These metrics are: touch direction, variability, drift, duration, extent, absolute/signed area change, area variability, area deviation, absolute/signed angle change, angle variability, and angle deviation. Unlike traditional touch performance measures that treat a touch as a single (x, y) coordinate, we regard a touch as a time series of ovals that occur from finger-down to finger-up. We provide a mathematical formula and intuitive description for each metric we propose. To evaluate our metrics, we run an analysis on a publicly available dataset containing touch inputs by people with and without limited fine motor function, finding our metrics helpful in characterizing different fine motor control challenges. Our metrics can be useful to designers and evaluators of touch-based systems, particularly when making touch screens accessible to all forms of touch.', 'doi': '10.1145/3441852.3476559', 'url': 'https://doi.org/10.1145/3441852.3476559', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'New Metrics for Understanding Touch by People with and without Limited Fine Motor Function', 'author': 'Kong, Junhan and Zhong, Mingyuan and Fogarty, James and Wobbrock, Jacob O.', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476559'}"
PatRec: A Mobile Game for Learning Social Haptic Communication,10.1145/3441852.3476563,"Social Haptic Communication (SHC) is one of the many tactile modes of communication used by persons with deafblindness to access information about their surroundings. SHC usually involves an interpreter executing finger and hand signs on the back of a person with multi-sensory disabilities. Learning SHC, however, can become challenging and time-consuming, particularly to those who experience deafblindness later in life. In this work, we present PatRec: a mobile game for learning SHC concepts. PatRec is a multiple-choice quiz game connected to a chair interface that contains a 3x3 array of vibration motors emulating different SHC signs. Players collect scores and badges whenever they guess the right SHC vibration pattern, leading to continuous engagement and a better position on a leaderboard. The game is also meant for family members to learn SHC. We report the technical implementation of PatRec and the findings from a user evaluation.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessible Games, Assistive Technology, Deafblindness, Game-Based Learning, Haptics, Tactile Sign Language, Vibrotactile feedback, Visual Impairments', 'numpages': '4', 'articleno': '81', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Social Haptic Communication (SHC) is one of the many tactile modes of communication used by persons with deafblindness to access information about their surroundings. SHC usually involves an interpreter executing finger and hand signs on the back of a person with multi-sensory disabilities. Learning SHC, however, can become challenging and time-consuming, particularly to those who experience deafblindness later in life. In this work, we present PatRec: a mobile game for learning SHC concepts. PatRec is a multiple-choice quiz game connected to a chair interface that contains a 3x3 array of vibration motors emulating different SHC signs. Players collect scores and badges whenever they guess the right SHC vibration pattern, leading to continuous engagement and a better position on a leaderboard. The game is also meant for family members to learn SHC. We report the technical implementation of PatRec and the findings from a user evaluation.', 'doi': '10.1145/3441852.3476563', 'url': 'https://doi.org/10.1145/3441852.3476563', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'PatRec: A Mobile Game for Learning Social Haptic Communication', 'author': 'Vuijk, Jessica G. J. and Gay, James and Plaisier, Myrthe A. and Kappers, Astrid M. L. and Theil, Arthur', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476563'}"
Rehabilitation through Accessible Mobile Gaming and Wearable Sensors,10.1145/3441852.3476544,"Play Access is an Android assistive technology that replaces touchscreen interaction with alternative interfaces, enabling people with upper extremity impairments to access mobile games, and providing alternative means of playing mobile games for all. We demonstrate the use of Play Access to support physical therapy for children with haemophilia, with the goal of preventing long-term mobility impairments. To achieve this, we modified Play Access to enable the use of body movements, recognized using wearable sensors, as an alternative interface for playing games. This way, Play Access makes it possible to use existing Android games as exergames, hence better targeting patients’ interest.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Interaction substitution., Physical therapy, Rehabilitation', 'numpages': '4', 'articleno': '82', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Play Access is an Android assistive technology that replaces touchscreen interaction with alternative interfaces, enabling people with upper extremity impairments to access mobile games, and providing alternative means of playing mobile games for all. We demonstrate the use of Play Access to support physical therapy for children with haemophilia, with the goal of preventing long-term mobility impairments. To achieve this, we modified Play Access to enable the use of body movements, recognized using wearable sensors, as an alternative interface for playing games. This way, Play Access makes it possible to use existing Android games as exergames, hence better targeting patients’ interest.', 'doi': '10.1145/3441852.3476544', 'url': 'https://doi.org/10.1145/3441852.3476544', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Rehabilitation through Accessible Mobile Gaming and Wearable Sensors', 'author': 'Ahmetovic, Dragan and Pugliese, Antonio and Mascetti, Sergio and Begnozzi, Valentina and Boccalandro, Elena and Gualtierotti, Roberta and Peyvandi, Flora', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476544'}"
Respectful Language as Perceived by People with Disabilities,10.1145/3441852.3476534,"Respectfully and adequately referring to people with various disabilities is difficult due to societal norms and constantly evolving languages. In this work, we address the question of how expert researchers in the field of accessibility are referring to people with disabilities and whether this terminology corresponds to how people with disabilities prefer to be addressed. By conducting a systematic literature review of the past three ASSETS proceeding, we summarize how accessibility researchers are currently referring to people with disabilities in English. A survey of 63 people with disabilities further revealed that while researchers from ASSETS are using terms that are mostly aligned with participants’ expectations, the same terminologies can be perceived both respectful and disrespectful by varying participants. Through this preliminary work, we pave the path for researchers to further explore respectful terminology and encourage researchers to improve the inclusivity and diversity of language use in our community.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'numpages': '4', 'articleno': '83', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Respectfully and adequately referring to people with various disabilities is difficult due to societal norms and constantly evolving languages. In this work, we address the question of how expert researchers in the field of accessibility are referring to people with disabilities and whether this terminology corresponds to how people with disabilities prefer to be addressed. By conducting a systematic literature review of the past three ASSETS proceeding, we summarize how accessibility researchers are currently referring to people with disabilities in English. A survey of 63 people with disabilities further revealed that while researchers from ASSETS are using terms that are mostly aligned with participants’ expectations, the same terminologies can be perceived both respectful and disrespectful by varying participants. Through this preliminary work, we pave the path for researchers to further explore respectful terminology and encourage researchers to improve the inclusivity and diversity of language use in our community.', 'doi': '10.1145/3441852.3476534', 'url': 'https://doi.org/10.1145/3441852.3476534', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Respectful Language as Perceived by People with Disabilities', 'author': 'Levy, Lior and Li, Qisheng and Sharif, Ather and Reinecke, Katharina', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476534'}"
Robot Trajectories When Approaching a User with a Visual Impairment,10.1145/3441852.3476538,"Mobile robots have been shown to be helpful in guiding users in complex indoor spaces. While these robots can assist all types of users, current implementations often rely on users visually rendezvousing with the robot, which may be a challenge for people with visual impairments. This paper describes a proof of concept for a robotic system that addresses this kind of short-range rendezvous for users with visual impairments. We propose to use a lattice graph-based Anytime Repairing A* (ARA*) planner as a global planner to discourage the robot from turning in place at its goal position, making its path more human-like and safer. We also interviewed an Orientation \&amp; Mobility (O&amp;M) Specialist for their thoughts on our planner. They observed that our planner produces less obtrusive trajectories to the user than the ROS default global planner and recommended that our system should allow the robot to approach the person from the side as opposed to the front as it currently does. In the future, we plan to test our system with users in-person to better validate our assumptions and find additional pain points.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'approach trajectory, people with visual impairments, rendezvous, robot navigation', 'numpages': '4', 'articleno': '84', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Mobile robots have been shown to be helpful in guiding users in complex indoor spaces. While these robots can assist all types of users, current implementations often rely on users visually rendezvousing with the robot, which may be a challenge for people with visual impairments. This paper describes a proof of concept for a robotic system that addresses this kind of short-range rendezvous for users with visual impairments. We propose to use a lattice graph-based Anytime Repairing A* (ARA*) planner as a global planner to discourage the robot from turning in place at its goal position, making its path more human-like and safer. We also interviewed an Orientation \\&amp; Mobility (O&amp;M) Specialist for their thoughts on our planner. They observed that our planner produces less obtrusive trajectories to the user than the ROS default global planner and recommended that our system should allow the robot to approach the person from the side as opposed to the front as it currently does. In the future, we plan to test our system with users in-person to better validate our assumptions and find additional pain points.', 'doi': '10.1145/3441852.3476538', 'url': 'https://doi.org/10.1145/3441852.3476538', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Robot Trajectories When Approaching a User with a Visual Impairment', 'author': 'Limprayoon, Jirachaya ""Fern"" and Pareek, Prithu and Tan, Xiang Zhi and Steinfeld, Aaron', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476538'}"
SciA11y: Converting Scientific Papers to Accessible HTML,10.1145/3441852.3476545,"We present SciA11y, a system that renders inaccessible scientific paper PDFs into HTML. SciA11y uses machine learning models to extract and understand the content of scientific PDFs, and reorganizes the resulting paper components into a form that better supports skimming and scanning for blind and low vision (BLV) readers. SciA11y adds navigation features such as tagged headings, a table of contents, and bidirectional links between inline citations and references, which allow readers to resolve citations without losing their context. A set of 1.5 million open access papers are processed and available at https://scia11y.org/. This system is a first step in addressing scientific PDF accessibility, and may significantly improve the experience of paper reading for BLV users.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, accessible reader, blind and low vision users, scientific documents', 'numpages': '4', 'articleno': '85', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'We present SciA11y, a system that renders inaccessible scientific paper PDFs into HTML. SciA11y uses machine learning models to extract and understand the content of scientific PDFs, and reorganizes the resulting paper components into a form that better supports skimming and scanning for blind and low vision (BLV) readers. SciA11y adds navigation features such as tagged headings, a table of contents, and bidirectional links between inline citations and references, which allow readers to resolve citations without losing their context. A set of 1.5 million open access papers are processed and available at https://scia11y.org/. This system is a first step in addressing scientific PDF accessibility, and may significantly improve the experience of paper reading for BLV users.', 'doi': '10.1145/3441852.3476545', 'url': 'https://doi.org/10.1145/3441852.3476545', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'SciA11y: Converting Scientific Papers to Accessible HTML', 'author': 'Wang, Lucy Lu and Cachola, Isabel and Bragg, Jonathan and Cheng, Evie Yu-Yen and Haupt, Chelsea and Latzke, Matt and Kuehl, Bailey and van Zuylen, Madeleine N and Wagner, Linda and Weld, Daniel', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476545'}"
See-Through Captions: Real-Time Captioning on Transparent Display for Deaf and Hard-of-Hearing People,10.1145/3441852.3476551,"Real-time captioning is a useful technique for deaf and hard-of-hearing (DHH) people to talk to hearing people. With the improvement in device performance and the accuracy of automatic speech recognition (ASR), real-time captioning is becoming an important tool for helping DHH people in their daily lives. To realize higher-quality communication and overcome the limitations of mobile and augmented-reality devices, real-time captioning that can be used comfortably while maintaining nonverbal communication and preventing incorrect recognition is required. Therefore, we propose a real-time captioning system that uses a transparent display. In this system, the captions are presented on both sides of the display to address the problem of incorrect ASR results, and the highly transparent display makes it possible to see both the body language and the captions.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Deaf and Hard-of-Hearing, Real-Time Captioning, Transparent Display', 'numpages': '4', 'articleno': '86', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Real-time captioning is a useful technique for deaf and hard-of-hearing (DHH) people to talk to hearing people. With the improvement in device performance and the accuracy of automatic speech recognition (ASR), real-time captioning is becoming an important tool for helping DHH people in their daily lives. To realize higher-quality communication and overcome the limitations of mobile and augmented-reality devices, real-time captioning that can be used comfortably while maintaining nonverbal communication and preventing incorrect recognition is required. Therefore, we propose a real-time captioning system that uses a transparent display. In this system, the captions are presented on both sides of the display to address the problem of incorrect ASR results, and the highly transparent display makes it possible to see both the body language and the captions.', 'doi': '10.1145/3441852.3476551', 'url': 'https://doi.org/10.1145/3441852.3476551', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'See-Through Captions: Real-Time Captioning on Transparent Display for Deaf and Hard-of-Hearing People', 'author': 'Yamamoto, Kenta and Suzuki, Ippei and Shitara, Akihisa and Ochiai, Yoichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476551'}"
"Sidewalk Gallery: An Interactive, Filterable Image Gallery of Over 500,000 Sidewalk Accessibility Problems",10.1145/3441852.3476542,"What do sidewalk accessibility problems look like? How might these problems differ across cities? In this poster paper, we introduce Sidewalk Gallery, an interactive, filterable gallery of over 500,000 crowdsourced sidewalk accessibility images across seven cities in two countries (US and Mexico). Gallery allows users to explore and interactively filter sidewalk images based on five primary accessibility problem types, 35 tag categories, and a 5-point severity scale. When browsing images, users can also provide feedback about data correctness. We envision Gallery as a tool for teaching in urban design and accessibility and as a visualization aid for disability advocacy.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Mobility, crowdsourcing, disability, open data, sidewalks', 'numpages': '5', 'articleno': '87', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'What do sidewalk accessibility problems look like? How might these problems differ across cities? In this poster paper, we introduce Sidewalk Gallery, an interactive, filterable gallery of over 500,000 crowdsourced sidewalk accessibility images across seven cities in two countries (US and Mexico). Gallery allows users to explore and interactively filter sidewalk images based on five primary accessibility problem types, 35 tag categories, and a 5-point severity scale. When browsing images, users can also provide feedback about data correctness. We envision Gallery as a tool for teaching in urban design and accessibility and as a visualization aid for disability advocacy.', 'doi': '10.1145/3441852.3476542', 'url': 'https://doi.org/10.1145/3441852.3476542', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Sidewalk Gallery: An Interactive, Filterable Image Gallery of Over 500,000 Sidewalk Accessibility Problems', 'author': 'Duan, Michael and Kumar, Aroosh and Saugstad, Michael and Zeng, Aileen and Savin, Ilia and E. Froehlich, Jon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476542'}"
Social Haptic Communication mimicked with vibrotactile patterns - an evaluation by users with deafblindness,10.1145/3441852.3476528,"Many devices, such as smart phones, implement vibration motors for tactile feedback. When multiple vibration motors are placed on, for instance, the backrest of a chair it is possible to trace shapes on the back of a person by sequentially switching motors on and off. Social Haptic Communication (SHC) is a tactile mode of communication for persons with deafblindness that makes use of tracing shapes or other types of spatiotemporal patterns with the hand on the back of another person. This could be emulated using vibrotactile patterns. Here we investigated whether SHC users with deafblindness would recognize the vibrotactile patterns as SHC signs (Haptices). In several cases the participants immediately linked a vibrotactile patterns to the Haptice that is was meant to imitate. Together with the participants we improved and expanded the set of vibrotactile patterns.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Social Haptic Communication (SHC), co-design, users with deafblindness, vibratory patterns', 'numpages': '3', 'articleno': '88', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many devices, such as smart phones, implement vibration motors for tactile feedback. When multiple vibration motors are placed on, for instance, the backrest of a chair it is possible to trace shapes on the back of a person by sequentially switching motors on and off. Social Haptic Communication (SHC) is a tactile mode of communication for persons with deafblindness that makes use of tracing shapes or other types of spatiotemporal patterns with the hand on the back of another person. This could be emulated using vibrotactile patterns. Here we investigated whether SHC users with deafblindness would recognize the vibrotactile patterns as SHC signs (Haptices). In several cases the participants immediately linked a vibrotactile patterns to the Haptice that is was meant to imitate. Together with the participants we improved and expanded the set of vibrotactile patterns.', 'doi': '10.1145/3441852.3476528', 'url': 'https://doi.org/10.1145/3441852.3476528', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Social Haptic Communication mimicked with vibrotactile patterns - an evaluation by users with deafblindness', 'author': 'Plaisier, Myrthe and Kappers, Astrid', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476528'}"
Sound Cells: Rendering Visual and Braille Music in the Browser,10.1145/3441852.3476555,"Many blind musicians and composers read and write music using braille. Yet, braille music is not as widely available as print (visual) music, sighted collaborators and educators do not read braille music, and workflows and toolchains for converting between print and braille music are complex. In this research, we present Sound Cells, a music notation system that simultaneously outputs visual and braille notation, and provides audio feedback as a user writes music with text. We share findings from a Design Probe in which two experienced blind musicians notated music using Sound Cells and reflected on it in the context of their current notation practices. Finally, we highlight music navigation and outputted score customization as opportunities for further study.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, braille, music notation, music technology, visual impairments', 'numpages': '4', 'articleno': '89', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Many blind musicians and composers read and write music using braille. Yet, braille music is not as widely available as print (visual) music, sighted collaborators and educators do not read braille music, and workflows and toolchains for converting between print and braille music are complex. In this research, we present Sound Cells, a music notation system that simultaneously outputs visual and braille notation, and provides audio feedback as a user writes music with text. We share findings from a Design Probe in which two experienced blind musicians notated music using Sound Cells and reflected on it in the context of their current notation practices. Finally, we highlight music navigation and outputted score customization as opportunities for further study.', 'doi': '10.1145/3441852.3476555', 'url': 'https://doi.org/10.1145/3441852.3476555', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Sound Cells: Rendering Visual and Braille Music in the Browser', 'author': 'Ahmed, Fabiha and Kuzminer, Dennis and Zachor, Michael and Ye, Lisa and Josepho, Rachel and Payne, William Christopher and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476555'}"
SynSLaG: Synthetic Sign Language Generator,10.1145/3441852.3476519,"Machine learning techniques have the potential to play an important role in sign language recognition. However, sign language datasets lack the volume and variety necessary to work well. To enlarge these datasets, we introduce SynSLaG, a tool that synthetically generates sign language datasets from 3D motion capture data. SynSLaG generates realistic images of various body shapes with ground truth 2D/3D poses, depth maps, body-part segmentations, optical flows, and surface normals. The large synthetic datasets provide possibilities for advancing sign language recognition and analysis.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Database, Sign language, Synthetic data generator', 'numpages': '4', 'articleno': '90', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Machine learning techniques have the potential to play an important role in sign language recognition. However, sign language datasets lack the volume and variety necessary to work well. To enlarge these datasets, we introduce SynSLaG, a tool that synthetically generates sign language datasets from 3D motion capture data. SynSLaG generates realistic images of various body shapes with ground truth 2D/3D poses, depth maps, body-part segmentations, optical flows, and surface normals. The large synthetic datasets provide possibilities for advancing sign language recognition and analysis.', 'doi': '10.1145/3441852.3476519', 'url': 'https://doi.org/10.1145/3441852.3476519', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'SynSLaG: Synthetic Sign Language Generator', 'author': 'Miura, Teppei and Sako, Shinji', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476519'}"
Towards a Secured and Safe Online Social Media Design Framework for People with Intellectual Disability,10.1145/3441852.3476540,"This paper aims to create a tangible design framework for practitioners to follow when designing an online social media platform for individuals with intellectual disability. Currently, legislation and best practice consider cyber security and safety for the general public, giving particular attention to the protection of children. However, despite the support in health care, financial assistance, and education, individuals with intellectual disability are rarely considered when it comes to cybersafety. To achieve inclusivity, an integrative review was conducted to make connections between disciplines of education and information technology and law. The process was split into three phases: (i) understanding the challenges those with intellectual disability face, both when using a social media interface and when evaluating safety risks; (ii) identifying gaps and understanding the implications for persons with intellectual disability from legislative and design and design principles; and (iii) visualisation of data flow to model interactions. In conclusion, an inclusive framework is proposed for practitioners when designing online social media platforms for people with intellectual disability.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Framework development, intellectual disability, online social media (OSM)', 'numpages': '4', 'articleno': '91', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This paper aims to create a tangible design framework for practitioners to follow when designing an online social media platform for individuals with intellectual disability. Currently, legislation and best practice consider cyber security and safety for the general public, giving particular attention to the protection of children. However, despite the support in health care, financial assistance, and education, individuals with intellectual disability are rarely considered when it comes to cybersafety. To achieve inclusivity, an integrative review was conducted to make connections between disciplines of education and information technology and law. The process was split into three phases: (i) understanding the challenges those with intellectual disability face, both when using a social media interface and when evaluating safety risks; (ii) identifying gaps and understanding the implications for persons with intellectual disability from legislative and design and design principles; and (iii) visualisation of data flow to model interactions. In conclusion, an inclusive framework is proposed for practitioners when designing online social media platforms for people with intellectual disability.', 'doi': '10.1145/3441852.3476540', 'url': 'https://doi.org/10.1145/3441852.3476540', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Towards a Secured and Safe Online Social Media Design Framework for People with Intellectual Disability', 'author': 'Chang, Ya-Wen and Sitbon, Laurianne and Simpson, Leonie', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476540'}"
Towards Using Live Photos to Mitigate Image Quality Issues In VQA Photography,10.1145/3441852.3476541,"Studies show Visual Question Answering (VQA) systems are valuable tools for people with visual impairments to quickly obtain information from an image. In this poster, we present our ongoing work towards developing uses of live photos to mitigate quality issues in photography from people with visual impairments for VQA. New contributions building on our prior research include an expanded live photos dataset, a more in-depth analysis of VQA results, and an analysis of features of our live photos compared with existing data collected from people with visual impairments. We show that live photos are a promising method for improving accuracy of VQA and that our sample live photos mimic the types of images taken in real-world settings by people with visual impairments for the task of VQA.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Computer Vision, Image Quality, Visual Question Answering', 'numpages': '3', 'articleno': '92', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Studies show Visual Question Answering (VQA) systems are valuable tools for people with visual impairments to quickly obtain information from an image. In this poster, we present our ongoing work towards developing uses of live photos to mitigate quality issues in photography from people with visual impairments for VQA. New contributions building on our prior research include an expanded live photos dataset, a more in-depth analysis of VQA results, and an analysis of features of our live photos compared with existing data collected from people with visual impairments. We show that live photos are a promising method for improving accuracy of VQA and that our sample live photos mimic the types of images taken in real-world settings by people with visual impairments for the task of VQA.', 'doi': '10.1145/3441852.3476541', 'url': 'https://doi.org/10.1145/3441852.3476541', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Towards Using Live Photos to Mitigate Image Quality Issues In VQA Photography', 'author': 'Olson, Lauren and Kambhamettu, Chandra and McCoy, Kathleen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476541'}"
Uncovering Patterns in Reviewers’ Feedback to Scene Description Authors,10.1145/3441852.3476550,"Audio descriptions (ADs) can increase access to videos for blind people. Researchers have explored different mechanisms for generating ADs, with some of the most recent studies involving paid novices; to improve the quality of their ADs, novices receive feedback from reviewers. However, reviewer feedback is not instantaneous. To explore the potential for real-time feedback through automation, in this paper, we analyze 1,120 comments that 40 sighted novices received from a sighted or a blind reviewer. We find that feedback patterns tend to fall under four themes: (i) Quality; commenting on different AD quality variables, (ii) Speech Act; the utterance or speech action that the reviewers used, (iii) Required Action; the recommended action that the authors should do to improve the AD, and (iv) Guidance; the additional help that the reviewers gave to help the authors. We discuss which of these patterns could be automated within the review process as design implications for future AD collaborative authoring systems.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Audio Description, collaborative writing, video accessibility, visual impairment', 'numpages': '4', 'articleno': '93', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Audio descriptions (ADs) can increase access to videos for blind people. Researchers have explored different mechanisms for generating ADs, with some of the most recent studies involving paid novices; to improve the quality of their ADs, novices receive feedback from reviewers. However, reviewer feedback is not instantaneous. To explore the potential for real-time feedback through automation, in this paper, we analyze 1,120 comments that 40 sighted novices received from a sighted or a blind reviewer. We find that feedback patterns tend to fall under four themes: (i) Quality; commenting on different AD quality variables, (ii) Speech Act; the utterance or speech action that the reviewers used, (iii) Required Action; the recommended action that the authors should do to improve the AD, and (iv) Guidance; the additional help that the reviewers gave to help the authors. We discuss which of these patterns could be automated within the review process as design implications for future AD collaborative authoring systems.', 'doi': '10.1145/3441852.3476550', 'url': 'https://doi.org/10.1145/3441852.3476550', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Uncovering Patterns in Reviewers’ Feedback to Scene Description Authors', 'author': 'Natalie, Rosiana and Loh, Jolene and Tan, Huei Suen and Tseng, Joshua and Kacorri, Hernisa and Hara, Kotaro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476550'}"
Using Games to Practice Screen Reader Gestures,10.1145/3441852.3476556,"Smartphones are shipped with built-in screen readers and other accessibility features that enable blind people to autonomously learn and interact with the device. However, the process is not seamless, and many face difficulties in the adoption and path to becoming more experienced users. In the past, games like Minesweeper served to introduce and train people in the use of the mouse, from its left and right click to precision pointing required to play the game. Smartphone gestures (and particularly screen reader gestures) pose similar challenges to the ones first faced by mouse users. In this work, we explore the use of games to inconspicuously train gestures. We designed and developed a set of accessible games, enabling users to practice smartphone gestures. We evaluated the games with 8 blind users and conducted remote interviews. Our results show how purposeful accessible games could be important in the process of training and discovering smartphone gestures, as they offer a playful method of learning. This, in turn, increases autonomy and inclusion, as this process becomes easier and more engaging.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, blind, game, gestures, screen reader, smartphone', 'numpages': '4', 'articleno': '94', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Smartphones are shipped with built-in screen readers and other accessibility features that enable blind people to autonomously learn and interact with the device. However, the process is not seamless, and many face difficulties in the adoption and path to becoming more experienced users. In the past, games like Minesweeper served to introduce and train people in the use of the mouse, from its left and right click to precision pointing required to play the game. Smartphone gestures (and particularly screen reader gestures) pose similar challenges to the ones first faced by mouse users. In this work, we explore the use of games to inconspicuously train gestures. We designed and developed a set of accessible games, enabling users to practice smartphone gestures. We evaluated the games with 8 blind users and conducted remote interviews. Our results show how purposeful accessible games could be important in the process of training and discovering smartphone gestures, as they offer a playful method of learning. This, in turn, increases autonomy and inclusion, as this process becomes easier and more engaging.', 'doi': '10.1145/3441852.3476556', 'url': 'https://doi.org/10.1145/3441852.3476556', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Using Games to Practice Screen Reader Gestures', 'author': ""Lobo, Gon\\c{c}alo Ferreira and Gon\\c{c}alves, David and Pais, Pedro and Guerreiro, Tiago and Rodrigues, Andr\\'{e}"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476556'}"
Visionary Caption: Improving the Accessibility of Presentation Slides Through Highlighting Visualization,10.1145/3441852.3476539,"Presentation slides are widely used in occasions such as academic talks and business meetings. Captions placed on slides support deaf and hard of hearing (DHH) people to understand spoken contents, but simultaneously comprehending and associating visual contents on slides and caption text could be challenging. In this paper, we design and develop a visualization technique to highlight and associate chart on a slide and numerical data in caption. We first conduct a small formative study with people with and without hearing impairments to assess the value of the visualization technique using a lo-fidelity video prototype. We then develop Visionary Caption, a visualization technique that uses natural language processing to automatically highlight visual content and numerical phrases, and show the association between them. We present a scenario and personas to showcase the potential utility of Visionary Caption and guide its future development.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, deaf and hard of hearing, information visualization', 'numpages': '4', 'articleno': '95', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Presentation slides are widely used in occasions such as academic talks and business meetings. Captions placed on slides support deaf and hard of hearing (DHH) people to understand spoken contents, but simultaneously comprehending and associating visual contents on slides and caption text could be challenging. In this paper, we design and develop a visualization technique to highlight and associate chart on a slide and numerical data in caption. We first conduct a small formative study with people with and without hearing impairments to assess the value of the visualization technique using a lo-fidelity video prototype. We then develop Visionary Caption, a visualization technique that uses natural language processing to automatically highlight visual content and numerical phrases, and show the association between them. We present a scenario and personas to showcase the potential utility of Visionary Caption and guide its future development.', 'doi': '10.1145/3441852.3476539', 'url': 'https://doi.org/10.1145/3441852.3476539', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Visionary Caption: Improving the Accessibility of Presentation Slides Through Highlighting Visualization', 'author': 'Yip, Carmen and Chong, Jie Mi and kwek, sin yee and Wang, Yong and Hara, Kotaro', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476539'}"
"Walker - An Autonomous, Interactive Walking Aid",10.1145/3441852.3476552,"In this paper, we describe ongoing work about a robotic walker-frame that was designed to aid patients in an orthopaedic rehabilitation clinic. The so-called Walker is able to autonomously drive to patients and then changes into a more traditional walking-frame, i.e. one that has to be pushed by the patient, but it can still help by giving navigation instructions. Walker was designed with a multi-modal user interface in such a way that it can also be used by visually, hearing or speaking impaired people.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'assistance robots, hardware design, human-robot interaction, verbal and non-verbal', 'numpages': '3', 'articleno': '96', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'In this paper, we describe ongoing work about a robotic walker-frame that was designed to aid patients in an orthopaedic rehabilitation clinic. The so-called Walker is able to autonomously drive to patients and then changes into a more traditional walking-frame, i.e. one that has to be pushed by the patient, but it can still help by giving navigation instructions. Walker was designed with a multi-modal user interface in such a way that it can also be used by visually, hearing or speaking impaired people.', 'doi': '10.1145/3441852.3476552', 'url': 'https://doi.org/10.1145/3441852.3476552', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Walker - An Autonomous, Interactive Walking Aid', 'author': 'Hackbarth, Johannes and Jacob, Caspar', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476552'}"
“What just happened?”: Understanding Non-visual Watching Sports Experiences,10.1145/3441852.3476525,"Sports enhances cultural and social life by bringing individuals and communities together. While sports have a different meaning and importance depending on the culture and people, there is a long history of people watching sports. However, sports viewing can rely on visual information, and not fully accessible to People with Vision Impairments (PVI). In this paper, we present findings from interviews with 43 PVI about their experiences and attitudes toward watching sports. We report on their stories about accessibility challenges, and suggestions for future accessible technologies that could increase the accessibility of watching sports, with a focus on the information needs and modality.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Entertainment, Sports, Visual impairments', 'numpages': '3', 'articleno': '97', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Sports enhances cultural and social life by bringing individuals and communities together. While sports have a different meaning and importance depending on the culture and people, there is a long history of people watching sports. However, sports viewing can rely on visual information, and not fully accessible to People with Vision Impairments (PVI). In this paper, we present findings from interviews with 43 PVI about their experiences and attitudes toward watching sports. We report on their stories about accessibility challenges, and suggestions for future accessible technologies that could increase the accessibility of watching sports, with a focus on the information needs and modality.', 'doi': '10.1145/3441852.3476525', 'url': 'https://doi.org/10.1145/3441852.3476525', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': '“What just happened?”: Understanding Non-visual Watching Sports Experiences', 'author': 'Asakawa, Saki and Hurst, Amy', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476525'}"
”Would the smart cane benefit me?”: Perceptions of the Visually Impaired towards Smart Canes,10.1145/3441852.3476524,"The white cane is used as one of the options for mobility by people who are blind or visually impaired (BVI) but it comes with limitations like the lack of overhead detection and recognition of safety hazards. Smart canes were designed to address some of the white cane’s issues but the adoption of this technology has been minimal. We spoke with 16 BVI participants for an in-depth view on their smart cane experiences and needs. While the biggest concern was related to cost, we found that other factors like product consistency, durability, and the lack of awareness, trust, and confidence from the users all contribute to the low adoption rate of smart canes.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Accessibility, Ambient Devices/Internet of Things, Individuals with Disabilities \\&amp; Assistive Technologies', 'numpages': '3', 'articleno': '98', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'The white cane is used as one of the options for mobility by people who are blind or visually impaired (BVI) but it comes with limitations like the lack of overhead detection and recognition of safety hazards. Smart canes were designed to address some of the white cane’s issues but the adoption of this technology has been minimal. We spoke with 16 BVI participants for an in-depth view on their smart cane experiences and needs. While the biggest concern was related to cost, we found that other factors like product consistency, durability, and the lack of awareness, trust, and confidence from the users all contribute to the low adoption rate of smart canes.', 'doi': '10.1145/3441852.3476524', 'url': 'https://doi.org/10.1145/3441852.3476524', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': '”Would the smart cane benefit me?”: Perceptions of the Visually Impaired towards Smart Canes', 'author': 'Milallos, Rezylle and Tibdewal, Vinita and Wang, Yiwen and Ogueh Udegbe, Andre and Oh, Tae', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476524'}"
Word Cloud for Meeting: A Visualization System for DHH People in Online Meetings,10.1145/3441852.3476547,"Deaf and hard of hearing (DHH) people have limited access to auditory input, so they mainly receive visual information during online meetings. In recent years, the usability of a system that visualizes the ongoing topic in a conference has been confirmed, but it has not been verified in a remote conference that includes DHH people. One possible reason is that visual dispersion occurs when there are multiple sources of visual information. In this study, we introduce “Word Cloud for Meeting,” a system that generates a separate word cloud for each participant and displays it in the background of each participant’s video to visualize who is saying what. We conducted an experiment with seven DHH participants and obtained positive qualitative feedback on the ease of recognizing topic changes. However, when the topic changed in a sequence, it was found to be distracting. Additionally, we discuss the design implications for visualizing topics for DHH people in online meetings.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Deaf, Hard of Hearing, Hearing Loss, Online Meetings, Real-Time Visualization, User Study', 'numpages': '4', 'articleno': '99', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Deaf and hard of hearing (DHH) people have limited access to auditory input, so they mainly receive visual information during online meetings. In recent years, the usability of a system that visualizes the ongoing topic in a conference has been confirmed, but it has not been verified in a remote conference that includes DHH people. One possible reason is that visual dispersion occurs when there are multiple sources of visual information. In this study, we introduce “Word Cloud for Meeting,” a system that generates a separate word cloud for each participant and displays it in the background of each participant’s video to visualize who is saying what. We conducted an experiment with seven DHH participants and obtained positive qualitative feedback on the ease of recognizing topic changes. However, when the topic changed in a sequence, it was found to be distracting. Additionally, we discuss the design implications for visualizing topics for DHH people in online meetings.', 'doi': '10.1145/3441852.3476547', 'url': 'https://doi.org/10.1145/3441852.3476547', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Word Cloud for Meeting: A Visualization System for DHH People in Online Meetings', 'author': 'Iijima, Ryo and Shitara, Akihisa and Sarcar, Sayan and Ochiai, Yoichi', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476547'}"
Activity Recognition in Older Adults with Training Data from Younger Adults: Preliminary Results on in Vivo Smartwatch Sensor Data,10.1145/3441852.3476475,"Self-tracking using commodity wearables such as smartwatches can help older adults reduce sedentary behaviors and engage in physical activity. However, activity recognition applications that are typically deployed in these wearables tend to be trained on datasets that best represent younger adults. We explore how our activity recognition model, a hybrid of long short-term memory and convolutional layers, pre-trained on smartwatch data from younger adults, performs on older adult data. We report results on week-long data from two older adults collected in a preliminary study in the wild with ground-truth annotations based on activPAL, a thigh-worn sensor. We find that activity recognition for older adults remains challenging even when comparing our model’s performance to state of the art deployed models such as the Google Activity Recognition API. More so, we show that models trained on younger adults tend to perform worse on older adults.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'human activity recognition, machine learning, older adults, self tracking, seniors, smartwatches', 'numpages': '4', 'articleno': '100', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Self-tracking using commodity wearables such as smartwatches can help older adults reduce sedentary behaviors and engage in physical activity. However, activity recognition applications that are typically deployed in these wearables tend to be trained on datasets that best represent younger adults. We explore how our activity recognition model, a hybrid of long short-term memory and convolutional layers, pre-trained on smartwatch data from younger adults, performs on older adult data. We report results on week-long data from two older adults collected in a preliminary study in the wild with ground-truth annotations based on activPAL, a thigh-worn sensor. We find that activity recognition for older adults remains challenging even when comparing our model’s performance to state of the art deployed models such as the Google Activity Recognition API. More so, we show that models trained on younger adults tend to perform worse on older adults.', 'doi': '10.1145/3441852.3476475', 'url': 'https://doi.org/10.1145/3441852.3476475', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Activity Recognition in Older Adults with Training Data from Younger Adults: Preliminary Results on in Vivo Smartwatch Sensor Data', 'author': 'Fatima, Sabahat', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476475'}"
Adee: Bringing Accessibility Right Inside Design Tools,10.1145/3441852.3476478,"According to the world bank organization report, about 15 percent of the world’s population (equal to 1 billion people) experience some form of disability [3]. However, designers can easily forget to take account of disabilities such as colorblindness, as most designers are not colorblind and tools for accessibility are not integrated into design tools. In this work, we introduce and evaluate Adee, an accessibility testing tool that has been integrated into widely used design tools Adobe XD, Figma and Sketch. Adee aims to make accessibility part of the design process, to create inclusive and ethical products.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Adee, alternative text, colorblind simulation, contrast check, touch target size, user experience and interface design', 'numpages': '4', 'articleno': '101', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'According to the world bank organization report, about 15 percent of the world’s population (equal to 1 billion people) experience some form of disability [3]. However, designers can easily forget to take account of disabilities such as colorblindness, as most designers are not colorblind and tools for accessibility are not integrated into design tools. In this work, we introduce and evaluate Adee, an accessibility testing tool that has been integrated into widely used design tools Adobe XD, Figma and Sketch. Adee aims to make accessibility part of the design process, to create inclusive and ethical products.', 'doi': '10.1145/3441852.3476478', 'url': 'https://doi.org/10.1145/3441852.3476478', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Adee: Bringing Accessibility Right Inside Design Tools', 'author': 'Hadadi, Samine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476478'}"
Auditory feedback to compensate audible instructions to support people with visual impairment,10.1145/3441852.3476477,"This work focuses on the use of adaptive sound feedback on mobile devices in mobility contexts characterized by external noise. The noise masks the device feedback, degrading the information it contains and preventing it from being fully perceived and understood. This leads to errors in the interaction with the device or requires the feedback to be repeated. Therefore compensation techniques are necessary in order to make the provided feedback audible and thus make the interaction with the device easier. As an initial research task, we experimented with compensation techniques on verbal information. Preliminary results indicate that increase in volume or adaptive equalization can improve the percentage of information understood without altering the intrusiveness of the compensated verbal instructions. Currently we are exploring similar compensation techniques for audio feedback based on sonification in order to make the information provided by modulating sound properties more understandable in a noisy context and thus enable reliable interaction with the user. For example, it would be desirable to apply effective compensations to instructions provided through sonification by turn-by-turn navigation assistants for people with visual impairments in order to make the navigation feasible in mobility contexts characterized by background noise.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'Audible Instructions, Sound Compensation, Visual Impairment', 'numpages': '3', 'articleno': '102', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'This work focuses on the use of adaptive sound feedback on mobile devices in mobility contexts characterized by external noise. The noise masks the device feedback, degrading the information it contains and preventing it from being fully perceived and understood. This leads to errors in the interaction with the device or requires the feedback to be repeated. Therefore compensation techniques are necessary in order to make the provided feedback audible and thus make the interaction with the device easier. As an initial research task, we experimented with compensation techniques on verbal information. Preliminary results indicate that increase in volume or adaptive equalization can improve the percentage of information understood without altering the intrusiveness of the compensated verbal instructions. Currently we are exploring similar compensation techniques for audio feedback based on sonification in order to make the information provided by modulating sound properties more understandable in a noisy context and thus enable reliable interaction with the user. For example, it would be desirable to apply effective compensations to instructions provided through sonification by turn-by-turn navigation assistants for people with visual impairments in order to make the navigation feasible in mobility contexts characterized by background noise.', 'doi': '10.1145/3441852.3476477', 'url': 'https://doi.org/10.1145/3441852.3476477', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Auditory feedback to compensate audible instructions to support people with visual impairment', 'author': 'Galimberti, Gabriele', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476477'}"
Measuring Text Comprehension for People with Reading Difficulties Using a Mobile Application,10.1145/3441852.3476474,"Measuring text comprehension is crucial for evaluating the accessibility of texts in Easy Language. However, accurate and objective comprehension tests tend to be expensive, time-consuming and sometimes difficult to implement for target groups of Easy Language. In this paper, we propose using computer-based testing with touchscreen devices as a means to simplify and accelerate data collection using comprehension tests, and to facilitate experiments with less proficient readers. We demonstrate this by designing and implementing a mobile touchscreen application and validating its effectiveness in an experiment with people with intellectual disabilities. The results suggest that there is no difference in terms of task difficulty between measuring comprehension using the mobile application and a traditional paper-and-pencil test. Moreover, reading times appear to be faster in the application than on paper.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'accessibility, comprehension assessment, easy-to-read, intellectual disabilities, readability', 'numpages': '4', 'articleno': '103', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Measuring text comprehension is crucial for evaluating the accessibility of texts in Easy Language. However, accurate and objective comprehension tests tend to be expensive, time-consuming and sometimes difficult to implement for target groups of Easy Language. In this paper, we propose using computer-based testing with touchscreen devices as a means to simplify and accelerate data collection using comprehension tests, and to facilitate experiments with less proficient readers. We demonstrate this by designing and implementing a mobile touchscreen application and validating its effectiveness in an experiment with people with intellectual disabilities. The results suggest that there is no difference in terms of task difficulty between measuring comprehension using the mobile application and a traditional paper-and-pencil test. Moreover, reading times appear to be faster in the application than on paper.', 'doi': '10.1145/3441852.3476474', 'url': 'https://doi.org/10.1145/3441852.3476474', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Measuring Text Comprehension for People with Reading Difficulties Using a Mobile Application', 'author': 'S\\""{a}uberli, Andreas', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476474'}"
Voice Creator: Giving Customized Voice to the Voiceless for Online Communication,10.1145/3441852.3476476,"Voice plays an important role in online communications by increasing intimacy among people. Despite the advantages of using voice in computer-mediated communications (CMC), it is difficult for people with speech or hearing impairments to participate in such communication methods. In this study, we investigate different attributes of voices and how it affects users’ preference. We also deployed a website called ‘Voice Creator’ for people who want to create an online voice by specifying the levels of different voice attributes: gender, age group, breathiness, smoothness, hoarseness, and variation. We plan to conduct a user study on the target users and study the behavior of voice customization in future work.","{'series': ""ASSETS '21"", 'location': 'Virtual Event, USA', 'keywords': 'computer mediated communication, hearing impairment, speaking impairment, voice customization', 'numpages': '3', 'articleno': '104', 'booktitle': 'Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility', 'abstract': 'Voice plays an important role in online communications by increasing intimacy among people. Despite the advantages of using voice in computer-mediated communications (CMC), it is difficult for people with speech or hearing impairments to participate in such communication methods. In this study, we investigate different attributes of voices and how it affects users’ preference. We also deployed a website called ‘Voice Creator’ for people who want to create an online voice by specifying the levels of different voice attributes: gender, age group, breathiness, smoothness, hoarseness, and variation. We plan to conduct a user study on the target users and study the behavior of voice customization in future work.', 'doi': '10.1145/3441852.3476476', 'url': 'https://doi.org/10.1145/3441852.3476476', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450383066', 'year': '2021', 'title': 'Voice Creator: Giving Customized Voice to the Voiceless for Online Communication', 'author': 'Byeon, Hyeon Jeong', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3441852.3476476'}"